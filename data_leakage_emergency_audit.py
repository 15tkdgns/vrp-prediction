"""
ê¸´ê¸‰ ë°ì´í„° ëˆ„ì¶œ ê°ì‚¬ ì‹œìŠ¤í…œ

ë†’ì€ RÂ² ì„±ëŠ¥ ëª¨ë¸ë“¤ì˜ ë°ì´í„° ëˆ„ì¶œ ì—¬ë¶€ë¥¼ ì² ì €íˆ ê²€ì¦
"""

import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

try:
    from sklearn.linear_model import Ridge
    from sklearn.metrics import r2_score
    from sklearn.model_selection import TimeSeriesSplit
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False


def analyze_target_leakage():
    """íƒ€ê²Ÿ ë³€ìˆ˜ì˜ ë°ì´í„° ëˆ„ì¶œ ë¶„ì„"""
    print("ğŸš¨ ê¸´ê¸‰ ë°ì´í„° ëˆ„ì¶œ ê°ì‚¬ ì‹œì‘")
    print("=" * 60)

    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„± (ì‹¤ì œì™€ ë™ì¼í•œ íŒ¨í„´)
    np.random.seed(42)
    n_samples = 1000
    returns = np.random.normal(0.0005, 0.02, n_samples)

    print("\nğŸ” 1ë‹¨ê³„: íƒ€ê²Ÿ ë³€ìˆ˜ ëˆ„ì¶œ íŒ¨í„´ ë¶„ì„")
    print("-" * 50)

    # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íƒ€ê²Ÿë“¤ ë¶„ì„
    suspicious_targets = {}

    # 1. target_momentum_5d ë¶„ì„ (ê°€ì¥ ë†’ì€ ì„±ëŠ¥)
    print("\nğŸ“Š target_momentum_5d ë¶„ì„:")

    # íŠ¹ì„±: í˜„ì¬ ì‹œì ì˜ 5ì¼ ëª¨ë©˜í…€
    current_momentum_5d = pd.Series(returns).rolling(5).mean()

    # íƒ€ê²Ÿ: ë‹¤ìŒ ì‹œì ì˜ 5ì¼ ëª¨ë©˜í…€
    target_momentum_5d = pd.Series(returns).rolling(5).mean().shift(-1)

    # ê²¹ì¹˜ëŠ” ê¸°ê°„ ë¶„ì„
    print("   í˜„ì¬ 5ì¼ ëª¨ë©˜í…€: (t-4, t-3, t-2, t-1, t)ì˜ í‰ê· ")
    print("   ë‹¤ìŒ 5ì¼ ëª¨ë©˜í…€: (t-3, t-2, t-1, t, t+1)ì˜ í‰ê· ")
    print("   ğŸš¨ 4ì¼ê°„ ë°ì´í„° ê²¹ì¹¨ (80% ì¤‘ë³µ!)")

    # ìƒê´€ê´€ê³„ ê³„ì‚°
    mask = ~(np.isnan(current_momentum_5d) | np.isnan(target_momentum_5d))
    correlation = np.corrcoef(
        current_momentum_5d[mask],
        target_momentum_5d[mask]
    )[0, 1]

    print(f"   ìƒê´€ê³„ìˆ˜: {correlation:.4f}")

    if correlation > 0.8:
        print("   ğŸš¨ ìœ„í—˜: ë§¤ìš° ë†’ì€ ìƒê´€ê´€ê³„ (ë°ì´í„° ëˆ„ì¶œ í™•ì‹¤)")
        leakage_severity = "CRITICAL"
    elif correlation > 0.5:
        print("   âš ï¸ ê²½ê³ : ë†’ì€ ìƒê´€ê´€ê³„ (ëˆ„ì¶œ ê°€ëŠ¥ì„±)")
        leakage_severity = "HIGH"
    else:
        print("   âœ… ì–‘í˜¸: ì ì • ìƒê´€ê´€ê³„")
        leakage_severity = "LOW"

    suspicious_targets['target_momentum_5d'] = {
        'correlation': correlation,
        'leakage_severity': leakage_severity,
        'overlap_ratio': 0.8,
        'description': 'í˜„ì¬ì™€ ë¯¸ë˜ 5ì¼ ëª¨ë©˜í…€ì˜ 4ì¼ ì¤‘ë³µ'
    }

    # 2. target_momentum_3d ë¶„ì„
    print("\nğŸ“Š target_momentum_3d ë¶„ì„:")

    current_momentum_3d = pd.Series(returns).rolling(3).mean()
    target_momentum_3d = pd.Series(returns).rolling(3).mean().shift(-1)

    print("   í˜„ì¬ 3ì¼ ëª¨ë©˜í…€: (t-2, t-1, t)ì˜ í‰ê· ")
    print("   ë‹¤ìŒ 3ì¼ ëª¨ë©˜í…€: (t-1, t, t+1)ì˜ í‰ê· ")
    print("   ğŸš¨ 2ì¼ê°„ ë°ì´í„° ê²¹ì¹¨ (67% ì¤‘ë³µ!)")

    mask = ~(np.isnan(current_momentum_3d) | np.isnan(target_momentum_3d))
    correlation = np.corrcoef(
        current_momentum_3d[mask],
        target_momentum_3d[mask]
    )[0, 1]

    print(f"   ìƒê´€ê³„ìˆ˜: {correlation:.4f}")

    if correlation > 0.8:
        leakage_severity = "CRITICAL"
    elif correlation > 0.5:
        leakage_severity = "HIGH"
    else:
        leakage_severity = "LOW"

    suspicious_targets['target_momentum_3d'] = {
        'correlation': correlation,
        'leakage_severity': leakage_severity,
        'overlap_ratio': 0.67,
        'description': 'í˜„ì¬ì™€ ë¯¸ë˜ 3ì¼ ëª¨ë©˜í…€ì˜ 2ì¼ ì¤‘ë³µ'
    }

    # 3. target_volatility_next ë¶„ì„
    print("\nğŸ“Š target_volatility_next ë¶„ì„:")

    current_vol = pd.Series(returns).rolling(5).std()
    target_vol = pd.Series(returns).rolling(5).std().shift(-1)

    print("   í˜„ì¬ 5ì¼ ë³€ë™ì„±: (t-4, t-3, t-2, t-1, t)ì˜ std")
    print("   ë‹¤ìŒ 5ì¼ ë³€ë™ì„±: (t-3, t-2, t-1, t, t+1)ì˜ std")
    print("   ğŸš¨ 4ì¼ê°„ ë°ì´í„° ê²¹ì¹¨ (80% ì¤‘ë³µ!)")

    mask = ~(np.isnan(current_vol) | np.isnan(target_vol))
    correlation = np.corrcoef(current_vol[mask], target_vol[mask])[0, 1]

    print(f"   ìƒê´€ê³„ìˆ˜: {correlation:.4f}")

    if correlation > 0.8:
        leakage_severity = "CRITICAL"
    elif correlation > 0.5:
        leakage_severity = "HIGH"
    else:
        leakage_severity = "LOW"

    suspicious_targets['target_volatility_next'] = {
        'correlation': correlation,
        'leakage_severity': leakage_severity,
        'overlap_ratio': 0.8,
        'description': 'í˜„ì¬ì™€ ë¯¸ë˜ ë³€ë™ì„±ì˜ 4ì¼ ì¤‘ë³µ'
    }

    print(f"\nğŸš¨ ëˆ„ì¶œ ê°ì‚¬ ê²°ê³¼ ìš”ì•½:")
    print("-" * 50)

    critical_count = 0
    high_count = 0

    for target_name, analysis in suspicious_targets.items():
        severity = analysis['leakage_severity']
        correlation = analysis['correlation']
        overlap = analysis['overlap_ratio']

        if severity == "CRITICAL":
            emoji = "ğŸš¨"
            critical_count += 1
        elif severity == "HIGH":
            emoji = "âš ï¸"
            high_count += 1
        else:
            emoji = "âœ…"

        print(f"   {emoji} {target_name}: {severity} (ìƒê´€ê´€ê³„: {correlation:.3f}, ì¤‘ë³µ: {overlap:.0%})")

    print(f"\nğŸ“Š ì „ì²´ ëˆ„ì¶œ ìƒí™©:")
    print(f"   ğŸš¨ ì‹¬ê°í•œ ëˆ„ì¶œ: {critical_count}ê°œ")
    print(f"   âš ï¸ ëˆ„ì¶œ ê°€ëŠ¥ì„±: {high_count}ê°œ")
    print(f"   âœ… ì•ˆì „í•œ íƒ€ê²Ÿ: {len(suspicious_targets) - critical_count - high_count}ê°œ")

    if critical_count > 0:
        print(f"\nğŸš¨ ê²°ë¡ : ì‹¬ê°í•œ ë°ì´í„° ëˆ„ì¶œ ë°œê²¬!")
        print(f"   RÂ² = 0.7682ëŠ” ë°ì´í„° ì¤‘ë³µìœ¼ë¡œ ì¸í•œ í—ˆìœ„ ì„±ê³¼ì…ë‹ˆë‹¤.")

    return suspicious_targets


def test_leak_free_alternatives():
    """ëˆ„ì¶œ ì—†ëŠ” ëŒ€ì•ˆ íƒ€ê²Ÿë“¤ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ”§ 2ë‹¨ê³„: ëˆ„ì¶œ ì—†ëŠ” ëŒ€ì•ˆ íƒ€ê²Ÿ ê°œë°œ")
    print("-" * 50)

    # ë°ì´í„° ìƒì„±
    np.random.seed(42)
    n_samples = 800

    # ë” í˜„ì‹¤ì ì¸ ê¸ˆìœµ ë°ì´í„°
    returns = np.zeros(n_samples)
    for i in range(1, n_samples):
        # ì•½í•œ í‰ê· íšŒê·€ + ë…¸ì´ì¦ˆ
        returns[i] = -0.05 * returns[i-1] + np.random.normal(0, 0.02)

    # ëˆ„ì¶œ ì—†ëŠ” íŠ¹ì„± ìƒì„±
    features = pd.DataFrame()

    # ê³¼ê±° ì •ë³´ë§Œ ì‚¬ìš© (ì•ˆì „í•œ íŠ¹ì„±ë“¤)
    for lag in [1, 2, 3, 5]:
        features[f'returns_lag_{lag}'] = pd.Series(returns).shift(lag)

    for window in [5, 10, 20]:
        features[f'ma_{window}'] = pd.Series(returns).rolling(window).mean()
        features[f'std_{window}'] = pd.Series(returns).rolling(window).std()

    # Z-score (í‰ê· íšŒê·€ ì‹ í˜¸)
    ma_20 = pd.Series(returns).rolling(20).mean()
    std_20 = pd.Series(returns).rolling(20).std()
    features['zscore_20'] = (pd.Series(returns) - ma_20) / std_20

    # ëª¨ë©˜í…€ (ê³¼ê±°ë§Œ)
    features['momentum_5d'] = pd.Series(returns).rolling(5).sum()

    # ë³€ë™ì„± ë¹„ìœ¨
    vol_5 = pd.Series(returns).rolling(5).std()
    vol_20 = pd.Series(returns).rolling(20).std()
    features['vol_ratio'] = vol_5 / (vol_20 + 1e-8)

    print("âœ… ëˆ„ì¶œ ì—†ëŠ” íŠ¹ì„± ìƒì„± ì™„ë£Œ")

    # ëˆ„ì¶œ ì—†ëŠ” ëŒ€ì•ˆ íƒ€ê²Ÿë“¤
    leak_free_targets = {}

    # 1. ë‹¨ìˆœ ë‹¤ìŒë‚  ìˆ˜ìµë¥  (ê¸°ë³¸)
    leak_free_targets['next_day_return'] = pd.Series(returns).shift(-1)

    # 2. ë‹¤ìŒ 3ì¼ ìˆ˜ìµë¥  í•© (ì¤‘ë³µ ì—†ìŒ)
    leak_free_targets['next_3d_sum'] = pd.Series(returns).shift(-1).rolling(3).sum()

    # 3. ë°©í–¥ ì˜ˆì¸¡ (ì´ì§„)
    leak_free_targets['direction_next'] = (pd.Series(returns).shift(-1) > 0).astype(int)

    # 4. í‰ê· íšŒê·€ íƒ€ê²Ÿ (ê³¼ë„í•œ í¸ì°¨ í›„ ë°˜ì „)
    deviation = pd.Series(returns) - ma_20
    leak_free_targets['reversion_signal'] = -deviation.shift(-1)  # ë°˜ì „ ì˜ˆì¸¡

    # 5. ë³€ë™ì„± ì˜ˆì¸¡ (ì¤‘ë³µ ì—†ëŠ” ë²„ì „)
    # í˜„ì¬ ì‹œì  ë³€ë™ì„± vs ë¯¸ë˜ ì™„ì „ ìƒˆë¡œìš´ ê¸°ê°„ ë³€ë™ì„±
    future_vol_no_overlap = pd.Series(returns).shift(-6).rolling(5).std()  # 6ì¼ í›„ë¶€í„° 5ì¼ê°„
    leak_free_targets['vol_prediction_safe'] = future_vol_no_overlap

    print(f"âœ… ëˆ„ì¶œ ì—†ëŠ” íƒ€ê²Ÿ {len(leak_free_targets)}ê°œ ìƒì„±")

    # ê° íƒ€ê²Ÿë³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ“Š ëˆ„ì¶œ ì—†ëŠ” íƒ€ê²Ÿ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸:")
    print("-" * 40)

    features = features.dropna()

    results = {}

    for target_name, target_series in leak_free_targets.items():
        # ì¸ë±ìŠ¤ ë§ì¶¤
        target_clean = target_series.dropna()
        common_index = features.index.intersection(target_clean.index)

        if len(common_index) < 100:  # ë°ì´í„° ë¶€ì¡±ì‹œ ìŠ¤í‚µ
            print(f"   {target_name:<25} ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ìŠ¤í‚µ")
            continue

        features_aligned = features.loc[common_index]
        target_aligned = target_clean.loc[common_index]

        # ê°„ë‹¨í•œ Ridge ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
        model = Ridge(alpha=1.0)
        scaler = StandardScaler()

        # ì‹œê³„ì—´ ë¶„í• 
        tscv = TimeSeriesSplit(n_splits=3)
        cv_scores = []

        for train_idx, val_idx in tscv.split(features_aligned):
            X_train = features_aligned.iloc[train_idx]
            X_val = features_aligned.iloc[val_idx]
            y_train = target_aligned.iloc[train_idx]
            y_val = target_aligned.iloc[val_idx]

            # ì •ê·œí™”
            X_train_scaled = scaler.fit_transform(X_train)
            X_val_scaled = scaler.transform(X_val)

            # í›ˆë ¨ ë° ì˜ˆì¸¡
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_val_scaled)

            score = r2_score(y_val, y_pred)
            cv_scores.append(score)

        avg_score = np.mean(cv_scores)
        std_score = np.std(cv_scores)

        results[target_name] = {
            'r2_mean': avg_score,
            'r2_std': std_score,
            'samples': len(common_index)
        }

        print(f"   {target_name:<25} RÂ² = {avg_score:.4f} (Â±{std_score:.4f})")

    # ìµœê³  ì„±ëŠ¥ ì°¾ê¸°
    if results:
        best_target = max(results.keys(), key=lambda k: results[k]['r2_mean'])
        best_score = results[best_target]['r2_mean']

        print(f"\nğŸ† ëˆ„ì¶œ ì—†ëŠ” ìµœê³  ì„±ëŠ¥:")
        print(f"   íƒ€ê²Ÿ: {best_target}")
        print(f"   RÂ² = {best_score:.4f}")

        if best_score > 0.1:
            print("   âœ… ìƒë‹¹í•œ ì˜ˆì¸¡ë ¥ ìœ ì§€")
        elif best_score > 0.05:
            print("   ğŸ“ˆ ì ì •í•œ ì˜ˆì¸¡ë ¥")
        elif best_score > 0.02:
            print("   ğŸ“Š ì•½í•œ ì˜ˆì¸¡ë ¥")
        else:
            print("   âš ï¸ ì˜ˆì¸¡ë ¥ ë¯¸í¡")

    return results


def recommend_corrective_actions():
    """ìˆ˜ì • ì¡°ì¹˜ ê¶Œì¥ì‚¬í•­"""
    print(f"\nğŸ› ï¸ 3ë‹¨ê³„: ìˆ˜ì • ì¡°ì¹˜ ê¶Œì¥ì‚¬í•­")
    print("-" * 50)

    print("ğŸ“‹ ì¦‰ì‹œ ì¡°ì¹˜ ì‚¬í•­:")
    print("   1. âŒ ê¸°ì¡´ ë†’ì€ RÂ² ëª¨ë¸ë“¤ ì¦‰ì‹œ ì‚¬ìš© ì¤‘ë‹¨")
    print("   2. ğŸ” íƒ€ê²Ÿ ë³€ìˆ˜ ì¬ì„¤ê³„ (ì¤‘ë³µ ì œê±°)")
    print("   3. âœ… ëˆ„ì¶œ ì—†ëŠ” ëŒ€ì•ˆ ëª¨ë¸ ê°œë°œ")
    print("   4. ğŸ“Š ì„±ëŠ¥ ê¸°ëŒ€ì¹˜ í˜„ì‹¤ì  ì¡°ì •")

    print(f"\nğŸ¯ ê¶Œì¥ ëŒ€ì•ˆ ì „ëµ:")

    strategies = [
        {
            'name': 'ë‹¨ìˆœ ë°©í–¥ ì˜ˆì¸¡',
            'target': 'ë‹¤ìŒë‚  ìƒìŠ¹/í•˜ë½',
            'expected_accuracy': '55-60%',
            'pros': 'ë°ì´í„° ëˆ„ì¶œ ì—†ìŒ, ë‹¨ìˆœí•¨',
            'cons': 'ë‚®ì€ ì˜ˆì¸¡ë ¥',
            'r2_range': 'N/A (ë¶„ë¥˜)'
        },
        {
            'name': 'í‰ê· íšŒê·€ ì‹ í˜¸',
            'target': 'ê³¼ë„í•œ í¸ì°¨ í›„ ë°˜ì „',
            'expected_accuracy': '52-57%',
            'pros': 'ì´ë¡ ì  ê·¼ê±°, ì•ˆì „í•¨',
            'cons': 'ì•½í•œ ì‹ í˜¸',
            'r2_range': '0.01-0.05'
        },
        {
            'name': 'ì§§ì€ ê¸°ê°„ ìˆ˜ìµë¥ ',
            'target': 'ë‹¤ìŒ 1-2ì¼ ìˆ˜ìµë¥ ',
            'expected_accuracy': 'RÂ² 0.01-0.05',
            'pros': 'ì§ì ‘ì , ì¤‘ë³µ ìµœì†Œ',
            'cons': 'ë…¸ì´ì¦ˆ ë§ìŒ',
            'r2_range': '0.005-0.03'
        },
        {
            'name': 'ë³€ë™ì„± ì˜ˆì¸¡ (ìˆ˜ì •)',
            'target': 'ë¯¸ë˜ ìƒˆë¡œìš´ ê¸°ê°„ ë³€ë™ì„±',
            'expected_accuracy': 'RÂ² 0.05-0.15',
            'pros': 'ìƒëŒ€ì  ì˜ˆì¸¡ ê°€ëŠ¥',
            'cons': 'ë³µì¡ì„±',
            'r2_range': '0.03-0.12'
        }
    ]

    for i, strategy in enumerate(strategies, 1):
        print(f"\n   {i}. {strategy['name']}:")
        print(f"      íƒ€ê²Ÿ: {strategy['target']}")
        print(f"      ì˜ˆìƒ ì„±ëŠ¥: {strategy['expected_accuracy']}")
        print(f"      RÂ² ë²”ìœ„: {strategy['r2_range']}")
        print(f"      ì¥ì : {strategy['pros']}")
        print(f"      ë‹¨ì : {strategy['cons']}")

    print(f"\nğŸ’¡ í˜„ì‹¤ì  ì„±ëŠ¥ ê¸°ëŒ€ì¹˜:")
    print("   â€¢ ë°©í–¥ ì˜ˆì¸¡: 52-65% (ê¸°ì¤€ì„  50%)")
    print("   â€¢ ìˆ˜ìµë¥  ì˜ˆì¸¡: RÂ² 0.005-0.10 (í˜„ì‹¤ì  ë²”ìœ„)")
    print("   â€¢ ë³€ë™ì„± ì˜ˆì¸¡: RÂ² 0.03-0.20 (ìƒëŒ€ì  ì˜ˆì¸¡ ê°€ëŠ¥)")
    print("   â€¢ ê¸°ì¡´ ì‹œìŠ¤í…œ: RÂ² -0.01~0.56 (ì‹¤ì œ ê²€ì¦ëœ ë²”ìœ„)")

    print(f"\nâš ï¸ ì¤‘ìš”í•œ êµí›ˆ:")
    print("   â€¢ ê¸ˆìœµ ì‹œì¥ì—ì„œ RÂ² > 0.3ì€ ë§¤ìš° ì˜ì‹¬ìŠ¤ëŸ¬ì›€")
    print("   â€¢ íŠ¹ì„±ê³¼ íƒ€ê²Ÿì˜ ì‹œê°„ì  ì¤‘ë³µì€ í—ˆìœ„ ì„±ê³¼ ì°½ì¶œ")
    print("   â€¢ ë‹¨ìˆœí•œ íŒ¨í„´ì¼ìˆ˜ë¡ ë°ì´í„° ëˆ„ì¶œ ìœ„í—˜ ë†’ìŒ")
    print("   â€¢ í˜„ì‹¤ì  ê¸°ëŒ€ì¹˜ ì„¤ì •ì´ ì¤‘ìš”í•¨")


if __name__ == "__main__":
    # 1. ë°ì´í„° ëˆ„ì¶œ ê°ì‚¬
    leakage_analysis = analyze_target_leakage()

    # 2. ëˆ„ì¶œ ì—†ëŠ” ëŒ€ì•ˆ í…ŒìŠ¤íŠ¸
    clean_results = test_leak_free_alternatives()

    # 3. ìˆ˜ì • ì¡°ì¹˜ ê¶Œì¥
    recommend_corrective_actions()

    print(f"\nğŸš¨ ìµœì¢… ê²°ë¡ :")
    print("   RÂ² = 0.7682ëŠ” ë°ì´í„° ì¤‘ë³µìœ¼ë¡œ ì¸í•œ í—ˆìœ„ ì„±ê³¼")
    print("   ì¦‰ì‹œ ì‚¬ìš© ì¤‘ë‹¨í•˜ê³  ëŒ€ì•ˆ ëª¨ë¸ ê°œë°œ í•„ìš”")
    print("   í˜„ì‹¤ì  ì„±ëŠ¥ ê¸°ëŒ€ì¹˜ë¡œ ì¬ì¡°ì • ê¶Œì¥")
    print("   ê¸°ì¡´ ê²€ì¦ëœ ëª¨ë¸ë“¤(RÂ² -0.01~0.56)ì´ ë” ì‹ ë¢°í•  ë§Œí•¨")