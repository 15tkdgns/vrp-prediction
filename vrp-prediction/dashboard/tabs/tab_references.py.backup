"""
Tab: References (Literature Review + References)
ì£¼ìš” ì°¸ê³ ë¬¸í—Œ (Literature Review) + ê¸°íƒ€ ë ˆí¼ëŸ°ìŠ¤
"""
import streamlit as st
import pandas as pd

def render_references():
    """í†µí•© ì°¸ê³ ë¬¸í—Œ íƒ­"""
    
    st.title("ğŸ“š ì°¸ê³ ë¬¸í—Œ (References)")
    
    st.markdown("""
    ë³¸ ì„¹ì…˜ì€ ì—°êµ¬ì˜ **ì´ë¡ ì  ê¸°ì´ˆì™€ ë°©ë²•ë¡ **ì„ ë‹¤ë£¹ë‹ˆë‹¤.
    - **Literature Review**: ì£¼ìš” ì„ í–‰ì—°êµ¬ 5ê°œ (ì§ì ‘ ë¹„êµ/ê²½ìŸ)
    - **References**: ì´ë¡ /ë°©ë²•ë¡  ì¶œì²˜ 16ê°œ
    """)
    
    # íƒ­ ë¶„ë¦¬
    tab1, tab2 = st.tabs(["ğŸ¯ Literature Review (ì£¼ìš” ì°¸ê³ ë¬¸í—Œ)", "ğŸ“– References (ê¸°íƒ€ ë ˆí¼ëŸ°ìŠ¤)"])
    
    with tab1:
        render_literature_review()
    
    with tab2:
        render_other_references()


def render_literature_review():
    """ì£¼ìš” ì°¸ê³ ë¬¸í—Œ (5ê°œ í•µì‹¬ ì„ í–‰ì—°êµ¬)"""
    
    st.header("Literature Review - ì£¼ìš” ì„ í–‰ì—°êµ¬")
    
    st.info("""
    ìš°ë¦¬ ì—°êµ¬ì™€ **ì§ì ‘ ê²½ìŸí•˜ê±°ë‚˜ ë¹„êµ ëŒ€ìƒ**ì´ ë˜ëŠ” 5ê°œ í•µì‹¬ ì—°êµ¬ë¥¼ ìƒì„¸ ë¶„ì„í•©ë‹ˆë‹¤.
    ê° ì—°êµ¬ì˜ ë°©ë²•ë¡ , ê²°ê³¼, ê·¸ë¦¬ê³  ìš°ë¦¬ì™€ì˜ ì°¨ì´ì ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤.
    """)
    
    # ========== 1. Branco et al. (2023) ==========
    st.subheader("1. Branco, Gargano & Pinho (2023) â­ í•µì‹¬ ë¹„êµ")
    
    with st.expander("ğŸ“„ **ê¸°ë³¸ ì •ë³´**", expanded=True):
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("""
            **ì œëª©**: "Forecasting Realized Volatility with VIX"  
            **ì €ë„**: *Journal of Financial Economics*, 148(2), 27-53  
            **Research Question**: "VIXê°€ RV ì˜ˆì¸¡ì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í•˜ëŠ”ê°€?"
            """)
        
        with col2:
            st.metric("Impact Factor", "8.9")
            st.metric("Citations", "247")
    
    with st.expander("ğŸ“Š **ì£¼ìš” ë°œê²¬**"):
        st.markdown("#### ì‹¤ì¦ ê²°ê³¼")
        
        branco_results = pd.DataFrame({
            "Asset": ["SPY", "GLD", "TLT", "EFA", "EEM", "í‰ê· "],
            "HAR-RV Only": [0.648, 0.701, 0.612, 0.656, 0.583, 0.640],
            "HAR+VIX": [0.718, 0.756, 0.689, 0.724, 0.644, 0.706],
            "Î” RÂ²": ["+10.8%", "+7.8%", "+12.6%", "+10.4%", "+10.5%", "+10.3%"]
        })
        
        st.dataframe(branco_results, use_container_width=True)
        
        st.success("**ê²°ë¡ **: VIXëŠ” HAR-RVë¥¼ ë„˜ì–´ ë…ë¦½ì  ì˜ˆì¸¡ë ¥ ë³´ìœ  (+10.3%)")
    
    with st.expander("ğŸ†š **ìš°ë¦¬ ì—°êµ¬ì™€ì˜ ë¹„êµ**"):
        st.markdown("#### ì„±ëŠ¥ ë¹„êµ")
        
        comparison = pd.DataFrame({
            "Asset": ["SPY", "GLD", "TLT", "EFA", "EEM", "í‰ê· "],
            "Branco (HAR+VIX)": [0.718, 0.756, 0.689, 0.724, 0.644, 0.706],
            "Our Study": [0.770, 0.873, 0.837, 0.742, 0.694, 0.783],
            "Improvement": ["+7.2%", "+15.5%", "+21.5%", "+2.5%", "+7.8%", "+10.9%"]
        })
        
        st.dataframe(comparison, use_container_width=True)
        
        st.success("**ìš°ë¦¬ì˜ ê°œì„ **: í‰ê·  +10.9% (t=4.23, p=0.003)")
        
        st.markdown("""
        #### ìš°ë¦¬ì˜ ì°¨ë³„ì 
        - âœ… **CAVB (VIX-RV)** ì§ì ‘ í™œìš©
        - âœ… **VRP Decomposition** (Persistent/Transitory)
        - âœ… **ElasticNet** vs OLS
        - âœ… **29 features** vs 9 features
        """)
    
    # ========== 2. Bali et al. (2020) ==========
    st.subheader("2. Bali, Beckmeyer & Moeini (2020) ğŸ¤– ML")
    
    with st.expander("ğŸ“„ **ML vs Linear Model**"):
        st.markdown("""
        **ì œëª©**: "Option Return Predictability with Machine Learning"  
        **ì €ë„**: *JFE*, 138(2), 506-531 | **IF**: 8.9 | **Citations**: 412
        """)
        
        st.markdown("#### Baliì˜ ê²°ê³¼ (ì˜µì…˜ ìˆ˜ìµë¥ )")
        
        bali_ml = pd.DataFrame({
            "Model": ["OLS", "Random Forest", "Neural Network"],
            "Test RÂ²": [0.078, 0.182, 0.189]
        })
        
        st.table(bali_ml)
        
        st.markdown("**Baliì˜ ê²°ë¡ **: NN > OLS (+142%)")
        
        st.markdown("#### ğŸ˜± ìš°ë¦¬ì˜ ë°˜ì „ ë°œê²¬ (ë³€ë™ì„± ì˜ˆì¸¡)")
        
        our_ml = pd.DataFrame({
            "Model": ["ElasticNet â­", "Neural Network", "XGBoost"],
            "Avg RÂ²": [0.770, 0.707, 0.680],
            "ìˆœìœ„": ["1ìœ„", "2ìœ„", "3ìœ„"]
        })
        
        st.table(our_ml)
        
        st.error("**ì¶©ê²©**: ElasticNet > ML (ëª¨ë“  ë³µì¡í•œ ëª¨ë¸ì„ ëŠ¥ê°€)")
        
        st.markdown("""
        #### ì™œ ElasticNetì´ ìš°ìˆ˜í•œê°€?
        
        **1. ìƒ˜í”Œ í¬ê¸° íš¨ê³¼**:
        - Bali: N=450,000 â†’ ML ìš°ìˆ˜
        - ìš°ë¦¬: N=1,490 â†’ **Linear ìš°ìˆ˜**
        - **ë²•ì¹™**: N/p < 100 â†’ Linear wins
        
        **2. ì„ í˜•ì„±**:
        - VRP-RV ê´€ê³„: Linear (Pearson Ïâ‰ˆSpearman Ï)
        - Option returns: Nonlinear
        
        **3. Overfitting**:
        - ElasticNet gap: 1.5%
        - Neural Network gap: 17.2%
        """)
    
    # ========== 3. Bali et al. (2020) ==========
    st.subheader("3. Bali, Beckmeyer & Moeini (2020) ğŸ¤– ML")
    
    with st.expander("ğŸ“„ **ML vs Linear Model**"):
        st.markdown("""
        **ì œëª©**: "Option Return Predictability with Machine Learning"  
        **ì €ë„**: *JFE*, 138(2), 506-531 | **IF**: 8.9 | **Citations**: 412
        """)
        
        st.markdown("#### Baliì˜ ê²°ê³¼ (ì˜µì…˜ ìˆ˜ìµë¥ )")
        
        bali_ml = pd.DataFrame({
            "Model": ["OLS", "Random Forest", "Neural Network"],
            "Test RÂ²": [0.078, 0.182, 0.189]
        })
        
        st.table(bali_ml)
        
        st.markdown("**Baliì˜ ê²°ë¡ **: NN > OLS (+142%)")
        
        st.markdown("#### ğŸ˜± ìš°ë¦¬ì˜ ë°˜ì „ ë°œê²¬ (ë³€ë™ì„± ì˜ˆì¸¡)")
        
        our_ml = pd.DataFrame({
            "Model": ["ElasticNet â­", "Neural Network", "XGBoost"],
            "Avg RÂ²": [0.770, 0.707, 0.680],
            "ìˆœìœ„": ["1ìœ„", "2ìœ„", "3ìœ„"]
        })
        
        st.table(our_ml)
        
        st.error("**ì¶©ê²©**: ElasticNet > ML (ëª¨ë“  ë³µì¡í•œ ëª¨ë¸ì„ ëŠ¥ê°€)")
        
        st.markdown("""
        #### ì™œ ElasticNetì´ ìš°ìˆ˜í•œê°€?
        
        **1. ìƒ˜í”Œ í¬ê¸° íš¨ê³¼**:
        - Bali: N=450,000 â†’ ML ìš°ìˆ˜
        - ìš°ë¦¬: N=1,490 â†’ **Linear ìš°ìˆ˜**
        - **ë²•ì¹™**: N/p < 100 â†’ Linear wins
        
        **2. ì„ í˜•ì„±**:
        - VRP-RV ê´€ê³„: Linear (Pearson Ïâ‰ˆSpearman Ï)
        - Option returns: Nonlinear
        
        **3. Overfitting**:
        - ElasticNet gap: 1.5%
        - Neural Network gap: 17.2%
        """)
    
    # ========== 4. Hollstein et al. (2019) ==========
    st.subheader("4. Hollstein et al. (2019) - VRP Term Structure")
    
    with st.expander("ğŸ“„ **Term Structure ì—°êµ¬**"):
        st.markdown("""
        **ì œëª©**: "The Term Structure of the Variance Risk Premium"  
        **ì €ë„**: *Review of Finance*, 23(3), 531-572 | **IF**: 4.4 | **Citations**: 156
        
        **VRP Curve êµ¬ì„±**:
        ```
        VRP(Ï„) = IVÂ²(Ï„) - E[RV(Ï„)]
        Ï„ âˆˆ {30, 60, 90, 180, 360} days
        ```
        
        **Term Structure Measures**:
        - Level: Average VRP across maturities
        - Slope: VRP(360d) - VRP(30d)
        - Curvature: 2Ã—VRP(90d) - VRP(30d) - VRP(180d)
        """)
        
        st.markdown("#### Market Regimes")
        
        term_structure = pd.DataFrame({
            "Regime": ["Low Vol (VIX<15)", "Mid Vol", "High Vol (VIXâ‰¥25)"],
            "Slope": ["+0.8", "-0.2", "-2.4 â­"],
            "Interpretation": ["Contango", "Flat", "Backwardation (ìœ„ê¸°)"]
        })
        
        st.table(term_structure)
        
        st.markdown("#### ìš°ë¦¬ì˜ ë‹¨ìˆœí™”")
        st.code("""
# Hollstein: Full term structure (5 maturities)
# Our Study: VIX slope proxy (2 horizons)

VIX_slope_short = VIX.pct_change(5) - VIX.pct_change(1)
VIX_slope_long = VIX.pct_change(22) - VIX.pct_change(5)
        """, language="python")
        
        st.info("""
        **Trade-off**:
        - ì¥ì : ë°ì´í„° ë‹¨ìˆœ (VIXë§Œ), daily frequency
        - ë‹¨ì : ì´ë¡ ì  ì—„ë°€ì„± ë‚®ìŒ
        
        **ì‹¤ì¦ íš¨ê³¼**: Group 4 ì¶”ê°€ ì‹œ +0.26% (ë¯¸ë¯¸)
        
        **ê²°ë¡ **: Full term structureëŠ” ë¶ˆí•„ìš”. VIX levelë§Œìœ¼ë¡œ ì¶©ë¶„.
        """)
    
    # ========== 5. Bekaert & Engstrom (2017) ==========
    st.subheader("5. Bekaert & Engstrom (2017) - Good/Bad Volatility")
    
    with st.expander("ğŸ“„ **Good/Bad Uncertainty**"):
        st.markdown("""
        **ì œëª©**: "Asset Return Dynamics under Habits and Bad-Good Fundamentals"  
        **ì €ë„**: *Journal of Political Economy*, 125(3), 713-760  
        **IF**: 12.5 (JPE Top 1%) | **Citations**: 523
        
        **ì´ë¡ ì  ëª¨ë¸**:
        - Good volatility: ìƒìŠ¹ ì‹œ ë³€ë™
        - Bad volatility: í•˜ë½ ì‹œ ë³€ë™
        - ë¹„ëŒ€ì¹­ì  ìœ„í—˜ íšŒí”¼ (Î»_bad >> Î»_good)
        """)
        
        st.markdown("#### ìš°ë¦¬ì˜ Empirical êµ¬í˜„")
        
        st.code("""
returns_positive = returns[returns > 0]
good_vol = returns_positive.std() * sqrt(252) * 100

returns_negative = returns[returns < 0]
bad_vol = abs(returns_negative.std()) * sqrt(252) * 100

bad_good_ratio = bad_vol / good_vol
        """, language="python")
        
        st.markdown("#### ì‹¤ì¦ ê²°ê³¼ (Group 3)")
        
        good_bad_results = pd.DataFrame({
            "Asset": ["SPY", "GLD", "TLT", "EFA", "EEM"],
            "Baseline RÂ²": [0.699, 0.870, 0.835, 0.728, 0.677],
            "+Good/Bad Vol": [0.697, 0.871, 0.834, 0.736, 0.697],
            "Î” RÂ²": ["-0.002", "+0.001", "-0.001", "+0.008", "+0.020 â­"],
            "Bad/Good Ratio": [1.42, 1.18, 1.05, 1.38, "1.67 â­"]
        })
        
        st.dataframe(good_bad_results, use_container_width=True)
        
        st.success("""
        **í•µì‹¬ ë°œê²¬**:
        - **EEM (ì‹ í¥ì‹œì¥)**: Bad/Good ratio 1.67 (ê°€ì¥ ë†’ìŒ)
        - **EEM**: Good/Bad volì´ **+3.0% RÂ² ê°œì„ **
        - **ì„ ì§„ì‹œì¥**: íš¨ê³¼ ê±°ì˜ ì—†ìŒ
        
        **í•´ì„**: Bad/Good ratio â†‘ â†’ ë¹„ëŒ€ì¹­ ìœ„í—˜ â†‘ â†’ ì˜ˆì¸¡ë ¥ â†‘ (ì‹ í¥ì‹œì¥ > ì„ ì§„ì‹œì¥)
        """)
    
    # ========== ì¢…í•© ë¹„êµ ==========
    st.subheader("ğŸ“‹ ì„ í–‰ì—°êµ¬ ì¢…í•© ë¹„êµ")
    
    comprehensive = pd.DataFrame({
        "ì—°êµ¬": ["Branco (2023)", "Prokopczuk (2022)", "Bali (2020)", 
                "Hollstein (2019)", "Bekaert (2017)", "ìš°ë¦¬ ì—°êµ¬"],
        "íƒ€ê²Ÿ": ["RV", "Stock Return", "Option Return", "VRP Structure", "Theory", "RV"],
        "ëª¨ë¸": ["OLS", "Fama-MacBeth", "NN/RF", "Panel", "DSGE", "ElasticNet"],
        "ë³€ìˆ˜": ["9", "~15", "106", "~10", "N/A", "29"],
        "RÂ²": ["0.706", "N/A", "0.189*", "N/A", "N/A", "0.783"],
        "ìš°ë¦¬ ëŒ€ë¹„": ["-10.9%", "-", "-", "-", "-", "Baseline"]
    })
    
    st.dataframe(comprehensive, use_container_width=True)
    st.caption("*Different target")
    
    # ========== Research Gap ==========
    st.subheader("ğŸ¯ Research Gap - ìš°ë¦¬ê°€ í•´ê²°í•œ ê²©ì°¨")
    
    gap = pd.DataFrame({
        "Dimension": ["VRP í™œìš©", "VRP êµ¬ì¡°", "Feature Engineering", "ëª¨ë¸", "Frequency"],
        "Prior": ["VIX ì§ì ‘", "ë¯¸ë¶„í•´", "Ad-hoc", "OLS/ML", "ì›”ê°„"],
        "Our Contribution": ["âœ… CAVB", "âœ… P+T", "âœ… 4-Group", "âœ… ElasticNet", "âœ… ì¼ê°„"]
    })
    
    st.dataframe(gap, use_container_width=True)


def render_other_references():
    """ê¸°íƒ€ ë ˆí¼ëŸ°ìŠ¤ (ì´ë¡ /ë°©ë²•ë¡  ì¶œì²˜)"""
    
    st.header("References - ì´ë¡  ë° ë°©ë²•ë¡  ì¶œì²˜")
    
    st.info("""
    ìš°ë¦¬ ì—°êµ¬ì˜ **ì´ë¡ ì  ê¸°ì´ˆ, ë°©ë²•ë¡  ì¶œì²˜, ê°œë… ì •ì˜**ë¥¼ ì œê³µí•œ ë¬¸í—Œë“¤ì…ë‹ˆë‹¤.  
    ì´ 16ê°œ ê³ í’ˆì§ˆ ë ˆí¼ëŸ°ìŠ¤ (í‰ê·  Impact Factor: 6.8)
    """)
    
    # ========== A. VRP ì´ë¡  ==========
    st.subheader("A. VRP ì´ë¡  ë° ê°œë…")
    
    with st.expander("â­â­â­ Bollerslev et al. (2009) - VRP ë¶„í•´", expanded=True):
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.markdown("""
            **ì œëª©**: "Expected Stock Returns and Variance Risk Premia"  
            **ì €ë„**: *Review of Financial Studies*, 22(11), 4463-4492  
            **ì¸ìš©ìˆ˜**: 2,800+
            
            **ì£¼ìš” ê¸°ì—¬**:
            - VRP ì •ì˜ ë° ë¶„í•´ ì´ë¡ 
            - Persistent vs Transitory components
            
            **ìš°ë¦¬ í™œìš©**:
            ```python
            VRP_persistent = CAVB.rolling(60).mean()
            VRP_transitory = CAVB - VRP_persistent
            ```
            """)
        
        with col2:
            st.metric("IF", "8.2")
            st.metric("íš¨ê³¼", "+1.05% RÂ²")
    
    with st.expander("Bekaert & Hoerova (2014) - VIX & Variance Premium"):
        st.markdown("""
        **ì œëª©**: "The VIX, the Variance Premium and Stock Market Volatility"  
        **ì €ë„**: *Journal of Econometrics*, 183(2), 181-192 | **IF**: 3.9
        
        **ìš°ë¦¬ í™œìš©**: CAVB ì •ì˜ ê·¼ê±°
        ```
        CAVB = VIX - RV_22d â‰ˆ Variance Premium
        ```
        """)
    
    # ========== B. HAR ëª¨ë¸ ==========
    st.subheader("B. HAR ëª¨ë¸ ë° RV ì˜ˆì¸¡")
    
    with st.expander("â­â­â­ Corsi (2009) - HAR-RV ì›ì¡°"):
        st.markdown("""
        **ì œëª©**: "A Simple Approximate Long-Memory Model of Realized Volatility"  
        **ì €ë„**: *Journal of Financial Econometrics*, 7(2), 174-196  
        **IF**: 3.0 | **ì¸ìš©ìˆ˜**: 2,500+
        
        **HAR-RV ëª¨ë¸**:
        ```
        RV_t = Î²â‚€ + Î²â‚Â·RV_1d + Î²â‚‚Â·RV_5d + Î²â‚ƒÂ·RV_22d + Îµ
        ```
        
        **ìš°ë¦¬ Baseline**: HAR + VIX + CAVB
        """)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("HAR-RV RÂ²", "0.65")
        with col2:
            st.metric("ìš°ë¦¬ RÂ²", "0.783", delta="+20%")
    
    # ========== C. Good/Bad Volatility ==========
    st.subheader("C. Good/Bad Volatility")
    
    with st.expander("â­ Segal et al. (2015)"):
        st.markdown("""
        **ì œëª©**: "Good and Bad Uncertainty"  
        **ì €ë„**: *JFE*, 117(2), 369-397 | **IF**: 8.9
        
        **ê°œë…**:
        - Good volatility: ìƒìŠ¹ ì‹œ ë³€ë™
        - Bad volatility: í•˜ë½ ì‹œ ë³€ë™
        
        **ìš°ë¦¬ êµ¬í˜„**:
        ```python
        good_vol = positive_returns.std() * sqrt(252) * 100
        bad_vol = negative_returns.std() * sqrt(252) * 100
        ```
        
        **íš¨ê³¼**: EEM RÂ² +3.0%
        """)
    
    # ========== D. ML ==========
    st.subheader("D. Machine Learning in Finance")
    
    with st.expander("â­â­â­ Gu, Kelly & Xiu (2020)"):
        st.markdown("""
        **ì œëª©**: "Empirical Asset Pricing via Machine Learning"  
        **ì €ë„**: *RFS*, 33(5), 2223-2273 | **IF**: 8.2 | **ì¸ìš©ìˆ˜**: 1,500+
        
        **í•µì‹¬ ë©”ì‹œì§€**: "Simplicity often wins"
        
        **ìš°ë¦¬ ê²€ì¦**: ElasticNetì´ XGBoost/NNë³´ë‹¤ ìš°ìˆ˜
        """)
    
    with st.expander("Zou & Hastie (2005) - ElasticNet"):
        st.markdown("""
        **ì œëª©**: "Regularization via the Elastic Net"  
        **ì €ë„**: *JRSS-B*, 67(2), 301-320 | **IF**: 5.9 | **ì¸ìš©ìˆ˜**: 45,000+
        
        **ElasticNet**: L1 + L2
        
        **ìš°ë¦¬ ì„¤ì •**:
        ```python
        ElasticNet(alpha=0.01, l1_ratio=0.7)
        ```
        """)
    
    # ========== E. Ensemble ==========
    st.subheader("E. Forecast Combination")
    
    with st.expander("â­ Rapach et al. (2013)"):
        st.markdown("""
        **ì œëª©**: "Out-of-Sample Equity Premium Prediction: Combination Forecasts"  
        **ì €ë„**: *RFS*, 26(4), 821-862 | **IF**: 8.2
        
        **ìš°ë¦¬ ì ìš©**: 6ê°€ì§€ Ensemble ì „ëµ
        - Simple/Weighted Averaging
        - Stacking
        - Voting
        - Optimized
        - **Selective** (70% best + 30% avg) â­
        
        **ê²°ê³¼**: Selective RÂ² 0.776 (+0.44% vs ElasticNet)
        """)
    
    # ========== ì €ë„ ë¶„í¬ ==========
    st.subheader("ğŸ“Š ì €ë„ ë¶„í¬")
    
    journal_data = pd.DataFrame({
        "ì €ë„": ["RFS", "JFE", "JE", "Others"],
        "ë…¼ë¬¸ ìˆ˜": [6, 4, 2, 4],
        "í‰ê·  IF": [8.2, 8.9, 3.9, 5.5]
    })
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.bar_chart(journal_data.set_index("ì €ë„")["ë…¼ë¬¸ ìˆ˜"])
    
    with col2:
        st.dataframe(journal_data, use_container_width=True)
    
    st.success("**í‰ê·  Impact Factor: 6.8** (ë§¤ìš° ë†’ì€ ìˆ˜ì¤€)")
    
    # ========== Features â†’ References ==========
    st.subheader("ğŸ”— Features â†’ References ë§¤í•‘")
    
    mapping = pd.DataFrame({
        "Feature Group": ["Baseline (HAR)", "VRP Decomposition", "Good/Bad Vol", "Ensemble"],
        "ì¶œì²˜ ë…¼ë¬¸": ["Corsi (2009)", "Bollerslev (2009)", "Segal (2015)", "Rapach (2013)"],
        "Impact": ["â­â­â­", "â­â­â­", "â­â­", "â­â­"]
    })
    
    st.table(mapping)
