#!/usr/bin/env python3
"""
ë¹ ë¥¸ í†µí•© ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import os
import sys
import numpy as np
import pandas as pd
import warnings
import time
from datetime import datetime, timedelta
import yfinance as yf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

print("âš¡ ë¹ ë¥¸ í†µí•© AI ì£¼ì‹ ì˜ˆì¸¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
print("=" * 60)
print(f"TensorFlow ë²„ì „: {tf.__version__}")
print(f"GPU: {'ìˆìŒ' if tf.config.list_physical_devices('GPU') else 'ì—†ìŒ'}")
print()

class QuickFeatureEngineering:
    """ë¹ ë¥¸ íŠ¹ì„± ê³µí•™"""
    
    def create_features(self, data):
        """í•µì‹¬ íŠ¹ì„±ë§Œ ë¹ ë¥´ê²Œ ìƒì„±"""
        features = {}
        
        # ê¸°ë³¸ ìˆ˜ìµë¥ 
        for period in [1, 5, 10, 20]:
            features[f'return_{period}'] = data['Close'].pct_change(period)
            features[f'volatility_{period}'] = data['Close'].rolling(period).std()
        
        # RSI
        delta = data['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        features['rsi'] = 100 - (100 / (1 + rs))
        
        # MACD
        exp1 = data['Close'].ewm(span=12).mean()
        exp2 = data['Close'].ewm(span=26).mean()
        features['macd'] = exp1 - exp2
        
        # ëª¨ë©˜í…€
        for period in [5, 10, 20]:
            features[f'momentum_{period}'] = data['Close'] / data['Close'].shift(period) - 1
        
        # ë³¼ë¦°ì € ë°´ë“œ ìœ„ì¹˜
        sma_20 = data['Close'].rolling(20).mean()
        std_20 = data['Close'].rolling(20).std()
        features['bollinger_position'] = (data['Close'] - sma_20) / std_20
        
        # ê°€ê²©-ê±°ë˜ëŸ‰ ìƒê´€ê´€ê³„
        price_changes = data['Close'].pct_change(5)
        volume_changes = data['Volume'].pct_change(5)
        features['price_vol_corr'] = price_changes.rolling(10).corr(volume_changes)
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        feature_df = pd.DataFrame(features, index=data.index)
        feature_df = feature_df.fillna(method='ffill').fillna(0)
        
        return feature_df

class SimpleLSTM:
    """ê°„ë‹¨í•œ LSTM ëª¨ë¸"""
    
    def __init__(self, sequence_length=20):
        self.sequence_length = sequence_length
        self.model = None
        self.scaler = StandardScaler()
    
    def prepare_sequences(self, X, y):
        """ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„"""
        X_seq, y_seq = [], []
        for i in range(len(X) - self.sequence_length):
            X_seq.append(X.iloc[i:i+self.sequence_length].values)
            y_seq.append(y.iloc[i+self.sequence_length])
        return np.array(X_seq), np.array(y_seq)
    
    def fit(self, X, y):
        """ëª¨ë¸ í•™ìŠµ"""
        # ì •ê·œí™”
        X_scaled = pd.DataFrame(
            self.scaler.fit_transform(X),
            columns=X.columns, index=X.index
        )
        
        # ì‹œí€€ìŠ¤ ì¤€ë¹„
        X_seq, y_seq = self.prepare_sequences(X_scaled, y)
        
        if len(X_seq) < 50:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬
            print("   âš ï¸ LSTM: ë°ì´í„° ë¶€ì¡±")
            return self
        
        # ëª¨ë¸ ìƒì„±
        self.model = keras.Sequential([
            layers.LSTM(32, input_shape=(self.sequence_length, X_seq.shape[2])),
            layers.Dropout(0.3),
            layers.Dense(16, activation='relu'),
            layers.Dense(1, activation='sigmoid')
        ])
        
        self.model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        # í•™ìŠµ
        self.model.fit(
            X_seq, y_seq,
            epochs=20,
            batch_size=32,
            validation_split=0.2,
            verbose=0
        )
        
        return self
    
    def predict(self, X):
        """ì˜ˆì¸¡"""
        if self.model is None:
            return np.random.choice([0, 1], len(X))
        
        X_scaled = pd.DataFrame(
            self.scaler.transform(X),
            columns=X.columns, index=X.index
        )
        
        X_seq, _ = self.prepare_sequences(X_scaled, pd.Series(range(len(X))))
        
        if len(X_seq) == 0:
            return np.random.choice([0, 1], len(X))
        
        pred_proba = self.model.predict(X_seq, verbose=0)
        
        # ì „ì²´ ê¸¸ì´ì— ë§ì¶° íŒ¨ë”©
        full_pred = np.zeros(len(X))
        full_pred[self.sequence_length:] = pred_proba.flatten()
        full_pred[:self.sequence_length] = pred_proba[0] if len(pred_proba) > 0 else 0.5
        
        return (full_pred > 0.5).astype(int)

def run_quick_test():
    """ë¹ ë¥¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ“Š SPY ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
    
    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ (1ë…„)
    ticker = yf.Ticker('SPY')
    data = ticker.history(period='1y')
    
    print(f"   âœ… ë°ì´í„°: {len(data)}ì¼ ({data.index[0].date()} ~ {data.index[-1].date()})")
    
    # íŠ¹ì„± ìƒì„±
    feature_eng = QuickFeatureEngineering()
    features = feature_eng.create_features(data)
    
    # íƒ€ê²Ÿ ìƒì„±
    target = (data['Close'].shift(-1) > data['Close']).astype(int)
    
    # ë§ˆì§€ë§‰ í–‰ ì œê±°
    features = features.iloc[:-1]
    target = target.iloc[:-1]
    
    print(f"   íŠ¹ì„± ìˆ˜: {len(features.columns)}")
    print(f"   ìƒìŠ¹ ë¹„ìœ¨: {target.mean():.1%}")
    print()
    
    # ë°ì´í„° ë¶„í•  (ì‹œê³„ì—´ ìˆœì„œ ìœ ì§€)
    split_idx = int(len(features) * 0.8)
    X_train, X_test = features.iloc[:split_idx], features.iloc[split_idx:]
    y_train, y_test = target.iloc[:split_idx], target.iloc[split_idx:]
    
    print(f"   í›ˆë ¨: {len(X_train)}ì¼, í…ŒìŠ¤íŠ¸: {len(X_test)}ì¼")
    print()
    
    # ë² ì´ìŠ¤ë¼ì¸
    baseline_random = 0.5000
    baseline_momentum = (y_test.shift(1).fillna(0) == y_test).mean()
    
    print("ğŸ¯ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    results = {}
    
    # 1. Random Forest
    print("1ï¸âƒ£ Random Forest í•™ìŠµ...")
    try:
        rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
        rf.fit(X_train, y_train)
        rf_pred = rf.predict(X_test)
        rf_acc = accuracy_score(y_test, rf_pred)
        results['RandomForest'] = rf_acc
        print(f"   âœ… Random Forest: {rf_acc:.4f}")
    except Exception as e:
        results['RandomForest'] = baseline_random
        print(f"   âŒ Random Forest ì‹¤íŒ¨: {str(e)[:30]}")
    
    # 2. AdaBoost
    print("2ï¸âƒ£ AdaBoost í•™ìŠµ...")
    try:
        ada = AdaBoostClassifier(n_estimators=50, random_state=42)
        ada.fit(X_train, y_train)
        ada_pred = ada.predict(X_test)
        ada_acc = accuracy_score(y_test, ada_pred)
        results['AdaBoost'] = ada_acc
        print(f"   âœ… AdaBoost: {ada_acc:.4f}")
    except Exception as e:
        results['AdaBoost'] = baseline_random
        print(f"   âŒ AdaBoost ì‹¤íŒ¨: {str(e)[:30]}")
    
    # 3. Logistic Regression
    print("3ï¸âƒ£ Logistic Regression í•™ìŠµ...")
    try:
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        lr = LogisticRegression(random_state=42, max_iter=1000)
        lr.fit(X_train_scaled, y_train)
        lr_pred = lr.predict(X_test_scaled)
        lr_acc = accuracy_score(y_test, lr_pred)
        results['LogisticRegression'] = lr_acc
        print(f"   âœ… Logistic Regression: {lr_acc:.4f}")
    except Exception as e:
        results['LogisticRegression'] = baseline_random
        print(f"   âŒ Logistic Regression ì‹¤íŒ¨: {str(e)[:30]}")
    
    # 4. Simple LSTM
    print("4ï¸âƒ£ Simple LSTM í•™ìŠµ...")
    try:
        lstm = SimpleLSTM(sequence_length=15)
        lstm.fit(X_train, y_train)
        lstm_pred = lstm.predict(X_test)
        lstm_acc = accuracy_score(y_test, lstm_pred)
        results['SimpleLSTM'] = lstm_acc
        print(f"   âœ… Simple LSTM: {lstm_acc:.4f}")
    except Exception as e:
        results['SimpleLSTM'] = baseline_random
        print(f"   âŒ Simple LSTM ì‹¤íŒ¨: {str(e)[:30]}")
    
    print()
    
    # ê²°ê³¼ ë¶„ì„
    print("ğŸ† ìµœì¢… ì„±ëŠ¥ ë¶„ì„")
    print("=" * 50)
    
    # ì„±ëŠ¥ ìˆœìœ„
    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)
    
    print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„:")
    for i, (model, acc) in enumerate(sorted_results, 1):
        print(f"   {i}. {model:20s}: {acc:.4f}")
    
    print(f"\nğŸ“ˆ ë² ì´ìŠ¤ë¼ì¸ ë¹„êµ:")
    print(f"   Random Walk (50%): {baseline_random:.4f}")
    print(f"   Momentum Strategy: {baseline_momentum:.4f}")
    
    if sorted_results:
        best_model, best_acc = sorted_results[0]
        improvement = best_acc - max(baseline_random, baseline_momentum)
        improvement_pct = (improvement / max(baseline_random, baseline_momentum)) * 100
        
        print(f"   ìµœê³  ëª¨ë¸ ({best_model}): {best_acc:.4f}")
        print(f"   ê°œì„ ë„: {improvement:+.4f} ({improvement_pct:+.1f}%)")
        
        # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
        target_min, target_max = 0.60, 0.65
        if best_acc >= target_min:
            if best_acc >= target_max:
                print(f"   ğŸ¯ ëª©í‘œ ë‹¬ì„±! (ëª©í‘œ: {target_min:.1%}-{target_max:.1%})")
            else:
                print(f"   ğŸ¯ ìµœì†Œ ëª©í‘œ ë‹¬ì„±! (ëª©í‘œ: {target_min:.1%}-{target_max:.1%})")
        else:
            needed = target_min - best_acc
            print(f"   ğŸ¯ ëª©í‘œê¹Œì§€ {needed:.4f} ({needed*100:.1f}%p) ë¶€ì¡±")
    
    return results

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    start_time = time.time()
    
    # GPU ë©”ëª¨ë¦¬ ì„¤ì •
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        except RuntimeError as e:
            print(f"GPU ì„¤ì • ì˜¤ë¥˜: {e}")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = run_quick_test()
    
    elapsed = time.time() - start_time
    print(f"\nâ° ì‹¤í–‰ ì‹œê°„: {elapsed:.1f}ì´ˆ")
    print("=" * 60)
    print("âœ… ë¹ ë¥¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    main()