#!/usr/bin/env python3
"""
ì¶”ê°€ ê°œì„  ì‹¤í—˜
==============

1. 10ë…„ ë°ì´í„° (2014-2024)
2. ë¡œê·¸ ë³€í™˜ íƒ€ê²Ÿ
3. ë³€ë™ì„± ë°©í–¥ ì˜ˆì¸¡ (ë¶„ë¥˜)
4. ìƒìœ„ íŠ¹ì„±ë§Œ ì‚¬ìš©
5. ë‹¤ë¥¸ ì˜ˆì¸¡ ê¸°ê°„ (1ì¼, 10ì¼, 22ì¼)
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
from sklearn.linear_model import ElasticNet, LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, accuracy_score, f1_score
import yfinance as yf
from pathlib import Path
import json
from datetime import datetime

SEED = 42
np.random.seed(SEED)


def experiment_1_longer_data():
    """ì‹¤í—˜ 1: 10ë…„ ë°ì´í„° (2014-2024)"""
    print("\n" + "=" * 60)
    print("[1/5] 10ë…„ ë°ì´í„° (2014-2024)")
    print("=" * 60)
    
    # 10ë…„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    print("  ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
    spy = yf.download('SPY', start='2014-01-01', end='2025-01-01', progress=False)
    vix = yf.download('^VIX', start='2014-01-01', end='2025-01-01', progress=False)
    
    if isinstance(spy.columns, pd.MultiIndex):
        spy.columns = spy.columns.get_level_values(0)
    if isinstance(vix.columns, pd.MultiIndex):
        vix.columns = vix.columns.get_level_values(0)
    
    spy['VIX'] = vix['Close'].reindex(spy.index).ffill()
    
    # íŠ¹ì„± ìƒì„±
    spy['returns'] = spy['Close'].pct_change()
    
    for window in [5, 10, 20, 50]:
        spy[f'volatility_{window}'] = spy['returns'].rolling(window).std()
    
    spy['vix_lag_1'] = spy['VIX'].shift(1)
    spy['vix_change'] = spy['VIX'].pct_change()
    spy['vix_zscore'] = (spy['VIX'] - spy['VIX'].rolling(20).mean()) / (spy['VIX'].rolling(20).std() + 1e-8)
    
    vix_lagged = spy['VIX'].shift(1)
    spy['regime_high_vol'] = (vix_lagged >= 25).astype(int)
    spy['vol_in_high_regime'] = spy['regime_high_vol'] * spy['volatility_5']
    spy['vix_excess_25'] = np.maximum(vix_lagged - 25, 0)
    
    for lag in [1, 2, 3, 5]:
        spy[f'vol_lag_{lag}'] = spy['volatility_5'].shift(lag)
    
    # íƒ€ê²Ÿ
    vol_values = []
    returns = spy['returns'].values
    for i in range(len(returns)):
        if i + 5 < len(returns):
            vol_values.append(pd.Series(returns[i+1:i+6]).std())
        else:
            vol_values.append(np.nan)
    spy['target'] = vol_values
    
    spy = spy.dropna()
    
    feature_cols = ['volatility_5', 'volatility_10', 'volatility_20', 'volatility_50',
                   'vix_lag_1', 'vix_change', 'vix_zscore', 'regime_high_vol',
                   'vol_in_high_regime', 'vix_excess_25', 'vol_lag_1', 'vol_lag_2', 
                   'vol_lag_3', 'vol_lag_5']
    
    X = spy[feature_cols].values
    y = spy['target'].values
    
    # 80-20 ë¶„í• 
    split_idx = int(len(spy) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_test_s = scaler.transform(X_test)
    
    model = ElasticNet(alpha=0.0003, l1_ratio=0.6, random_state=SEED, max_iter=10000)
    model.fit(X_train_s, y_train)
    y_pred = model.predict(X_test_s)
    r2 = r2_score(y_test, y_pred)
    
    # Bootstrap ì‹ ë¢°êµ¬ê°„
    n_bootstrap = 500
    r2_scores = []
    for i in range(n_bootstrap):
        idx = np.random.choice(len(y_test), size=len(y_test), replace=True)
        r2_scores.append(r2_score(y_test[idx], y_pred[idx]))
    
    ci_lower = np.percentile(r2_scores, 2.5)
    ci_upper = np.percentile(r2_scores, 97.5)
    
    print(f"\n  ğŸ“Š ê²°ê³¼:")
    print(f"     ë°ì´í„°: {len(spy)} í–‰ (10ë…„)")
    print(f"     Train: {len(X_train)}, Test: {len(X_test)}")
    print(f"     RÂ² = {r2:.4f}")
    print(f"     95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]")
    print(f"     CI í­: {ci_upper - ci_lower:.4f}")
    
    return {
        'n_samples': len(spy),
        'r2': float(r2),
        'ci_lower': float(ci_lower),
        'ci_upper': float(ci_upper),
        'ci_width': float(ci_upper - ci_lower)
    }


def experiment_2_log_transform():
    """ì‹¤í—˜ 2: ë¡œê·¸ ë³€í™˜ íƒ€ê²Ÿ"""
    print("\n" + "=" * 60)
    print("[2/5] ë¡œê·¸ ë³€í™˜ íƒ€ê²Ÿ")
    print("=" * 60)
    
    # ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©
    csv_path = Path('data/raw/spy_data_2020_2025.csv')
    spy = pd.read_csv(csv_path, index_col=0, parse_dates=True)
    
    vix = yf.download('^VIX', start=spy.index[0], end=spy.index[-1], progress=False)
    if isinstance(vix.columns, pd.MultiIndex):
        vix.columns = vix.columns.get_level_values(0)
    spy['VIX'] = vix['Close'].reindex(spy.index).ffill()
    
    spy['returns'] = spy['Close'].pct_change()
    
    for window in [5, 10, 20, 50]:
        spy[f'volatility_{window}'] = spy['returns'].rolling(window).std()
    
    spy['vix_lag_1'] = spy['VIX'].shift(1)
    spy['vix_change'] = spy['VIX'].pct_change()
    spy['vix_zscore'] = (spy['VIX'] - spy['VIX'].rolling(20).mean()) / (spy['VIX'].rolling(20).std() + 1e-8)
    
    vix_lagged = spy['VIX'].shift(1)
    spy['regime_high_vol'] = (vix_lagged >= 25).astype(int)
    spy['vol_in_high_regime'] = spy['regime_high_vol'] * spy['volatility_5']
    spy['vix_excess_25'] = np.maximum(vix_lagged - 25, 0)
    
    for lag in [1, 2, 3, 5]:
        spy[f'vol_lag_{lag}'] = spy['volatility_5'].shift(lag)
    
    # íƒ€ê²Ÿ
    vol_values = []
    returns = spy['returns'].values
    for i in range(len(returns)):
        if i + 5 < len(returns):
            vol_values.append(pd.Series(returns[i+1:i+6]).std())
        else:
            vol_values.append(np.nan)
    spy['target'] = vol_values
    spy['target_log'] = np.log(spy['target'] + 1e-8)
    
    spy = spy.dropna()
    
    feature_cols = ['volatility_5', 'volatility_10', 'volatility_20', 'volatility_50',
                   'vix_lag_1', 'vix_change', 'vix_zscore', 'regime_high_vol',
                   'vol_in_high_regime', 'vix_excess_25', 'vol_lag_1', 'vol_lag_2', 
                   'vol_lag_3', 'vol_lag_5']
    
    X = spy[feature_cols].values
    y_original = spy['target'].values
    y_log = spy['target_log'].values
    
    split_idx = int(len(spy) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train_orig, y_test_orig = y_original[:split_idx], y_original[split_idx:]
    y_train_log, y_test_log = y_log[:split_idx], y_log[split_idx:]
    
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_test_s = scaler.transform(X_test)
    
    # ì›ë³¸ íƒ€ê²Ÿ
    model_orig = ElasticNet(alpha=0.0003, l1_ratio=0.6, random_state=SEED, max_iter=10000)
    model_orig.fit(X_train_s, y_train_orig)
    y_pred_orig = model_orig.predict(X_test_s)
    r2_orig = r2_score(y_test_orig, y_pred_orig)
    
    # ë¡œê·¸ íƒ€ê²Ÿ
    model_log = ElasticNet(alpha=0.0003, l1_ratio=0.6, random_state=SEED, max_iter=10000)
    model_log.fit(X_train_s, y_train_log)
    y_pred_log = model_log.predict(X_test_s)
    y_pred_exp = np.exp(y_pred_log) - 1e-8  # ì—­ë³€í™˜
    r2_log = r2_score(y_test_orig, y_pred_exp)
    
    print(f"\n  ğŸ“Š ê²°ê³¼:")
    print(f"     ì›ë³¸ íƒ€ê²Ÿ RÂ²:  {r2_orig:.4f}")
    print(f"     ë¡œê·¸ íƒ€ê²Ÿ RÂ²:  {r2_log:.4f}")
    print(f"     ê°œì„ :          {r2_log - r2_orig:+.4f}")
    
    return {
        'original_r2': float(r2_orig),
        'log_r2': float(r2_log),
        'improvement': float(r2_log - r2_orig)
    }


def experiment_3_direction_prediction():
    """ì‹¤í—˜ 3: ë³€ë™ì„± ë°©í–¥ ì˜ˆì¸¡ (ë¶„ë¥˜)"""
    print("\n" + "=" * 60)
    print("[3/5] ë³€ë™ì„± ë°©í–¥ ì˜ˆì¸¡ (ë¶„ë¥˜)")
    print("=" * 60)
    
    csv_path = Path('data/raw/spy_data_2020_2025.csv')
    spy = pd.read_csv(csv_path, index_col=0, parse_dates=True)
    
    vix = yf.download('^VIX', start=spy.index[0], end=spy.index[-1], progress=False)
    if isinstance(vix.columns, pd.MultiIndex):
        vix.columns = vix.columns.get_level_values(0)
    spy['VIX'] = vix['Close'].reindex(spy.index).ffill()
    
    spy['returns'] = spy['Close'].pct_change()
    
    for window in [5, 10, 20, 50]:
        spy[f'volatility_{window}'] = spy['returns'].rolling(window).std()
    
    spy['vix_lag_1'] = spy['VIX'].shift(1)
    spy['vix_change'] = spy['VIX'].pct_change()
    spy['vix_zscore'] = (spy['VIX'] - spy['VIX'].rolling(20).mean()) / (spy['VIX'].rolling(20).std() + 1e-8)
    
    vix_lagged = spy['VIX'].shift(1)
    spy['regime_high_vol'] = (vix_lagged >= 25).astype(int)
    spy['vol_in_high_regime'] = spy['regime_high_vol'] * spy['volatility_5']
    spy['vix_excess_25'] = np.maximum(vix_lagged - 25, 0)
    
    for lag in [1, 2, 3, 5]:
        spy[f'vol_lag_{lag}'] = spy['volatility_5'].shift(lag)
    
    # ë¯¸ë˜ ë³€ë™ì„±
    vol_values = []
    returns = spy['returns'].values
    for i in range(len(returns)):
        if i + 5 < len(returns):
            vol_values.append(pd.Series(returns[i+1:i+6]).std())
        else:
            vol_values.append(np.nan)
    spy['future_vol'] = vol_values
    
    # ë°©í–¥ íƒ€ê²Ÿ: ë¯¸ë˜ ë³€ë™ì„± > í˜„ì¬ ë³€ë™ì„±
    spy['direction'] = (spy['future_vol'] > spy['volatility_5']).astype(int)
    
    spy = spy.dropna()
    
    feature_cols = ['volatility_5', 'volatility_10', 'volatility_20', 'volatility_50',
                   'vix_lag_1', 'vix_change', 'vix_zscore', 'regime_high_vol',
                   'vol_in_high_regime', 'vix_excess_25', 'vol_lag_1', 'vol_lag_2', 
                   'vol_lag_3', 'vol_lag_5']
    
    X = spy[feature_cols].values
    y = spy['direction'].values
    
    split_idx = int(len(spy) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_test_s = scaler.transform(X_test)
    
    model = LogisticRegression(C=0.1, random_state=SEED, max_iter=10000)
    model.fit(X_train_s, y_train)
    y_pred = model.predict(X_test_s)
    y_prob = model.predict_proba(X_test_s)[:, 1]
    
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    baseline_acc = max(y_test.mean(), 1 - y_test.mean())  # ë‹¤ìˆ˜ í´ë˜ìŠ¤ ì˜ˆì¸¡
    
    print(f"\n  ğŸ“Š ê²°ê³¼:")
    print(f"     ì •í™•ë„:        {accuracy:.4f}")
    print(f"     F1 Score:      {f1:.4f}")
    print(f"     ê¸°ì¤€ì„  (ë‹¤ìˆ˜):  {baseline_acc:.4f}")
    print(f"     ê°œì„ :          {accuracy - baseline_acc:+.4f}")
    
    return {
        'accuracy': float(accuracy),
        'f1': float(f1),
        'baseline': float(baseline_acc),
        'improvement': float(accuracy - baseline_acc)
    }


def experiment_4_top_features():
    """ì‹¤í—˜ 4: ìƒìœ„ íŠ¹ì„±ë§Œ ì‚¬ìš©"""
    print("\n" + "=" * 60)
    print("[4/5] ìƒìœ„ íŠ¹ì„±ë§Œ ì‚¬ìš©")
    print("=" * 60)
    
    csv_path = Path('data/raw/spy_data_2020_2025.csv')
    spy = pd.read_csv(csv_path, index_col=0, parse_dates=True)
    
    vix = yf.download('^VIX', start=spy.index[0], end=spy.index[-1], progress=False)
    if isinstance(vix.columns, pd.MultiIndex):
        vix.columns = vix.columns.get_level_values(0)
    spy['VIX'] = vix['Close'].reindex(spy.index).ffill()
    
    spy['returns'] = spy['Close'].pct_change()
    
    for window in [5, 10, 20, 50]:
        spy[f'volatility_{window}'] = spy['returns'].rolling(window).std()
    
    spy['vix_lag_1'] = spy['VIX'].shift(1)
    spy['vix_change'] = spy['VIX'].pct_change()
    spy['vix_zscore'] = (spy['VIX'] - spy['VIX'].rolling(20).mean()) / (spy['VIX'].rolling(20).std() + 1e-8)
    
    vix_lagged = spy['VIX'].shift(1)
    spy['regime_high_vol'] = (vix_lagged >= 25).astype(int)
    spy['vol_in_high_regime'] = spy['regime_high_vol'] * spy['volatility_5']
    spy['vix_excess_25'] = np.maximum(vix_lagged - 25, 0)
    
    for lag in [1, 2, 3, 5]:
        spy[f'vol_lag_{lag}'] = spy['volatility_5'].shift(lag)
    
    vol_values = []
    returns = spy['returns'].values
    for i in range(len(returns)):
        if i + 5 < len(returns):
            vol_values.append(pd.Series(returns[i+1:i+6]).std())
        else:
            vol_values.append(np.nan)
    spy['target'] = vol_values
    
    spy = spy.dropna()
    
    all_features = ['volatility_5', 'volatility_10', 'volatility_20', 'volatility_50',
                   'vix_lag_1', 'vix_change', 'vix_zscore', 'regime_high_vol',
                   'vol_in_high_regime', 'vix_excess_25', 'vol_lag_1', 'vol_lag_2', 
                   'vol_lag_3', 'vol_lag_5']
    
    # ìƒìœ„ 3ê°œë§Œ (vix_lag_1, volatility_20, volatility_5)
    top_3 = ['vix_lag_1', 'volatility_20', 'volatility_5']
    
    # ìƒìœ„ 5ê°œ
    top_5 = ['vix_lag_1', 'volatility_20', 'volatility_5', 'vix_change', 'regime_high_vol']
    
    y = spy['target'].values
    split_idx = int(len(spy) * 0.8)
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    results = {}
    
    for name, features in [('ì „ì²´ (14)', all_features), ('ìƒìœ„ 5', top_5), ('ìƒìœ„ 3', top_3)]:
        X = spy[features].values
        X_train, X_test = X[:split_idx], X[split_idx:]
        
        scaler = StandardScaler()
        X_train_s = scaler.fit_transform(X_train)
        X_test_s = scaler.transform(X_test)
        
        model = ElasticNet(alpha=0.0003, l1_ratio=0.6, random_state=SEED, max_iter=10000)
        model.fit(X_train_s, y_train)
        y_pred = model.predict(X_test_s)
        r2 = r2_score(y_test, y_pred)
        
        results[name] = float(r2)
        print(f"     {name:15s}: RÂ² = {r2:.4f}")
    
    return results


def experiment_5_different_horizons():
    """ì‹¤í—˜ 5: ë‹¤ë¥¸ ì˜ˆì¸¡ ê¸°ê°„"""
    print("\n" + "=" * 60)
    print("[5/5] ë‹¤ë¥¸ ì˜ˆì¸¡ ê¸°ê°„ (1ì¼, 5ì¼, 10ì¼, 22ì¼)")
    print("=" * 60)
    
    csv_path = Path('data/raw/spy_data_2020_2025.csv')
    spy = pd.read_csv(csv_path, index_col=0, parse_dates=True)
    
    vix = yf.download('^VIX', start=spy.index[0], end=spy.index[-1], progress=False)
    if isinstance(vix.columns, pd.MultiIndex):
        vix.columns = vix.columns.get_level_values(0)
    spy['VIX'] = vix['Close'].reindex(spy.index).ffill()
    
    spy['returns'] = spy['Close'].pct_change()
    
    for window in [5, 10, 20, 50]:
        spy[f'volatility_{window}'] = spy['returns'].rolling(window).std()
    
    spy['vix_lag_1'] = spy['VIX'].shift(1)
    spy['vix_change'] = spy['VIX'].pct_change()
    spy['vix_zscore'] = (spy['VIX'] - spy['VIX'].rolling(20).mean()) / (spy['VIX'].rolling(20).std() + 1e-8)
    
    vix_lagged = spy['VIX'].shift(1)
    spy['regime_high_vol'] = (vix_lagged >= 25).astype(int)
    spy['vol_in_high_regime'] = spy['regime_high_vol'] * spy['volatility_5']
    spy['vix_excess_25'] = np.maximum(vix_lagged - 25, 0)
    
    for lag in [1, 2, 3, 5]:
        spy[f'vol_lag_{lag}'] = spy['volatility_5'].shift(lag)
    
    feature_cols = ['volatility_5', 'volatility_10', 'volatility_20', 'volatility_50',
                   'vix_lag_1', 'vix_change', 'vix_zscore', 'regime_high_vol',
                   'vol_in_high_regime', 'vix_excess_25', 'vol_lag_1', 'vol_lag_2', 
                   'vol_lag_3', 'vol_lag_5']
    
    results = {}
    
    for horizon in [1, 5, 10, 22]:
        # ê° horizonì— ëŒ€í•œ íƒ€ê²Ÿ ìƒì„±
        vol_values = []
        returns = spy['returns'].values
        for i in range(len(returns)):
            if i + horizon < len(returns):
                vol_values.append(pd.Series(returns[i+1:i+1+horizon]).std())
            else:
                vol_values.append(np.nan)
        spy[f'target_{horizon}d'] = vol_values
        
        data = spy.dropna(subset=[f'target_{horizon}d'] + feature_cols)
        
        X = data[feature_cols].values
        y = data[f'target_{horizon}d'].values
        
        split_idx = int(len(data) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        scaler = StandardScaler()
        X_train_s = scaler.fit_transform(X_train)
        X_test_s = scaler.transform(X_test)
        
        model = ElasticNet(alpha=0.0003, l1_ratio=0.6, random_state=SEED, max_iter=10000)
        model.fit(X_train_s, y_train)
        y_pred = model.predict(X_test_s)
        r2 = r2_score(y_test, y_pred)
        
        results[f'{horizon}d'] = float(r2)
        print(f"     {horizon:2d}ì¼ ì˜ˆì¸¡: RÂ² = {r2:.4f}")
    
    return results


def main():
    print("\n" + "ğŸ”¬" * 30)
    print("ì¶”ê°€ ê°œì„  ì‹¤í—˜")
    print("ğŸ”¬" * 30)
    
    # ì‹¤í—˜ ì‹¤í–‰
    result_1 = experiment_1_longer_data()
    result_2 = experiment_2_log_transform()
    result_3 = experiment_3_direction_prediction()
    result_4 = experiment_4_top_features()
    result_5 = experiment_5_different_horizons()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ìµœì¢… ìš”ì•½")
    print("=" * 60)
    
    print(f"""
    ê¸°ì¤€ ì„±ëŠ¥: RÂ² = 0.2608
    
    1ï¸âƒ£ 10ë…„ ë°ì´í„°
       â€¢ RÂ² = {result_1['r2']:.4f}
       â€¢ 95% CI: [{result_1['ci_lower']:.4f}, {result_1['ci_upper']:.4f}]
       â€¢ CI í­: {result_1['ci_width']:.4f} (ì¶•ì†Œ íš¨ê³¼ í™•ì¸)
    
    2ï¸âƒ£ ë¡œê·¸ ë³€í™˜ íƒ€ê²Ÿ
       â€¢ ì›ë³¸: RÂ² = {result_2['original_r2']:.4f}
       â€¢ ë¡œê·¸: RÂ² = {result_2['log_r2']:.4f}
       â€¢ ê°œì„ : {result_2['improvement']:+.4f}
    
    3ï¸âƒ£ ë³€ë™ì„± ë°©í–¥ ì˜ˆì¸¡ (ë¶„ë¥˜)
       â€¢ ì •í™•ë„: {result_3['accuracy']:.4f}
       â€¢ ê¸°ì¤€ì„  ëŒ€ë¹„: {result_3['improvement']:+.4f}
    
    4ï¸âƒ£ ìƒìœ„ íŠ¹ì„±ë§Œ ì‚¬ìš©
       â€¢ ì „ì²´: RÂ² = {result_4.get('ì „ì²´ (14)', 0):.4f}
       â€¢ ìƒìœ„ 5: RÂ² = {result_4.get('ìƒìœ„ 5', 0):.4f}
       â€¢ ìƒìœ„ 3: RÂ² = {result_4.get('ìƒìœ„ 3', 0):.4f}
    
    5ï¸âƒ£ ì˜ˆì¸¡ ê¸°ê°„ë³„ ì„±ëŠ¥
       â€¢ 1ì¼: RÂ² = {result_5.get('1d', 0):.4f}
       â€¢ 5ì¼: RÂ² = {result_5.get('5d', 0):.4f}
       â€¢ 10ì¼: RÂ² = {result_5.get('10d', 0):.4f}
       â€¢ 22ì¼: RÂ² = {result_5.get('22d', 0):.4f}
    """)
    
    # ì €ì¥
    output = {
        'longer_data': result_1,
        'log_transform': result_2,
        'direction_prediction': result_3,
        'top_features': result_4,
        'different_horizons': result_5,
        'timestamp': datetime.now().isoformat()
    }
    
    with open('paper/additional_improvements_results.json', 'w') as f:
        json.dump(output, f, indent=2)
    
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: paper/additional_improvements_results.json")


if __name__ == '__main__':
    main()
