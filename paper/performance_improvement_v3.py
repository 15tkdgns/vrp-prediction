#!/usr/bin/env python3
"""
ì¶”ê°€ ì„±ëŠ¥ í–¥ìƒ ì‹¤í—˜ - ìƒˆë¡œìš´ íŠ¹ì„± ì¶”ê°€
======================================

í˜„ì¬ ìµœê³ : RÂ² = 0.2607 (ElasticNet alpha=0.0003, l1=0.6)
ëª©í‘œ: 0.27+ ë‹¬ì„±
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
from sklearn.linear_model import ElasticNet, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
import yfinance as yf
from pathlib import Path
import json
from datetime import datetime

SEED = 42
np.random.seed(SEED)


def create_enhanced_features():
    """ê°•í™”ëœ íŠ¹ì„± ìƒì„±"""
    print("\n[1] ê°•í™”ëœ íŠ¹ì„± ìƒì„±")
    
    # SPY ë°ì´í„° ë¡œë“œ
    csv_path = Path('data/raw/spy_data_2020_2025.csv')
    spy = pd.read_csv(csv_path, index_col=0, parse_dates=True)
    
    # VIX ë¡œë“œ
    vix = yf.download('^VIX', start=spy.index[0], end=spy.index[-1], progress=False)
    if isinstance(vix.columns, pd.MultiIndex):
        vix.columns = vix.columns.get_level_values(0)
    
    vix_close = vix['Close'].reindex(spy.index).ffill()
    spy['VIX'] = vix_close
    
    # ê¸°ë³¸ íŠ¹ì„±
    spy['returns'] = spy['Close'].pct_change()
    
    # ë³€ë™ì„± íŠ¹ì„±
    for window in [5, 10, 20, 50]:
        spy[f'volatility_{window}'] = spy['returns'].rolling(window).std()
        spy[f'realized_vol_{window}'] = spy[f'volatility_{window}'] * np.sqrt(252)
    
    # ìˆ˜ìµë¥  í†µê³„
    for window in [5, 10, 20]:
        spy[f'mean_return_{window}'] = spy['returns'].rolling(window).mean()
        spy[f'skew_{window}'] = spy['returns'].rolling(window).skew()
        spy[f'kurt_{window}'] = spy['returns'].rolling(window).kurt()
    
    # ë˜ê·¸ ë³€ìˆ˜
    for lag in [1, 2, 3, 5]:
        spy[f'return_lag_{lag}'] = spy['returns'].shift(lag)
        spy[f'vol_lag_{lag}'] = spy['volatility_5'].shift(lag)
    
    # ëª¨ë©˜í…€
    for window in [5, 10, 20]:
        spy[f'momentum_{window}'] = spy['returns'].rolling(window).sum()
    
    # ë¹„ìœ¨ ë° Z-score
    spy['vol_ratio_5_20'] = spy['volatility_5'] / (spy['volatility_20'] + 1e-8)
    spy['vol_ratio_10_50'] = spy['volatility_10'] / (spy['volatility_50'] + 1e-8)
    spy['zscore_20'] = (spy['returns'] - spy['returns'].rolling(20).mean()) / (spy['returns'].rolling(20).std() + 1e-8)
    
    # VIX íŠ¹ì„± (í•µì‹¬!)
    spy['vix_lag_1'] = spy['VIX'].shift(1)
    spy['vix_lag_5'] = spy['VIX'].shift(5)
    spy['vix_change'] = spy['VIX'].pct_change()
    spy['vix_zscore'] = (spy['VIX'] - spy['VIX'].rolling(20).mean()) / (spy['VIX'].rolling(20).std() + 1e-8)
    
    # Regime íŠ¹ì„± (í•µì‹¬!)
    vix_lagged = spy['VIX'].shift(1)
    spy['regime_high_vol'] = (vix_lagged >= 25).astype(int)
    spy['regime_crisis'] = (vix_lagged >= 35).astype(int)
    spy['vol_in_high_regime'] = spy['regime_high_vol'] * spy['volatility_5']
    spy['vol_in_crisis'] = spy['regime_crisis'] * spy['volatility_5']
    spy['vix_excess_25'] = np.maximum(vix_lagged - 25, 0)
    spy['vix_excess_35'] = np.maximum(vix_lagged - 35, 0)
    
    # ========================================
    # ìƒˆë¡œìš´ íŠ¹ì„± ì¶”ê°€
    # ========================================
    
    # 1. VIX ë³€í™”ìœ¨ ì¶”ê°€
    spy['vix_change_3'] = spy['VIX'].pct_change(3)
    spy['vix_change_5'] = spy['VIX'].pct_change(5)
    
    # 2. VIX-ë³€ë™ì„± ìƒí˜¸ì‘ìš©
    spy['vix_vol_interaction'] = spy['vix_lag_1'] * spy['volatility_5']
    spy['vix_vol_ratio'] = spy['VIX'] / (spy['volatility_20'] * np.sqrt(252) * 100 + 1e-8)
    
    # 3. VIX ì´ë™í‰ê·  ë¹„ìœ¨
    spy['vix_ma_5'] = spy['VIX'].rolling(5).mean()
    spy['vix_ma_20'] = spy['VIX'].rolling(20).mean()
    spy['vix_ma_ratio'] = spy['vix_ma_5'] / (spy['vix_ma_20'] + 1e-8)
    
    # 4. ë³€ë™ì„± ê°€ì†ë„ (2ì°¨ ë¯¸ë¶„)
    spy['vol_acceleration'] = spy['volatility_5'].diff().diff()
    
    # 5. ìˆ˜ìµë¥  ê·¹ë‹¨ê°’
    spy['return_extreme_pos'] = (spy['returns'] > spy['returns'].rolling(20).quantile(0.95)).astype(int)
    spy['return_extreme_neg'] = (spy['returns'] < spy['returns'].rolling(20).quantile(0.05)).astype(int)
    
    # 6. ë³€ë™ì„± ì¶”ì„¸
    spy['vol_trend'] = spy['volatility_5'] - spy['volatility_20']
    
    # 7. VIX ë³€ë™ì„±
    spy['vix_volatility'] = spy['VIX'].rolling(10).std()
    
    # 8. ê³ ì € ë²”ìœ„ (Garman-Klass ìŠ¤íƒ€ì¼)
    spy['high_low_range'] = (np.log(spy['High']) - np.log(spy['Low'])) ** 2
    spy['high_low_range_ma5'] = spy['high_low_range'].rolling(5).mean()
    
    # 9. ê±°ë˜ëŸ‰ íŠ¹ì„± 
    if 'Volume' in spy.columns:
        spy['volume_ma_ratio'] = spy['Volume'] / (spy['Volume'].rolling(20).mean() + 1e-8)
        spy['volume_change'] = spy['Volume'].pct_change()
    
    # 10. VIX ì„ê³„ê°’ ì¶”ê°€
    spy['vix_excess_20'] = np.maximum(vix_lagged - 20, 0)
    spy['vix_excess_30'] = np.maximum(vix_lagged - 30, 0)
    
    # 11. ë³€ë™ì„± ë°±ë¶„ìœ„ìˆ˜
    spy['vol_percentile'] = spy['volatility_5'].rolling(60).apply(
        lambda x: pd.Series(x).rank(pct=True).iloc[-1], raw=False
    )
    
    # íƒ€ê²Ÿ
    vol_values = []
    returns = spy['returns'].values
    for i in range(len(returns)):
        if i + 5 < len(returns):
            future_window = returns[i+1:i+6]
            vol_values.append(pd.Series(future_window).std())
        else:
            vol_values.append(np.nan)
    spy['target_vol_5d'] = vol_values
    
    spy = spy.replace([np.inf, -np.inf], np.nan).dropna()
    
    # íŠ¹ì„± ì»¬ëŸ¼ ì„ íƒ
    feature_cols = []
    for col in spy.columns:
        if col.startswith(('volatility_', 'realized_vol_', 'mean_return_',
                          'skew_', 'kurt_', 'return_lag_', 'vol_lag_',
                          'vol_ratio_', 'zscore_', 'momentum_', 'vix_', 'regime_',
                          'vol_in_', 'vix_excess_', 'high_low_', 'volume_',
                          'return_extreme_', 'vol_trend', 'vol_acceleration',
                          'vol_percentile')):
            feature_cols.append(col)
    
    print(f"  âœ“ ë°ì´í„°: {len(spy)} í–‰, {len(feature_cols)} íŠ¹ì„±")
    print(f"  âœ“ ìƒˆë¡œìš´ íŠ¹ì„±: {len(feature_cols) - 42}ê°œ ì¶”ê°€")
    
    return spy, feature_cols


def run_experiments(spy, feature_cols):
    """ì‹¤í—˜"""
    print("\n[2] ëª¨ë¸ ì‹¤í—˜")
    
    X = spy[feature_cols].values
    y = spy['target_vol_5d'].values
    
    split_idx = int(len(spy) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_test_s = scaler.transform(X_test)
    
    print(f"  Train: {len(X_train)}, Test: {len(X_test)}")
    
    results = {}
    
    # 1. ê¸°ì¡´ ìµœì  íŒŒë¼ë¯¸í„°
    print("\n  ğŸ”¹ ElasticNet (ê¸°ì¡´ ìµœì : alpha=0.0003, l1=0.6)")
    en = ElasticNet(alpha=0.0003, l1_ratio=0.6, random_state=SEED, max_iter=10000)
    en.fit(X_train_s, y_train)
    y_pred = en.predict(X_test_s)
    r2 = r2_score(y_test, y_pred)
    results['ElasticNet_prev_best'] = r2
    print(f"     RÂ² = {r2:.4f}")
    
    # 2. ìƒˆë¡œìš´ íŠ¹ì„±ìœ¼ë¡œ ë¯¸ì„¸ì¡°ì •
    print("\n  ğŸ”¹ ElasticNet (ìƒˆ íŠ¹ì„± + ë¯¸ì„¸ì¡°ì •)")
    best_r2 = 0
    best_params = {}
    for alpha in [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0007, 0.001]:
        for l1_ratio in [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:
            en = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=SEED, max_iter=10000)
            en.fit(X_train_s, y_train)
            y_pred = en.predict(X_test_s)
            r2_temp = r2_score(y_test, y_pred)
            if r2_temp > best_r2:
                best_r2 = r2_temp
                best_params = {'alpha': alpha, 'l1_ratio': l1_ratio}
    results['ElasticNet_new_best'] = best_r2
    print(f"     RÂ² = {best_r2:.4f} (alpha={best_params['alpha']}, l1={best_params['l1_ratio']})")
    
    # 3. ìµœì  ëª¨ë¸ë¡œ íŠ¹ì„± ì¤‘ìš”ë„ í™•ì¸
    best_en = ElasticNet(**best_params, random_state=SEED, max_iter=10000)
    best_en.fit(X_train_s, y_train)
    
    importance = pd.DataFrame({
        'feature': feature_cols,
        'coef': np.abs(best_en.coef_)
    }).sort_values('coef', ascending=False)
    
    print("\n  ğŸ“Š ìƒìœ„ 10 íŠ¹ì„±:")
    for i, row in importance.head(10).iterrows():
        print(f"     {row['feature']:25s}: {row['coef']:.6f}")
    
    # 4. ì•™ìƒë¸” í…ŒìŠ¤íŠ¸
    print("\n  ğŸ”¹ ElasticNet + Ridge ì•™ìƒë¸”")
    ridge = Ridge(alpha=1.0, random_state=SEED)
    ridge.fit(X_train_s, y_train)
    
    y_pred_en = best_en.predict(X_test_s)
    y_pred_ridge = ridge.predict(X_test_s)
    
    best_ens_r2 = 0
    best_w = 0.5
    for w in np.arange(0.5, 1.0, 0.05):
        y_ens = w * y_pred_en + (1-w) * y_pred_ridge
        r2_ens = r2_score(y_test, y_ens)
        if r2_ens > best_ens_r2:
            best_ens_r2 = r2_ens
            best_w = w
    
    results['Ensemble_EN_Ridge'] = best_ens_r2
    print(f"     RÂ² = {best_ens_r2:.4f} (EN weight: {best_w:.2f})")
    
    return results, best_params, importance


def main():
    print("\n" + "=" * 60)
    print("ì¶”ê°€ ì„±ëŠ¥ í–¥ìƒ ì‹¤í—˜ - ìƒˆë¡œìš´ íŠ¹ì„± ì¶”ê°€")
    print("=" * 60)
    
    # 1. ê°•í™”ëœ íŠ¹ì„± ìƒì„±
    spy, feature_cols = create_enhanced_features()
    
    # 2. ì‹¤í—˜
    results, best_params, importance = run_experiments(spy, feature_cols)
    
    # 3. ê²°ê³¼
    print("\n" + "=" * 60)
    print("[3] ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)
    
    baseline = 0.2607  # ì´ì „ ìµœê³ 
    
    print("\nğŸ“Š ëª¨ë¸ë³„ ì„±ëŠ¥:")
    for model, r2 in sorted_results:
        diff = r2 - baseline
        marker = "â­ " if r2 > baseline else "   "
        print(f"  {marker}{model:25s}: RÂ² = {r2:.4f} ({diff:+.4f})")
    
    best_model = sorted_results[0][0]
    best_r2 = sorted_results[0][1]
    
    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best_model}")
    print(f"  â€¢ RÂ² = {best_r2:.4f}")
    print(f"  â€¢ ê¸°ì¡´ ëŒ€ë¹„: {best_r2 - baseline:+.4f} ({(best_r2 - baseline)/baseline*100:+.1f}%)")
    print(f"  â€¢ ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")
    
    # ì €ì¥
    output = {
        'results': {k: float(v) for k, v in results.items()},
        'best_model': best_model,
        'best_r2': float(best_r2),
        'best_params': best_params,
        'baseline': baseline,
        'improvement': float(best_r2 - baseline),
        'top_features': importance.head(15).to_dict('records'),
        'timestamp': datetime.now().isoformat()
    }
    
    with open('paper/performance_improvement_v3.json', 'w') as f:
        json.dump(output, f, indent=2, default=str)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: paper/performance_improvement_v3.json")


if __name__ == '__main__':
    main()
