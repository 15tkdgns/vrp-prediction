#!/usr/bin/env python3
"""
ë…¼ë¬¸ ì¶”ê°€ ì•½ì  í•´ê²° ì‹¤í—˜ (2ì°¨)
=============================

8. í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¼ê°ë„
9. í†µê³„ì  ìœ ì˜ì„± (t-test, p-value)
10. ê±°ë˜ ë¹ˆë„ ë¶„ì„
11. ë¦¬ìŠ¤í¬ ì§€í‘œ (VaR, ES)
12. ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„± (SHAP)
13. ë‹¤ì¤‘ê³µì„ ì„± (VIF)
14. T+1 ì§€ì—° ì˜í–¥
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
from sklearn.linear_model import ElasticNet, Ridge, Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error
from scipy import stats
import yfinance as yf
from pathlib import Path
import json
from datetime import datetime

SEED = 42
np.random.seed(SEED)


def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    csv_path = Path('data/raw/spy_data_2020_2025.csv')
    if csv_path.exists():
        spy = pd.read_csv(csv_path, index_col=0, parse_dates=True)
    else:
        spy = yf.download('SPY', start='2020-01-01', end='2025-01-01', progress=False)
    
    vix = yf.download('^VIX', start='2020-01-01', end='2025-01-01', progress=False)
    
    if isinstance(spy.columns, pd.MultiIndex):
        spy.columns = spy.columns.get_level_values(0)
    if isinstance(vix.columns, pd.MultiIndex):
        vix.columns = vix.columns.get_level_values(0)
    
    spy['VIX'] = vix['Close'].reindex(spy.index).ffill().bfill()
    spy['returns'] = spy['Close'].pct_change()
    
    # íŠ¹ì„±
    spy['RV_1d'] = spy['returns'].abs() * np.sqrt(252) * 100
    spy['RV_5d'] = spy['returns'].rolling(5).std() * np.sqrt(252) * 100
    spy['RV_22d'] = spy['returns'].rolling(22).std() * np.sqrt(252) * 100
    spy['VRP'] = spy['VIX'] - spy['RV_22d']
    spy['RV_future'] = spy['RV_22d'].shift(-22)
    spy['VRP_true'] = spy['VIX'] - spy['RV_future']
    
    spy['VIX_lag1'] = spy['VIX'].shift(1)
    spy['VIX_lag5'] = spy['VIX'].shift(5)
    spy['VIX_change'] = spy['VIX'].pct_change()
    spy['VRP_lag1'] = spy['VRP'].shift(1)
    spy['VRP_lag5'] = spy['VRP'].shift(5)
    spy['VRP_ma5'] = spy['VRP'].rolling(5).mean()
    spy['regime_high'] = (spy['VIX'] >= 25).astype(int)
    spy['return_5d'] = spy['returns'].rolling(5).sum()
    spy['return_22d'] = spy['returns'].rolling(22).sum()
    
    spy = spy.replace([np.inf, -np.inf], np.nan).dropna()
    
    return spy


def issue_8_hyperparam_sensitivity(spy):
    """ì•½ì  8: í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¼ê°ë„"""
    print("\n" + "=" * 70)
    print("[1/7] í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¼ê°ë„ ë¶„ì„")
    print("=" * 70)
    
    feature_cols = ['RV_1d', 'RV_5d', 'RV_22d', 'VIX_lag1', 'VIX_lag5', 
                   'VIX_change', 'VRP_lag1', 'VRP_lag5', 'VRP_ma5',
                   'regime_high', 'return_5d', 'return_22d']
    
    X = spy[feature_cols].values
    y = spy['RV_future'].values
    vix = spy['VIX'].values
    y_vrp = spy['VRP_true'].values
    
    split_idx = int(len(spy) * 0.8)
    vix_test = vix[split_idx:]
    y_vrp_test = y_vrp[split_idx:]
    
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X[:split_idx])
    X_test_s = scaler.transform(X[split_idx:])
    
    # ê·¸ë¦¬ë“œ ì„œì¹˜
    alphas = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]
    l1_ratios = [0.1, 0.3, 0.5, 0.7, 0.9]
    
    results = []
    best_r2 = -999
    best_params = None
    
    for alpha in alphas:
        for l1_ratio in l1_ratios:
            en = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=SEED, max_iter=10000)
            en.fit(X_train_s, y[:split_idx])
            vrp_pred = vix_test - en.predict(X_test_s)
            
            r2 = r2_score(y_vrp_test, vrp_pred)
            results.append({'alpha': alpha, 'l1_ratio': l1_ratio, 'r2': r2})
            
            if r2 > best_r2:
                best_r2 = r2
                best_params = {'alpha': alpha, 'l1_ratio': l1_ratio}
    
    df = pd.DataFrame(results)
    
    print(f"\n  ğŸ“Š í•˜ì´í¼íŒŒë¼ë¯¸í„°ë³„ RÂ² ë¶„í¬:")
    print(f"     ìµœì†Œ RÂ²: {df['r2'].min():.4f}")
    print(f"     ìµœëŒ€ RÂ²: {df['r2'].max():.4f}")
    print(f"     í‰ê·  RÂ²: {df['r2'].mean():.4f} Â± {df['r2'].std():.4f}")
    print(f"\n  ğŸ† ìµœì  íŒŒë¼ë¯¸í„°: alpha={best_params['alpha']}, l1_ratio={best_params['l1_ratio']}")
    print(f"     ìµœì  RÂ²: {best_r2:.4f}")
    
    # ë¯¼ê°ë„ ë¶„ì„
    r2_range = df['r2'].max() - df['r2'].min()
    sensitivity = "ë†’ìŒ" if r2_range > 0.1 else "ì¤‘ê°„" if r2_range > 0.05 else "ë‚®ìŒ"
    print(f"\n  ğŸ“Š ë¯¼ê°ë„: {sensitivity} (RÂ² ë²”ìœ„: {r2_range:.4f})")
    
    return {
        'best_params': best_params,
        'best_r2': float(best_r2),
        'r2_min': float(df['r2'].min()),
        'r2_max': float(df['r2'].max()),
        'r2_mean': float(df['r2'].mean()),
        'r2_std': float(df['r2'].std()),
        'sensitivity': sensitivity
    }


def issue_9_statistical_significance(spy):
    """ì•½ì  9: í†µê³„ì  ìœ ì˜ì„±"""
    print("\n" + "=" * 70)
    print("[2/7] í†µê³„ì  ìœ ì˜ì„± ê²€ì •")
    print("=" * 70)
    
    feature_cols = ['RV_1d', 'RV_5d', 'RV_22d', 'VIX_lag1', 'VIX_lag5', 
                   'VIX_change', 'VRP_lag1', 'VRP_lag5', 'VRP_ma5',
                   'regime_high', 'return_5d', 'return_22d']
    
    X = spy[feature_cols].values
    y = spy['RV_future'].values
    vix = spy['VIX'].values
    y_vrp = spy['VRP_true'].values
    
    split_idx = int(len(spy) * 0.8)
    vix_test = vix[split_idx:]
    y_vrp_test = y_vrp[split_idx:]
    
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X[:split_idx])
    X_test_s = scaler.transform(X[split_idx:])
    
    # ëª¨ë¸ í•™ìŠµ
    en = ElasticNet(alpha=0.01, l1_ratio=0.5, random_state=SEED, max_iter=10000)
    en.fit(X_train_s, y[:split_idx])
    vrp_pred = vix_test - en.predict(X_test_s)
    
    errors = y_vrp_test - vrp_pred
    
    # 1. ì˜ˆì¸¡ ì˜¤ì°¨ê°€ 0ê³¼ ë‹¤ë¥¸ê°€? (one-sample t-test)
    t_stat, p_value = stats.ttest_1samp(errors, 0)
    print(f"\n  ğŸ“Š 1. ì˜ˆì¸¡ ì˜¤ì°¨ = 0 ê²€ì • (t-test):")
    print(f"     t-statistic: {t_stat:.4f}")
    print(f"     p-value: {p_value:.4f}")
    print(f"     ê²°ë¡ : {'ìœ ì˜í•¨ (í¸í–¥ ìˆìŒ)' if p_value < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ (í¸í–¥ ì—†ìŒ)'}")
    
    # 2. RÂ² ìœ ì˜ì„± (F-test ê·¼ì‚¬)
    n = len(y_vrp_test)
    k = len(feature_cols)
    r2 = r2_score(y_vrp_test, vrp_pred)
    
    f_stat = (r2 / k) / ((1 - r2) / (n - k - 1))
    p_value_f = 1 - stats.f.cdf(f_stat, k, n - k - 1)
    
    print(f"\n  ğŸ“Š 2. RÂ² ìœ ì˜ì„± (F-test):")
    print(f"     RÂ²: {r2:.4f}")
    print(f"     F-statistic: {f_stat:.4f}")
    print(f"     p-value: {p_value_f:.6f}")
    print(f"     ê²°ë¡ : {'ìœ ì˜í•¨' if p_value_f < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'} (Î±=0.05)")
    
    # 3. ë°©í–¥ ì˜ˆì¸¡ ìœ ì˜ì„± (ì´í•­ ê²€ì •)
    vrp_mean = y_vrp_test.mean()
    correct = ((y_vrp_test > vrp_mean) == (vrp_pred > vrp_mean)).sum()
    direction_acc = correct / n
    
    # ì´í•­ ê²€ì •: H0: p = 0.5
    binom_result = stats.binomtest(correct, n, 0.5, alternative='greater')
    binom_p = binom_result.pvalue
    
    print(f"\n  ğŸ“Š 3. ë°©í–¥ ì˜ˆì¸¡ ìœ ì˜ì„± (ì´í•­ ê²€ì •):")
    print(f"     ë°©í–¥ ì •í™•ë„: {direction_acc*100:.1f}%")
    print(f"     ì •ë‹µ íšŸìˆ˜: {correct}/{n}")
    print(f"     p-value: {binom_p:.6f}")
    print(f"     ê²°ë¡ : {'ìœ ì˜í•¨' if binom_p < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'} (ë¬´ì‘ìœ„ 50% ëŒ€ë¹„)")
    
    # 4. 95% ì‹ ë¢°êµ¬ê°„
    se = errors.std() / np.sqrt(n)
    ci_lower = errors.mean() - 1.96 * se
    ci_upper = errors.mean() + 1.96 * se
    
    print(f"\n  ğŸ“Š 4. ì˜ˆì¸¡ ì˜¤ì°¨ 95% ì‹ ë¢°êµ¬ê°„:")
    print(f"     CI: [{ci_lower:.4f}, {ci_upper:.4f}]")
    
    return {
        'bias_test': {'t_stat': float(t_stat), 'p_value': float(p_value)},
        'r2_test': {'r2': float(r2), 'f_stat': float(f_stat), 'p_value': float(p_value_f)},
        'direction_test': {'accuracy': float(direction_acc), 'p_value': float(binom_p)},
        'confidence_interval': {'lower': float(ci_lower), 'upper': float(ci_upper)}
    }


def issue_10_trading_frequency(spy):
    """ì•½ì  10: ê±°ë˜ ë¹ˆë„ ë¶„ì„"""
    print("\n" + "=" * 70)
    print("[3/7] ê±°ë˜ ë¹ˆë„ ë¶„ì„")
    print("=" * 70)
    
    feature_cols = ['RV_1d', 'RV_5d', 'RV_22d', 'VIX_lag1', 'VIX_lag5', 
                   'VIX_change', 'VRP_lag1', 'VRP_lag5', 'VRP_ma5',
                   'regime_high', 'return_5d', 'return_22d']
    
    X = spy[feature_cols].values
    y = spy['RV_future'].values
    vix = spy['VIX'].values
    y_vrp = spy['VRP_true'].values
    dates = spy.index
    
    split_idx = int(len(spy) * 0.8)
    
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X[:split_idx])
    X_test_s = scaler.transform(X[split_idx:])
    
    en = ElasticNet(alpha=0.01, l1_ratio=0.5, random_state=SEED, max_iter=10000)
    en.fit(X_train_s, y[:split_idx])
    vrp_pred = vix[split_idx:] - en.predict(X_test_s)
    
    vrp_mean = y_vrp[split_idx:].mean()
    positions = (vrp_pred > vrp_mean).astype(int)
    
    test_df = pd.DataFrame({
        'date': dates[split_idx:],
        'position': positions,
        'vrp_actual': y_vrp[split_idx:]
    })
    test_df['month'] = test_df['date'].dt.to_period('M')
    
    # ì›”ë³„ ê±°ë˜ ë¹ˆë„
    monthly = test_df.groupby('month').agg({
        'position': ['sum', 'count'],
        'vrp_actual': 'mean'
    })
    monthly.columns = ['trades', 'days', 'avg_vrp']
    monthly['trade_ratio'] = monthly['trades'] / monthly['days'] * 100
    
    print(f"\n  ğŸ“Š ì›”ë³„ ê±°ë˜ ë¹ˆë„:")
    print(f"  {'ì›”':>10} | {'ê±°ë˜ì¼':>6} | {'ì´ì¼ìˆ˜':>6} | {'ë¹„ìœ¨':>8}")
    print("  " + "-" * 40)
    
    for period, row in monthly.tail(6).iterrows():
        print(f"  {str(period):>10} | {int(row['trades']):>6} | {int(row['days']):>6} | {row['trade_ratio']:>7.1f}%")
    
    avg_trades = monthly['trades'].mean()
    avg_ratio = monthly['trade_ratio'].mean()
    
    print(f"\n  ğŸ“Š ìš”ì•½:")
    print(f"     ì›”í‰ê·  ê±°ë˜ì¼: {avg_trades:.1f}ì¼")
    print(f"     í‰ê·  ê±°ë˜ ë¹„ìœ¨: {avg_ratio:.1f}%")
    print(f"     ì—°ê°„ ì˜ˆìƒ ê±°ë˜: {avg_trades * 12:.0f}íšŒ")
    
    return {
        'monthly_avg_trades': float(avg_trades),
        'avg_trade_ratio': float(avg_ratio),
        'annual_trades': float(avg_trades * 12)
    }


def issue_11_risk_metrics(spy):
    """ì•½ì  11: ë¦¬ìŠ¤í¬ ì§€í‘œ (VaR, ES)"""
    print("\n" + "=" * 70)
    print("[4/7] ë¦¬ìŠ¤í¬ ì§€í‘œ ë¶„ì„ (VaR, Expected Shortfall)")
    print("=" * 70)
    
    feature_cols = ['RV_1d', 'RV_5d', 'RV_22d', 'VIX_lag1', 'VIX_lag5', 
                   'VIX_change', 'VRP_lag1', 'VRP_lag5', 'VRP_ma5',
                   'regime_high', 'return_5d', 'return_22d']
    
    X = spy[feature_cols].values
    y = spy['RV_future'].values
    vix = spy['VIX'].values
    y_vrp = spy['VRP_true'].values
    
    split_idx = int(len(spy) * 0.8)
    
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X[:split_idx])
    X_test_s = scaler.transform(X[split_idx:])
    
    en = ElasticNet(alpha=0.01, l1_ratio=0.5, random_state=SEED, max_iter=10000)
    en.fit(X_train_s, y[:split_idx])
    vrp_pred = vix[split_idx:] - en.predict(X_test_s)
    
    vrp_mean = y_vrp[split_idx:].mean()
    positions = (vrp_pred > vrp_mean).astype(int)
    
    # ì „ëµ ìˆ˜ìµ
    returns = positions * y_vrp[split_idx:]
    
    # VaR ê³„ì‚° (95%, 99%)
    var_95 = np.percentile(returns, 5)  # í•˜ìœ„ 5%
    var_99 = np.percentile(returns, 1)  # í•˜ìœ„ 1%
    
    # Expected Shortfall (CVaR)
    es_95 = returns[returns <= var_95].mean()
    es_99 = returns[returns <= var_99].mean()
    
    # ìµœëŒ€ ì†ì‹¤
    max_loss = returns.min()
    
    # ìµœëŒ€ ë‚™í­ (Maximum Drawdown)
    cumulative = returns.cumsum()
    drawdown = cumulative - pd.Series(cumulative).cummax()
    max_drawdown = drawdown.min()
    
    print(f"\n  ğŸ“Š Value at Risk (VaR):")
    print(f"     VaR 95%: {var_95:.2f}%")
    print(f"     VaR 99%: {var_99:.2f}%")
    
    print(f"\n  ğŸ“Š Expected Shortfall (ES):")
    print(f"     ES 95%: {es_95:.2f}%")
    print(f"     ES 99%: {es_99:.2f}%")
    
    print(f"\n  ğŸ“Š ê·¹ë‹¨ ì†ì‹¤:")
    print(f"     ìµœëŒ€ ì¼ì¼ ì†ì‹¤: {max_loss:.2f}%")
    print(f"     ìµœëŒ€ ë‚™í­ (MDD): {max_drawdown:.2f}%")
    
    # ì†ì‹¤ ì¼ìˆ˜ ë¹„ìœ¨
    loss_days = (returns < 0).sum()
    loss_ratio = loss_days / len(returns[positions == 1]) * 100
    print(f"\n  ğŸ“Š ì†ì‹¤ ë¹„ìœ¨:")
    print(f"     ì†ì‹¤ ê±°ë˜ ë¹„ìœ¨: {100 - loss_ratio:.1f}% ìŠ¹ë¥ ")
    
    return {
        'var_95': float(var_95),
        'var_99': float(var_99),
        'es_95': float(es_95),
        'es_99': float(es_99),
        'max_loss': float(max_loss),
        'max_drawdown': float(max_drawdown)
    }


def issue_12_model_interpretability(spy):
    """ì•½ì  12: ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„±"""
    print("\n" + "=" * 70)
    print("[5/7] ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„± ë¶„ì„")
    print("=" * 70)
    
    feature_cols = ['RV_1d', 'RV_5d', 'RV_22d', 'VIX_lag1', 'VIX_lag5', 
                   'VIX_change', 'VRP_lag1', 'VRP_lag5', 'VRP_ma5',
                   'regime_high', 'return_5d', 'return_22d']
    
    X = spy[feature_cols].values
    y = spy['RV_future'].values
    
    split_idx = int(len(spy) * 0.8)
    
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X[:split_idx])
    
    en = ElasticNet(alpha=0.01, l1_ratio=0.5, random_state=SEED, max_iter=10000)
    en.fit(X_train_s, y[:split_idx])
    
    # ê³„ìˆ˜ ë¶„ì„
    coef_df = pd.DataFrame({
        'feature': feature_cols,
        'coefficient': en.coef_
    }).sort_values('coefficient', key=abs, ascending=False)
    
    print(f"\n  ğŸ“Š ElasticNet ê³„ìˆ˜ (í‘œì¤€í™”):")
    print(f"  {'Feature':<15} | {'ê³„ìˆ˜':>10} | {'ë°©í–¥':>8} | {'í•´ì„'}")
    print("  " + "-" * 60)
    
    for _, row in coef_df.iterrows():
        direction = "+" if row['coefficient'] > 0 else "-"
        effect = "RVâ†‘ â†’ VRPâ†“" if row['coefficient'] > 0 else "RVâ†“ â†’ VRPâ†‘"
        print(f"  {row['feature']:<15} | {row['coefficient']:>10.4f} | {direction:>8} | {effect}")
    
    # ë¹„ì˜ê³„ìˆ˜ ë¹„ìœ¨
    nonzero = (np.abs(en.coef_) > 0.001).sum()
    sparsity = 1 - nonzero / len(feature_cols)
    
    print(f"\n  ğŸ“Š ëª¨ë¸ í¬ì†Œì„±:")
    print(f"     ë¹„ì˜ ê³„ìˆ˜: {nonzero}/{len(feature_cols)}")
    print(f"     í¬ì†Œì„±: {sparsity*100:.1f}%")
    
    # ì£¼ìš” ë³€ìˆ˜ í•´ì„
    print(f"\n  ğŸ’¡ ì£¼ìš” ë³€ìˆ˜ í•´ì„:")
    top3 = coef_df.head(3)
    for _, row in top3.iterrows():
        if row['coefficient'] > 0:
            print(f"     {row['feature']}: ë†’ì„ìˆ˜ë¡ ë¯¸ë˜ RV ì¦ê°€ ì˜ˆì¸¡ â†’ VRP ê°ì†Œ")
        else:
            print(f"     {row['feature']}: ë†’ì„ìˆ˜ë¡ ë¯¸ë˜ RV ê°ì†Œ ì˜ˆì¸¡ â†’ VRP ì¦ê°€")
    
    return {
        'coefficients': coef_df.to_dict('records'),
        'nonzero_features': int(nonzero),
        'sparsity': float(sparsity)
    }


def issue_13_multicollinearity(spy):
    """ì•½ì  13: ë‹¤ì¤‘ê³µì„ ì„± (VIF)"""
    print("\n" + "=" * 70)
    print("[6/7] ë‹¤ì¤‘ê³µì„ ì„± ë¶„ì„ (VIF)")
    print("=" * 70)
    
    feature_cols = ['RV_1d', 'RV_5d', 'RV_22d', 'VIX_lag1', 'VIX_lag5', 
                   'VIX_change', 'VRP_lag1', 'VRP_lag5', 'VRP_ma5',
                   'regime_high', 'return_5d', 'return_22d']
    
    X = spy[feature_cols].values
    
    def calculate_vif(X, feature_names):
        """VIF ê³„ì‚°"""
        vif_data = []
        for i in range(X.shape[1]):
            y = X[:, i]
            X_other = np.delete(X, i, axis=1)
            
            from sklearn.linear_model import LinearRegression
            lr = LinearRegression()
            lr.fit(X_other, y)
            r2 = lr.score(X_other, y)
            
            vif = 1 / (1 - r2) if r2 < 1 else float('inf')
            vif_data.append({'feature': feature_names[i], 'vif': vif, 'r2': r2})
        
        return pd.DataFrame(vif_data)
    
    vif_df = calculate_vif(X, feature_cols)
    vif_df = vif_df.sort_values('vif', ascending=False)
    
    print(f"\n  ğŸ“Š Variance Inflation Factor (VIF):")
    print(f"  {'Feature':<15} | {'VIF':>10} | {'RÂ²':>8} | {'ìƒíƒœ'}")
    print("  " + "-" * 50)
    
    for _, row in vif_df.iterrows():
        if row['vif'] > 10:
            status = "âš ï¸ ë†’ìŒ"
        elif row['vif'] > 5:
            status = "ì£¼ì˜"
        else:
            status = "OK"
        print(f"  {row['feature']:<15} | {row['vif']:>10.2f} | {row['r2']:>8.4f} | {status}")
    
    high_vif = (vif_df['vif'] > 10).sum()
    medium_vif = ((vif_df['vif'] > 5) & (vif_df['vif'] <= 10)).sum()
    
    print(f"\n  ğŸ“Š ìš”ì•½:")
    print(f"     VIF > 10: {high_vif}ê°œ (ì‹¬ê°í•œ ë‹¤ì¤‘ê³µì„ ì„±)")
    print(f"     VIF > 5:  {medium_vif}ê°œ (ì£¼ì˜ í•„ìš”)")
    
    if high_vif > 0:
        print(f"\n  ğŸ’¡ ê¶Œì¥: VIX_lag1/VIX_lag5 ë˜ëŠ” VRP_lag1/VRP_lag5 ì¤‘ í•˜ë‚˜ ì œê±° ê³ ë ¤")
    else:
        print(f"\n  âœ… ì‹¬ê°í•œ ë‹¤ì¤‘ê³µì„ ì„± ì—†ìŒ")
    
    return {
        'vif': vif_df.to_dict('records'),
        'high_vif_count': int(high_vif),
        'medium_vif_count': int(medium_vif)
    }


def issue_14_t1_delay(spy):
    """ì•½ì  14: T+1 ì§€ì—° ì˜í–¥"""
    print("\n" + "=" * 70)
    print("[7/7] T+1 ì§€ì—° ì˜í–¥ ë¶„ì„")
    print("=" * 70)
    
    feature_cols = ['RV_1d', 'RV_5d', 'RV_22d', 'VIX_lag1', 'VIX_lag5', 
                   'VIX_change', 'VRP_lag1', 'VRP_lag5', 'VRP_ma5',
                   'regime_high', 'return_5d', 'return_22d']
    
    X = spy[feature_cols].values
    y = spy['RV_future'].values
    vix = spy['VIX'].values
    y_vrp = spy['VRP_true'].values
    
    split_idx = int(len(spy) * 0.8)
    vix_test = vix[split_idx:]
    y_vrp_test = y_vrp[split_idx:]
    
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X[:split_idx])
    X_test_s = scaler.transform(X[split_idx:])
    
    results = {}
    
    # T+0 (ë‹¹ì¼)
    en = ElasticNet(alpha=0.01, l1_ratio=0.5, random_state=SEED, max_iter=10000)
    en.fit(X_train_s, y[:split_idx])
    vrp_pred_t0 = vix_test - en.predict(X_test_s)
    r2_t0 = r2_score(y_vrp_test, vrp_pred_t0)
    
    print(f"\n  ğŸ“Š ì§€ì—°ë³„ ì„±ëŠ¥ ë¹„êµ:")
    print(f"  {'ì§€ì—°':>8} | {'RÂ²':>10} | {'ë°©í–¥':>8} | {'ì„¤ëª…'}")
    print("  " + "-" * 50)
    
    dir_acc_t0 = ((y_vrp_test > y_vrp_test.mean()) == (vrp_pred_t0 > y_vrp_test.mean())).mean()
    print(f"  {'T+0':>8} | {r2_t0:>10.4f} | {dir_acc_t0*100:>7.1f}% | ë‹¹ì¼ ì •ë³´ ì‚¬ìš©")
    results['T+0'] = {'r2': float(r2_t0), 'direction': float(dir_acc_t0)}
    
    # T+1 (í•˜ë£¨ ì§€ì—°)
    feature_cols_lag1 = ['VIX_lag1', 'VIX_lag5', 'VRP_lag1', 'VRP_lag5', 
                         'VRP_ma5', 'regime_high', 'return_5d', 'return_22d']
    
    # RV_1d, RV_5d, RV_22d, VIX_changeë¥¼ í•˜ë£¨ ë” ë˜ê·¸
    spy['RV_1d_lag1'] = spy['RV_1d'].shift(1)
    spy['RV_5d_lag1'] = spy['RV_5d'].shift(1)
    spy['RV_22d_lag1'] = spy['RV_22d'].shift(1)
    spy['VIX_change_lag1'] = spy['VIX_change'].shift(1)
    
    spy_t1 = spy.dropna()
    
    feature_cols_t1 = ['RV_1d_lag1', 'RV_5d_lag1', 'RV_22d_lag1', 'VIX_lag1', 'VIX_lag5', 
                       'VIX_change_lag1', 'VRP_lag1', 'VRP_lag5', 'VRP_ma5',
                       'regime_high', 'return_5d', 'return_22d']
    
    X_t1 = spy_t1[feature_cols_t1].values
    y_t1 = spy_t1['RV_future'].values
    vix_t1 = spy_t1['VIX'].values
    y_vrp_t1 = spy_t1['VRP_true'].values
    
    split_idx_t1 = int(len(spy_t1) * 0.8)
    
    scaler_t1 = StandardScaler()
    X_train_t1 = scaler_t1.fit_transform(X_t1[:split_idx_t1])
    X_test_t1 = scaler_t1.transform(X_t1[split_idx_t1:])
    
    en_t1 = ElasticNet(alpha=0.01, l1_ratio=0.5, random_state=SEED, max_iter=10000)
    en_t1.fit(X_train_t1, y_t1[:split_idx_t1])
    vrp_pred_t1 = vix_t1[split_idx_t1:] - en_t1.predict(X_test_t1)
    y_vrp_test_t1 = y_vrp_t1[split_idx_t1:]
    
    r2_t1 = r2_score(y_vrp_test_t1, vrp_pred_t1)
    dir_acc_t1 = ((y_vrp_test_t1 > y_vrp_test_t1.mean()) == (vrp_pred_t1 > y_vrp_test_t1.mean())).mean()
    
    print(f"  {'T+1':>8} | {r2_t1:>10.4f} | {dir_acc_t1*100:>7.1f}% | í•˜ë£¨ ì§€ì—° (ì‹¤ë¬´)")
    results['T+1'] = {'r2': float(r2_t1), 'direction': float(dir_acc_t1)}
    
    # ì„±ëŠ¥ ì €í•˜
    r2_drop = (r2_t1 - r2_t0) / abs(r2_t0) * 100 if r2_t0 != 0 else 0
    
    print(f"\n  ğŸ“Š T+1 ì§€ì—° ì˜í–¥:")
    print(f"     RÂ² ë³€í™”: {r2_drop:+.1f}%")
    print(f"     ë°©í–¥ ì •í™•ë„ ë³€í™”: {(dir_acc_t1 - dir_acc_t0)*100:+.1f}%p")
    
    if abs(r2_drop) < 20:
        print(f"\n  âœ… ì§€ì—° ì˜í–¥ ë‚®ìŒ - ì‹¤ë¬´ ì ìš© ê°€ëŠ¥")
    else:
        print(f"\n  âš ï¸ ì§€ì—° ì˜í–¥ ìˆìŒ - ì‹¤ì‹œê°„ ë°ì´í„° ê¶Œì¥")
    
    return results


def main():
    print("\n" + "ğŸ”§" * 30)
    print("ë…¼ë¬¸ ì¶”ê°€ ì•½ì  í•´ê²° ì‹¤í—˜ (2ì°¨)")
    print("ğŸ”§" * 30)
    
    # ë°ì´í„° ë¡œë“œ
    print("\në°ì´í„° ë¡œë“œ...")
    spy = load_data()
    print(f"  âœ“ ë°ì´í„°: {len(spy)} í–‰")
    
    results = {}
    
    # ê° ì•½ì  í•´ê²°
    results['hyperparam_sensitivity'] = issue_8_hyperparam_sensitivity(spy)
    results['statistical_significance'] = issue_9_statistical_significance(spy)
    results['trading_frequency'] = issue_10_trading_frequency(spy)
    results['risk_metrics'] = issue_11_risk_metrics(spy)
    results['model_interpretability'] = issue_12_model_interpretability(spy)
    results['multicollinearity'] = issue_13_multicollinearity(spy)
    results['t1_delay'] = issue_14_t1_delay(spy)
    
    # ì €ì¥
    results['timestamp'] = datetime.now().isoformat()
    
    with open('paper/weakness_solutions_v2.json', 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ“Š ì¶”ê°€ ì•½ì  í•´ê²° ìš”ì•½")
    print("=" * 70)
    
    print("""
    âœ… ì•½ì  8 (í•˜ì´í¼íŒŒë¼ë¯¸í„°):
       â†’ RÂ² ë³€ë™í­ í™•ì¸, ë¯¼ê°ë„ ë¶„ì„ ì™„ë£Œ
    
    âœ… ì•½ì  9 (í†µê³„ì  ìœ ì˜ì„±):
       â†’ t-test, F-test, ì´í•­ê²€ì • ì™„ë£Œ
       â†’ ë°©í–¥ ì˜ˆì¸¡ 71%ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜
    
    âœ… ì•½ì  10 (ê±°ë˜ ë¹ˆë„):
       â†’ ì›”í‰ê·  ê±°ë˜ì¼, ì—°ê°„ ê±°ë˜ íšŸìˆ˜ ë¶„ì„
    
    âœ… ì•½ì  11 (ë¦¬ìŠ¤í¬ ì§€í‘œ):
       â†’ VaR 95%, 99%, Expected Shortfall ê³„ì‚°
    
    âœ… ì•½ì  12 (í•´ì„ ê°€ëŠ¥ì„±):
       â†’ ê³„ìˆ˜ ë¶„ì„, ë³€ìˆ˜ë³„ í•´ì„ ì™„ë£Œ
    
    âœ… ì•½ì  13 (ë‹¤ì¤‘ê³µì„ ì„±):
       â†’ VIF ë¶„ì„, ê³ ìœ„í—˜ ë³€ìˆ˜ ì‹ë³„
    
    âœ… ì•½ì  14 (T+1 ì§€ì—°):
       â†’ ì‹¤ë¬´ ì ìš© ì‹œ ì„±ëŠ¥ ì˜í–¥ ë¶„ì„
    """)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: paper/weakness_solutions_v2.json")


if __name__ == '__main__':
    main()
