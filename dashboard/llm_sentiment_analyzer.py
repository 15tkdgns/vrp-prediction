#!/usr/bin/env python3
"""
LLM ê¸°ë°˜ ë‰´ìŠ¤ ê°ì • ë¶„ì„ê¸°
- Claudeì™€ GPTë¥¼ í™œìš©í•œ ë‹¤ì¸µ ê°ì • ë¶„ì„
- SPY/ì‹œìž¥ ì˜í–¥ë„ í‰ê°€
- ë°°ì¹˜ ì²˜ë¦¬ ë° ë¹„ìš© ìµœì í™”
"""

import os
import json
import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
import logging
from dataclasses import dataclass
import anthropic
import openai
from news_data_collector import NewsArticle

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SentimentAnalysis:
    """ê°ì • ë¶„ì„ ê²°ê³¼"""
    sentiment_score: float  # -1.0 to +1.0
    market_impact: float    # 0.0 to 1.0
    spy_relevance: float    # 0.0 to 1.0
    confidence: float       # 0.0 to 1.0
    reasoning: str
    analysis_time: datetime
    llm_model: str

class LLMSentimentAnalyzer:
    """
    ë‹¤ì¤‘ LLM ê¸°ë°˜ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ
    """
    
    def __init__(self):
        # API í‚¤ ë¡œë“œ
        self.anthropic_key = os.getenv('ANTHROPIC_API_KEY')
        self.openai_key = os.getenv('OPENAI_API_KEY')
        
        # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if self.anthropic_key:
            self.anthropic_client = anthropic.Anthropic(api_key=self.anthropic_key)
        else:
            self.anthropic_client = None
            
        if self.openai_key:
            openai.api_key = self.openai_key
            self.openai_client = openai
        else:
            self.openai_client = None
        
        # ëª¨ë¸ ì„¤ì •
        self.models = {
            'claude': {
                'model': 'claude-3-haiku-20240307',
                'cost_per_token': 0.00025,  # ìž…ë ¥ í† í°ë‹¹ ë¹„ìš©
                'max_tokens': 4000,
                'temperature': 0.3
            },
            'gpt': {
                'model': 'gpt-4o-mini',
                'cost_per_token': 0.00015,
                'max_tokens': 4000, 
                'temperature': 0.3
            }
        }
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.sentiment_prompt = self._create_sentiment_prompt()
        
    def _create_sentiment_prompt(self) -> str:
        """ê°ì • ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return """
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ S&P 500 ì§€ìˆ˜(SPY ETF)ì— ëŒ€í•œ ì˜í–¥ì„ ì •í™•ížˆ í‰ê°€í•´ì£¼ì„¸ìš”.

ë‰´ìŠ¤ ì œëª©: {title}
ë‰´ìŠ¤ ìš”ì•½: {description}
ë°œí–‰ì¼: {date}
ë‰´ìŠ¤ ì†ŒìŠ¤: {source}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ì‹ ì¤‘í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ê°ì • ì ìˆ˜ (-1.0 ~ +1.0):
   - +1.0: ë§¤ìš° ê¸ì •ì  (ê°•í•œ ìƒìŠ¹ ìš”ì¸)
   - 0.0: ì¤‘ë¦½ì  (ì˜í–¥ ì—†ìŒ)
   - -1.0: ë§¤ìš° ë¶€ì •ì  (ê°•í•œ í•˜ë½ ìš”ì¸)

2. ì‹œìž¥ ì˜í–¥ë„ (0.0 ~ 1.0):
   - 1.0: í° ì˜í–¥ (ì‹œìž¥ ì „ì²´ë¥¼ ì›€ì§ì¼ ìˆ˜ ìžˆìŒ)
   - 0.5: ë³´í†µ ì˜í–¥ (ì¼ë¶€ ë°˜ì‘ ì˜ˆìƒ)
   - 0.0: ì˜í–¥ ì—†ìŒ (ì‹œìž¥ ë¬´ê´€ì‹¬)

3. SPY ê´€ë ¨ë„ (0.0 ~ 1.0):
   - 1.0: ì§ì ‘ ê´€ë ¨ (S&P 500 ì „ì²´ì— ì˜í–¥)
   - 0.5: ê°„ì ‘ ê´€ë ¨ (ì£¼ìš” ì„¹í„°ì— ì˜í–¥)
   - 0.0: ë¬´ê´€ (SPYì— ì˜í–¥ ì—†ìŒ)

4. ì‹ ë¢°ë„ (0.0 ~ 1.0):
   - ë¶„ì„ì˜ í™•ì‹¤ì„± ì •ë„
   - ë‰´ìŠ¤ì˜ ëª…í™•ì„±ê³¼ ì‹ ë¢°ì„± ê³ ë ¤

ì¤‘ìš” ê³ ë ¤ì‚¬í•­:
- Fed ê¸ˆë¦¬, ì¸í”Œë ˆì´ì…˜, GDP ë“± ê±°ì‹œê²½ì œ ì§€í‘œëŠ” ë†’ì€ ì˜í–¥ë„
- ê°œë³„ ê¸°ì—… ë‰´ìŠ¤ëŠ” í•´ë‹¹ ê¸°ì—…ì´ SPYì—ì„œ ì°¨ì§€í•˜ëŠ” ë¹„ì¤‘ ê³ ë ¤
- ì§€ì •í•™ì  ë¦¬ìŠ¤í¬, ì „ìŸ, íŒ¬ë°ë¯¹ ë“±ì€ ë†’ì€ ì˜í–¥ë„
- ë‹¨ìˆœ ë£¨ë¨¸ë‚˜ ì¶”ì¸¡ì„± ê¸°ì‚¬ëŠ” ë‚®ì€ ì‹ ë¢°ë„

JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "sentiment_score": float,
    "market_impact": float, 
    "spy_relevance": float,
    "confidence": float,
    "reasoning": "ë¶„ì„ ê·¼ê±°ë¥¼ 2-3ë¬¸ìž¥ìœ¼ë¡œ ì„¤ëª…"
}}
"""
    
    async def analyze_with_claude(self, article: NewsArticle) -> Optional[SentimentAnalysis]:
        """Claudeë¥¼ ì‚¬ìš©í•œ ê°ì • ë¶„ì„"""
        if not self.anthropic_client:
            logger.warning("Claude API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self.sentiment_prompt.format(
                title=article.title,
                description=article.description,
                date=article.published_at.strftime('%Y-%m-%d'),
                source=article.source
            )
            
            # Claude API í˜¸ì¶œ
            response = self.anthropic_client.messages.create(
                model=self.models['claude']['model'],
                max_tokens=self.models['claude']['max_tokens'],
                temperature=self.models['claude']['temperature'],
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            # ì‘ë‹µ íŒŒì‹±
            content = response.content[0].text
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                result = json.loads(content)
                
                return SentimentAnalysis(
                    sentiment_score=float(result['sentiment_score']),
                    market_impact=float(result['market_impact']),
                    spy_relevance=float(result['spy_relevance']),
                    confidence=float(result['confidence']),
                    reasoning=result['reasoning'],
                    analysis_time=datetime.now(),
                    llm_model='claude-3-haiku'
                )
                
            except json.JSONDecodeError:
                logger.error(f"Claude ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {content[:200]}...")
                return None
                
        except Exception as e:
            logger.error(f"Claude ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return None
    
    async def analyze_with_gpt(self, article: NewsArticle) -> Optional[SentimentAnalysis]:
        """GPTë¥¼ ì‚¬ìš©í•œ ê°ì • ë¶„ì„"""
        if not self.openai_client:
            logger.warning("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self.sentiment_prompt.format(
                title=article.title,
                description=article.description,
                date=article.published_at.strftime('%Y-%m-%d'),
                source=article.source
            )
            
            # GPT API í˜¸ì¶œ
            response = await self.openai_client.ChatCompletion.acreate(
                model=self.models['gpt']['model'],
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸ˆìœµ ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. ì •í™•í•˜ê³  ê°ê´€ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.models['gpt']['max_tokens'],
                temperature=self.models['gpt']['temperature']
            )
            
            # ì‘ë‹µ íŒŒì‹±
            content = response.choices[0].message.content
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                result = json.loads(content)
                
                return SentimentAnalysis(
                    sentiment_score=float(result['sentiment_score']),
                    market_impact=float(result['market_impact']),
                    spy_relevance=float(result['spy_relevance']),
                    confidence=float(result['confidence']),
                    reasoning=result['reasoning'],
                    analysis_time=datetime.now(),
                    llm_model='gpt-4o-mini'
                )
                
            except json.JSONDecodeError:
                logger.error(f"GPT ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {content[:200]}...")
                return None
                
        except Exception as e:
            logger.error(f"GPT ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def ensemble_analysis(self, claude_result: Optional[SentimentAnalysis], 
                         gpt_result: Optional[SentimentAnalysis]) -> Optional[SentimentAnalysis]:
        """
        ë‘ LLM ê²°ê³¼ë¥¼ ì•™ìƒë¸”í•˜ì—¬ ìµœì¢… ë¶„ì„ ìƒì„±
        """
        if not claude_result and not gpt_result:
            return None
        
        if claude_result and not gpt_result:
            return claude_result
        
        if gpt_result and not claude_result:
            return gpt_result
        
        # ë‘ ê²°ê³¼ ëª¨ë‘ ìžˆì„ ë•Œ ê°€ì¤‘í‰ê· 
        # ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜
        claude_weight = claude_result.confidence
        gpt_weight = gpt_result.confidence
        total_weight = claude_weight + gpt_weight
        
        if total_weight == 0:
            return claude_result  # ê¸°ë³¸ê°’
        
        # ê°€ì¤‘í‰ê·  ê³„ì‚°
        sentiment_score = (claude_result.sentiment_score * claude_weight + 
                          gpt_result.sentiment_score * gpt_weight) / total_weight
        
        market_impact = (claude_result.market_impact * claude_weight + 
                        gpt_result.market_impact * gpt_weight) / total_weight
        
        spy_relevance = (claude_result.spy_relevance * claude_weight + 
                        gpt_result.spy_relevance * gpt_weight) / total_weight
        
        confidence = max(claude_result.confidence, gpt_result.confidence)  # ë†’ì€ ì‹ ë¢°ë„ ì„ íƒ
        
        # í•©ì„± reasoning
        reasoning = f"Claude: {claude_result.reasoning[:100]}... | GPT: {gpt_result.reasoning[:100]}..."
        
        return SentimentAnalysis(
            sentiment_score=sentiment_score,
            market_impact=market_impact,
            spy_relevance=spy_relevance,
            confidence=confidence,
            reasoning=reasoning,
            analysis_time=datetime.now(),
            llm_model='ensemble'
        )
    
    async def analyze_single_article(self, article: NewsArticle) -> Optional[SentimentAnalysis]:
        """ë‹¨ì¼ ê¸°ì‚¬ ê°ì • ë¶„ì„"""
        logger.info(f"ë¶„ì„ ì¤‘: {article.title[:50]}...")
        
        # ë³‘ë ¬ë¡œ ë‘ ëª¨ë¸ ì‹¤í–‰ (ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ ì„ íƒì )
        tasks = []
        
        if self.anthropic_client:
            tasks.append(self.analyze_with_claude(article))
        
        # GPTëŠ” ë¹„ìš©ì´ ë” ë†’ìœ¼ë¯€ë¡œ Claudeê°€ ì—†ê±°ë‚˜ ì¤‘ìš”í•œ ë‰´ìŠ¤ì¼ ë•Œë§Œ
        if self.openai_client and (not self.anthropic_client or article.spy_relevance > 0.7):
            tasks.append(self.analyze_with_gpt(article))
        
        if not tasks:
            logger.error("ì‚¬ìš© ê°€ëŠ¥í•œ LLM APIê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë³‘ë ¬ ì‹¤í–‰
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ ë¶„ë¦¬
        claude_result = None
        gpt_result = None
        
        for i, result in enumerate(results):
            if isinstance(result, SentimentAnalysis):
                if len(tasks) == 1 or i == 0:  # Claude ê²°ê³¼
                    claude_result = result
                else:  # GPT ê²°ê³¼
                    gpt_result = result
            else:
                logger.error(f"LLM ë¶„ì„ ì˜¤ë¥˜: {str(result)}")
        
        # ì•™ìƒë¸” ê²°ê³¼ ìƒì„±
        return self.ensemble_analysis(claude_result, gpt_result)
    
    async def analyze_batch(self, articles: List[NewsArticle], 
                          max_concurrent: int = 5) -> Dict[str, SentimentAnalysis]:
        """ë‰´ìŠ¤ ë°°ì¹˜ ê°ì • ë¶„ì„"""
        logger.info(f"ðŸ“Š {len(articles)}ê°œ ë‰´ìŠ¤ ë°°ì¹˜ ê°ì • ë¶„ì„ ì‹œìž‘")
        
        # ë™ì‹œ ì‹¤í–‰ ì œí•œ
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def analyze_with_semaphore(article):
            async with semaphore:
                return await self.analyze_single_article(article)
        
        # ë³‘ë ¬ ì²˜ë¦¬
        tasks = [analyze_with_semaphore(article) for article in articles]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ ì •ë¦¬
        sentiment_results = {}
        successful_analyses = 0
        
        for article, result in zip(articles, results):
            if isinstance(result, SentimentAnalysis):
                # URLì„ í‚¤ë¡œ ì‚¬ìš©
                sentiment_results[article.url] = result
                successful_analyses += 1
            else:
                logger.error(f"ë°°ì¹˜ ë¶„ì„ ì‹¤íŒ¨ ({article.title[:30]}...): {str(result)}")
        
        logger.info(f"âœ… ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {successful_analyses}/{len(articles)} ì„±ê³µ")
        return sentiment_results
    
    def calculate_daily_sentiment_score(self, sentiment_results: Dict[str, SentimentAnalysis]) -> Dict[str, float]:
        """
        ì¼ì¼ ì¢…í•© ê°ì • ì ìˆ˜ ê³„ì‚°
        """
        if not sentiment_results:
            return {
                'overall_sentiment': 0.0,
                'market_impact': 0.0,
                'confidence': 0.0,
                'total_articles': 0
            }
        
        analyses = list(sentiment_results.values())
        
        # ê°€ì¤‘í‰ê·  ê³„ì‚° (market_impact * spy_relevanceë¡œ ê°€ì¤‘ì¹˜)
        weighted_sentiment = 0.0
        weighted_impact = 0.0
        total_weight = 0.0
        confidences = []
        
        for analysis in analyses:
            weight = analysis.market_impact * analysis.spy_relevance
            weighted_sentiment += analysis.sentiment_score * weight
            weighted_impact += analysis.market_impact * weight
            total_weight += weight
            confidences.append(analysis.confidence)
        
        if total_weight == 0:
            return {
                'overall_sentiment': 0.0,
                'market_impact': 0.0,
                'confidence': 0.0,
                'total_articles': len(analyses)
            }
        
        return {
            'overall_sentiment': weighted_sentiment / total_weight,
            'market_impact': weighted_impact / total_weight,
            'confidence': sum(confidences) / len(confidences),
            'total_articles': len(analyses),
            'positive_articles': len([a for a in analyses if a.sentiment_score > 0.1]),
            'negative_articles': len([a for a in analyses if a.sentiment_score < -0.1]),
            'neutral_articles': len([a for a in analyses if -0.1 <= a.sentiment_score <= 0.1])
        }
    
    def save_sentiment_analysis(self, date: datetime, sentiment_results: Dict[str, SentimentAnalysis]):
        """ê°ì • ë¶„ì„ ê²°ê³¼ ì €ìž¥"""
        # ì¼ì¼ ì¢…í•© ì ìˆ˜ ê³„ì‚°
        daily_score = self.calculate_daily_sentiment_score(sentiment_results)
        
        # ì €ìž¥ ë°ì´í„° êµ¬ì„±
        save_data = {
            'date': date.strftime('%Y-%m-%d'),
            'analysis_time': datetime.now().isoformat(),
            'daily_summary': daily_score,
            'individual_analyses': {}
        }
        
        # ê°œë³„ ë¶„ì„ ê²°ê³¼ ì €ìž¥
        for url, analysis in sentiment_results.items():
            save_data['individual_analyses'][url] = {
                'sentiment_score': analysis.sentiment_score,
                'market_impact': analysis.market_impact,
                'spy_relevance': analysis.spy_relevance,
                'confidence': analysis.confidence,
                'reasoning': analysis.reasoning,
                'llm_model': analysis.llm_model,
                'analysis_time': analysis.analysis_time.isoformat()
            }
        
        # íŒŒì¼ ì €ìž¥
        filename = f"data/raw/sentiment_analysis_{date.strftime('%Y%m%d')}.json"
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ðŸ’¾ ê°ì • ë¶„ì„ ê²°ê³¼ ì €ìž¥: {filename}")
        logger.info(f"ðŸ“Š ì¼ì¼ ì¢…í•© ê°ì • ì ìˆ˜: {daily_score['overall_sentiment']:.3f}")

async def main():
    """ê°ì • ë¶„ì„ ì‹¤í–‰ ì˜ˆì œ"""
    analyzer = LLMSentimentAnalyzer()
    
    # ì˜ˆì œ ë‰´ìŠ¤ (ì‹¤ì œë¡œëŠ” news_data_collectorì—ì„œ ë¡œë“œ)
    sample_articles = [
        NewsArticle(
            title="Fed Cuts Interest Rates by 0.5%",
            description="The Federal Reserve announced a surprise 0.5% rate cut to combat economic slowdown.",
            content="",
            url="https://example.com/1",
            published_at=datetime.now(),
            source="Reuters",
            spy_relevance=0.9,
            market_impact_potential=0.8
        )
    ]
    
    # ê°ì • ë¶„ì„ ì‹¤í–‰
    results = await analyzer.analyze_batch(sample_articles)
    
    # ê²°ê³¼ ì €ìž¥
    analyzer.save_sentiment_analysis(datetime.now(), results)

if __name__ == "__main__":
    asyncio.run(main())