#!/usr/bin/env python3
"""
SPY ì˜ˆì¸¡ ëª¨ë¸ ì •í™•ë„ ê°œì„  ë¶„ì„ ë° êµ¬í˜„ ë°©ì•ˆ
"""

import json
import numpy as np
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

class ModelImprovementAnalyzer:
    def __init__(self):
        self.prediction_data = None
        self.actual_data = None
        
    def load_data(self):
        """í˜„ì¬ ì˜ˆì¸¡ ë°ì´í„° ë¡œë“œ"""
        with open('data/raw/spy_2025_h1_predictions.json', 'r') as f:
            self.prediction_data = json.load(f)
            
        with open('data/raw/spy_2025_h1.json', 'r') as f:
            self.actual_data = json.load(f)
            
    def analyze_current_performance(self):
        """í˜„ì¬ ëª¨ë¸ ì„±ëŠ¥ ìƒì„¸ ë¶„ì„"""
        predictions = self.prediction_data['predictions']
        
        # ì›”ë³„ ì •í™•ë„ ë¶„ì„
        monthly_accuracy = {}
        for pred in predictions:
            month = pred['date'][:7]  # YYYY-MM
            if month not in monthly_accuracy:
                monthly_accuracy[month] = {'correct': 0, 'total': 0, 'predictions': []}
            
            actual_direction = 1 if pred['actual_return'] > 0 else 0
            is_correct = actual_direction == pred['prediction']
            
            monthly_accuracy[month]['predictions'].append({
                'date': pred['date'],
                'predicted': pred['prediction'],
                'actual_direction': actual_direction,
                'correct': is_correct,
                'confidence': pred['confidence'],
                'actual_return': pred['actual_return']
            })
            
            if is_correct:
                monthly_accuracy[month]['correct'] += 1
            monthly_accuracy[month]['total'] += 1
            
        return monthly_accuracy
        
    def identify_improvement_opportunities(self):
        """ê°œì„  ê¸°íšŒ ì‹ë³„"""
        monthly_data = self.analyze_current_performance()
        
        opportunities = {
            'low_accuracy_months': [],
            'confidence_correlation': [],
            'return_magnitude_analysis': {},
            'pattern_analysis': {}
        }
        
        # ë‚®ì€ ì •í™•ë„ ì›” ì‹ë³„
        for month, data in monthly_data.items():
            accuracy = data['correct'] / data['total']
            if accuracy < 0.5:
                opportunities['low_accuracy_months'].append({
                    'month': month,
                    'accuracy': accuracy,
                    'sample_size': data['total']
                })
                
        # ì‹ ë¢°ë„ì™€ ì •í™•ë„ ìƒê´€ê´€ê³„
        all_predictions = []
        for month_data in monthly_data.values():
            all_predictions.extend(month_data['predictions'])
            
        high_conf_correct = sum(1 for p in all_predictions if p['confidence'] >= 0.7 and p['correct'])
        high_conf_total = sum(1 for p in all_predictions if p['confidence'] >= 0.7)
        low_conf_correct = sum(1 for p in all_predictions if p['confidence'] < 0.7 and p['correct'])
        low_conf_total = sum(1 for p in all_predictions if p['confidence'] < 0.7)
        
        opportunities['confidence_correlation'] = {
            'high_confidence_accuracy': high_conf_correct / high_conf_total if high_conf_total > 0 else 0,
            'low_confidence_accuracy': low_conf_correct / low_conf_total if low_conf_total > 0 else 0,
            'high_conf_sample': high_conf_total,
            'low_conf_sample': low_conf_total
        }
        
        return opportunities
        
    def generate_improvement_recommendations(self):
        """êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ ìƒì„±"""
        opportunities = self.identify_improvement_opportunities()
        
        recommendations = {
            'immediate_actions': [],
            'feature_engineering': [],
            'model_architecture': [],
            'data_enhancement': []
        }
        
        # ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­
        recommendations['immediate_actions'] = [
            {
                'action': 'Dynamic Confidence Threshold',
                'description': 'ì‹ ë¢°ë„ ê¸°ë°˜ ì˜ˆì¸¡ í•„í„°ë§ - 70% ë¯¸ë§Œ ì‹ ë¢°ë„ ì˜ˆì¸¡ ì œì™¸',
                'expected_improvement': '5-10% ì •í™•ë„ í–¥ìƒ',
                'implementation': 'confidence_threshold = 0.7'
            },
            {
                'action': 'Ensemble Method',
                'description': 'ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” (Random Forest + XGBoost + LSTM)',
                'expected_improvement': '3-7% ì •í™•ë„ í–¥ìƒ',
                'implementation': 'VotingClassifier with 3+ models'
            }
        ]
        
        # íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ê°œì„ 
        recommendations['feature_engineering'] = [
            {
                'category': 'Market Microstructure',
                'features': ['Bid-Ask Spread', 'Order Flow Imbalance', 'Tick Direction'],
                'expected_impact': 'Medium'
            },
            {
                'category': 'Cross-Asset Signals',
                'features': ['VIX', 'DXY', '10Y Treasury', 'Gold/SPY Ratio'],
                'expected_impact': 'High'
            },
            {
                'category': 'Advanced Technical',
                'features': ['Fractal Dimension', 'Hurst Exponent', 'Entropy Measures'],
                'expected_impact': 'Medium-High'
            }
        ]
        
        # ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œì„ 
        recommendations['model_architecture'] = [
            {
                'model': 'Transformer-based Time Series',
                'description': 'Attention mechanism for sequential patterns',
                'complexity': 'High',
                'expected_improvement': '10-15%'
            },
            {
                'model': 'Graph Neural Networks',
                'description': 'Sector correlation and market relationships',
                'complexity': 'Very High',
                'expected_improvement': '8-12%'
            },
            {
                'model': 'Multi-Task Learning',
                'description': 'Predict price AND direction simultaneously',
                'complexity': 'Medium',
                'expected_improvement': '5-8%'
            }
        ]
        
        return recommendations
        
    def create_implementation_roadmap(self):
        """êµ¬í˜„ ë¡œë“œë§µ ìƒì„±"""
        roadmap = {
            'Phase 1 (ì¦‰ì‹œ êµ¬í˜„ - 1ì£¼)': [
                'ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§ êµ¬í˜„',
                'VIX ë°ì´í„° ì¶”ê°€',
                'ì•™ìƒë¸” ëª¨ë¸ ê¸°ë³¸ êµ¬í˜„'
            ],
            'Phase 2 (ë‹¨ê¸° - 2-3ì£¼)': [
                'ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ 10ê°œ ì¶”ê°€',
                'ê²½ì œ ìº˜ë¦°ë” ì´ë²¤íŠ¸ í†µí•©',
                'ë‹¤ì¤‘ ì‹œê°„í”„ë ˆì„ ë¶„ì„'
            ],
            'Phase 3 (ì¤‘ê¸° - 1-2ê°œì›”)': [
                'Transformer ëª¨ë¸ êµ¬í˜„',
                'ì‹¤ì‹œê°„ ë‰´ìŠ¤ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„',
                'ì˜µì…˜ ë°ì´í„° í†µí•©'
            ],
            'Phase 4 (ì¥ê¸° - 3-6ê°œì›”)': [
                'ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ ìµœì í™”',
                'ê°•í™”í•™ìŠµ ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬',
                'ì‹¤ì‹œê°„ ì ì‘í˜• ëª¨ë¸'
            ]
        }
        
        return roadmap
        
    def estimate_improvement_potential(self):
        """ê°œì„  ì ì¬ë ¥ ì¶”ì •"""
        current_accuracy = 0.5455
        
        improvements = {
            'Conservative Estimate': {
                'target_accuracy': 0.62,
                'improvement': '+6.45%',
                'methods': ['Ensemble', 'Feature Engineering', 'Confidence Filtering']
            },
            'Optimistic Estimate': {
                'target_accuracy': 0.68,
                'improvement': '+12.45%',
                'methods': ['Advanced ML', 'Multi-Modal Data', 'Market Regime Detection']
            },
            'Best Case Scenario': {
                'target_accuracy': 0.72,
                'improvement': '+16.45%',
                'methods': ['State-of-art Deep Learning', 'Alternative Data', 'Real-time Adaptation']
            }
        }
        
        return improvements

def main():
    analyzer = ModelImprovementAnalyzer()
    analyzer.load_data()
    
    print("ğŸ” SPY ì˜ˆì¸¡ ëª¨ë¸ ê°œì„  ë¶„ì„ ë³´ê³ ì„œ")
    print("=" * 50)
    
    # í˜„ì¬ ì„±ëŠ¥ ë¶„ì„
    monthly_performance = analyzer.analyze_current_performance()
    print("\nğŸ“Š ì›”ë³„ ì„±ëŠ¥ ë¶„ì„:")
    for month, data in monthly_performance.items():
        accuracy = data['correct'] / data['total'] * 100
        print(f"{month}: {accuracy:.1f}% ({data['correct']}/{data['total']})")
    
    # ê°œì„  ê¸°íšŒ
    opportunities = analyzer.identify_improvement_opportunities()
    print(f"\nğŸ¯ ê°œì„  ê¸°íšŒ:")
    print(f"- ë‚®ì€ ì„±ëŠ¥ ì›”: {len(opportunities['low_accuracy_months'])}ê°œì›”")
    
    conf_analysis = opportunities['confidence_correlation']
    print(f"- ê³ ì‹ ë¢°ë„ ì •í™•ë„: {conf_analysis['high_confidence_accuracy']:.1%}")
    print(f"- ì €ì‹ ë¢°ë„ ì •í™•ë„: {conf_analysis['low_confidence_accuracy']:.1%}")
    
    # ê°œì„  ë°©ì•ˆ
    recommendations = analyzer.generate_improvement_recommendations()
    print(f"\nğŸš€ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­:")
    for action in recommendations['immediate_actions']:
        print(f"- {action['action']}: {action['expected_improvement']}")
    
    # ì˜ˆìƒ ê°œì„  íš¨ê³¼
    improvements = analyzer.estimate_improvement_potential()
    print(f"\nğŸ“ˆ ì˜ˆìƒ ê°œì„  íš¨ê³¼:")
    for scenario, data in improvements.items():
        print(f"{scenario}: {data['target_accuracy']:.1%} ({data['improvement']})")
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ - ìƒì„¸ ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()