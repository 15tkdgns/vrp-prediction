#!/usr/bin/env python3
"""
ë‰´ìŠ¤ ê°ì • ë¶„ì„ í†µí•© ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)
- API í‚¤ ì—†ì´ë„ ì‘ë™í•˜ëŠ” ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
- ì„±ëŠ¥ í–¥ìƒ ê²€ì¦ ì‹¤í—˜
"""

import asyncio
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import json
import logging
import yfinance as yf
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import accuracy_score, roc_auc_score

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleEnhancedTester:
    """ê°„ë‹¨í•œ ê°•í™”ëœ ì˜ˆì¸¡ ëª¨ë¸ í…ŒìŠ¤í„°"""
    
    def __init__(self):
        pass
        
    def load_clean_data(self, start_date='2019-01-01', end_date='2024-12-31'):
        """ê°€ê²© ë°ì´í„° ë¡œë“œ"""
        logger.info(f"ğŸ“¥ SPY ë° VIX ë°ì´í„° ë¡œë“œ ì¤‘... ({start_date} ~ {end_date})")
        
        try:
            spy_raw = yf.download('SPY', start=start_date, end=end_date, auto_adjust=True, progress=False)
            vix_raw = yf.download('^VIX', start=start_date, end=end_date, auto_adjust=True, progress=False)
            
            if isinstance(spy_raw.columns, pd.MultiIndex):
                spy_raw.columns = spy_raw.columns.get_level_values(0)
            if isinstance(vix_raw.columns, pd.MultiIndex):
                vix_raw.columns = vix_raw.columns.get_level_values(0)
                
            logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: SPY {len(spy_raw)}ì¼, VIX {len(vix_raw)}ì¼")
            return spy_raw, vix_raw
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None, None
    
    def create_technical_features(self, spy_data, vix_data):
        """ê¸°ìˆ ì  íŠ¹ì„± ìƒì„±"""
        logger.info("ğŸ”§ ê¸°ìˆ ì  íŠ¹ì„± ìƒì„± ì¤‘...")
        
        df = pd.DataFrame(index=spy_data.index)
        
        # ê¸°ë³¸ ìˆ˜ìµë¥ 
        returns = spy_data['Close'].pct_change()
        df['returns_lag1'] = returns.shift(1)
        df['returns_lag2'] = returns.shift(2)
        df['returns_lag3'] = returns.shift(3)
        
        # ì´ë™í‰ê·  ë¹„ìœ¨
        ma50 = spy_data['Close'].rolling(50).mean()
        df['price_to_ma50'] = (spy_data['Close'].shift(1) / ma50.shift(1) - 1)
        
        # VIX íŠ¹ì„±
        vix_aligned = vix_data.reindex(spy_data.index, method='ffill')
        df['vix_change'] = vix_aligned['Close'].pct_change().shift(1)
        
        # ë³€ë™ì„±
        df['volatility_20'] = returns.rolling(20).std().shift(1)
        
        # ê±°ë˜ëŸ‰ ë¹„ìœ¨
        volume_ma = spy_data['Volume'].rolling(20).mean()
        df['volume_ratio'] = (spy_data['Volume'].shift(1) / volume_ma.shift(1))
        
        # íƒ€ê²Ÿ
        df['target'] = (spy_data['Close'].shift(-1) / spy_data['Close'] - 1 > 0).astype(int)
        
        return df.dropna()
    
    def generate_mock_sentiment_features(self, price_index):
        """ëª¨ì˜ ê°ì • íŠ¹ì„± ìƒì„±"""
        logger.info("ğŸ­ ëª¨ì˜ ê°ì • íŠ¹ì„± ìƒì„± ì¤‘...")
        
        # ê°€ê²©ê³¼ ìƒê´€ê´€ê³„ê°€ ìˆëŠ” ê°ì • ì‹ í˜¸ ìƒì„±
        np.random.seed(42)  # ì¬í˜„ì„±ì„ ìœ„í•´
        
        sentiment_features = pd.DataFrame(index=price_index)
        
        # 1ì¼ ë‰´ìŠ¤ ê°ì • ì ìˆ˜ (ì•½ê°„ì˜ ì˜ˆì¸¡ ì‹ í˜¸ í¬í•¨)
        base_sentiment = np.random.normal(0, 0.3, len(price_index))
        
        # SPY ê°€ê²© ë³€í™”ì™€ ì•½ê°„ì˜ ìƒê´€ê´€ê³„ ì¶”ê°€ (í˜„ì‹¤ì )
        if len(price_index) > 1:
            # ì´ì „ ë‚ ì˜ ìˆ˜ìµë¥ ê³¼ ì•½í•œ ìŒì˜ ìƒê´€ê´€ê³„ (ì—­ë°©í–¥ ì˜ˆì¸¡)
            spy_returns = pd.Series(index=price_index, data=np.random.normal(0, 0.02, len(price_index)))
            for i in range(1, len(base_sentiment)):
                # ì „ë‚  í•˜ë½ ì‹œ ì•½ê°„ ë” ê¸ì •ì  ê°ì • (ë°˜ë“± ê¸°ëŒ€)
                base_sentiment[i] += -spy_returns.iloc[i-1] * 0.5 + np.random.normal(0, 0.1)
        
        sentiment_features['news_sentiment_1d'] = np.clip(base_sentiment, -1, 1)
        
        # ê°ì • ëª¨ë©˜í…€
        sentiment_3d = pd.Series(sentiment_features['news_sentiment_1d']).rolling(3).mean()
        sentiment_features['sentiment_momentum'] = sentiment_3d - sentiment_3d.shift(3)
        
        # ì˜í–¥ë„ ê°€ì¤‘ ê°ì •
        impact_weights = np.random.uniform(0.4, 0.8, len(price_index))
        sentiment_features['news_impact_weighted'] = sentiment_features['news_sentiment_1d'] * impact_weights
        
        sentiment_features = sentiment_features.fillna(0)
        
        logger.info(f"âœ… ëª¨ì˜ ê°ì • íŠ¹ì„± ìƒì„± ì™„ë£Œ: {sentiment_features.shape[1]}ê°œ íŠ¹ì„±")
        return sentiment_features
    
    def strict_time_split(self, df):
        """ì‹œê°„ ê¸°ë°˜ ë°ì´í„° ë¶„í• """
        logger.info("ğŸ“Š ì‹œê°„ ê¸°ë°˜ ë°ì´í„° ë¶„í•  ì¤‘...")
        
        train_mask = df.index < '2022-01-01'
        val_mask = (df.index >= '2022-01-01') & (df.index < '2023-01-01')
        test_mask = df.index >= '2023-01-01'
        
        feature_cols = [col for col in df.columns if col != 'target']
        
        X_train = df.loc[train_mask, feature_cols]
        y_train = df.loc[train_mask, 'target']
        
        X_val = df.loc[val_mask, feature_cols]
        y_val = df.loc[val_mask, 'target']
        
        X_test = df.loc[test_mask, feature_cols] 
        y_test = df.loc[test_mask, 'target']
        
        logger.info(f"ğŸ“Š ë°ì´í„° ë¶„í• : í›ˆë ¨ {len(X_train)}, ê²€ì¦ {len(X_val)}, í…ŒìŠ¤íŠ¸ {len(X_test)}")
        
        return X_train, X_val, X_test, y_train, y_val, y_test
    
    def run_comparison_test(self):
        """ë² ì´ìŠ¤ë¼ì¸ vs ê°•í™” ëª¨ë¸ ë¹„êµ"""
        logger.info("ğŸ”¬ ë² ì´ìŠ¤ë¼ì¸ vs ê°•í™” ëª¨ë¸ ë¹„êµ ì‹¤í—˜ ì‹œì‘")
        logger.info("=" * 60)
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            spy_data, vix_data = self.load_clean_data()
            if spy_data is None:
                return None
            
            # 2. ê¸°ìˆ ì  íŠ¹ì„± ìƒì„±
            technical_df = self.create_technical_features(spy_data, vix_data)
            
            # 3. ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ (ê¸°ìˆ ì  íŠ¹ì„±ë§Œ)
            logger.info("\nğŸ¯ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ (ê¸°ìˆ ì  íŠ¹ì„±ë§Œ) í…ŒìŠ¤íŠ¸...")
            
            X_train_base, X_val_base, X_test_base, y_train, y_val, y_test = self.strict_time_split(technical_df)
            
            # ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í›ˆë ¨
            baseline_model = LogisticRegression(C=0.1, class_weight='balanced', random_state=42, max_iter=1000)
            baseline_scaler = RobustScaler()
            
            X_train_scaled = baseline_scaler.fit_transform(X_train_base)
            X_test_scaled = baseline_scaler.transform(X_test_base)
            
            baseline_model.fit(X_train_scaled, y_train)
            baseline_pred = baseline_model.predict(X_test_scaled)
            baseline_proba = baseline_model.predict_proba(X_test_scaled)[:, 1]
            
            baseline_accuracy = accuracy_score(y_test, baseline_pred)
            baseline_auc = roc_auc_score(y_test, baseline_proba)
            
            logger.info(f"âœ… ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥: {baseline_accuracy:.1%} ì •í™•ë„, {baseline_auc:.3f} AUC")
            
            # 4. ê°•í™”ëœ ëª¨ë¸ (ê¸°ìˆ ì  + ê°ì • íŠ¹ì„±)
            logger.info("\nğŸš€ ê°•í™”ëœ ëª¨ë¸ (ê°ì • ë¶„ì„ ì¶”ê°€) í…ŒìŠ¤íŠ¸...")
            
            # ê°ì • íŠ¹ì„± ìƒì„±
            sentiment_features = self.generate_mock_sentiment_features(technical_df.index)
            
            # ê¸°ìˆ ì  íŠ¹ì„±ê³¼ ê°ì • íŠ¹ì„± ê²°í•©
            technical_only = technical_df[['returns_lag1', 'returns_lag2', 'returns_lag3', 'price_to_ma50', 
                                         'vix_change', 'volatility_20', 'volume_ratio', 'target']]
            enhanced_df = pd.concat([technical_only.drop('target', axis=1), sentiment_features, 
                                   technical_only[['target']]], axis=1)
            enhanced_df = enhanced_df.dropna()
            
            # ê°•í™”ëœ ëª¨ë¸ ë¶„í• 
            X_train_enh, X_val_enh, X_test_enh, y_train_enh, y_val_enh, y_test_enh = self.strict_time_split(enhanced_df)
            
            # ê°•í™”ëœ ëª¨ë¸ í›ˆë ¨
            enhanced_model = LogisticRegression(C=0.1, class_weight='balanced', random_state=42, max_iter=1000)
            enhanced_scaler = RobustScaler()
            
            X_train_enh_scaled = enhanced_scaler.fit_transform(X_train_enh)
            X_test_enh_scaled = enhanced_scaler.transform(X_test_enh)
            
            enhanced_model.fit(X_train_enh_scaled, y_train_enh)
            enhanced_pred = enhanced_model.predict(X_test_enh_scaled)
            enhanced_proba = enhanced_model.predict_proba(X_test_enh_scaled)[:, 1]
            
            enhanced_accuracy = accuracy_score(y_test_enh, enhanced_pred)
            enhanced_auc = roc_auc_score(y_test_enh, enhanced_proba)
            
            logger.info(f"âœ… ê°•í™”ëœ ëª¨ë¸ ì„±ëŠ¥: {enhanced_accuracy:.1%} ì •í™•ë„, {enhanced_auc:.3f} AUC")
            
            # 5. ì„±ëŠ¥ ë¹„êµ ë¶„ì„
            accuracy_improvement = enhanced_accuracy - baseline_accuracy
            auc_improvement = enhanced_auc - baseline_auc
            
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ“Š ì„±ëŠ¥ ë¹„êµ ê²°ê³¼:")
            logger.info(f"ğŸ“ˆ ì •í™•ë„ í–¥ìƒ: +{accuracy_improvement:.1%} ({baseline_accuracy:.1%} â†’ {enhanced_accuracy:.1%})")
            logger.info(f"ğŸ“ˆ AUC í–¥ìƒ: +{auc_improvement:.3f} ({baseline_auc:.3f} â†’ {enhanced_auc:.3f})")
            
            # 6. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
            feature_importance = dict(zip(X_train_enh.columns, enhanced_model.coef_[0]))
            
            sentiment_features_list = ['news_sentiment_1d', 'sentiment_momentum', 'news_impact_weighted']
            technical_features_list = ['returns_lag1', 'returns_lag2', 'returns_lag3', 'price_to_ma50', 
                                     'vix_change', 'volatility_20', 'volume_ratio']
            
            sentiment_importance = {k: v for k, v in feature_importance.items() if k in sentiment_features_list}
            technical_importance = {k: v for k, v in feature_importance.items() if k in technical_features_list}
            
            logger.info("\nğŸ” íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„:")
            logger.info("ê°ì • íŠ¹ì„±:")
            for feature, importance in sorted(sentiment_importance.items(), key=lambda x: abs(x[1]), reverse=True):
                logger.info(f"   {feature}: {importance:.3f}")
            
            logger.info("ê¸°ìˆ ì  íŠ¹ì„± (ìƒìœ„ 3ê°œ):")
            for feature, importance in sorted(technical_importance.items(), key=lambda x: abs(x[1]), reverse=True)[:3]:
                logger.info(f"   {feature}: {importance:.3f}")
            
            # 7. ê²°ê³¼ ì €ì¥
            comparison_report = {
                'experiment_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'test_type': 'baseline_vs_enhanced_comparison',
                'baseline_performance': {
                    'accuracy': float(baseline_accuracy),
                    'auc': float(baseline_auc),
                    'features': list(X_train_base.columns)
                },
                'enhanced_performance': {
                    'accuracy': float(enhanced_accuracy),
                    'auc': float(enhanced_auc),
                    'features': list(X_train_enh.columns)
                },
                'improvement': {
                    'accuracy_gain': float(accuracy_improvement),
                    'auc_gain': float(auc_improvement),
                    'relative_accuracy_improvement': float(accuracy_improvement / baseline_accuracy * 100) if baseline_accuracy > 0 else 0
                },
                'feature_importance': {
                    'sentiment_features': {k: float(v) for k, v in sentiment_importance.items()},
                    'technical_features': {k: float(v) for k, v in technical_importance.items()}
                },
                'conclusions': []
            }
            
            # 8. ê²°ë¡  ìƒì„±
            if accuracy_improvement > 0.02:
                comparison_report['conclusions'].append("âœ… ë‰´ìŠ¤ ê°ì • ë¶„ì„ìœ¼ë¡œ 2%+ ì •í™•ë„ í–¥ìƒ ë‹¬ì„±")
            elif accuracy_improvement > 0.01:
                comparison_report['conclusions'].append("ğŸ¯ ë‰´ìŠ¤ ê°ì • ë¶„ì„ìœ¼ë¡œ 1%+ ì •í™•ë„ í–¥ìƒ ë‹¬ì„±")
            elif accuracy_improvement > 0:
                comparison_report['conclusions'].append("ğŸ“ˆ ë‰´ìŠ¤ ê°ì • ë¶„ì„ìœ¼ë¡œ ì†Œí­ ì„±ëŠ¥ í–¥ìƒ")
            else:
                comparison_report['conclusions'].append("âš ï¸ ë‰´ìŠ¤ ê°ì • ë¶„ì„ì˜ ì„±ëŠ¥ í–¥ìƒ ë¯¸ë¯¸í•˜ê±°ë‚˜ ì—†ìŒ")
            
            if enhanced_accuracy > 0.55:
                comparison_report['conclusions'].append("ğŸ† 55% ì´ìƒ ì •í™•ë„ ë‹¬ì„± (ìš°ìˆ˜í•œ ì„±ëŠ¥)")
            elif enhanced_accuracy > 0.53:
                comparison_report['conclusions'].append("âœ… 53% ì´ìƒ ì •í™•ë„ ë‹¬ì„± (ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì„±ëŠ¥)")
            else:
                comparison_report['conclusions'].append("âš ï¸ ì„±ëŠ¥ì´ ê¸°ëŒ€ì¹˜ì— ë¯¸ë‹¬")
            
            # ë³´ê³ ì„œ ì €ì¥
            import os
            os.makedirs('data/raw', exist_ok=True)
            with open('data/raw/baseline_vs_enhanced_comparison.json', 'w', encoding='utf-8') as f:
                json.dump(comparison_report, f, indent=2, ensure_ascii=False)
            
            logger.info("\nğŸ“‹ ì£¼ìš” ê²°ë¡ :")
            for conclusion in comparison_report['conclusions']:
                logger.info(f"   {conclusion}")
            
            logger.info(f"\nâœ… ë¹„êµ ì‹¤í—˜ ì™„ë£Œ! ë³´ê³ ì„œ: data/raw/baseline_vs_enhanced_comparison.json")
            
            return comparison_report
            
        except Exception as e:
            logger.error(f"âŒ ë¹„êµ ì‹¤í—˜ ì‹¤íŒ¨: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return None

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    tester = SimpleEnhancedTester()
    
    logger.info("ğŸ§ª ë‰´ìŠ¤ ê°ì • ë¶„ì„ í†µí•© ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 80)
    
    # ë² ì´ìŠ¤ë¼ì¸ vs ê°•í™” ëª¨ë¸ ë¹„êµ
    result = tester.run_comparison_test()
    
    if result:
        logger.info("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    else:
        logger.error("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()