#!/usr/bin/env python3
"""
SPY ëª¨ë¸ ë¹ ë¥¸ ê²€ì¦ ë° ìˆ˜ì •
- ì˜¤ë²„í”¼íŒ… í•´ê²°
- ë°ì´í„° ëˆ„ìˆ˜ ì™„ì „ ì°¨ë‹¨
- ì •í™•ë„ ê°œì„ 
"""

import json
import numpy as np
import pandas as pd
import yfinance as yf
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
from sklearn.feature_selection import SelectKBest, f_classif

class QuickModelFix:
    def __init__(self):
        self.results = {}
        
    def load_clean_data(self):
        """ê¹”ë”í•œ ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“¥ ê¹”ë”í•œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        try:
            # 2019-2024 ë°ì´í„°ë¡œ ì œí•œ (ë„ˆë¬´ ì˜¤ë˜ëœ ë°ì´í„° ì œì™¸)
            spy_raw = yf.download('SPY', start='2019-01-01', end='2024-12-31', auto_adjust=True, progress=False)
            vix_raw = yf.download('^VIX', start='2019-01-01', end='2024-12-31', auto_adjust=True, progress=False)
            
            # MultiIndex ì»¬ëŸ¼ ì •ë¦¬
            if isinstance(spy_raw.columns, pd.MultiIndex):
                spy_raw.columns = spy_raw.columns.get_level_values(0)
            if isinstance(vix_raw.columns, pd.MultiIndex):
                vix_raw.columns = vix_raw.columns.get_level_values(0)
                
            print(f"âœ… SPY: {len(spy_raw)} ì¼, VIX: {len(vix_raw)} ì¼")
            return spy_raw, vix_raw
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None, None
    
    def create_simple_features(self, spy_data, vix_data):
        """ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ íŠ¹ì„±ë§Œ ìƒì„±"""
        print("ğŸ”§ ê°„ë‹¨í•œ íŠ¹ì„± ìƒì„± ì¤‘...")
        
        df = pd.DataFrame(index=spy_data.index)
        
        # ê¸°ë³¸ ìˆ˜ìµë¥  (1ì¼ ì§€ì—°ìœ¼ë¡œ ëˆ„ìˆ˜ ë°©ì§€)
        returns = spy_data['Close'].pct_change()
        df['returns_lag1'] = returns.shift(1)
        df['returns_lag2'] = returns.shift(2)
        df['returns_lag3'] = returns.shift(3)
        df['returns_lag5'] = returns.shift(5)
        
        # ë‹¨ìˆœ ì´ë™í‰ê·  (ê³¼ê±°ë§Œ)
        for period in [10, 20, 50]:
            ma = spy_data['Close'].rolling(period).mean()
            df[f'price_to_ma{period}'] = (spy_data['Close'].shift(1) / ma.shift(1) - 1)
        
        # RSI (ê°„ë‹¨ ë²„ì „, ê³¼ê±°ë§Œ)
        def simple_rsi(prices, period=14):
            delta = prices.diff().shift(1)  # 1ì¼ ì§€ì—°
            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            return rsi
            
        df['rsi'] = simple_rsi(spy_data['Close'])
        df['rsi_normalized'] = (df['rsi'] - 50) / 50  # -1 ~ 1ë¡œ ì •ê·œí™”
        
        # VIX íŠ¹ì„± (ê³¼ê±°ë§Œ)
        vix_aligned = vix_data.reindex(spy_data.index, method='ffill')
        df['vix'] = vix_aligned['Close'].shift(1)  # 1ì¼ ì§€ì—°
        df['vix_normalized'] = (df['vix'] - 20) / 20  # VIX 20 ê¸°ì¤€ ì •ê·œí™”
        df['vix_change'] = df['vix'].pct_change()
        
        # ë³€ë™ì„± (ê³¼ê±°ë§Œ)
        df['volatility_10'] = returns.rolling(10).std().shift(1)
        df['volatility_20'] = returns.rolling(20).std().shift(1)
        
        # ê±°ë˜ëŸ‰ (ê³¼ê±°ë§Œ)
        volume_ma = spy_data['Volume'].rolling(20).mean()
        df['volume_ratio'] = (spy_data['Volume'].shift(1) / volume_ma.shift(1))
        
        # íƒ€ê²Ÿ: ë‹¤ìŒë‚  ìˆ˜ìµë¥  ë°©í–¥
        df['target'] = (spy_data['Close'].shift(-1) / spy_data['Close'] - 1 > 0).astype(int)
        
        print(f"âœ… {len(df.columns)}ê°œ íŠ¹ì„± ìƒì„± ì™„ë£Œ")
        return df.dropna()
    
    def strict_time_split(self, df):
        """ì—„ê²©í•œ ì‹œê°„ ë¶„í• """
        print("ğŸ“Š ì—„ê²©í•œ ì‹œê°„ ë¶„í•  ì¤‘...")
        
        # 2019-2021: í›ˆë ¨
        # 2022: ê²€ì¦
        # 2023-2024: í…ŒìŠ¤íŠ¸
        
        train_mask = df.index < '2022-01-01'
        val_mask = (df.index >= '2022-01-01') & (df.index < '2023-01-01')
        test_mask = df.index >= '2023-01-01'
        
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        feature_cols = [col for col in df.columns if col != 'target']
        
        X_train = df.loc[train_mask, feature_cols]
        y_train = df.loc[train_mask, 'target']
        
        X_val = df.loc[val_mask, feature_cols]
        y_val = df.loc[val_mask, 'target']
        
        X_test = df.loc[test_mask, feature_cols] 
        y_test = df.loc[test_mask, 'target']
        
        print(f"ğŸ“Š í›ˆë ¨: {len(X_train)} | ê²€ì¦: {len(X_val)} | í…ŒìŠ¤íŠ¸: {len(X_test)}")
        print(f"ğŸ“Š í›ˆë ¨ í´ë˜ìŠ¤ ë¶„í¬: {dict(y_train.value_counts())}")
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ë¶„í¬: {dict(y_test.value_counts())}")
        
        return X_train, X_val, X_test, y_train, y_val, y_test
    
    def feature_selection(self, X_train, y_train, X_val, X_test, k=8):
        """ìµœì  íŠ¹ì„± ì„ íƒ (ì˜¤ë²„í”¼íŒ… ë°©ì§€)"""
        print(f"ğŸ¯ ìµœì  íŠ¹ì„± {k}ê°œ ì„ íƒ ì¤‘...")
        
        # í†µê³„ì  íŠ¹ì„± ì„ íƒ
        selector = SelectKBest(score_func=f_classif, k=k)
        X_train_selected = selector.fit_transform(X_train, y_train)
        X_val_selected = selector.transform(X_val)
        X_test_selected = selector.transform(X_test)
        
        # ì„ íƒëœ íŠ¹ì„±ëª…
        selected_features = X_train.columns[selector.get_support()]
        print(f"âœ… ì„ íƒëœ íŠ¹ì„±: {list(selected_features)}")
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features, index=X_train.index)
        X_val_selected = pd.DataFrame(X_val_selected, columns=selected_features, index=X_val.index)
        X_test_selected = pd.DataFrame(X_test_selected, columns=selected_features, index=X_test.index)
        
        return X_train_selected, X_val_selected, X_test_selected, selector
    
    def train_conservative_models(self, X_train, X_val, X_test, y_train, y_val, y_test):
        """ë³´ìˆ˜ì ì¸ ëª¨ë¸ë“¤ (ì˜¤ë²„í”¼íŒ… ë°©ì§€)"""
        print("ğŸ¯ ë³´ìˆ˜ì  ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        
        models = {
            'conservative_rf': RandomForestClassifier(
                n_estimators=50,      # ì ê²Œ
                max_depth=6,          # ì–•ê²Œ
                min_samples_split=50, # í¬ê²Œ
                min_samples_leaf=20,  # í¬ê²Œ
                max_features=0.5,     # ì ê²Œ
                class_weight='balanced',
                random_state=42
            ),
            'simple_lr': LogisticRegression(
                C=0.1,               # ê°•í•œ ì •ê·œí™”
                class_weight='balanced',
                random_state=42,
                max_iter=1000
            )
        }
        
        results = {}
        
        for name, model in models.items():
            print(f"\nğŸ”§ {name} í›ˆë ¨ ì¤‘...")
            
            # ìŠ¤ì¼€ì¼ë§ (ë¡œì§€ìŠ¤í‹± íšŒê·€ë§Œ)
            if 'lr' in name:
                scaler = RobustScaler()
                X_train_proc = scaler.fit_transform(X_train)
                X_val_proc = scaler.transform(X_val)
                X_test_proc = scaler.transform(X_test)
            else:
                X_train_proc = X_train
                X_val_proc = X_val
                X_test_proc = X_test
                scaler = None
            
            # í›ˆë ¨
            model.fit(X_train_proc, y_train)
            
            # ì˜ˆì¸¡
            train_pred = model.predict(X_train_proc)
            val_pred = model.predict(X_val_proc)
            test_pred = model.predict(X_test_proc)
            
            # ì„±ëŠ¥
            train_acc = accuracy_score(y_train, train_pred)
            val_acc = accuracy_score(y_val, val_pred)
            test_acc = accuracy_score(y_test, test_pred)
            
            # AUC
            if hasattr(model, 'predict_proba'):
                test_proba = model.predict_proba(X_test_proc)[:, 1]
                test_auc = roc_auc_score(y_test, test_proba)
            else:
                test_auc = 0.5
            
            # ì˜¤ë²„í”¼íŒ… ì²´í¬
            overfitting_gap = train_acc - val_acc
            
            results[name] = {
                'model': model,
                'scaler': scaler,
                'train_accuracy': train_acc,
                'val_accuracy': val_acc,
                'test_accuracy': test_acc,
                'test_auc': test_auc,
                'overfitting_gap': overfitting_gap,
                'overfitting': overfitting_gap > 0.1
            }
            
            print(f"   í›ˆë ¨: {train_acc:.3f} | ê²€ì¦: {val_acc:.3f} | í…ŒìŠ¤íŠ¸: {test_acc:.3f}")
            print(f"   AUC: {test_auc:.3f} | ì˜¤ë²„í”¼íŒ… ê°­: {overfitting_gap:.3f}")
            
            if overfitting_gap > 0.1:
                print("   âš ï¸ ì˜¤ë²„í”¼íŒ… ê°ì§€!")
            else:
                print("   âœ… ì˜¤ë²„í”¼íŒ… ì—†ìŒ")
        
        return results
    
    def cross_validation_check(self, X_train, y_train, model, model_name):
        """êµì°¨ ê²€ì¦ìœ¼ë¡œ ì•ˆì •ì„± ì²´í¬"""
        print(f"ğŸ” {model_name} êµì°¨ ê²€ì¦ ì¤‘...")
        
        # ì‹œê³„ì—´ êµì°¨ ê²€ì¦
        tscv = TimeSeriesSplit(n_splits=5)
        cv_scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring='accuracy')
        
        cv_mean = cv_scores.mean()
        cv_std = cv_scores.std()
        
        print(f"   CV í‰ê· : {cv_mean:.3f} Â± {cv_std:.3f}")
        
        if cv_std > 0.05:
            print("   âš ï¸ ë¶ˆì•ˆì •í•œ ì„±ëŠ¥")
        else:
            print("   âœ… ì•ˆì •ì  ì„±ëŠ¥")
        
        return cv_mean, cv_std
    
    def create_quick_report(self, results, selector):
        """ë¹ ë¥¸ ë³´ê³ ì„œ ìƒì„±"""
        print("ğŸ“ ë¹ ë¥¸ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        report = {
            'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'models_tested': len(results),
            'selected_features': list(selector.feature_names_in_[selector.get_support()]),
            'model_performance': {},
            'best_model': None,
            'overfitting_issues': [],
            'recommendations': []
        }
        
        # ì„±ëŠ¥ ì •ë¦¬
        for name, data in results.items():
            report['model_performance'][name] = {
                'test_accuracy': float(data['test_accuracy']),
                'test_auc': float(data['test_auc']),
                'overfitting_gap': float(data['overfitting_gap']),
                'has_overfitting': bool(data['overfitting'])
            }
            
            if data['overfitting']:
                report['overfitting_issues'].append(name)
        
        # ìµœê³  ëª¨ë¸
        best_model = max(results.keys(), key=lambda k: results[k]['test_accuracy'])
        best_acc = results[best_model]['test_accuracy']
        
        report['best_model'] = best_model
        report['best_accuracy'] = float(best_acc)
        
        # ê¶Œì¥ì‚¬í•­
        recommendations = []
        
        if len(report['overfitting_issues']) == 0:
            recommendations.append("âœ… ì˜¤ë²„í”¼íŒ… ë¬¸ì œ í•´ê²°ë¨")
        else:
            recommendations.append(f"âš ï¸ ì˜¤ë²„í”¼íŒ… ëª¨ë¸: {report['overfitting_issues']}")
        
        if best_acc > 0.55:
            recommendations.append("âœ… í•©ë¦¬ì  ì„±ëŠ¥ ë‹¬ì„±")
        else:
            recommendations.append("ğŸ¯ ì„±ëŠ¥ ì¶”ê°€ ê°œì„  í•„ìš”")
            
        recommendations.append("ğŸ”§ íŠ¹ì„± ì„ íƒìœ¼ë¡œ ë³µì¡ë„ ê°ì†Œ")
        recommendations.append("ğŸ“Š ì—„ê²©í•œ ì‹œê°„ ë¶„í• ë¡œ ëˆ„ìˆ˜ ë°©ì§€")
        
        report['recommendations'] = recommendations
        
        # ì €ì¥
        with open('data/raw/quick_model_fix_report.json', 'w') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        return report
    
    def run_quick_fix(self):
        """ë¹ ë¥¸ ìˆ˜ì • í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸ”§ SPY ëª¨ë¸ ë¹ ë¥¸ ìˆ˜ì • ì‹œì‘!")
        print("=" * 50)
        
        # 1. ë°ì´í„° ë¡œë“œ
        spy_data, vix_data = self.load_clean_data()
        if spy_data is None:
            return
        
        # 2. ê°„ë‹¨í•œ íŠ¹ì„± ìƒì„±
        df = self.create_simple_features(spy_data, vix_data)
        
        # 3. ì—„ê²©í•œ ì‹œê°„ ë¶„í• 
        X_train, X_val, X_test, y_train, y_val, y_test = self.strict_time_split(df)
        
        # 4. íŠ¹ì„± ì„ íƒ (ì˜¤ë²„í”¼íŒ… ë°©ì§€)
        X_train_sel, X_val_sel, X_test_sel, selector = self.feature_selection(
            X_train, y_train, X_val, X_test, k=8
        )
        
        # 5. ë³´ìˆ˜ì  ëª¨ë¸ í›ˆë ¨
        results = self.train_conservative_models(
            X_train_sel, X_val_sel, X_test_sel, y_train, y_val, y_test
        )
        
        # 6. êµì°¨ ê²€ì¦
        for name, data in results.items():
            cv_mean, cv_std = self.cross_validation_check(
                X_train_sel if data['scaler'] is None else data['scaler'].transform(X_train_sel),
                y_train, 
                data['model'], 
                name
            )
            results[name]['cv_mean'] = cv_mean
            results[name]['cv_std'] = cv_std
        
        # 7. ë³´ê³ ì„œ ìƒì„±
        report = self.create_quick_report(results, selector)
        
        print("\n" + "=" * 50)
        print("ğŸ† ë¹ ë¥¸ ìˆ˜ì • ê²°ê³¼:")
        print(f"ğŸ¯ ìµœê³  ëª¨ë¸: {report['best_model']}")
        print(f"ğŸ“Š ìµœê³  ì •í™•ë„: {report['best_accuracy']:.1%}")
        print(f"ğŸ”§ ì„ íƒëœ íŠ¹ì„±: {len(report['selected_features'])}ê°œ")
        print(f"âš ï¸ ì˜¤ë²„í”¼íŒ… ëª¨ë¸: {len(report['overfitting_issues'])}ê°œ")
        
        print("\nğŸ“‹ í•µì‹¬ ê°œì„ ì‚¬í•­:")
        for rec in report['recommendations']:
            print(f"   {rec}")
        
        print(f"\nâœ… ë¹ ë¥¸ ìˆ˜ì • ì™„ë£Œ! ë³´ê³ ì„œ: data/raw/quick_model_fix_report.json")
        
        self.results = results
        return results

def main():
    fixer = QuickModelFix()
    fixer.run_quick_fix()

if __name__ == "__main__":
    main()