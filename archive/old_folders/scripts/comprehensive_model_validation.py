#!/usr/bin/env python3
"""
í¬ê´„ì  ëª¨ë¸ ê²€ì¦: ëª¨ë“  ëª¨ë¸ì„ ë™ì¼í•œ ë°ì´í„°ì™€ ê²€ì¦ ë°©ë²•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
- ëª©ì : Paper figuresì˜ í•˜ë“œì½”ë”© ì œê±°
- ë°©ë²•: Purged K-Fold CVë¡œ ê³µì •í•œ ë¹„êµ
- ë°ì´í„° ëˆ„ì¶œ ë°©ì§€: ì™„ì „í•œ ì‹œê°„ì  ë¶„ë¦¬
"""
import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import json
import warnings
from datetime import datetime
from pathlib import Path

warnings.filterwarnings('ignore')

# Purged K-Fold CV import
import sys
sys.path.append('/root/workspace/src')
from validation.purged_cross_validation import PurgedKFold

def load_spy_data():
    """SPY ë°ì´í„° ë¡œë“œ (2015-2024)"""
    print("ğŸ“Š SPY ë°ì´í„° ë¡œë“œ ì¤‘...")
    spy = yf.download('SPY', start='2015-01-01', end='2024-12-31', progress=False)
    spy['returns'] = spy['Close'].pct_change()

    # VIX ë°ì´í„° ì¶”ê°€
    try:
        vix = yf.download('^VIX', start='2015-01-01', end='2024-12-31', progress=False)
        spy['vix'] = vix['Close'].reindex(spy.index, method='ffill')
    except:
        spy['vix'] = 20.0

    spy = spy.dropna()
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(spy)} ê´€ì¸¡ì¹˜")
    return spy

def create_volatility_features(data):
    """ë³€ë™ì„± íŠ¹ì„± ìƒì„± (ì‹œê°„ì  ë¶„ë¦¬ ë³´ì¥)"""
    print("ğŸ”§ ë³€ë™ì„± íŠ¹ì„± ìƒì„± ì¤‘...")

    features = pd.DataFrame(index=data.index)
    returns = data['returns']
    high = data['High']
    low = data['Low']
    prices = data['Close']

    # 1. ê¸°ë³¸ ë³€ë™ì„± (í˜„ì¬ ì‹œì  ì´ì „ë§Œ ì‚¬ìš©)
    for window in [5, 10, 20]:
        features[f'volatility_{window}'] = returns.rolling(window).std()
        features[f'realized_vol_{window}'] = features[f'volatility_{window}'] * np.sqrt(252)

    # 2. ì§€ìˆ˜ ê°€ì¤‘ ë³€ë™ì„±
    for span in [5, 10, 20]:
        features[f'ewm_vol_{span}'] = returns.ewm(span=span).std()

    # 3. ë˜ê·¸ íŠ¹ì„±
    for lag in [1, 2, 3, 5]:
        features[f'vol_lag_{lag}'] = features['volatility_5'].shift(lag)

    # 4. Garman-Klass ë³€ë™ì„±
    for window in [5, 10]:
        gk_vol = np.log(high / low) ** 2
        features[f'garman_klass_{window}'] = gk_vol.rolling(window).mean()

    # 5. ì¼ì¤‘ ë³€ë™ì„±
    for window in [5, 10]:
        intraday_range = (high - low) / prices
        features[f'intraday_vol_{window}'] = intraday_range.rolling(window).mean()

    # 6. VIX íŠ¹ì„±
    if 'vix' in data.columns:
        vix = data['vix']
        features['vix_level'] = vix
        for window in [5, 20]:
            features[f'vix_ma_{window}'] = vix.rolling(window).mean()
            features[f'vix_std_{window}'] = vix.rolling(window).std()

    # 7. HAR íŠ¹ì„± (realized volatility)
    features['rv_daily'] = features['volatility_5']
    features['rv_weekly'] = returns.rolling(5).std()  # 5ì¼ í‰ê· 
    features['rv_monthly'] = returns.rolling(22).std()  # 22ì¼ í‰ê· 

    print(f"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: {len(features.columns)}ê°œ")
    return features

def create_target_volatility(data, horizon=5):
    """íƒ€ê²Ÿ ë³€ë™ì„± ìƒì„± (ë¯¸ë˜ t+1 ~ t+horizon)"""
    print(f"ğŸ¯ íƒ€ê²Ÿ ë³€ë™ì„± ìƒì„± ì¤‘ (horizon={horizon})...")

    returns = data['returns']
    target = []

    for i in range(len(returns)):
        if i + horizon < len(returns):
            # ë¯¸ë˜ ìˆ˜ìµë¥ ë¡œë§Œ ê³„ì‚° (t+1ë¶€í„° ì‹œì‘)
            future_returns = returns.iloc[i+1:i+1+horizon]
            target.append(future_returns.std())
        else:
            target.append(np.nan)

    print(f"âœ… íƒ€ê²Ÿ ìƒì„± ì™„ë£Œ")
    return pd.Series(target, index=data.index, name='target_vol_5d')

def purged_cv_evaluation(model, X, y, model_name, n_splits=5, pct_embargo=0.01):
    """Purged K-Fold CVë¡œ ëª¨ë¸ í‰ê°€"""
    print(f"\n{'='*60}")
    print(f"í‰ê°€ ì¤‘: {model_name}")
    print(f"{'='*60}")

    # NaN ì œê±°
    combined = pd.concat([X, y], axis=1).dropna()
    X_clean = combined[X.columns]
    y_clean = combined[y.name]

    print(f"ìœ íš¨ ìƒ˜í”Œ: {len(X_clean)}")

    if len(X_clean) < 100:
        print("âš ï¸ ìƒ˜í”Œ ìˆ˜ ë¶€ì¡±")
        return None

    # Purged K-Fold CV
    cv = PurgedKFold(n_splits=n_splits, pct_embargo=pct_embargo)

    cv_scores = []
    fold_num = 1

    for train_idx, test_idx in cv.split(X_clean, y_clean):
        # indicesë¥¼ ì •ìˆ˜ ìœ„ì¹˜ë¡œ ë³€í™˜
        if hasattr(X_clean.index, 'get_indexer'):
            train_pos = X_clean.index.get_indexer(train_idx)
            test_pos = X_clean.index.get_indexer(test_idx)
        else:
            train_pos = train_idx
            test_pos = test_idx

        X_train, X_test = X_clean.iloc[train_pos], X_clean.iloc[test_pos]
        y_train, y_test = y_clean.iloc[train_pos], y_clean.iloc[test_pos]

        # ìŠ¤ì¼€ì¼ë§ (íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì€ ì„ íƒì )
        if isinstance(model, (Ridge, Lasso, ElasticNet)):
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
        else:
            X_train_scaled = X_train.values
            X_test_scaled = X_test.values

        # í•™ìŠµ ë° í‰ê°€
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)

        score = r2_score(y_test, y_pred)
        cv_scores.append(score)
        print(f"  Fold {fold_num}: RÂ² = {score:.4f}")
        fold_num += 1

    mean_r2 = np.mean(cv_scores)
    std_r2 = np.std(cv_scores)

    print(f"\ní‰ê·  CV RÂ² = {mean_r2:.4f} Â± {std_r2:.4f}")

    return {
        'model_name': model_name,
        'cv_r2_mean': mean_r2,
        'cv_r2_std': std_r2,
        'cv_fold_scores': cv_scores,
        'n_samples': len(X_clean),
        'n_features': len(X_clean.columns)
    }

def walk_forward_test(model, X, y, model_name, train_ratio=0.8):
    """Walk-Forward Test (Out-of-sample)"""
    print(f"\nWalk-Forward Test: {model_name}")

    # NaN ì œê±°
    combined = pd.concat([X, y], axis=1).dropna()
    X_clean = combined[X.columns]
    y_clean = combined[y.name]

    split_idx = int(len(X_clean) * train_ratio)
    X_train, X_test = X_clean.iloc[:split_idx], X_clean.iloc[split_idx:]
    y_train, y_test = y_clean.iloc[:split_idx], y_clean.iloc[split_idx:]

    print(f"  Train: {len(X_train)}, Test: {len(X_test)}")

    # ìŠ¤ì¼€ì¼ë§
    if isinstance(model, (Ridge, Lasso, ElasticNet)):
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
    else:
        X_train_scaled = X_train.values
        X_test_scaled = X_test.values

    # í•™ìŠµ ë° í‰ê°€
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)

    print(f"  Test RÂ² = {r2:.4f}, MAE = {mae:.6f}")

    return {
        'test_r2': r2,
        'test_mse': mse,
        'test_mae': mae,
        'test_rmse': np.sqrt(mse)
    }

def main():
    """ë©”ì¸ ê²€ì¦ í•¨ìˆ˜"""
    print("="*80)
    print("ğŸ” í¬ê´„ì  ëª¨ë¸ ê²€ì¦ ì‹œì‘")
    print("="*80)
    print("\nëª©ì : Paper figuresì˜ í•˜ë“œì½”ë”© ì œê±°")
    print("ë°©ë²•: ë™ì¼ ë°ì´í„° + ë™ì¼ ê²€ì¦ ë°©ë²•ìœ¼ë¡œ ê³µì •í•œ ë¹„êµ")
    print("="*80)

    # 1. ë°ì´í„° ë¡œë“œ
    spy_data = load_spy_data()

    # 2. íŠ¹ì„± ìƒì„±
    features = create_volatility_features(spy_data)

    # 3. íƒ€ê²Ÿ ìƒì„±
    target = create_target_volatility(spy_data, horizon=5)

    # 4. ìƒìœ„ 31ê°œ íŠ¹ì„± ì„ íƒ (ìƒê´€ê´€ê³„ ê¸°ë°˜)
    print("\nğŸ“Š íŠ¹ì„± ì„ íƒ ì¤‘...")
    combined_for_selection = pd.concat([features, target], axis=1).dropna()
    correlations = combined_for_selection[features.columns].corrwith(
        combined_for_selection['target_vol_5d']
    ).abs().sort_values(ascending=False)

    top_features = correlations.head(31).index
    X = features[top_features]

    print(f"âœ… ì„ íƒëœ íŠ¹ì„±: {len(top_features)}ê°œ")
    print("ìƒìœ„ 10ê°œ íŠ¹ì„±:")
    for i, (feat, corr) in enumerate(correlations.head(10).items()):
        print(f"  {i+1:2d}. {feat:25}: {corr:.4f}")

    # 5. ëª¨ë¸ ì •ì˜
    models = {
        'HAR Benchmark': Ridge(alpha=0.01),  # HARëŠ” 3ê°œ íŠ¹ì„±ë§Œ ì‚¬ìš©
        'Ridge Volatility': Ridge(alpha=1.0),
        'Lasso 0.001': Lasso(alpha=0.001, max_iter=3000, random_state=42),
        'ElasticNet': ElasticNet(alpha=0.001, l1_ratio=0.5, max_iter=3000, random_state=42),
        'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=8, random_state=42)
    }

    # 6. ëª¨ë“  ëª¨ë¸ í‰ê°€
    results = {}

    for model_name, model in models.items():
        # HARëŠ” 3ê°œ íŠ¹ì„±ë§Œ ì‚¬ìš©
        if model_name == 'HAR Benchmark':
            har_features = ['rv_daily', 'rv_weekly', 'rv_monthly']
            X_model = X[har_features] if all(f in X.columns for f in har_features) else X.iloc[:, :3]
        else:
            X_model = X

        # Purged K-Fold CV
        cv_result = purged_cv_evaluation(model, X_model, target, model_name)

        if cv_result is not None:
            # Walk-Forward Test
            wf_result = walk_forward_test(model, X_model, target, model_name)

            # ê²°ê³¼ ë³‘í•©
            results[model_name] = {
                **cv_result,
                **wf_result
            }

    # 7. ê²°ê³¼ ì €ì¥
    output_dir = Path('/root/workspace/data/validation')
    output_dir.mkdir(exist_ok=True)

    validation_summary = {
        'timestamp': datetime.now().isoformat(),
        'data_source': 'SPY (2015-2024)',
        'validation_method': 'Purged K-Fold CV (5-fold, embargo=1%)',
        'target': 'target_vol_5d (5-day future volatility)',
        'n_features_total': len(features.columns),
        'n_features_selected': len(top_features),
        'models': results
    }

    output_file = output_dir / 'comprehensive_model_validation.json'
    with open(output_file, 'w') as f:
        json.dump(validation_summary, f, indent=2, default=str)

    print("\n" + "="*80)
    print("âœ… ê²€ì¦ ì™„ë£Œ - ê²°ê³¼ ìš”ì•½")
    print("="*80)
    print(f"\n{'Model':<20} {'CV RÂ²':<15} {'Test RÂ²':<15}")
    print("-"*50)

    for model_name, result in results.items():
        cv_r2 = result['cv_r2_mean']
        test_r2 = result.get('test_r2', np.nan)
        print(f"{model_name:<20} {cv_r2:>7.4f} Â± {result['cv_r2_std']:.4f}  {test_r2:>7.4f}")

    print("\n" + "="*80)
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
    print("="*80)

    return validation_summary

if __name__ == "__main__":
    results = main()
