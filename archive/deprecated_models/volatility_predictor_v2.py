#!/usr/bin/env python3
"""
ë³€ë™ì„± ì˜ˆì¸¡ V2: í˜ì‹ ì  ì ‘ê·¼ ë°©ë²•ë“¤
- GARCH ê³„ì—´ ëª¨ë¸
- Quantile Regression (ê·¹ë‹¨ê°’ ì˜ˆì¸¡)
- Regime-Switching (ê³ ë³€ë™/ì €ë³€ë™ êµ¬ë¶„)
- Multi-horizon ì˜ˆì¸¡
- Rolling Window Optimization

ëª©í‘œ: RÂ² 0.30 â†’ 0.40+
"""

import pandas as pd
import numpy as np
import yfinance as yf
from sklearn.linear_model import Ridge, QuantileRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.cluster import KMeans
import warnings
warnings.filterwarnings('ignore')

class VolatilityPredictorV2:
    """í˜ì‹ ì  ë³€ë™ì„± ì˜ˆì¸¡ ëª¨ë¸ V2"""

    def __init__(self, ticker="SPY", start_date="2015-01-01", end_date="2024-12-31"):
        self.ticker = ticker
        self.start_date = start_date
        self.end_date = end_date
        self.data = None
        self.results = {}

    def load_and_prepare_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print(f"ğŸ“‚ {self.ticker} ë°ì´í„° ë¡œë“œ ì¤‘...")

        spy = yf.Ticker(self.ticker)
        df = spy.history(start=self.start_date, end=self.end_date)
        df.index = pd.to_datetime(df.index).tz_localize(None)

        # ê¸°ë³¸ ê³„ì‚°
        df['returns'] = np.log(df['Close'] / df['Close'].shift(1))
        df['volatility'] = df['returns'].rolling(20).std()

        # ë‹¤ì–‘í•œ ì‹œê°„ëŒ€ ë³€ë™ì„±
        for window in [5, 10, 20, 60]:
            df[f'vol_{window}d'] = df['returns'].rolling(window).std()

        # Lag íŠ¹ì„±
        for lag in [1, 2, 3, 5, 10, 20]:
            df[f'vol_lag_{lag}'] = df['volatility'].shift(lag)

        # íƒ€ê²Ÿë“¤ (multi-horizon)
        df['target_vol_1d'] = df['volatility'].shift(-1)
        df['target_vol_5d'] = df['returns'].rolling(5).std().shift(-5)
        df['target_vol_20d'] = df['returns'].rolling(20).std().shift(-20)

        df = df.dropna()
        self.data = df

        print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(df)} ìƒ˜í”Œ")
        return True

    def method1_garch_features(self):
        """ë°©ë²• 1: GARCH-inspired íŠ¹ì„± (arch ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´)"""
        print("\nğŸ”¹ ë°©ë²• 1: GARCH-inspired íŠ¹ì„± ìƒì„±...")

        df = self.data.copy()

        # GARCH ê·¼ì‚¬: ê³¼ê±° ì œê³± ìˆ˜ìµë¥ ê³¼ ê³¼ê±° ë³€ë™ì„±ì˜ ê°€ì¤‘ ì¡°í•©
        df['squared_returns'] = df['returns'] ** 2
        df['garch_proxy'] = (
            0.1 * df['squared_returns'].shift(1) +
            0.8 * df['volatility'].shift(1) ** 2
        )
        df['garch_vol'] = np.sqrt(df['garch_proxy'])

        # ë³€ë™ì„± persistence (ìê¸°ìƒê´€)
        df['vol_persistence'] = df['volatility'].rolling(5).apply(
            lambda x: x.autocorr(lag=1) if len(x) >= 5 else 0
        )

        # íŠ¹ì„± ì„ íƒ
        features = ['volatility', 'garch_vol', 'vol_persistence'] + \
                   [f'vol_lag_{i}' for i in [1, 2, 3, 5, 10]]

        X = df[features].dropna()
        y = df.loc[X.index, 'target_vol_5d']

        # Ridge ëª¨ë¸
        r2 = self._train_and_evaluate(X, y, "GARCH-inspired")

        self.results['method1_garch'] = {
            'r2': r2,
            'features': features,
            'description': 'GARCH proxy features'
        }

        return r2

    def method2_quantile_regression(self):
        """ë°©ë²• 2: Quantile Regression (ê·¹ë‹¨ê°’ ì˜ˆì¸¡)"""
        print("\nğŸ”¹ ë°©ë²• 2: Quantile Regression (50%, 75%, 90% ë¶„ìœ„)...")

        df = self.data.copy()

        features = ['volatility'] + [f'vol_lag_{i}' for i in [1, 2, 3, 5, 10]]
        X = df[features].dropna()
        y = df.loc[X.index, 'target_vol_5d']

        # 3ê°œ ë¶„ìœ„ìˆ˜ ëª¨ë¸
        quantiles = [0.5, 0.75, 0.9]
        predictions = []

        for q in quantiles:
            model = QuantileRegressor(quantile=q, alpha=0.1, solver='highs')

            tscv = TimeSeriesSplit(n_splits=3)
            preds = []

            for train_idx, test_idx in tscv.split(X):
                X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
                y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

                model.fit(X_train, y_train)
                pred = model.predict(X_test)
                preds.extend(pred)

            predictions.append(preds)

        # ì•™ìƒë¸”: í‰ê· 
        ensemble_pred = np.mean(predictions, axis=0)

        # ë§ˆì§€ë§‰ foldë§Œ í‰ê°€
        r2 = r2_score(y.iloc[-len(preds):], ensemble_pred)

        print(f"   Quantile Ensemble RÂ²: {r2:.4f}")

        self.results['method2_quantile'] = {
            'r2': r2,
            'quantiles': quantiles,
            'description': 'Quantile regression ensemble'
        }

        return r2

    def method3_regime_switching(self):
        """ë°©ë²• 3: Regime-Switching (ê³ ë³€ë™/ì €ë³€ë™ êµ¬ë¶„ í•™ìŠµ)"""
        print("\nğŸ”¹ ë°©ë²• 3: Regime-Switching ëª¨ë¸...")

        df = self.data.copy()

        # Regime êµ¬ë¶„: K-meansë¡œ ê³ ë³€ë™/ì €ë³€ë™ í´ëŸ¬ìŠ¤í„°ë§
        vol_values = df['volatility'].values.reshape(-1, 1)
        kmeans = KMeans(n_clusters=2, random_state=42)
        df['regime'] = kmeans.fit_predict(vol_values)

        # ê³ ë³€ë™ = 1, ì €ë³€ë™ = 0ìœ¼ë¡œ ì •ë ¬
        cluster_means = df.groupby('regime')['volatility'].mean()
        if cluster_means[0] > cluster_means[1]:
            df['regime'] = 1 - df['regime']

        print(f"   ê³ ë³€ë™ regime: {(df['regime']==1).sum()} ìƒ˜í”Œ")
        print(f"   ì €ë³€ë™ regime: {(df['regime']==0).sum()} ìƒ˜í”Œ")

        # ê° regimeë³„ ëª¨ë¸ í•™ìŠµ
        features = ['volatility'] + [f'vol_lag_{i}' for i in [1, 2, 3, 5, 10]]

        predictions = []
        actuals = []

        for regime in [0, 1]:
            df_regime = df[df['regime'] == regime].copy()

            if len(df_regime) < 100:
                continue

            X = df_regime[features]
            y = df_regime['target_vol_5d']

            # ê°„ë‹¨í•œ train/test split (ì‹œê³„ì—´ ìˆœì„œ ìœ ì§€)
            split = int(len(X) * 0.8)
            X_train, X_test = X[:split], X[split:]
            y_train, y_test = y[:split], y[split:]

            model = Ridge(alpha=1.0)
            model.fit(X_train, y_train)

            pred = model.predict(X_test)
            predictions.extend(pred)
            actuals.extend(y_test)

        r2 = r2_score(actuals, predictions)
        print(f"   Regime-Switching RÂ²: {r2:.4f}")

        self.results['method3_regime'] = {
            'r2': r2,
            'n_regimes': 2,
            'description': 'Separate models for high/low volatility regimes'
        }

        return r2

    def method4_multi_horizon(self):
        """ë°©ë²• 4: Multi-horizon ì˜ˆì¸¡ (1ì¼, 5ì¼, 20ì¼ ë™ì‹œ)"""
        print("\nğŸ”¹ ë°©ë²• 4: Multi-horizon ì˜ˆì¸¡...")

        df = self.data.copy()

        features = ['volatility'] + [f'vol_lag_{i}' for i in [1, 2, 3, 5, 10]]
        X = df[features].dropna()

        # 3ê°œ íƒ€ê²Ÿ ë™ì‹œ í•™ìŠµ
        targets = {
            '1d': df.loc[X.index, 'target_vol_1d'],
            '5d': df.loc[X.index, 'target_vol_5d'],
            '20d': df.loc[X.index, 'target_vol_20d']
        }

        results = {}

        for horizon, y in targets.items():
            y = y.dropna()
            X_aligned = X.loc[y.index]

            split = int(len(X_aligned) * 0.8)
            X_train = X_aligned[:split]
            X_test = X_aligned[split:]
            y_train = y[:split]
            y_test = y[split:]

            model = Ridge(alpha=1.0)
            model.fit(X_train, y_train)

            pred = model.predict(X_test)
            r2 = r2_score(y_test, pred)

            print(f"   {horizon} horizon RÂ²: {r2:.4f}")
            results[horizon] = r2

        # 5ì¼ ê¸°ì¤€ í‰ê°€
        r2_main = results['5d']

        self.results['method4_multihorizon'] = {
            'r2_5d': r2_main,
            'all_horizons': results,
            'description': 'Multi-horizon predictions (1d, 5d, 20d)'
        }

        return r2_main

    def method5_rolling_optimization(self):
        """ë°©ë²• 5: Rolling Window ì ì‘í˜• í•™ìŠµ"""
        print("\nğŸ”¹ ë°©ë²• 5: Rolling Window Optimization...")

        df = self.data.copy()

        features = ['volatility'] + [f'vol_lag_{i}' for i in [1, 2, 3, 5, 10]]
        X = df[features].dropna()
        y = df.loc[X.index, 'target_vol_5d']

        # Rolling window parameters
        train_window = 500  # 500ì¼ í•™ìŠµ
        test_window = 50    # 50ì¼ í…ŒìŠ¤íŠ¸

        predictions = []
        actuals = []

        start = train_window
        while start + test_window < len(X):
            # Train window
            X_train = X.iloc[start-train_window:start]
            y_train = y.iloc[start-train_window:start]

            # Test window
            X_test = X.iloc[start:start+test_window]
            y_test = y.iloc[start:start+test_window]

            # ì ì‘í˜• alpha ì„ íƒ (ìµœê·¼ ë³€ë™ì„±ì— ë”°ë¼)
            recent_vol = df['volatility'].iloc[start-10:start].mean()
            alpha = 0.5 if recent_vol > df['volatility'].median() else 1.5

            model = Ridge(alpha=alpha)
            model.fit(X_train, y_train)

            pred = model.predict(X_test)
            predictions.extend(pred)
            actuals.extend(y_test)

            start += test_window

        r2 = r2_score(actuals, predictions)
        print(f"   Rolling Window RÂ²: {r2:.4f}")
        print(f"   ì´ {len(predictions)} ì˜ˆì¸¡ ìƒì„±")

        self.results['method5_rolling'] = {
            'r2': r2,
            'train_window': train_window,
            'test_window': test_window,
            'description': 'Adaptive rolling window with dynamic alpha'
        }

        return r2

    def method6_exponential_weighting(self):
        """ë°©ë²• 6: ì§€ìˆ˜ ê°€ì¤‘ íŠ¹ì„± (ìµœê·¼ ë°ì´í„° ê°•ì¡°)"""
        print("\nğŸ”¹ ë°©ë²• 6: Exponential Weighted Features...")

        df = self.data.copy()

        # ì§€ìˆ˜ ê°€ì¤‘ ì´ë™í‰ê· 
        spans = [5, 10, 20, 60]
        for span in spans:
            df[f'ewm_vol_{span}'] = df['volatility'].ewm(span=span).mean()

        # ì§€ìˆ˜ ê°€ì¤‘ í‘œì¤€í¸ì°¨
        df['ewm_std'] = df['returns'].ewm(span=20).std()

        features = [f'ewm_vol_{s}' for s in spans] + ['ewm_std'] + \
                   [f'vol_lag_{i}' for i in [1, 2, 3, 5]]

        X = df[features].dropna()
        y = df.loc[X.index, 'target_vol_5d']

        r2 = self._train_and_evaluate(X, y, "Exponential Weighted")

        self.results['method6_ewm'] = {
            'r2': r2,
            'features': features,
            'description': 'Exponentially weighted moving features'
        }

        return r2

    def _train_and_evaluate(self, X, y, method_name):
        """ê³µí†µ í•™ìŠµ ë° í‰ê°€"""
        split = int(len(X) * 0.8)
        X_train, X_test = X[:split], X[split:]
        y_train, y_test = y[:split], y[split:]

        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        model = Ridge(alpha=1.0)
        model.fit(X_train_scaled, y_train)

        pred = model.predict(X_test_scaled)
        r2 = r2_score(y_test, pred)

        print(f"   {method_name} RÂ²: {r2:.4f}")

        return r2

    def run_all_methods(self):
        """ëª¨ë“  ë°©ë²• ì‹¤í–‰ ë° ë¹„êµ"""
        print("="*60)
        print("ğŸš€ ë³€ë™ì„± ì˜ˆì¸¡ V2: í˜ì‹ ì  ì ‘ê·¼ ë°©ë²•ë“¤")
        print("="*60)
        print("ê¸°ì¤€ì„ : Ridge RÂ² = 0.303\n")

        self.load_and_prepare_data()

        methods = [
            ("GARCH-inspired Features", self.method1_garch_features),
            ("Quantile Regression", self.method2_quantile_regression),
            ("Regime-Switching", self.method3_regime_switching),
            ("Multi-horizon", self.method4_multi_horizon),
            ("Rolling Window", self.method5_rolling_optimization),
            ("Exponential Weighting", self.method6_exponential_weighting),
        ]

        scores = []

        for name, method in methods:
            try:
                r2 = method()
                scores.append((name, r2))
            except Exception as e:
                print(f"   âŒ {name} ì‹¤íŒ¨: {e}")
                scores.append((name, 0.0))

        # ìµœì¢… ë¹„êµ
        print("\n" + "="*60)
        print("ğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ")
        print("="*60)

        baseline = 0.303
        print(f"{'ë°©ë²•':<30s} {'RÂ²':>10s} {'vs Baseline':>15s}")
        print("-"*60)
        print(f"{'Baseline (ê¸°ì¡´ Ridge)':<30s} {baseline:>10.4f} {'-':>15s}")

        for name, r2 in sorted(scores, key=lambda x: x[1], reverse=True):
            improvement = r2 - baseline
            symbol = "âœ…" if r2 > baseline else "âŒ"
            print(f"{name:<30s} {r2:>10.4f} {improvement:>+14.4f} {symbol}")

        # ìµœê³  ì„±ëŠ¥
        best_method, best_r2 = max(scores, key=lambda x: x[1])

        print("\n" + "="*60)
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥: {best_method}")
        print(f"   RÂ² = {best_r2:.4f}")
        print(f"   ê°œì„ í­ = {best_r2 - baseline:+.4f}")
        print("="*60)

        # ê²°ê³¼ ì €ì¥
        import json
        from datetime import datetime

        output = {
            'experiment': 'volatility_prediction_v2',
            'baseline_r2': baseline,
            'best_method': best_method,
            'best_r2': best_r2,
            'improvement': best_r2 - baseline,
            'all_results': self.results,
            'timestamp': datetime.now().isoformat()
        }

        with open('data/raw/volatility_v2_results.json', 'w') as f:
            json.dump(output, f, indent=2)

        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥: data/raw/volatility_v2_results.json")

        return best_r2

if __name__ == "__main__":
    predictor = VolatilityPredictorV2()
    predictor.run_all_methods()
