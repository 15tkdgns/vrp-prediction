#!/usr/bin/env python3
"""
í–¥ìƒëœ ë³€ë™ì„± ì˜ˆì¸¡ ëª¨ë¸
Phase 1: ë¹„ëŒ€ì¹­ íŠ¹ì„± ì¶”ê°€ (Leverage Effect, Downside Risk)

ëª©í‘œ: RÂ² 0.30 â†’ 0.35
"""

import pandas as pd
import numpy as np
import yfinance as yf
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class EnhancedVolatilityPredictor:
    """í–¥ìƒëœ ë³€ë™ì„± ì˜ˆì¸¡ ëª¨ë¸"""

    def __init__(self, ticker="SPY", start_date="2015-01-01", end_date="2024-12-31"):
        self.ticker = ticker
        self.start_date = start_date
        self.end_date = end_date
        self.data = None
        self.model = None
        self.scaler = StandardScaler()
        self.results = {}

    def load_and_prepare_data(self):
        """ë°ì´í„° ë¡œë“œ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§"""
        print(f"ğŸ“‚ {self.ticker} ë°ì´í„° ë¡œë“œ ì¤‘...")

        # SPY ë°ì´í„°
        spy = yf.Ticker(self.ticker)
        df = spy.history(start=self.start_date, end=self.end_date)
        df.index = pd.to_datetime(df.index).tz_localize(None)

        print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(df)} ìƒ˜í”Œ")

        # ê¸°ë³¸ íŠ¹ì„±
        df['returns'] = np.log(df['Close'] / df['Close'].shift(1))
        df['volatility_5d'] = df['returns'].rolling(5).std()
        df['volatility_10d'] = df['returns'].rolling(10).std()
        df['volatility_20d'] = df['returns'].rolling(20).std()

        # **ìƒˆë¡œìš´ ë¹„ëŒ€ì¹­ íŠ¹ì„± ì¶”ê°€**
        print("\nğŸ†• ë¹„ëŒ€ì¹­ íŠ¹ì„± ì¶”ê°€ ì¤‘...")

        # 1. Leverage Effect (í•˜ë½ ì‹œ ë³€ë™ì„± ì¦í­)
        df['leverage_effect'] = (df['returns'] < 0).astype(int) * df['returns'].abs()
        df['leverage_vol'] = df['leverage_effect'].rolling(5).std()

        # 2. Downside Volatility (í•˜ë°© ìœ„í—˜)
        df['negative_returns'] = df['returns'].where(df['returns'] < 0, 0)
        df['downside_vol_5d'] = df['negative_returns'].rolling(5).std()
        df['downside_vol_20d'] = df['negative_returns'].rolling(20).std()

        # 3. Upside Volatility (ìƒìŠ¹ ë³€ë™ì„±)
        df['positive_returns'] = df['returns'].where(df['returns'] > 0, 0)
        df['upside_vol_5d'] = df['positive_returns'].rolling(5).std()

        # 4. Asymmetry Ratio (ë¹„ëŒ€ì¹­ ë¹„ìœ¨)
        df['asym_ratio'] = df['downside_vol_5d'] / (df['upside_vol_5d'] + 1e-6)

        # 5. Jump Detection (ê·¹ë‹¨ ì›€ì§ì„)
        df['jump'] = (df['returns'].abs() > 3 * df['volatility_20d']).astype(int)
        df['jump_frequency'] = df['jump'].rolling(20).sum()

        # 6. Intraday Range (ì¼ì¤‘ ë³€ë™í­)
        df['intraday_range'] = (df['High'] - df['Low']) / df['Close']
        df['range_volatility'] = df['intraday_range'].rolling(5).std()

        # 7. Parkinson Volatility (High-Low ê¸°ë°˜)
        df['parkinson_vol'] = np.sqrt(
            1 / (4 * np.log(2)) * np.log(df['High'] / df['Low']) ** 2
        )

        # ê¸°ì¡´ lag íŠ¹ì„±
        for lag in [1, 2, 3, 5, 10]:
            df[f'vol_lag_{lag}'] = df['volatility_5d'].shift(lag)
            df[f'downside_lag_{lag}'] = df['downside_vol_5d'].shift(lag)

        # íƒ€ê²Ÿ: 5ì¼ í›„ ë³€ë™ì„±
        df['target_vol'] = df['volatility_5d'].shift(-5)

        # ê²°ì¸¡ì¹˜ ì œê±°
        df = df.dropna()

        print(f"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: {df.shape[1]}ê°œ ì»¬ëŸ¼")
        print(f"   - ê¸°ë³¸ ë³€ë™ì„±: 3ê°œ")
        print(f"   - ë¹„ëŒ€ì¹­ íŠ¹ì„±: 7ê°œ (NEW)")
        print(f"   - Lag íŠ¹ì„±: 10ê°œ")

        self.data = df
        return True

    def train_model(self):
        """ëª¨ë¸ í•™ìŠµ (TimeSeriesSplit)"""
        print("\nğŸ¤– í–¥ìƒëœ Ridge ëª¨ë¸ í•™ìŠµ ì¤‘...")

        # íŠ¹ì„± ì„ íƒ
        feature_cols = [
            # ê¸°ë³¸ ë³€ë™ì„±
            'volatility_5d', 'volatility_10d', 'volatility_20d',

            # ë¹„ëŒ€ì¹­ íŠ¹ì„±
            'leverage_effect', 'leverage_vol',
            'downside_vol_5d', 'downside_vol_20d',
            'upside_vol_5d', 'asym_ratio',
            'jump_frequency', 'intraday_range', 'range_volatility',
            'parkinson_vol',

            # Lag íŠ¹ì„±
            'vol_lag_1', 'vol_lag_2', 'vol_lag_3', 'vol_lag_5', 'vol_lag_10',
            'downside_lag_1', 'downside_lag_2', 'downside_lag_3', 'downside_lag_5', 'downside_lag_10'
        ]

        X = self.data[feature_cols]
        y = self.data['target_vol']

        print(f"   íŠ¹ì„± ìˆ˜: {len(feature_cols)}")
        print(f"   ìƒ˜í”Œ ìˆ˜: {len(X)}")

        # TimeSeriesSplit CV
        tscv = TimeSeriesSplit(n_splits=5)
        cv_scores = []

        for fold_idx, (train_idx, test_idx) in enumerate(tscv.split(X), 1):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            # ìŠ¤ì¼€ì¼ë§
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            # Ridge ëª¨ë¸
            model = Ridge(alpha=1.0)
            model.fit(X_train_scaled, y_train)

            # ì˜ˆì¸¡
            y_pred = model.predict(X_test_scaled)

            # ì„±ëŠ¥
            r2 = r2_score(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            mae = mean_absolute_error(y_test, y_pred)

            print(f"   Fold {fold_idx}: RÂ² = {r2:.4f}, RMSE = {rmse:.6f}, MAE = {mae:.6f}")

            cv_scores.append({
                'fold': fold_idx,
                'r2': r2,
                'rmse': rmse,
                'mae': mae
            })

        # í‰ê·  ì„±ëŠ¥
        mean_r2 = np.mean([s['r2'] for s in cv_scores])
        std_r2 = np.std([s['r2'] for s in cv_scores])
        mean_rmse = np.mean([s['rmse'] for s in cv_scores])
        mean_mae = np.mean([s['mae'] for s in cv_scores])

        print(f"\nğŸ“Š TimeSeriesSplit CV í‰ê·  ì„±ëŠ¥:")
        print(f"   RÂ² = {mean_r2:.4f} Â± {std_r2:.4f}")
        print(f"   RMSE = {mean_rmse:.6f}")
        print(f"   MAE = {mean_mae:.6f}")

        # ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ
        X_scaled = self.scaler.fit_transform(X)
        self.model = Ridge(alpha=1.0)
        self.model.fit(X_scaled, y)

        # ê²°ê³¼ ì €ì¥
        self.results = {
            'model_name': 'Enhanced Ridge with Asymmetric Features',
            'cv_mean_r2': mean_r2,
            'cv_std_r2': std_r2,
            'cv_mean_rmse': mean_rmse,
            'cv_mean_mae': mean_mae,
            'n_features': len(feature_cols),
            'n_samples': len(X),
            'cv_scores': cv_scores,
            'feature_list': feature_cols
        }

        # Feature importance (Ridge ê³„ìˆ˜)
        feature_importance = pd.DataFrame({
            'feature': feature_cols,
            'coefficient': self.model.coef_
        }).sort_values('coefficient', key=abs, ascending=False)

        print(f"\nğŸ” Top 10 ì¤‘ìš” íŠ¹ì„±:")
        for idx, row in feature_importance.head(10).iterrows():
            print(f"   {row['feature']:30s}: {row['coefficient']:+.4f}")

        self.results['feature_importance'] = feature_importance.to_dict('records')

        return True

    def compare_with_baseline(self):
        """ê¸°ì¡´ ëª¨ë¸ê³¼ ë¹„êµ"""
        print(f"\nğŸ“ˆ ê¸°ì¡´ ëª¨ë¸ê³¼ ë¹„êµ...")

        # ê¸°ì¡´ ëª¨ë¸ ì„±ëŠ¥ (README ê¸°ì¤€)
        baseline_r2 = 0.303
        current_r2 = self.results['cv_mean_r2']

        improvement = current_r2 - baseline_r2
        improvement_pct = (improvement / baseline_r2) * 100

        print(f"\n   ê¸°ì¡´ Ridge (31ê°œ íŠ¹ì„±): RÂ² = {baseline_r2:.4f}")
        print(f"   í–¥ìƒ Ridge (ë¹„ëŒ€ì¹­ ì¶”ê°€): RÂ² = {current_r2:.4f}")
        print(f"   ê°œì„ í­: {improvement:+.4f} ({improvement_pct:+.1f}%)")

        if current_r2 > baseline_r2:
            print(f"   âœ… ì„±ëŠ¥ í–¥ìƒ ì„±ê³µ!")
        else:
            print(f"   âš ï¸  ì„±ëŠ¥ í–¥ìƒ ì‹¤íŒ¨ (ì¶”ê°€ ì¡°ì • í•„ìš”)")

        self.results['comparison'] = {
            'baseline_r2': baseline_r2,
            'current_r2': current_r2,
            'improvement': improvement,
            'improvement_pct': improvement_pct
        }

        return True

    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        try:
            self.results['metadata'] = {
                'experiment': 'enhanced_volatility_phase1',
                'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'improvements': [
                    'Leverage effect',
                    'Downside volatility',
                    'Asymmetry ratio',
                    'Jump detection',
                    'Parkinson volatility'
                ]
            }

            output_path = "data/raw/enhanced_volatility_phase1_results.json"
            with open(output_path, 'w') as f:
                json.dump(self.results, f, indent=2)

            print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
            return True

        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def run_experiment(self):
        """ì „ì²´ ì‹¤í—˜ ì‹¤í–‰"""
        print("="*60)
        print("ğŸš€ ë³€ë™ì„± ì˜ˆì¸¡ ì„±ëŠ¥ í–¥ìƒ ì‹¤í—˜ - Phase 1")
        print("="*60)
        print("ëª©í‘œ: ë¹„ëŒ€ì¹­ íŠ¹ì„± ì¶”ê°€ë¡œ RÂ² 0.30 â†’ 0.35\n")

        if not self.load_and_prepare_data():
            return False

        if not self.train_model():
            return False

        if not self.compare_with_baseline():
            return False

        if not self.save_results():
            return False

        print("\n" + "="*60)
        print("âœ… Phase 1 ì‹¤í—˜ ì™„ë£Œ!")
        print("="*60)

        # ìµœì¢… ìš”ì•½
        current_r2 = self.results['cv_mean_r2']
        target_r2 = 0.35

        print(f"\nğŸ“‹ ìµœì¢… ê²°ê³¼:")
        print(f"   ë‹¬ì„± RÂ²: {current_r2:.4f}")
        print(f"   ëª©í‘œ RÂ²: {target_r2:.4f}")

        if current_r2 >= target_r2:
            print(f"   âœ… Phase 1 ëª©í‘œ ë‹¬ì„±!")
        else:
            gap = target_r2 - current_r2
            print(f"   âš ï¸  ëª©í‘œ ë¯¸ë‹¬ (ë¶€ì¡±: {gap:.4f})")
            print(f"   â†’ Phase 2 (GARCH) í•„ìš”")

        return True

if __name__ == "__main__":
    predictor = EnhancedVolatilityPredictor(
        ticker="SPY",
        start_date="2015-01-01",
        end_date="2024-12-31"
    )

    predictor.run_experiment()
