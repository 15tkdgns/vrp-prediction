#!/usr/bin/env python3
"""
ë³€ë™ì„± ì˜ˆì¸¡ V3 Fixed: ë°ì´í„° ëˆ„ì¶œ ìˆ˜ì •
ëª¨ë“  íŠ¹ì„±ì— shift(1) ì ìš© â†’ ì™„ì „í•œ ì‹œê°„ì  ë¶„ë¦¬

ëª©í‘œ: RÂ² 0.33 â†’ 0.40+ (ëˆ„ì¶œ ì—†ì´)
"""

import pandas as pd
import numpy as np
import yfinance as yf
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class VolatilityPredictorV3Fixed:
    """ë°ì´í„° ëˆ„ì¶œ ìˆ˜ì •ëœ V3"""

    def __init__(self, ticker="SPY", start_date="2015-01-01", end_date="2024-12-31"):
        self.ticker = ticker
        self.start_date = start_date
        self.end_date = end_date
        self.data = None
        self.results = {}

    def load_and_engineer_features(self):
        """ì™„ì „í•œ ì‹œê°„ì  ë¶„ë¦¬ ë³´ì¥"""
        print(f"ğŸ“‚ {self.ticker} ë°ì´í„° ë¡œë“œ ì¤‘...")

        spy = yf.Ticker(self.ticker)
        df = spy.history(start=self.start_date, end=self.end_date)
        df.index = pd.to_datetime(df.index).tz_localize(None)

        print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(df)} ìƒ˜í”Œ")

        # ê¸°ë³¸ ê³„ì‚°
        df['returns'] = np.log(df['Close'] / df['Close'].shift(1))

        # âš ï¸ ì¤‘ìš”: ëª¨ë“  ë³€ë™ì„± ê³„ì‚° í›„ shift(1) ì ìš©!
        df['volatility'] = df['returns'].rolling(20).std()
        df['vol_5d'] = df['returns'].rolling(5).std()
        df['vol_10d'] = df['returns'].rolling(10).std()
        df['vol_20d'] = df['returns'].rolling(20).std()
        df['vol_60d'] = df['returns'].rolling(60).std()

        print("\nğŸ”§ íŒ¨í„´ ê¸°ë°˜ íŠ¹ì„± ìƒì„± (ë°ì´í„° ëˆ„ì¶œ ë°©ì§€)...")

        # === íŒ¨í„´ 1: ATR (shift ì ìš©) ===
        df['high_low'] = df['High'] - df['Low']
        df['high_close'] = abs(df['High'] - df['Close'].shift(1))
        df['low_close'] = abs(df['Low'] - df['Close'].shift(1))
        df['true_range'] = df[['high_low', 'high_close', 'low_close']].max(axis=1)
        df['atr_14_raw'] = df['true_range'].rolling(14).mean()
        df['atr_14'] = df['atr_14_raw'].shift(1)  # âœ… shift!
        df['atr_ratio'] = (df['atr_14'] / df['Close']).shift(1)  # âœ… ì¶”ê°€ shift!

        # === íŒ¨í„´ 2: Gap (ì´ë¯¸ ì˜¬ë°”ë¦„) ===
        df['gap'] = (df['Open'] - df['Close'].shift(1)) / df['Close'].shift(1)
        df['gap_size'] = df['gap'].abs()
        df['gap_size_ma'] = df['gap_size'].rolling(10).mean().shift(1)
        df['large_gap_count'] = (df['gap_size'] > df['gap_size'].quantile(0.9)).rolling(20).sum().shift(1)

        # === íŒ¨í„´ 3: Volume ===
        df['volume_ratio'] = (df['Volume'] / df['Volume'].rolling(20).mean()).shift(1)  # âœ… shift!
        df['volume_spike'] = (df['volume_ratio'] > 1.5).astype(int)
        df['volume_spike_count'] = df['volume_spike'].rolling(20).sum().shift(1)

        # === íŒ¨í„´ 4: Momentum ===
        df['momentum_5'] = (df['Close'].shift(1) / df['Close'].shift(6) - 1)  # âœ… t-1 ê¸°ì¤€
        df['momentum_10'] = (df['Close'].shift(1) / df['Close'].shift(11) - 1)
        df['momentum_20'] = (df['Close'].shift(1) / df['Close'].shift(21) - 1)
        df['momentum_strength'] = df['momentum_20'].abs()

        # === íŒ¨í„´ 5: Vol-of-Vol ===
        df['vol_of_vol'] = df['vol_20d'].rolling(20).std().shift(1)  # âœ… shift!
        df['vol_of_vol_ratio'] = (df['vol_of_vol'] / df['vol_20d'].shift(1))

        # === íŒ¨í„´ 6: Parkinson Vol (shift ì ìš©) ===
        df['parkinson_vol_raw'] = np.sqrt(
            1 / (4 * np.log(2)) * np.log(df['High'] / df['Low']) ** 2
        )
        df['parkinson_vol'] = df['parkinson_vol_raw'].shift(1)  # âœ… shift!

        # === íŒ¨í„´ 7: Realized Range (shift ì ìš©) ===
        df['realized_range_raw'] = (df['High'] - df['Low']) / df['Open']
        df['realized_range'] = df['realized_range_raw'].shift(1)  # âœ… shift!

        # === íŒ¨í„´ 8: Rolling Skew/Kurt ===
        df['rolling_skew_20'] = df['returns'].rolling(20).skew().shift(1)  # âœ… shift!
        df['rolling_kurt_20'] = df['returns'].rolling(20).kurt().shift(1)  # âœ… shift!

        # === íŒ¨í„´ 9: ë³€ë™ì„± Lag (ì´ë¯¸ shiftë¨) ===
        df['vol_lag_1'] = df['vol_20d'].shift(1)
        df['vol_lag_2'] = df['vol_20d'].shift(2)
        df['vol_lag_3'] = df['vol_20d'].shift(3)
        df['vol_lag_5'] = df['vol_20d'].shift(5)
        df['vol_lag_10'] = df['vol_20d'].shift(10)

        # === íŒ¨í„´ 10: ê·¹ë‹¨ê°’ ì¹´ìš´í„° ===
        df['extreme_return'] = (df['returns'].abs() > df['returns'].rolling(60).std() * 2).astype(int)
        df['extreme_count'] = df['extreme_return'].rolling(20).sum().shift(1)  # âœ… shift!

        # === ìƒí˜¸ì‘ìš© íŠ¹ì„± (ëª¨ë‘ shiftëœ ë³€ìˆ˜ ì‚¬ìš©) ===
        df['atr_x_volume'] = df['atr_ratio'] * df['volume_ratio']
        df['gap_x_momentum'] = df['gap_size'] * df['momentum_strength']
        df['vov_x_parkinson'] = df['vol_of_vol'] * df['parkinson_vol']

        # íƒ€ê²Ÿ: 5ì¼ í›„ ë³€ë™ì„± (ì˜¬ë°”ë¦„)
        df['target_vol_5d'] = df['vol_20d'].shift(-5)

        df = df.dropna()
        self.data = df

        print(f"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: {df.shape[1]}ê°œ ì»¬ëŸ¼, {len(df)} ìƒ˜í”Œ")
        print(f"âœ… ëª¨ë“  íŠ¹ì„± shift(1) ì ìš© ì™„ë£Œ (t-1ì¼ê¹Œì§€ ì •ë³´ë§Œ ì‚¬ìš©)")

        return True

    def method1_pattern_ridge_fixed(self):
        """ë°©ë²• 1: íŒ¨í„´ ê¸°ë°˜ Ridge (ëˆ„ì¶œ ìˆ˜ì •)"""
        print("\nğŸ”¹ ë°©ë²• 1: íŒ¨í„´ ê¸°ë°˜ Ridge (Fixed)...")

        features = [
            'atr_ratio', 'gap_size', 'gap_size_ma', 'large_gap_count',
            'volume_ratio', 'volume_spike_count',
            'momentum_strength', 'vol_of_vol', 'vol_of_vol_ratio',
            'parkinson_vol', 'realized_range',
            'rolling_skew_20', 'rolling_kurt_20',
            'vol_lag_1', 'vol_lag_2', 'vol_lag_5', 'vol_lag_10',
            'extreme_count', 'atr_x_volume', 'gap_x_momentum'
        ]

        X = self.data[features].dropna()
        y = self.data.loc[X.index, 'target_vol_5d']

        r2 = self._train_and_evaluate(X, y, Ridge(alpha=1.0), "Pattern Ridge Fixed")

        self.results['method1_ridge_fixed'] = {'r2': r2, 'n_features': len(features)}
        return r2

    def method2_xgboost_fixed(self):
        """ë°©ë²• 2: XGBoost (ëˆ„ì¶œ ìˆ˜ì •)"""
        print("\nğŸ”¹ ë°©ë²• 2: XGBoost (Fixed)...")

        features = [
            'atr_ratio', 'gap_size', 'volume_ratio', 'momentum_strength',
            'vol_of_vol', 'parkinson_vol', 'rolling_kurt_20',
            'vol_lag_1', 'vol_lag_2', 'vol_lag_5',
            'extreme_count', 'atr_x_volume', 'gap_x_momentum'
        ]

        X = self.data[features].dropna()
        y = self.data.loc[X.index, 'target_vol_5d']

        model = XGBRegressor(
            n_estimators=100,
            max_depth=3,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            verbosity=0
        )

        r2 = self._train_and_evaluate(X, y, model, "XGBoost Fixed")

        self.results['method2_xgboost_fixed'] = {'r2': r2, 'n_features': len(features)}
        return r2

    def method3_vix_fixed(self):
        """ë°©ë²• 3: VIX + íŒ¨í„´ (ëˆ„ì¶œ ìˆ˜ì •)"""
        print("\nğŸ”¹ ë°©ë²• 3: VIX + íŒ¨í„´ (Fixed)...")

        try:
            vix = yf.Ticker("^VIX")
            vix_data = vix.history(start=self.start_date, end=self.end_date)
            vix_data.index = pd.to_datetime(vix_data.index).tz_localize(None)

            df = self.data.copy()
            df['vix'] = vix_data['Close'].reindex(df.index, method='ffill').shift(1)  # âœ… shift!
            df['vix_change'] = df['vix'].pct_change(5)
            df['vix_ma'] = df['vix'].rolling(20).mean().shift(1)

            df = df.dropna()

            features = [
                'vix', 'vix_change', 'vix_ma',
                'atr_ratio', 'gap_size', 'volume_ratio',
                'vol_of_vol', 'parkinson_vol',
                'vol_lag_1', 'vol_lag_5', 'momentum_strength'
            ]

            X = df[features]
            y = df['target_vol_5d']

            r2 = self._train_and_evaluate(X, y, Ridge(alpha=1.0), "Ridge + VIX Fixed")

            self.results['method3_vix_fixed'] = {'r2': r2, 'n_features': len(features)}
            return r2

        except Exception as e:
            print(f"   âš ï¸  VIX ì‹¤íŒ¨: {e}")
            self.results['method3_vix_fixed'] = {'r2': 0.0, 'error': str(e)}
            return 0.0

    def method4_lightgbm_fixed(self):
        """ë°©ë²• 4: LightGBM (ëˆ„ì¶œ ìˆ˜ì •)"""
        print("\nğŸ”¹ ë°©ë²• 4: LightGBM (Fixed)...")

        features = [
            'atr_ratio', 'gap_size', 'volume_ratio', 'momentum_strength',
            'vol_of_vol', 'parkinson_vol', 'rolling_skew_20',
            'vol_lag_1', 'vol_lag_5', 'extreme_count',
            'atr_x_volume', 'gap_x_momentum', 'vov_x_parkinson'
        ]

        X = self.data[features].dropna()
        y = self.data.loc[X.index, 'target_vol_5d']

        model = LGBMRegressor(
            n_estimators=100,
            max_depth=3,
            learning_rate=0.05,
            num_leaves=15,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            verbosity=-1
        )

        r2 = self._train_and_evaluate(X, y, model, "LightGBM Fixed")

        self.results['method4_lightgbm_fixed'] = {'r2': r2, 'n_features': len(features)}
        return r2

    def method5_stacking_fixed(self):
        """ë°©ë²• 5: Stacking (ëˆ„ì¶œ ìˆ˜ì •)"""
        print("\nğŸ”¹ ë°©ë²• 5: Stacking Ensemble (Fixed)...")

        features = [
            'atr_ratio', 'gap_size', 'volume_ratio', 'momentum_strength',
            'vol_of_vol', 'parkinson_vol', 'vol_lag_1', 'vol_lag_5',
            'extreme_count', 'atr_x_volume'
        ]

        X = self.data[features].dropna()
        y = self.data.loc[X.index, 'target_vol_5d']

        tscv = TimeSeriesSplit(n_splits=5)
        all_preds = []
        all_actuals = []

        for train_idx, test_idx in tscv.split(X):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            ridge = Ridge(alpha=1.0)
            xgb = XGBRegressor(n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42, verbosity=0)

            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            ridge.fit(X_train_scaled, y_train)
            xgb.fit(X_train, y_train)

            ridge_pred = ridge.predict(X_test_scaled)
            xgb_pred = xgb.predict(X_test)

            ensemble_pred = 0.6 * ridge_pred + 0.4 * xgb_pred

            all_preds.extend(ensemble_pred)
            all_actuals.extend(y_test)

        r2 = r2_score(all_actuals, all_preds)
        print(f"   Stacking Fixed RÂ²: {r2:.4f}")

        self.results['method5_stacking_fixed'] = {'r2': r2}
        return r2

    def _train_and_evaluate(self, X, y, model, method_name):
        """TimeSeriesSplit í‰ê°€"""
        tscv = TimeSeriesSplit(n_splits=5)
        scores = []

        for train_idx, test_idx in tscv.split(X):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            if isinstance(model, Ridge):
                scaler = StandardScaler()
                X_train = scaler.fit_transform(X_train)
                X_test = scaler.transform(X_test)

            model.fit(X_train, y_train)
            pred = model.predict(X_test)

            r2 = r2_score(y_test, pred)
            scores.append(r2)

        mean_r2 = np.mean(scores)
        print(f"   {method_name} RÂ²: {mean_r2:.4f} (Â±{np.std(scores):.4f})")

        return mean_r2

    def run_all_methods(self):
        """ëª¨ë“  ë°©ë²• ì‹¤í–‰"""
        print("="*60)
        print("ğŸš€ ë³€ë™ì„± ì˜ˆì¸¡ V3 Fixed: ë°ì´í„° ëˆ„ì¶œ ìˆ˜ì •")
        print("="*60)
        print("ê¸°ì¤€ì„ : V2 Regime RÂ² = 0.328\n")

        self.load_and_engineer_features()

        methods = [
            ("Pattern Ridge Fixed", self.method1_pattern_ridge_fixed),
            ("XGBoost Fixed", self.method2_xgboost_fixed),
            ("VIX + Ridge Fixed", self.method3_vix_fixed),
            ("LightGBM Fixed", self.method4_lightgbm_fixed),
            ("Stacking Fixed", self.method5_stacking_fixed),
        ]

        scores = []

        for name, method in methods:
            try:
                r2 = method()
                scores.append((name, r2))
            except Exception as e:
                print(f"   âŒ {name} ì‹¤íŒ¨: {e}")
                scores.append((name, 0.0))

        # ìµœì¢… ë¹„êµ
        print("\n" + "="*60)
        print("ğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ (ë°ì´í„° ëˆ„ì¶œ ìˆ˜ì •)")
        print("="*60)

        baseline_v2 = 0.328
        baseline_v0 = 0.303

        print(f"{'ë°©ë²•':<30s} {'RÂ²':>10s} {'vs V2':>12s} {'vs V0':>12s}")
        print("-"*60)
        print(f"{'V0 Ridge':<30s} {baseline_v0:>10.4f} {'-':>12s} {'-':>12s}")
        print(f"{'V2 Regime':<30s} {baseline_v2:>10.4f} {'-':>12s} {f'+{baseline_v2-baseline_v0:.4f}':>12s}")

        for name, r2 in sorted(scores, key=lambda x: x[1], reverse=True):
            improvement_v2 = r2 - baseline_v2
            improvement_v0 = r2 - baseline_v0
            symbol = "âœ…" if r2 > baseline_v2 else "âŒ"
            print(f"{name:<30s} {r2:>10.4f} {improvement_v2:>+11.4f} {improvement_v0:>+11.4f} {symbol}")

        best_method, best_r2 = max(scores, key=lambda x: x[1])

        print("\n" + "="*60)
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥: {best_method}")
        print(f"   RÂ² = {best_r2:.4f}")
        print(f"   vs V2 ê°œì„ í­ = {best_r2 - baseline_v2:+.4f}")
        print(f"   vs V0 ê°œì„ í­ = {best_r2 - baseline_v0:+.4f}")
        print("="*60)

        output = {
            'experiment': 'volatility_prediction_v3_fixed',
            'baseline_v0_r2': baseline_v0,
            'baseline_v2_r2': baseline_v2,
            'best_method': best_method,
            'best_r2': best_r2,
            'improvement_vs_v2': best_r2 - baseline_v2,
            'improvement_vs_v0': best_r2 - baseline_v0,
            'all_results': self.results,
            'data_leakage': 'FIXED - All features shifted',
            'timestamp': datetime.now().isoformat()
        }

        with open('data/raw/volatility_v3_fixed_results.json', 'w') as f:
            json.dump(output, f, indent=2)

        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥: data/raw/volatility_v3_fixed_results.json")

        return best_r2

if __name__ == "__main__":
    predictor = VolatilityPredictorV3Fixed()
    predictor.run_all_methods()
