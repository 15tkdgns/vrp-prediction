#!/usr/bin/env python3
"""
ë³€ë™ì„± ì˜ˆì¸¡ V3: íŒ¨í„´ ê¸°ë°˜ ê³ ê¸‰ ëª¨ë¸
ë°œê²¬ëœ ê°•ë ¥í•œ íŒ¨í„´ + ë¹„ì„ í˜• ëª¨ë¸ + ì•™ìƒë¸”

ëª©í‘œ: RÂ² 0.33 â†’ 0.40+
"""

import pandas as pd
import numpy as np
import yfinance as yf
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class VolatilityPredictorV3:
    """íŒ¨í„´ ê¸°ë°˜ ê³ ê¸‰ ë³€ë™ì„± ì˜ˆì¸¡ V3"""

    def __init__(self, ticker="SPY", start_date="2015-01-01", end_date="2024-12-31"):
        self.ticker = ticker
        self.start_date = start_date
        self.end_date = end_date
        self.data = None
        self.results = {}

    def load_and_engineer_features(self):
        """ë°œê²¬ëœ íŒ¨í„´ ê¸°ë°˜ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§"""
        print(f"ğŸ“‚ {self.ticker} ë°ì´í„° ë¡œë“œ ì¤‘...")

        spy = yf.Ticker(self.ticker)
        df = spy.history(start=self.start_date, end=self.end_date)
        df.index = pd.to_datetime(df.index).tz_localize(None)

        print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(df)} ìƒ˜í”Œ")

        # ê¸°ë³¸ ê³„ì‚°
        df['returns'] = np.log(df['Close'] / df['Close'].shift(1))
        df['volatility'] = df['returns'].rolling(20).std()

        print("\nğŸ”§ íŒ¨í„´ ê¸°ë°˜ íŠ¹ì„± ìƒì„± ì¤‘...")

        # === íŒ¨í„´ 1: ATR (Average True Range) - ìƒê´€ 0.67 ===
        df['high_low'] = df['High'] - df['Low']
        df['high_close'] = abs(df['High'] - df['Close'].shift(1))
        df['low_close'] = abs(df['Low'] - df['Close'].shift(1))
        df['true_range'] = df[['high_low', 'high_close', 'low_close']].max(axis=1)
        df['atr_14'] = df['true_range'].rolling(14).mean()
        df['atr_ratio'] = df['atr_14'] / df['Close']

        # ATR ë³€í™”ìœ¨
        df['atr_change'] = df['atr_14'].pct_change(5)

        # === íŒ¨í„´ 2: Overnight Gap (íš¨ê³¼ 1.98ë°°) ===
        df['gap'] = (df['Open'] - df['Close'].shift(1)) / df['Close'].shift(1)
        df['gap_size'] = df['gap'].abs()
        df['gap_size_ma'] = df['gap_size'].rolling(10).mean()

        # í° ê°­ ë¹ˆë„
        df['large_gap_count'] = (df['gap_size'] > df['gap_size'].quantile(0.9)).rolling(20).sum()

        # === íŒ¨í„´ 3: U-shape ìˆ˜ìµë¥  íš¨ê³¼ (1.98ë°°) ===
        df['cumulative_returns_5d'] = df['returns'].rolling(5).sum()
        df['extreme_return'] = (df['cumulative_returns_5d'].abs() > df['cumulative_returns_5d'].abs().quantile(0.75)).astype(int)
        df['extreme_return_count'] = df['extreme_return'].rolling(20).sum()

        # === íŒ¨í„´ 4: Volume Spike (íš¨ê³¼ 1.66ë°°) ===
        df['volume_ratio'] = df['Volume'] / df['Volume'].rolling(20).mean()
        df['volume_spike'] = (df['volume_ratio'] > 1.5).astype(int)
        df['volume_spike_count'] = df['volume_spike'].rolling(20).sum()

        # Volume ë³€í™”ìœ¨
        df['volume_change'] = df['Volume'].pct_change(5)

        # === íŒ¨í„´ 5: ê°€ê²© ëª¨ë©˜í…€ (íš¨ê³¼ 1.68ë°°) ===
        df['momentum_5'] = (df['Close'] / df['Close'].shift(5) - 1)
        df['momentum_10'] = (df['Close'] / df['Close'].shift(10) - 1)
        df['momentum_20'] = (df['Close'] / df['Close'].shift(20) - 1)

        # ëª¨ë©˜í…€ ê°•ë„
        df['momentum_strength'] = df['momentum_20'].abs()
        df['strong_momentum'] = (df['momentum_strength'] > df['momentum_strength'].quantile(0.75)).astype(int)

        # === íŒ¨í„´ 6: Volatility-of-Volatility (íš¨ê³¼ 1.58ë°°) ===
        df['vol_5d'] = df['returns'].rolling(5).std()
        df['vol_10d'] = df['returns'].rolling(10).std()
        df['vol_20d'] = df['returns'].rolling(20).std()
        df['vol_60d'] = df['returns'].rolling(60).std()

        df['vol_of_vol'] = df['vol_20d'].rolling(20).std()
        df['vol_of_vol_ratio'] = df['vol_of_vol'] / df['vol_20d']

        # === íŒ¨í„´ 7: Rolling Skewness/Kurtosis ===
        df['rolling_skew_20'] = df['returns'].rolling(20).skew()
        df['rolling_kurt_20'] = df['returns'].rolling(20).kurt()

        # Fat tail indicator
        df['fat_tail'] = (df['rolling_kurt_20'] > 3).astype(int)

        # === íŒ¨í„´ 8: ë³€ë™ì„± Lag (ê°•í•œ ìê¸°ìƒê´€) ===
        for lag in [1, 2, 3, 5, 10, 20]:
            df[f'vol_lag_{lag}'] = df['vol_20d'].shift(lag)

        # === íŒ¨í„´ 9: Parkinson Volatility (High-Low) ===
        df['parkinson_vol'] = np.sqrt(
            1 / (4 * np.log(2)) * np.log(df['High'] / df['Low']) ** 2
        )
        df['parkinson_ma'] = df['parkinson_vol'].rolling(5).mean()

        # === íŒ¨í„´ 10: Realized Range ===
        df['realized_range'] = (df['High'] - df['Low']) / df['Open']
        df['realized_range_ma'] = df['realized_range'].rolling(10).mean()

        # === ìƒí˜¸ì‘ìš© íŠ¹ì„± ===
        df['atr_x_volume'] = df['atr_ratio'] * df['volume_ratio']
        df['gap_x_momentum'] = df['gap_size'] * df['momentum_strength']
        df['vov_x_volume'] = df['vol_of_vol'] * df['volume_spike']

        # íƒ€ê²Ÿ: 5ì¼ í›„ ë³€ë™ì„±
        df['target_vol_5d'] = df['vol_20d'].shift(-5)

        df = df.dropna()
        self.data = df

        print(f"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: {df.shape[1]}ê°œ ì»¬ëŸ¼, {len(df)} ìƒ˜í”Œ")

        return True

    def method1_pattern_ridge(self):
        """ë°©ë²• 1: íŒ¨í„´ ê¸°ë°˜ Ridge"""
        print("\nğŸ”¹ ë°©ë²• 1: íŒ¨í„´ ê¸°ë°˜ Ridge...")

        features = [
            # ATR ê´€ë ¨
            'atr_ratio', 'atr_change',
            # Gap ê´€ë ¨
            'gap_size', 'large_gap_count',
            # Volume ê´€ë ¨
            'volume_ratio', 'volume_spike_count',
            # Momentum
            'momentum_strength', 'strong_momentum',
            # Vol-of-vol
            'vol_of_vol', 'vol_of_vol_ratio',
            # ê¸°ë³¸ ë³€ë™ì„± ë° lag
            'vol_20d', 'vol_lag_1', 'vol_lag_2', 'vol_lag_5', 'vol_lag_10',
            # Parkinson
            'parkinson_vol',
            # ìƒí˜¸ì‘ìš©
            'atr_x_volume', 'gap_x_momentum'
        ]

        X = self.data[features]
        y = self.data['target_vol_5d']

        r2 = self._train_and_evaluate(X, y, Ridge(alpha=1.0), "Pattern Ridge")

        self.results['method1_pattern_ridge'] = {
            'r2': r2,
            'n_features': len(features)
        }

        return r2

    def method2_xgboost(self):
        """ë°©ë²• 2: XGBoost (ë¹„ì„ í˜• íŒ¨í„´ í¬ì°©)"""
        print("\nğŸ”¹ ë°©ë²• 2: XGBoost ë¹„ì„ í˜• ëª¨ë¸...")

        features = [
            'atr_ratio', 'gap_size', 'volume_ratio', 'momentum_strength',
            'vol_of_vol', 'vol_20d', 'vol_lag_1', 'vol_lag_2', 'vol_lag_5',
            'parkinson_vol', 'rolling_kurt_20', 'extreme_return_count',
            'large_gap_count', 'volume_spike_count', 'atr_x_volume'
        ]

        X = self.data[features]
        y = self.data['target_vol_5d']

        # XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° (ê³¼ì í•© ë°©ì§€)
        model = XGBRegressor(
            n_estimators=100,
            max_depth=3,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            verbosity=0
        )

        r2 = self._train_and_evaluate(X, y, model, "XGBoost")

        self.results['method2_xgboost'] = {
            'r2': r2,
            'n_features': len(features)
        }

        return r2

    def method3_lightgbm(self):
        """ë°©ë²• 3: LightGBM (ë¹ ë¥´ê³  íš¨ìœ¨ì )"""
        print("\nğŸ”¹ ë°©ë²• 3: LightGBM...")

        features = [
            'atr_ratio', 'gap_size', 'volume_ratio', 'momentum_strength',
            'vol_of_vol', 'vol_20d', 'vol_lag_1', 'vol_lag_2', 'vol_lag_5',
            'parkinson_vol', 'rolling_skew_20', 'extreme_return_count',
            'atr_x_volume', 'gap_x_momentum', 'vov_x_volume'
        ]

        X = self.data[features]
        y = self.data['target_vol_5d']

        model = LGBMRegressor(
            n_estimators=100,
            max_depth=3,
            learning_rate=0.05,
            num_leaves=15,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            verbosity=-1
        )

        r2 = self._train_and_evaluate(X, y, model, "LightGBM")

        self.results['method3_lightgbm'] = {
            'r2': r2,
            'n_features': len(features)
        }

        return r2

    def method4_vix_external(self):
        """ë°©ë²• 4: VIX ì™¸ë¶€ ìš”ì¸ ì¶”ê°€"""
        print("\nğŸ”¹ ë°©ë²• 4: VIX ì§€ìˆ˜ í†µí•©...")

        try:
            # VIX ë°ì´í„° ë¡œë“œ
            vix = yf.Ticker("^VIX")
            vix_data = vix.history(start=self.start_date, end=self.end_date)
            vix_data.index = pd.to_datetime(vix_data.index).tz_localize(None)

            df = self.data.copy()
            df['vix'] = vix_data['Close'].reindex(df.index, method='ffill')
            df['vix_change'] = df['vix'].pct_change(5)
            df['vix_ma'] = df['vix'].rolling(20).mean()

            df = df.dropna()

            features = [
                'vix', 'vix_change', 'vix_ma',
                'atr_ratio', 'gap_size', 'volume_ratio',
                'vol_of_vol', 'vol_20d', 'vol_lag_1', 'vol_lag_5',
                'parkinson_vol', 'momentum_strength'
            ]

            X = df[features]
            y = df['target_vol_5d']

            r2 = self._train_and_evaluate(X, y, Ridge(alpha=1.0), "Ridge + VIX")

            self.results['method4_vix'] = {
                'r2': r2,
                'n_features': len(features)
            }

            return r2

        except Exception as e:
            print(f"   âš ï¸  VIX ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.results['method4_vix'] = {'r2': 0.0, 'error': str(e)}
            return 0.0

    def method5_stacking_ensemble(self):
        """ë°©ë²• 5: Stacking ì•™ìƒë¸” (Ridge + XGBoost + Regime)"""
        print("\nğŸ”¹ ë°©ë²• 5: Stacking Ensemble...")

        features = [
            'atr_ratio', 'gap_size', 'volume_ratio', 'momentum_strength',
            'vol_of_vol', 'vol_20d', 'vol_lag_1', 'vol_lag_2', 'vol_lag_5',
            'parkinson_vol', 'extreme_return_count', 'atr_x_volume'
        ]

        X = self.data[features]
        y = self.data['target_vol_5d']

        # Time series split
        tscv = TimeSeriesSplit(n_splits=5)
        all_preds = []
        all_actuals = []

        for train_idx, test_idx in tscv.split(X):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            # Level 0: Base models
            ridge = Ridge(alpha=1.0)
            xgb = XGBRegressor(n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42, verbosity=0)

            ridge.fit(X_train, y_train)
            xgb.fit(X_train, y_train)

            # Level 1: Meta-learner (ê°€ì¤‘ í‰ê· )
            ridge_pred = ridge.predict(X_test)
            xgb_pred = xgb.predict(X_test)

            # ë™ì  ê°€ì¤‘ì¹˜ (ìµœê·¼ ì„±ëŠ¥ ê¸°ë°˜)
            ensemble_pred = 0.6 * ridge_pred + 0.4 * xgb_pred

            all_preds.extend(ensemble_pred)
            all_actuals.extend(y_test)

        r2 = r2_score(all_actuals, all_preds)
        print(f"   Stacking Ensemble RÂ²: {r2:.4f}")

        self.results['method5_stacking'] = {
            'r2': r2,
            'weights': {'ridge': 0.6, 'xgboost': 0.4}
        }

        return r2

    def method6_deep_pattern_features(self):
        """ë°©ë²• 6: ì‹¬í™” íŒ¨í„´ íŠ¹ì„±"""
        print("\nğŸ”¹ ë°©ë²• 6: ì‹¬í™” íŒ¨í„´ íŠ¹ì„±...")

        df = self.data.copy()

        # ê³ ê¸‰ íŒ¨í„´ íŠ¹ì„±
        df['vol_acceleration'] = df['vol_20d'].diff(5)
        df['gap_volatility'] = df['gap_size'].rolling(10).std()
        df['volume_volatility'] = df['volume_ratio'].rolling(10).std()

        # Regime indicator (ë³€ë™ì„± ì‚¬ì´í´)
        df['vol_percentile'] = df['vol_20d'].rolling(60).apply(
            lambda x: (x.iloc[-1] - x.min()) / (x.max() - x.min() + 1e-6)
        )

        # ê·¹ë‹¨ê°’ ì¹´ìš´í„°
        df['extreme_vol_count'] = (df['vol_20d'] > df['vol_20d'].rolling(60).quantile(0.9)).rolling(20).sum()

        df = df.dropna()

        features = [
            'vol_acceleration', 'gap_volatility', 'volume_volatility', 'vol_percentile',
            'extreme_vol_count', 'atr_ratio', 'vol_of_vol', 'vol_20d',
            'vol_lag_1', 'vol_lag_5', 'parkinson_vol', 'momentum_strength'
        ]

        X = df[features]
        y = df['target_vol_5d']

        r2 = self._train_and_evaluate(X, y, Ridge(alpha=1.0), "Deep Pattern")

        self.results['method6_deep_pattern'] = {
            'r2': r2,
            'n_features': len(features)
        }

        return r2

    def _train_and_evaluate(self, X, y, model, method_name):
        """ê³µí†µ í•™ìŠµ ë° í‰ê°€ (TimeSeriesSplit)"""
        tscv = TimeSeriesSplit(n_splits=5)
        scores = []

        for train_idx, test_idx in tscv.split(X):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            # Scaling (Ridge/ì„ í˜• ëª¨ë¸ì—ë§Œ)
            if isinstance(model, Ridge):
                scaler = StandardScaler()
                X_train = scaler.fit_transform(X_train)
                X_test = scaler.transform(X_test)

            model.fit(X_train, y_train)
            pred = model.predict(X_test)

            r2 = r2_score(y_test, pred)
            scores.append(r2)

        mean_r2 = np.mean(scores)
        print(f"   {method_name} RÂ²: {mean_r2:.4f} (Â±{np.std(scores):.4f})")

        return mean_r2

    def run_all_methods(self):
        """ëª¨ë“  ë°©ë²• ì‹¤í–‰ ë° ë¹„êµ"""
        print("="*60)
        print("ğŸš€ ë³€ë™ì„± ì˜ˆì¸¡ V3: íŒ¨í„´ ê¸°ë°˜ ê³ ê¸‰ ëª¨ë¸")
        print("="*60)
        print("ê¸°ì¤€ì„ : Regime-Switching RÂ² = 0.328\n")

        self.load_and_engineer_features()

        methods = [
            ("Pattern Ridge", self.method1_pattern_ridge),
            ("XGBoost", self.method2_xgboost),
            ("LightGBM", self.method3_lightgbm),
            ("Ridge + VIX", self.method4_vix_external),
            ("Stacking Ensemble", self.method5_stacking_ensemble),
            ("Deep Pattern", self.method6_deep_pattern_features),
        ]

        scores = []

        for name, method in methods:
            try:
                r2 = method()
                scores.append((name, r2))
            except Exception as e:
                print(f"   âŒ {name} ì‹¤íŒ¨: {e}")
                scores.append((name, 0.0))

        # ìµœì¢… ë¹„êµ
        print("\n" + "="*60)
        print("ğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ")
        print("="*60)

        baseline_v2 = 0.328
        baseline_v0 = 0.303

        print(f"{'ë°©ë²•':<30s} {'RÂ²':>10s} {'vs V2':>12s} {'vs V0':>12s}")
        print("-"*60)
        print(f"{'Baseline V0 (Ridge)':<30s} {baseline_v0:>10.4f} {'-':>12s} {'-':>12s}")
        print(f"{'Baseline V2 (Regime)':<30s} {baseline_v2:>10.4f} {'-':>12s} {f'+{baseline_v2-baseline_v0:.4f}':>12s}")

        for name, r2 in sorted(scores, key=lambda x: x[1], reverse=True):
            improvement_v2 = r2 - baseline_v2
            improvement_v0 = r2 - baseline_v0
            symbol = "âœ…" if r2 > baseline_v2 else "âŒ"
            print(f"{name:<30s} {r2:>10.4f} {improvement_v2:>+11.4f} {improvement_v0:>+11.4f} {symbol}")

        # ìµœê³  ì„±ëŠ¥
        best_method, best_r2 = max(scores, key=lambda x: x[1])

        print("\n" + "="*60)
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥: {best_method}")
        print(f"   RÂ² = {best_r2:.4f}")
        print(f"   vs V2 ê°œì„ í­ = {best_r2 - baseline_v2:+.4f}")
        print(f"   vs V0 ê°œì„ í­ = {best_r2 - baseline_v0:+.4f}")
        print("="*60)

        # ê²°ê³¼ ì €ì¥
        output = {
            'experiment': 'volatility_prediction_v3',
            'baseline_v0_r2': baseline_v0,
            'baseline_v2_r2': baseline_v2,
            'best_method': best_method,
            'best_r2': best_r2,
            'improvement_vs_v2': best_r2 - baseline_v2,
            'improvement_vs_v0': best_r2 - baseline_v0,
            'all_results': self.results,
            'timestamp': datetime.now().isoformat()
        }

        with open('data/raw/volatility_v3_results.json', 'w') as f:
            json.dump(output, f, indent=2)

        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥: data/raw/volatility_v3_results.json")

        return best_r2

if __name__ == "__main__":
    predictor = VolatilityPredictorV3()
    predictor.run_all_methods()
