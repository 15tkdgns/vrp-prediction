#!/usr/bin/env python3
"""
LSTM ê¸°ë°˜ ìˆ˜ìµë¥  ì˜ˆì¸¡ ëª¨ë¸
ëª©í‘œ: RÂ² â‰¥ 0.3 (ì‹¤íŒ¨ ê°€ëŠ¥ì„± ë†’ìŒ - EMHë¡œ ì¸í•œ ì´ë¡ ì  í•œê³„)

ê²½ê³ :
- ìˆ˜ìµë¥  ì˜ˆì¸¡ì€ íš¨ìœ¨ì  ì‹œì¥ ê°€ì„¤(EMH)ë¡œ ì¸í•´ ë³¸ì§ˆì ìœ¼ë¡œ ì–´ë ¤ì›€
- í•™ìˆ  ì—°êµ¬ì—ì„œë„ out-of-sample RÂ² ìŒìˆ˜ê°€ ì¼ë°˜ì 
- ë°ì´í„° ëˆ„ì¶œ ì—†ì´ RÂ² 0.3ì€ ê·¹íˆ ì–´ë ¤ì›€
"""

import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # TensorFlow ë¡œê·¸ ì–µì œ

try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers, models, callbacks
    from tensorflow.keras.optimizers import Adam
    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False
    print("âš ï¸ TensorFlow í•„ìš”: pip install tensorflow")

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import pickle
import json
from datetime import datetime

try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
except ImportError:
    YFINANCE_AVAILABLE = False


class PurgedKFold:
    """ê¸ˆìœµ ì‹œê³„ì—´ íŠ¹í™” êµì°¨ ê²€ì¦"""
    def __init__(self, n_splits=5, purge_length=5, embargo_length=5):
        self.n_splits = n_splits
        self.purge_length = purge_length
        self.embargo_length = embargo_length

    def split(self, X, y=None, groups=None):
        n_samples = len(X)
        test_size = n_samples // self.n_splits

        for i in range(self.n_splits):
            test_start = i * test_size
            test_end = (i + 1) * test_size if i < self.n_splits - 1 else n_samples
            test_indices = list(range(test_start, test_end))

            train_indices = []
            if test_start > self.purge_length:
                train_indices.extend(range(0, test_start - self.purge_length))
            if test_end + self.embargo_length < n_samples:
                train_indices.extend(range(test_end + self.embargo_length, n_samples))

            yield train_indices, test_indices


def get_spy_data():
    """SPY ë°ì´í„° ë¡œë“œ"""
    print("ğŸ“Š SPY ë°ì´í„° ë¡œë“œ ì¤‘...")

    # ê¸°ì¡´ ë°ì´í„°ì…‹ ì‚¬ìš© (yfinance ì´ìŠˆ íšŒí”¼)
    dataset_path = 'data/training/multi_modal_sp500_dataset.csv'

    if os.path.exists(dataset_path):
        print(f"   ê¸°ì¡´ ë°ì´í„°ì…‹ ì‚¬ìš©: {dataset_path}")
        full_data = pd.read_csv(dataset_path, parse_dates=['Date'])
        full_data = full_data.set_index('Date').sort_index()

        # OHLCV ë°ì´í„° ì¶”ì¶œ
        df = pd.DataFrame({
            'open': full_data['open'],
            'high': full_data['high'],
            'low': full_data['low'],
            'close': full_data['close'],
            'volume': full_data['volume']
        })

        print(f"âœ… SPY ë°ì´í„°: {len(df)} ê´€ì¸¡ì¹˜")
        return df

    # fallback: yfinance ì‹œë„
    if not YFINANCE_AVAILABLE:
        raise ImportError("yfinance í•„ìš”í•˜ì§€ë§Œ ë°ì´í„°ì…‹ë„ ì—†ìŒ")

    print("   yfinanceë¡œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    data = yf.download("SPY", start="2015-01-01", end="2024-12-31", progress=False)

    if data.empty:
        raise ValueError("SPY ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")

    df = pd.DataFrame({
        'open': data['Open'],
        'high': data['High'],
        'low': data['Low'],
        'close': data['Close'],
        'volume': data['Volume']
    })

    print(f"âœ… SPY ë°ì´í„°: {len(df)} ê´€ì¸¡ì¹˜")
    return df


def create_advanced_features(data):
    """ê³ ê¸‰ ì‹œê³„ì—´ í”¼ì²˜ ìƒì„± (LSTM ì…ë ¥ìš©)"""
    print("ğŸ”§ ê³ ê¸‰ ì‹œê³„ì—´ í”¼ì²˜ ìƒì„±...")

    df = data.copy()

    # ê¸°ë³¸ ìˆ˜ìµë¥ 
    df['returns'] = np.log(df['close'] / df['close'].shift(1))

    # 1. ê°€ê²© ê¸°ë°˜ í”¼ì²˜
    for window in [5, 10, 20, 50]:
        df[f'sma_{window}'] = df['close'].rolling(window).mean()
        df[f'ema_{window}'] = df['close'].ewm(span=window).mean()
        df[f'price_to_sma_{window}'] = df['close'] / df[f'sma_{window}']

    # 2. ë³€ë™ì„± í”¼ì²˜ (ì‹œê³„ì—´ íŠ¹í™”)
    for window in [5, 10, 20]:
        df[f'volatility_{window}'] = df['returns'].rolling(window).std()
        df[f'volatility_ewm_{window}'] = df['returns'].ewm(span=window).std()

    # 3. ëª¨ë©˜í…€ í”¼ì²˜
    for window in [5, 10, 20]:
        df[f'momentum_{window}'] = df['returns'].rolling(window).sum()
        df[f'roc_{window}'] = (df['close'] - df['close'].shift(window)) / df['close'].shift(window)

    # 4. í†µê³„ì  í”¼ì²˜
    for window in [5, 10, 20]:
        df[f'mean_return_{window}'] = df['returns'].rolling(window).mean()
        df[f'std_return_{window}'] = df['returns'].rolling(window).std()
        df[f'skew_{window}'] = df['returns'].rolling(window).skew()
        df[f'kurt_{window}'] = df['returns'].rolling(window).kurt()

    # 5. ë˜ê·¸ í”¼ì²˜ (ê³¼ê±° ì •ë³´ë§Œ)
    for lag in [1, 2, 3, 5, 10]:
        df[f'return_lag_{lag}'] = df['returns'].shift(lag)
        df[f'vol_lag_{lag}'] = df[f'volatility_5'].shift(lag)

    # 6. ê±°ë˜ëŸ‰ í”¼ì²˜
    df['volume_ma_5'] = df['volume'].rolling(5).mean()
    df['volume_ma_20'] = df['volume'].rolling(20).mean()
    df['volume_ratio'] = df['volume'] / df['volume_ma_20']

    # 7. High-Low í”¼ì²˜
    df['high_low_ratio'] = df['high'] / df['low']
    df['high_low_range'] = (df['high'] - df['low']) / df['close']

    # 8. ì‹œê°„ì  êµì°¨ í”¼ì²˜
    df['vol_5_to_vol_20'] = df['volatility_5'] / (df['volatility_20'] + 1e-8)
    df['mom_5_to_mom_20'] = df['momentum_5'] / (df['momentum_20'] + 1e-8)

    print(f"âœ… í”¼ì²˜ ìƒì„± ì™„ë£Œ: {len(df.columns)}ê°œ")
    return df


def create_return_target(data, horizon=5):
    """ìˆ˜ìµë¥  íƒ€ê²Ÿ ìƒì„± (ì™„ì „í•œ ì‹œê°„ì  ë¶„ë¦¬)"""
    print(f"ğŸ¯ íƒ€ê²Ÿ ìƒì„± ({horizon}ì¼ í›„ í‰ê·  ìˆ˜ìµë¥ )...")

    returns = data['returns']
    target_values = []

    for i in range(len(returns)):
        if i + horizon < len(returns):
            # t+1ë¶€í„° t+horizonê¹Œì§€ì˜ í‰ê·  ìˆ˜ìµë¥ 
            future_window = returns.iloc[i+1:i+1+horizon]
            target_values.append(future_window.mean())
        else:
            target_values.append(np.nan)

    target = pd.Series(target_values, index=data.index, name='target_return_5d')
    print(f"âœ… íƒ€ê²Ÿ ìƒì„± ì™„ë£Œ")
    return target


def create_sequences(X, y, sequence_length=20):
    """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„± (LSTM ì…ë ¥ìš©)"""
    X_sequences = []
    y_sequences = []

    for i in range(sequence_length, len(X)):
        X_sequences.append(X[i-sequence_length:i])
        y_sequences.append(y[i])

    return np.array(X_sequences), np.array(y_sequences)


def build_lstm_model(input_shape, learning_rate=0.001):
    """Bidirectional LSTM + Attention ëª¨ë¸"""

    # ì…ë ¥ ë ˆì´ì–´
    inputs = layers.Input(shape=input_shape)

    # Bidirectional LSTM layers
    lstm1 = layers.Bidirectional(
        layers.LSTM(128, return_sequences=True, dropout=0.2)
    )(inputs)

    lstm2 = layers.Bidirectional(
        layers.LSTM(64, return_sequences=True, dropout=0.2)
    )(lstm1)

    # Attention mechanism (ê°„ë‹¨í•œ ë²„ì „)
    attention = layers.Dense(1, activation='tanh')(lstm2)
    attention = layers.Flatten()(attention)
    attention = layers.Activation('softmax')(attention)
    attention = layers.RepeatVector(128)(attention)
    attention = layers.Permute([2, 1])(attention)

    # Apply attention
    lstm2_reshaped = layers.Reshape((input_shape[0], 128))(lstm2)
    merged = layers.Multiply()([lstm2_reshaped, attention])
    merged = layers.Lambda(lambda x: tf.reduce_sum(x, axis=1))(merged)

    # Dense layers
    dense1 = layers.Dense(64, activation='relu')(merged)
    dense1 = layers.Dropout(0.3)(dense1)

    dense2 = layers.Dense(32, activation='relu')(dense1)
    dense2 = layers.Dropout(0.2)(dense2)

    # Output layer
    outputs = layers.Dense(1)(dense2)

    # ëª¨ë¸ ì»´íŒŒì¼
    model = models.Model(inputs=inputs, outputs=outputs)

    optimizer = Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])

    return model


def train_lstm_model():
    """LSTM ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€"""

    if not TENSORFLOW_AVAILABLE:
        raise ImportError("TensorFlow í•„ìš”")

    print("ğŸš€ LSTM ìˆ˜ìµë¥  ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨")
    print("=" * 80)
    print("âš ï¸ ê²½ê³ : ìˆ˜ìµë¥  ì˜ˆì¸¡ì€ EMHë¡œ ì¸í•´ ë³¸ì§ˆì ìœ¼ë¡œ ì–´ë ¤ì›€")
    print("âš ï¸ RÂ² â‰¥ 0.3 ë‹¬ì„± ê°€ëŠ¥ì„±ì€ ë§¤ìš° ë‚®ìŒ")
    print("=" * 80)

    # 1. ë°ì´í„° ë¡œë“œ ë° í”¼ì²˜ ìƒì„±
    data = get_spy_data()
    data_with_features = create_advanced_features(data)
    target = create_return_target(data_with_features, horizon=5)

    # 2. ë°ì´í„° ê²°í•©
    combined = pd.concat([data_with_features, target], axis=1).dropna()

    # í”¼ì²˜ ì„ íƒ (íƒ€ê²Ÿê³¼ ê¸°ë³¸ OHLCV ì œì™¸)
    feature_cols = [col for col in combined.columns
                   if col not in ['target_return_5d', 'open', 'high', 'low', 'close', 'volume']]

    X = combined[feature_cols].values
    y = combined['target_return_5d'].values

    print(f"\nğŸ’¾ ë°ì´í„°:")
    print(f"   ìƒ˜í”Œ ìˆ˜: {len(X)}")
    print(f"   í”¼ì²˜ ìˆ˜: {len(feature_cols)}")

    # 3. Purged K-Fold CV
    print(f"\nğŸ¤– Bidirectional LSTM + Attention ëª¨ë¸ í›ˆë ¨")
    print(f"   ì‹œí€€ìŠ¤ ê¸¸ì´: 20ì¼")
    print(f"   ì•„í‚¤í…ì²˜: BiLSTM(128) -> BiLSTM(64) -> Attention -> Dense")
    print("-" * 80)

    purged_cv = PurgedKFold(n_splits=5, purge_length=5, embargo_length=5)

    cv_results = []
    sequence_length = 20

    for fold, (train_idx, val_idx) in enumerate(purged_cv.split(X)):
        print(f"\nğŸ“Š Fold {fold+1}/5")

        # ìŠ¤ì¼€ì¼ë§ (train ê¸°ì¤€)
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X[train_idx])
        X_val_scaled = scaler.transform(X[val_idx])

        y_train = y[train_idx]
        y_val = y[val_idx]

        # ì‹œí€€ìŠ¤ ìƒì„±
        X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, sequence_length)
        X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val, sequence_length)

        if len(X_train_seq) < 50 or len(X_val_seq) < 10:
            print(f"   âš ï¸ ë°ì´í„° ë¶€ì¡±, fold ìŠ¤í‚µ")
            continue

        print(f"   í›ˆë ¨ ì‹œí€€ìŠ¤: {len(X_train_seq)}, ê²€ì¦ ì‹œí€€ìŠ¤: {len(X_val_seq)}")

        # ëª¨ë¸ êµ¬ì¶•
        model = build_lstm_model(
            input_shape=(sequence_length, X_train_seq.shape[2]),
            learning_rate=0.001
        )

        # Early stopping
        early_stop = callbacks.EarlyStopping(
            monitor='val_loss',
            patience=10,
            restore_best_weights=True,
            verbose=0
        )

        # í›ˆë ¨
        history = model.fit(
            X_train_seq, y_train_seq,
            validation_data=(X_val_seq, y_val_seq),
            epochs=100,
            batch_size=32,
            callbacks=[early_stop],
            verbose=0
        )

        # ì˜ˆì¸¡
        y_pred = model.predict(X_val_seq, verbose=0).flatten()

        # í‰ê°€
        r2 = r2_score(y_val_seq, y_pred)
        mae = mean_absolute_error(y_val_seq, y_pred)
        mse = mean_squared_error(y_val_seq, y_pred)
        rmse = np.sqrt(mse)

        cv_results.append({
            'fold': fold + 1,
            'r2': r2,
            'mae': mae,
            'rmse': rmse,
            'train_samples': len(X_train_seq),
            'val_samples': len(X_val_seq),
            'epochs': len(history.history['loss'])
        })

        print(f"   RÂ² = {r2:7.4f}, MAE = {mae:.6f}, RMSE = {rmse:.6f}")
        print(f"   í›ˆë ¨ epochs: {len(history.history['loss'])}")

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“Š Cross-Validation ê²°ê³¼")
    print("=" * 80)

    if not cv_results:
        print("âŒ ëª¨ë“  fold ì‹¤íŒ¨")
        return None

    cv_df = pd.DataFrame(cv_results)

    avg_r2 = cv_df['r2'].mean()
    std_r2 = cv_df['r2'].std()
    avg_mae = cv_df['mae'].mean()
    avg_rmse = cv_df['rmse'].mean()

    print(f"\nê° Fold ì„±ëŠ¥:")
    for _, row in cv_df.iterrows():
        print(f"   Fold {int(row['fold'])}: RÂ² = {row['r2']:7.4f}, "
              f"MAE = {row['mae']:.6f}, RMSE = {row['rmse']:.6f}")

    print(f"\ní‰ê·  ì„±ëŠ¥:")
    print(f"   RÂ²:   {avg_r2:7.4f} Â± {std_r2:.4f}")
    print(f"   MAE:  {avg_mae:.6f}")
    print(f"   RMSE: {avg_rmse:.6f}")

    # ì„±ëŠ¥ í‰ê°€
    print(f"\nğŸ¯ ì„±ëŠ¥ í‰ê°€:")
    if avg_r2 >= 0.3:
        print(f"   âœ… ëª©í‘œ ë‹¬ì„±! RÂ² â‰¥ 0.3")
        print(f"   âš ï¸ ë°ì´í„° ëˆ„ì¶œ ê²€ì¦ í•„ìˆ˜!")
    elif avg_r2 >= 0.15:
        print(f"   ğŸ“ˆ ì–‘í˜¸í•œ ì„±ëŠ¥ (RÂ² â‰¥ 0.15)")
        print(f"   âš ï¸ ì—¬ì „íˆ ëª©í‘œ ë¯¸ë‹¬")
    elif avg_r2 >= 0.05:
        print(f"   ğŸ“Š ë¯¸ì•½í•œ ì˜ˆì¸¡ë ¥ (RÂ² â‰¥ 0.05)")
    elif avg_r2 > 0:
        print(f"   âš ï¸ ë§¤ìš° ì•½í•œ ì˜ˆì¸¡ë ¥ (RÂ² > 0)")
    else:
        print(f"   âŒ ì˜ˆì¸¡ë ¥ ì—†ìŒ (RÂ² â‰¤ 0)")
        print(f"   â†’ ëœë¤ ì¶”ì¸¡ë³´ë‹¤ ëª»í•¨")

    # ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í›ˆë ¨ (ì €ì¥ìš©)
    print(f"\nğŸ”¨ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í›ˆë ¨...")

    scaler_final = StandardScaler()
    X_scaled = scaler_final.fit_transform(X)
    X_seq, y_seq = create_sequences(X_scaled, y, sequence_length)

    final_model = build_lstm_model(
        input_shape=(sequence_length, X_seq.shape[2]),
        learning_rate=0.001
    )

    early_stop = callbacks.EarlyStopping(
        monitor='loss',
        patience=15,
        restore_best_weights=True,
        verbose=0
    )

    final_model.fit(
        X_seq, y_seq,
        epochs=100,
        batch_size=32,
        callbacks=[early_stop],
        verbose=0
    )

    # ëª¨ë¸ ì €ì¥
    os.makedirs('models', exist_ok=True)
    os.makedirs('data/raw', exist_ok=True)

    final_model.save('models/lstm_return_prediction.keras')

    with open('models/lstm_scaler.pkl', 'wb') as f:
        pickle.dump(scaler_final, f)

    with open('models/lstm_feature_names.pkl', 'wb') as f:
        pickle.dump(feature_cols, f)

    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'model_type': 'Bidirectional LSTM + Attention',
        'target': 'target_return_5d',
        'sequence_length': sequence_length,
        'feature_count': len(feature_cols),
        'feature_names': feature_cols,
        'cv_performance': {
            'mean_r2': float(avg_r2),
            'std_r2': float(std_r2),
            'mean_mae': float(avg_mae),
            'mean_rmse': float(avg_rmse),
            'fold_results': cv_results
        },
        'architecture': {
            'lstm1': 'Bidirectional(128)',
            'lstm2': 'Bidirectional(64)',
            'attention': 'Dense attention mechanism',
            'dense': '[64, 32, 1]',
            'dropout': [0.2, 0.2, 0.3, 0.2]
        },
        'training_samples': len(X_seq),
        'trained_date': datetime.now().isoformat(),
        'data_period': '2015-01-01 to 2024-12-31',
        'warning': 'EMHë¡œ ì¸í•´ ìˆ˜ìµë¥  ì˜ˆì¸¡ì€ ë³¸ì§ˆì ìœ¼ë¡œ ì–´ë ¤ì›€. ë°ì´í„° ëˆ„ì¶œ ê²€ì¦ í•„ìˆ˜.'
    }

    with open('models/lstm_model_metadata.json', 'w') as f:
        json.dump(metadata, f, indent=2)

    # ì„±ëŠ¥ ë°ì´í„° ì €ì¥
    performance_data = {
        'model_name': 'LSTM Return Predictor',
        'model_type': 'Bidirectional LSTM + Attention',
        'target': 'target_return_5d',
        'test_r2': float(avg_r2),
        'test_mae': float(avg_mae),
        'test_rmse': float(avg_rmse),
        'cv_std': float(std_r2),
        'validation_method': 'Purged K-Fold CV (5-fold)',
        'n_samples': len(X_seq),
        'n_features': len(feature_cols),
        'timestamp': datetime.now().isoformat()
    }

    with open('data/raw/lstm_model_performance.json', 'w') as f:
        json.dump(performance_data, f, indent=2)

    print(f"\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ:")
    print(f"   - models/lstm_return_prediction.keras")
    print(f"   - models/lstm_scaler.pkl")
    print(f"   - models/lstm_feature_names.pkl")
    print(f"   - models/lstm_model_metadata.json")
    print(f"   - data/raw/lstm_model_performance.json")

    return metadata, cv_results


if __name__ == "__main__":
    try:
        metadata, results = train_lstm_model()

        print(f"\n" + "=" * 80)
        print(f"âœ… LSTM ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        print(f"=" * 80)

        avg_r2 = metadata['cv_performance']['mean_r2']

        if avg_r2 >= 0.3:
            print(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±: RÂ² = {avg_r2:.4f} â‰¥ 0.3")
            print(f"âš ï¸ ë°ì´í„° ëˆ„ì¶œ ê²€ì¦ì„ ë°˜ë“œì‹œ ìˆ˜í–‰í•˜ì„¸ìš”!")
        else:
            print(f"ğŸ“Š ìµœì¢… ê²°ê³¼: RÂ² = {avg_r2:.4f}")
            print(f"âš ï¸ ëª©í‘œ ë¯¸ë‹¬ (RÂ² < 0.3)")
            print(f"â†’ EMHë¡œ ì¸í•´ ì˜ˆìƒëœ ê²°ê³¼ì…ë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ LSTM ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
