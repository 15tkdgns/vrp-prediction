import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import TimeSeriesSplit
from sklearn.linear_model import HuberRegressor, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.pipeline import Pipeline
import logging
import json
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LeakFreeModelPipeline:
    def __init__(self):
        self.data_path = Path('/root/workspace/data/training/multi_modal_sp500_dataset.csv')
        self.output_dir = Path('/root/workspace/data/leak_free')
        self.output_dir.mkdir(exist_ok=True)

        # ì•ˆì „í•œ íƒ€ê²Ÿë§Œ ì‚¬ìš©
        self.safe_targets = [
            'target_return_1d',
            'target_return_5d',
            'target_direction_1d',
            'target_direction_5d'
        ]

        # ëˆ„ì¶œ ìœ„í—˜ íŠ¹ì„± ì œê±°
        self.leak_risk_features = [
            'target_price_1d',
            'target_price_5d'
        ]

    def prepare_leak_free_dataset(self):
        """ëˆ„ì¶œ ì—†ëŠ” ë°ì´í„°ì…‹ ì¤€ë¹„"""
        logger.info("ëˆ„ì¶œ ì—†ëŠ” ë°ì´í„°ì…‹ ì¤€ë¹„ ì¤‘...")

        # ì›ë³¸ ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(self.data_path)
        logger.info(f"ì›ë³¸ ë°ì´í„°: {df.shape}")

        # ë‚ ì§œ ì²˜ë¦¬
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date').reset_index(drop=True)

        # ëˆ„ì¶œ ìœ„í—˜ ì»¬ëŸ¼ ì œê±°
        columns_to_drop = [col for col in df.columns if any(risk in col for risk in self.leak_risk_features)]
        if columns_to_drop:
            logger.info(f"ì œê±°í•  ëˆ„ì¶œ ìœ„í—˜ ì»¬ëŸ¼: {columns_to_drop}")
            df = df.drop(columns=columns_to_drop)

        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        feature_cols = [col for col in df.columns
                       if col not in self.safe_targets + ['Date']]

        logger.info(f"íŠ¹ì„± ì»¬ëŸ¼: {len(feature_cols)}ê°œ")
        logger.info(f"ì•ˆì „í•œ íƒ€ê²Ÿ: {len(self.safe_targets)}ê°œ")

        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        df[feature_cols] = df[feature_cols].fillna(method='ffill')
        df[self.safe_targets] = df[self.safe_targets].fillna(0)

        # ìµœì¢… ë°ì´í„°ì…‹ ê²€ì¦
        self._validate_temporal_separation(df)

        # ì €ì¥
        clean_data_path = self.output_dir / 'leak_free_sp500_dataset.csv'
        df.to_csv(clean_data_path, index=False)
        logger.info(f"ëˆ„ì¶œ ì—†ëŠ” ë°ì´í„°ì…‹ ì €ì¥: {clean_data_path}")

        return df, feature_cols

    def _validate_temporal_separation(self, df):
        """ì‹œê°„ì  ë¶„ë¦¬ ê²€ì¦"""
        logger.info("ì‹œê°„ì  ë¶„ë¦¬ ê²€ì¦...")

        validation_results = {
            'chronological_order': df['Date'].is_monotonic_increasing,
            'date_gaps': [],
            'target_validation': {}
        }

        # ë‚ ì§œ ê°„ê²© í™•ì¸
        date_diffs = df['Date'].diff().dt.days
        unusual_gaps = date_diffs[date_diffs > 10].count()
        validation_results['unusual_gaps'] = unusual_gaps

        # íƒ€ê²Ÿë³„ ì‹œê°„ì  ë¶„ë¦¬ í™•ì¸
        for target in self.safe_targets:
            # ìˆ˜ìµë¥  íƒ€ê²Ÿì˜ ê²½ìš° t+1 ë°ì´í„° ì‚¬ìš© í™•ì¸
            target_stats = {
                'mean': float(df[target].mean()),
                'std': float(df[target].std()),
                'min': float(df[target].min()),
                'max': float(df[target].max()),
                'valid_range': abs(df[target].mean()) < 0.1  # ì¼ì¼ ìˆ˜ìµë¥ ì€ ë³´í†µ 10% ë¯¸ë§Œ
            }
            validation_results['target_validation'][target] = target_stats

        logger.info("âœ… ì‹œê°„ì  ë¶„ë¦¬ ê²€ì¦ ì™„ë£Œ")
        return validation_results

class PurgedTimeSeriesSplit:
    """ë°ì´í„° ëˆ„ì¶œ ë°©ì§€ë¥¼ ìœ„í•œ Purged Time Series Split"""

    def __init__(self, n_splits=5, purge_length=5, embargo_length=5):
        self.n_splits = n_splits
        self.purge_length = purge_length
        self.embargo_length = embargo_length

    def split(self, X, y=None):
        """ì™„ì „í•œ ì‹œê°„ì  ë¶„ë¦¬ë¥¼ ë³´ì¥í•˜ëŠ” ë¶„í• """
        n_samples = len(X)
        test_size = n_samples // (self.n_splits + 1)

        for i in range(self.n_splits):
            # í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì •ì˜
            test_start = (i + 1) * test_size
            test_end = test_start + test_size

            # í›ˆë ¨ êµ¬ê°„ ì •ì˜ (purgeì™€ embargo ì ìš©)
            train_end = test_start - self.purge_length
            test_start_with_embargo = test_end + self.embargo_length

            if train_end > 0:
                train_idx = np.arange(0, train_end)
                test_idx = np.arange(test_start, min(test_end, n_samples))

                if len(train_idx) > 0 and len(test_idx) > 0:
                    yield train_idx, test_idx

class LeakFreeModelTrainer:
    def __init__(self, data, features):
        self.data = data
        self.features = features
        self.models = {}
        self.results = {}

    def train_models(self, target_col):
        """ì—¬ëŸ¬ ëª¨ë¸ë¡œ ëˆ„ì¶œ ì—†ëŠ” í•™ìŠµ"""
        logger.info(f"íƒ€ê²Ÿ '{target_col}'ì— ëŒ€í•œ ëª¨ë¸ í•™ìŠµ...")

        X = self.data[self.features].values
        y = self.data[target_col].values

        # ëª¨ë¸ ì •ì˜
        models = {
            'Ridge': Pipeline([
                ('scaler', StandardScaler()),
                ('model', Ridge(alpha=1.0))
            ]),
            'Huber': Pipeline([
                ('scaler', StandardScaler()),
                ('model', HuberRegressor(epsilon=1.35, max_iter=1000))
            ]),
            'RandomForest': Pipeline([
                ('scaler', StandardScaler()),
                ('model', RandomForestRegressor(n_estimators=50, max_depth=8, random_state=42))
            ])
        }

        # Purged Time Series Splitìœ¼ë¡œ êµì°¨ê²€ì¦
        tscv = PurgedTimeSeriesSplit(n_splits=5, purge_length=5, embargo_length=5)

        model_results = {}

        for model_name, pipeline in models.items():
            logger.info(f"  {model_name} í•™ìŠµ ì¤‘...")

            cv_scores = {
                'mae': [],
                'rmse': [],
                'r2': []
            }

            fold = 0
            for train_idx, test_idx in tscv.split(X):
                fold += 1

                X_train, X_test = X[train_idx], X[test_idx]
                y_train, y_test = y[train_idx], y[test_idx]

                # í•™ìŠµ
                pipeline.fit(X_train, y_train)

                # ì˜ˆì¸¡
                y_pred = pipeline.predict(X_test)

                # í‰ê°€
                mae = mean_absolute_error(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                r2 = r2_score(y_test, y_pred)

                cv_scores['mae'].append(mae)
                cv_scores['rmse'].append(rmse)
                cv_scores['r2'].append(r2)

                logger.info(f"    Fold {fold}: MAE={mae:.4f}, RMSE={rmse:.4f}, RÂ²={r2:.4f}")

            # í‰ê·  ì„±ëŠ¥ ê³„ì‚°
            avg_performance = {
                'mae_mean': np.mean(cv_scores['mae']),
                'mae_std': np.std(cv_scores['mae']),
                'rmse_mean': np.mean(cv_scores['rmse']),
                'rmse_std': np.std(cv_scores['rmse']),
                'r2_mean': np.mean(cv_scores['r2']),
                'r2_std': np.std(cv_scores['r2'])
            }

            model_results[model_name] = {
                'cv_scores': cv_scores,
                'avg_performance': avg_performance
            }

            logger.info(f"  {model_name} í‰ê·  ì„±ëŠ¥:")
            logger.info(f"    MAE: {avg_performance['mae_mean']:.4f} Â± {avg_performance['mae_std']:.4f}")
            logger.info(f"    RMSE: {avg_performance['rmse_mean']:.4f} Â± {avg_performance['rmse_std']:.4f}")
            logger.info(f"    RÂ²: {avg_performance['r2_mean']:.4f} Â± {avg_performance['r2_std']:.4f}")

        # ìµœì¢… ëª¨ë¸ í•™ìŠµ (ì „ì²´ ë°ì´í„°ì˜ 80%ë§Œ ì‚¬ìš©)
        train_size = int(len(X) * 0.8)
        X_final_train = X[:train_size]
        y_final_train = y[:train_size]

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ (RÂ² ê¸°ì¤€)
        best_model_name = max(model_results.keys(),
                             key=lambda k: model_results[k]['avg_performance']['r2_mean'])

        best_pipeline = models[best_model_name]
        best_pipeline.fit(X_final_train, y_final_train)

        logger.info(f"  ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")

        self.models[target_col] = {
            'pipeline': best_pipeline,
            'model_name': best_model_name,
            'results': model_results
        }

        return model_results

    def evaluate_final_performance(self):
        """ìµœì¢… ì„±ëŠ¥ í‰ê°€"""
        logger.info("ìµœì¢… ì„±ëŠ¥ í‰ê°€...")

        # ë§ˆì§€ë§‰ 20%ë¥¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ì‚¬ìš©
        train_size = int(len(self.data) * 0.8)
        test_data = self.data.iloc[train_size:].copy()

        X_test = test_data[self.features].values

        final_results = {}

        for target_col, model_info in self.models.items():
            y_test = test_data[target_col].values
            y_pred = model_info['pipeline'].predict(X_test)

            # ì„±ëŠ¥ ê³„ì‚°
            mae = mean_absolute_error(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)

            # ë°©í–¥ì„± ì •í™•ë„ (ìˆ˜ìµë¥ ì˜ ê²½ìš°)
            direction_accuracy = None
            if 'return' in target_col:
                direction_pred = (y_pred > 0).astype(int)
                direction_true = (y_test > 0).astype(int)
                direction_accuracy = (direction_pred == direction_true).mean()

            final_results[target_col] = {
                'model_name': model_info['model_name'],
                'test_mae': float(mae),
                'test_rmse': float(rmse),
                'test_r2': float(r2),
                'direction_accuracy': float(direction_accuracy) if direction_accuracy is not None else None,
                'test_samples': len(y_test)
            }

            logger.info(f"{target_col} ({model_info['model_name']}):")
            logger.info(f"  MAE: {mae:.4f}")
            logger.info(f"  RMSE: {rmse:.4f}")
            logger.info(f"  RÂ²: {r2:.4f}")
            if direction_accuracy is not None:
                logger.info(f"  ë°©í–¥ ì •í™•ë„: {direction_accuracy:.1%}")

        return final_results

def main():
    logger.info("ë°ì´í„° ëˆ„ì¶œ ì—†ëŠ” S&P 500 ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶• ì‹œì‘")

    # 1. ëˆ„ì¶œ ì—†ëŠ” ë°ì´í„°ì…‹ ì¤€ë¹„
    pipeline = LeakFreeModelPipeline()
    clean_data, features = pipeline.prepare_leak_free_dataset()

    # 2. ëª¨ë¸ í•™ìŠµ
    trainer = LeakFreeModelTrainer(clean_data, features)

    all_results = {}
    safe_targets = ['target_return_1d', 'target_return_5d']  # ìˆ˜ìµë¥  íƒ€ê²Ÿì— ì§‘ì¤‘

    for target in safe_targets:
        cv_results = trainer.train_models(target)
        all_results[target] = cv_results

    # 3. ìµœì¢… ì„±ëŠ¥ í‰ê°€
    final_results = trainer.evaluate_final_performance()

    # 4. ê²°ê³¼ ì €ì¥
    results_summary = {
        'analysis_timestamp': datetime.now().isoformat(),
        'data_info': {
            'samples': len(clean_data),
            'features': len(features),
            'targets': safe_targets,
            'date_range': {
                'start': str(clean_data['Date'].min()),
                'end': str(clean_data['Date'].max())
            }
        },
        'cross_validation_results': all_results,
        'final_test_results': final_results,
        'data_leakage_prevention': {
            'purged_cv': True,
            'temporal_separation': True,
            'safe_targets_only': True,
            'leak_risk_features_removed': True
        }
    }

    # ê²°ê³¼ ì €ì¥
    output_path = Path('/root/workspace/leak_free_model_results.json')
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, ensure_ascii=False, indent=2, default=str)

    logger.info(f"ëˆ„ì¶œ ì—†ëŠ” ëª¨ë¸ ê²°ê³¼ ì €ì¥: {output_path}")

    # ìš”ì•½ ì¶œë ¥
    print("\n" + "="*60)
    print("ë°ì´í„° ëˆ„ì¶œ ì—†ëŠ” S&P 500 ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ")
    print("="*60)

    print(f"\nğŸ“Š ë°ì´í„° ì •ë³´:")
    print(f"   ìƒ˜í”Œ ìˆ˜: {len(clean_data):,}ê°œ")
    print(f"   íŠ¹ì„± ìˆ˜: {len(features)}ê°œ")
    print(f"   íƒ€ê²Ÿ ìˆ˜: {len(safe_targets)}ê°œ")
    print(f"   ê¸°ê°„: {clean_data['Date'].min().date()} ~ {clean_data['Date'].max().date()}")

    print(f"\nğŸ›¡ï¸ ëˆ„ì¶œ ë°©ì§€ ì¡°ì¹˜:")
    print(f"   âœ… Purged Time Series Cross-Validation")
    print(f"   âœ… ì™„ì „í•œ ì‹œê°„ì  ë¶„ë¦¬ (purge=5, embargo=5)")
    print(f"   âœ… ì•ˆì „í•œ íƒ€ê²Ÿë§Œ ì‚¬ìš© (ìˆ˜ìµë¥  ê¸°ë°˜)")
    print(f"   âœ… ëˆ„ì¶œ ìœ„í—˜ íŠ¹ì„± ì œê±°")

    print(f"\nğŸ“ˆ ìµœì¢… ì„±ëŠ¥ (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸):")
    for target, result in final_results.items():
        print(f"   {target} ({result['model_name']}):")
        print(f"     MAE: {result['test_mae']:.4f}")
        print(f"     RÂ²: {result['test_r2']:.4f}")
        if result['direction_accuracy']:
            print(f"     ë°©í–¥ ì •í™•ë„: {result['direction_accuracy']:.1%}")

    print(f"\nâœ… ì´ ëª¨ë¸ë“¤ì€ ë°ì´í„° ëˆ„ì¶œ ì—†ì´ êµ¬ì¶•ë˜ì—ˆìœ¼ë©° ì‹¤ì œ ìš´ì˜ì— ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    print("="*60)

if __name__ == "__main__":
    main()