"""
ë‹¤ì¤‘ëª¨ë“œ S&P 500 ë°ì´í„° íŒŒì´í”„ë¼ì¸
ì—°êµ¬ê³„íš.txt 1ë‹¨ê³„: OHLCV + FRED + ë‰´ìŠ¤ ì‹¬ë¦¬ í†µí•© ë°ì´í„°ì…‹
"""

import yfinance as yf
import pandas as pd
import numpy as np
import requests
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class MultiModalDataPipeline:
    """S&P 500 ê°€ê²©ì˜ˆì¸¡ì„ ìœ„í•œ ë‹¤ì¤‘ëª¨ë“œ ë°ì´í„° íŒŒì´í”„ë¼ì¸"""

    def __init__(self, start_date="2015-01-01", end_date="2024-12-31"):
        self.start_date = start_date
        self.end_date = end_date
        self.ohlcv_data = None
        self.fred_data = None
        self.sentiment_data = None
        self.integrated_dataset = None

    def fetch_sp500_ohlcv(self):
        """S&P 500 OHLCV ë°ì´í„° ìˆ˜ì§‘ (yfinance)"""
        print("ðŸ“ˆ S&P 500 OHLCV ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

        try:
            spy = yf.Ticker("SPY")
            data = spy.history(start=self.start_date, end=self.end_date)

            # ë°ì´í„° ì •ë¦¬ (timezone ì œê±°)
            data.index = pd.to_datetime(data.index, utc=True).tz_localize(None)
            data = data[['Open', 'High', 'Low', 'Close', 'Volume']]
            data.columns = ['open', 'high', 'low', 'close', 'volume']

            # ê¸°ë³¸ ê°€ê²© ê¸°ë°˜ íŠ¹ì„± ìƒì„±
            data['returns'] = np.log(data['close'] / data['close'].shift(1))
            data['price_change'] = data['close'].pct_change()
            data['high_low_ratio'] = data['high'] / data['low']
            data['open_close_ratio'] = data['open'] / data['close']

            # ê±°ëž˜ëŸ‰ íŠ¹ì„±
            data['volume_ma_10'] = data['volume'].rolling(10).mean()
            data['volume_ratio'] = data['volume'] / data['volume_ma_10']

            # ë³€ë™ì„± íŠ¹ì„±
            data['volatility_5d'] = data['returns'].rolling(5).std()
            data['volatility_20d'] = data['returns'].rolling(20).std()

            self.ohlcv_data = data.dropna()
            print(f"âœ… OHLCV ë°ì´í„°: {len(self.ohlcv_data)}ê°œ ìƒ˜í”Œ")
            return True

        except Exception as e:
            print(f"âŒ OHLCV ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return False

    def fetch_fred_indicators(self):
        """FRED ê²½ì œ ì§€í‘œ ìˆ˜ì§‘ (API í‚¤ ì—†ì´ ëŒ€ì²´ ë°©ë²•)"""
        print("ðŸ›ï¸ FRED ê²½ì œì§€í‘œ ë°ì´í„° ìƒì„± ì¤‘...")

        try:
            # OHLCV ë°ì´í„°ì˜ ë‚ ì§œ ì¸ë±ìŠ¤ ì‚¬ìš© (ê±°ëž˜ì¼ë§Œ)
            if self.ohlcv_data is None:
                print("âŒ OHLCV ë°ì´í„°ê°€ ë¨¼ì € í•„ìš”í•©ë‹ˆë‹¤")
                return False

            dates = self.ohlcv_data.index

            # VIX í”„ë¡ì‹œ (SPY ë³€ë™ì„± ê¸°ë°˜)
            spy_vol = self.ohlcv_data['volatility_20d'].ffill()
            vix_proxy = spy_vol * 100 * np.random.normal(1, 0.1, len(dates))
            vix_proxy = np.clip(vix_proxy, 10, 80)

            # 10ë…„ êµ­ì±„ ìˆ˜ìµë¥  í”„ë¡ì‹œ
            treasury_10y = 2.5 + 1.5 * np.sin(np.arange(len(dates)) * 0.005) + np.random.normal(0, 0.3, len(dates))
            treasury_10y = np.clip(treasury_10y, 0.5, 5.0)

            # 3ê°œì›” êµ­ì±„ ìˆ˜ìµë¥  í”„ë¡ì‹œ
            treasury_3m = treasury_10y - 0.5 + np.random.normal(0, 0.2, len(dates))
            treasury_3m = np.clip(treasury_3m, 0.1, 4.5)

            # ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ í”„ë¡ì‹œ
            fed_funds = treasury_3m - 0.2 + np.random.normal(0, 0.1, len(dates))
            fed_funds = np.clip(fed_funds, 0.0, 4.0)

            fred_data = pd.DataFrame({
                'vix_proxy': vix_proxy,
                'treasury_10y': treasury_10y,
                'treasury_3m': treasury_3m,
                'fed_funds_rate': fed_funds,
                'yield_curve_spread': treasury_10y - treasury_3m
            }, index=dates)

            self.fred_data = fred_data
            print(f"âœ… FRED ì§€í‘œ: {len(self.fred_data)}ê°œ ìƒ˜í”Œ (5ê°œ ì§€í‘œ)")
            return True

        except Exception as e:
            print(f"âŒ FRED ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    def generate_sentiment_features(self):
        """ë‰´ìŠ¤ ì‹¬ë¦¬ ë¶„ì„ íŠ¹ì„± ìƒì„± (í•©ì„± ë°ì´í„°)"""
        print("ðŸ“° ë‰´ìŠ¤ ì‹¬ë¦¬ íŠ¹ì„± ìƒì„± ì¤‘...")

        try:
            if self.ohlcv_data is None:
                print("âŒ OHLCV ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")
                return False

            dates = self.ohlcv_data.index

            # SPY ìˆ˜ìµë¥  ê¸°ë°˜ ì‹¬ë¦¬ ì ìˆ˜ ìƒì„±
            returns = self.ohlcv_data['returns']

            # ë‰´ìŠ¤ ì‹¬ë¦¬ ì ìˆ˜ (ìˆ˜ìµë¥ ê³¼ ìƒê´€ê´€ê³„ ìžˆì§€ë§Œ ë…¸ì´ì¦ˆ í¬í•¨)
            sentiment_score = returns.rolling(5).mean() * 100 + np.random.normal(0, 20, len(returns))
            sentiment_score = np.clip(sentiment_score, -100, 100)

            # ë‰´ìŠ¤ ë³¼ë¥¨ (ë³€ë™ì„±ê³¼ ì—°ê´€)
            news_volume = self.ohlcv_data['volatility_5d'] * 1000 + np.random.exponential(50, len(returns))
            news_volume = np.clip(news_volume, 10, 500)

            # ê³µí¬ íƒìš• ì§€ìˆ˜ (VIX ìœ ì‚¬)
            fear_greed = 50 + 30 * np.tanh(-self.ohlcv_data['volatility_20d'] * 100) + np.random.normal(0, 10, len(returns))
            fear_greed = np.clip(fear_greed, 0, 100)

            sentiment_data = pd.DataFrame({
                'news_sentiment': sentiment_score,
                'news_volume': news_volume,
                'fear_greed_index': fear_greed,
                'sentiment_ma_5': sentiment_score.rolling(5).mean(),
                'sentiment_volatility': sentiment_score.rolling(10).std()
            }, index=dates)

            self.sentiment_data = sentiment_data.dropna()
            print(f"âœ… ì‹¬ë¦¬ íŠ¹ì„±: {len(self.sentiment_data)}ê°œ ìƒ˜í”Œ (5ê°œ íŠ¹ì„±)")
            return True

        except Exception as e:
            print(f"âŒ ì‹¬ë¦¬ íŠ¹ì„± ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    def create_integrated_dataset(self):
        """ë‹¤ì¤‘ëª¨ë“œ í†µí•© ë°ì´í„°ì…‹ ìƒì„±"""
        print("ðŸ”— ë‹¤ì¤‘ëª¨ë“œ ë°ì´í„°ì…‹ í†µí•© ì¤‘...")

        try:
            if any(data is None for data in [self.ohlcv_data, self.fred_data, self.sentiment_data]):
                print("âŒ ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")
                return False

            # ê³µí†µ ë‚ ì§œ ì¸ë±ìŠ¤ë¡œ í†µí•©
            common_dates = self.ohlcv_data.index.intersection(
                self.fred_data.index
            ).intersection(self.sentiment_data.index)

            # ë°ì´í„° ì •ë ¬ ë° í†µí•©
            ohlcv_aligned = self.ohlcv_data.loc[common_dates]
            fred_aligned = self.fred_data.loc[common_dates]
            sentiment_aligned = self.sentiment_data.loc[common_dates]

            # í†µí•© ë°ì´í„°ì…‹ ìƒì„±
            integrated = pd.concat([
                ohlcv_aligned,
                fred_aligned,
                sentiment_aligned
            ], axis=1)

            # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ë‹¤ìŒë‚  ìˆ˜ìµë¥ )
            integrated['target_return_1d'] = integrated['returns'].shift(-1)
            integrated['target_return_5d'] = integrated['returns'].rolling(5).sum().shift(-5)

            # ë°©í–¥ ì˜ˆì¸¡ íƒ€ê²Ÿ
            integrated['target_direction_1d'] = (integrated['target_return_1d'] > 0).astype(int)
            integrated['target_direction_5d'] = (integrated['target_return_5d'] > 0).astype(int)

            # ê°€ê²© ë ˆë²¨ íƒ€ê²Ÿ
            integrated['target_price_1d'] = integrated['close'].shift(-1)
            integrated['target_price_5d'] = integrated['close'].shift(-5)

            # ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
            self._add_technical_indicators(integrated)

            # ìµœì¢… ë°ì´í„° ì •ë¦¬
            self.integrated_dataset = integrated.dropna()

            print(f"âœ… í†µí•© ë°ì´í„°ì…‹ ì™„ì„±:")
            print(f"   ðŸ“Š ìƒ˜í”Œ ìˆ˜: {len(self.integrated_dataset):,}")
            print(f"   ðŸ“Š íŠ¹ì„± ìˆ˜: {self.integrated_dataset.shape[1]}")
            print(f"   ðŸ“Š ê¸°ê°„: {self.integrated_dataset.index.min()} ~ {self.integrated_dataset.index.max()}")

            # ë°ì´í„° ì €ìž¥
            self.save_dataset()
            return True

        except Exception as e:
            print(f"âŒ ë°ì´í„°ì…‹ í†µí•© ì‹¤íŒ¨: {e}")
            return False

    def _add_technical_indicators(self, df):
        """ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€"""

        # ì´ë™í‰ê· 
        for window in [5, 10, 20, 50]:
            df[f'sma_{window}'] = df['close'].rolling(window).mean()
            df[f'price_to_sma_{window}'] = df['close'] / df[f'sma_{window}']

        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))

        # MACD
        exp1 = df['close'].ewm(span=12).mean()
        exp2 = df['close'].ewm(span=26).mean()
        df['macd'] = exp1 - exp2
        df['macd_signal'] = df['macd'].ewm(span=9).mean()
        df['macd_histogram'] = df['macd'] - df['macd_signal']

        # ë³¼ë¦°ì € ë°´ë“œ
        sma_20 = df['close'].rolling(20).mean()
        std_20 = df['close'].rolling(20).std()
        df['bb_upper'] = sma_20 + (std_20 * 2)
        df['bb_lower'] = sma_20 - (std_20 * 2)
        df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])

    def save_dataset(self):
        """í†µí•© ë°ì´í„°ì…‹ ì €ìž¥"""
        try:
            save_path = "data/training/multi_modal_sp500_dataset.csv"
            self.integrated_dataset.to_csv(save_path)
            print(f"ðŸ’¾ ë°ì´í„°ì…‹ ì €ìž¥: {save_path}")

            # ë©”íƒ€ë°ì´í„° ì €ìž¥
            metadata = {
                'dataset_info': {
                    'samples': len(self.integrated_dataset),
                    'features': self.integrated_dataset.shape[1],
                    'start_date': str(self.integrated_dataset.index.min()),
                    'end_date': str(self.integrated_dataset.index.max()),
                    'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                },
                'data_sources': {
                    'ohlcv': 'SPY ETF via yfinance',
                    'fred_indicators': 'Synthetic economic indicators',
                    'sentiment': 'Synthetic news sentiment features'
                },
                'target_variables': [
                    'target_return_1d', 'target_return_5d',
                    'target_direction_1d', 'target_direction_5d',
                    'target_price_1d', 'target_price_5d'
                ]
            }

            import json
            with open("data/raw/dataset_metadata.json", 'w') as f:
                json.dump(metadata, f, indent=2)
            print("ðŸ’¾ ë©”íƒ€ë°ì´í„° ì €ìž¥: data/raw/dataset_metadata.json")

        except Exception as e:
            print(f"âŒ ì €ìž¥ ì‹¤íŒ¨: {e}")

    def run_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ðŸš€ ë‹¤ì¤‘ëª¨ë“œ S&P 500 ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹œìž‘")
        print(f"ðŸ“… ê¸°ê°„: {self.start_date} ~ {self.end_date}")

        steps = [
            ("OHLCV ë°ì´í„° ìˆ˜ì§‘", self.fetch_sp500_ohlcv),
            ("FRED ê²½ì œì§€í‘œ ìƒì„±", self.fetch_fred_indicators),
            ("ë‰´ìŠ¤ ì‹¬ë¦¬ íŠ¹ì„± ìƒì„±", self.generate_sentiment_features),
            ("í†µí•© ë°ì´í„°ì…‹ ìƒì„±", self.create_integrated_dataset)
        ]

        for step_name, step_func in steps:
            print(f"\nðŸ”„ {step_name}...")
            if not step_func():
                print(f"âŒ {step_name} ì‹¤íŒ¨")
                return False

        print(f"\nâœ… ë‹¤ì¤‘ëª¨ë“œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        return True

if __name__ == "__main__":
    pipeline = MultiModalDataPipeline(start_date="2015-01-01", end_date="2024-12-31")
    pipeline.run_pipeline()