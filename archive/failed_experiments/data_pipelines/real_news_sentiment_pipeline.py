#!/usr/bin/env python3
"""
ì‹¤ì œ ë‰´ìŠ¤ ë°ì´í„° ê¸°ë°˜ ê°ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸
LLM ê°ì„±ì§€í‘œë¡œ ì£¼ê°€ ì˜ˆì¸¡ ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘

ëª©í‘œ: í•©ì„± ë°ì´í„°ë¥¼ ì œê±°í•˜ê³  ì‹¤ì œ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ê¸°ë°˜ ê°ì„± ì ìˆ˜ ìƒì„±
"""

import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from textblob import TextBlob
import warnings
warnings.filterwarnings('ignore')

class RealNewsSentimentPipeline:
    """ì‹¤ì œ ë‰´ìŠ¤ ë°ì´í„° ê¸°ë°˜ ê°ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸"""

    def __init__(self, ticker="SPY", start_date="2015-01-01", end_date="2024-12-31"):
        self.ticker = ticker
        self.start_date = start_date
        self.end_date = end_date
        self.news_data = []
        self.sentiment_features = None
        self.price_data = None

    def fetch_spy_price_data(self):
        """SPY ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ (íƒ€ê²Ÿ ë³€ìˆ˜ìš©)"""
        print(f"ğŸ“ˆ {self.ticker} ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

        try:
            spy = yf.Ticker(self.ticker)
            data = spy.history(start=self.start_date, end=self.end_date)

            # íƒ€ì„ì¡´ ì œê±° ë° ì •ë¦¬
            data.index = pd.to_datetime(data.index, utc=True).tz_localize(None)
            data = data[['Open', 'High', 'Low', 'Close', 'Volume']]
            data.columns = ['open', 'high', 'low', 'close', 'volume']

            # ìˆ˜ìµë¥  ê³„ì‚° (íƒ€ê²Ÿ ë³€ìˆ˜)
            data['returns'] = np.log(data['close'] / data['close'].shift(1))

            # ë³€ë™ì„± (ë¹„êµ íŠ¹ì„±)
            data['volatility_5d'] = data['returns'].rolling(5).std()
            data['volatility_20d'] = data['returns'].rolling(20).std()

            self.price_data = data.dropna()
            print(f"âœ… ê°€ê²© ë°ì´í„°: {len(self.price_data)} ìƒ˜í”Œ")
            return True

        except Exception as e:
            print(f"âŒ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return False

    def fetch_news_from_yfinance(self, max_news_per_request=50):
        """yfinanceë¥¼ í†µí•œ ì‹¤ì œ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìˆ˜ì§‘"""
        print(f"ğŸ“° {self.ticker} ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

        try:
            spy = yf.Ticker(self.ticker)

            # yfinance ë‰´ìŠ¤ API ì‚¬ìš©
            news = spy.news

            if not news:
                print(f"âš ï¸  yfinanceì—ì„œ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ. ëŒ€ì²´ ë°©ë²• ì‚¬ìš©...")
                return self._generate_realistic_news_proxy()

            # ë‰´ìŠ¤ ë°ì´í„° íŒŒì‹±
            for item in news[:max_news_per_request]:
                try:
                    news_item = {
                        'date': pd.to_datetime(item.get('providerPublishTime', 0), unit='s'),
                        'title': item.get('title', ''),
                        'publisher': item.get('publisher', 'Unknown'),
                        'link': item.get('link', '')
                    }
                    self.news_data.append(news_item)
                except Exception as e:
                    continue

            # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ì²´í¬ (10ê°œ ì´í•˜ë©´ í”„ë¡ì‹œ ì‚¬ìš©)
            if len(self.news_data) < 100:
                print(f"âš ï¸  ë‰´ìŠ¤ ìƒ˜í”Œ ë¶€ì¡± ({len(self.news_data)}ê°œ). VIX ê¸°ë°˜ í”„ë¡ì‹œ ì‚¬ìš©...")
                self.news_data = []  # ë¦¬ì…‹
                return self._generate_realistic_news_proxy()
            else:
                print(f"âœ… ì‹¤ì œ ë‰´ìŠ¤ ìˆ˜ì§‘: {len(self.news_data)}ê°œ")
                return True

        except Exception as e:
            print(f"âš ï¸  ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            print("âš ï¸  ëŒ€ì²´ ë°©ë²• ì‚¬ìš©: ì‹œì¥ ë³€ë™ì„± ê¸°ë°˜ í”„ë¡ì‹œ ìƒì„±...")
            return self._generate_realistic_news_proxy()

    def _generate_realistic_news_proxy(self):
        """
        ì‹¤ì œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë¶ˆê°€ ì‹œ ëŒ€ì²´ ë°©ì•ˆ

        ì¤‘ìš”: ì´ê²ƒì€ "í•©ì„± ë°ì´í„°"ì´ì§€ë§Œ, ê¸°ì¡´ê³¼ ë‹¬ë¦¬ ìˆ˜ìµë¥ ê³¼ ì§ì ‘ ì—°ê²°í•˜ì§€ ì•ŠìŒ
        ëŒ€ì‹  VIX, ê±°ë˜ëŸ‰ ë“± ë…ë¦½ì ì¸ ì‹œì¥ ì§€í‘œ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
        """
        print("ğŸ”„ ì‹œì¥ ë³€ë™ì„± ê¸°ë°˜ ë‰´ìŠ¤ í”„ë¡ì‹œ ìƒì„± ì¤‘...")

        try:
            if self.price_data is None:
                print("âŒ ê°€ê²© ë°ì´í„° í•„ìš”")
                return False

            dates = self.price_data.index

            # VIX í”„ë¡ì‹œ ìˆ˜ì§‘ ì‹œë„
            try:
                vix = yf.Ticker("^VIX")
                vix_data = vix.history(start=self.start_date, end=self.end_date)
                vix_data.index = pd.to_datetime(vix_data.index, utc=True).tz_localize(None)
                vix_close = vix_data['Close'].reindex(dates, method='ffill')
                print("âœ… ì‹¤ì œ VIX ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ")
            except:
                # VIX ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œ SPY ë³€ë™ì„± ê¸°ë°˜ í”„ë¡ì‹œ
                vix_close = self.price_data['volatility_20d'] * 100
                print("âš ï¸  VIX í”„ë¡ì‹œ ì‚¬ìš© (SPY ë³€ë™ì„± ê¸°ë°˜)")

            # ê±°ë˜ëŸ‰ ì´ìƒì¹˜ (ë‰´ìŠ¤ ë³¼ë¥¨ í”„ë¡ì‹œ)
            volume_ma = self.price_data['volume'].rolling(20).mean()
            volume_ratio = self.price_data['volume'] / volume_ma

            # ê°€ê²© ë³€ë™í­ (ì‹œì¥ ê´€ì‹¬ë„)
            price_range = (self.price_data['high'] - self.price_data['low']) / self.price_data['close']

            # ë‰´ìŠ¤ í”„ë¡ì‹œ ìƒì„± (ë‚ ì§œë³„)
            for date in dates:
                # í•´ë‹¹ ë‚ ì§œì˜ ì‹œì¥ ì§€í‘œ
                vix_val = vix_close.loc[date] if date in vix_close.index else 15.0
                vol_ratio = volume_ratio.loc[date] if date in volume_ratio.index else 1.0
                price_rng = price_range.loc[date] if date in price_range.index else 0.01

                # NaN ì²´í¬
                if pd.isna(vix_val):
                    vix_val = 15.0
                if pd.isna(vol_ratio):
                    vol_ratio = 1.0
                if pd.isna(price_rng):
                    price_rng = 0.01

                # ë‰´ìŠ¤ ë³¼ë¥¨ ì¶”ì • (VIX ë†’ê³  ê±°ë˜ëŸ‰ ë§ìœ¼ë©´ ë‰´ìŠ¤ ë§ìŒ)
                news_volume = int(vix_val / 2 + vol_ratio * 10 + price_rng * 500)
                news_volume = max(5, min(news_volume, 100))

                # ê°€ìƒì˜ ë‰´ìŠ¤ ìƒì„± (ì‹¤ì œ íƒ€ì´í‹€ì€ ì—†ì§€ë§Œ ë©”íƒ€ë°ì´í„°ë§Œ)
                for _ in range(min(news_volume, 20)):  # ìµœëŒ€ 20ê°œ/ì¼
                    self.news_data.append({
                        'date': date,
                        'title': f'Market proxy news (VIX={vix_val:.1f})',
                        'publisher': 'VIX-based-proxy',
                        'vix_level': vix_val,
                        'volume_ratio': vol_ratio,
                        'price_range': price_rng
                    })

            print(f"âœ… ë‰´ìŠ¤ í”„ë¡ì‹œ ìƒì„±: {len(self.news_data)}ê°œ (VIX ê¸°ë°˜)")
            return True

        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ í”„ë¡ì‹œ ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    def analyze_sentiment_with_textblob(self):
        """
        TextBlob ê¸°ë°˜ ê°ì„± ë¶„ì„ (ê°„ë‹¨í•œ LLM ëŒ€ì²´)

        ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” FinBERT, GPT ë“± ì‚¬ìš© ê°€ëŠ¥
        ì—¬ê¸°ì„œëŠ” TextBlobì˜ ê·¹ì„±(polarity) ì ìˆ˜ í™œìš©
        """
        print("ğŸ¤– TextBlob ê°ì„± ë¶„ì„ ì‹¤í–‰ ì¤‘...")

        try:
            if not self.news_data:
                print("âŒ ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ")
                return False

            # ê° ë‰´ìŠ¤ì— ê°ì„± ì ìˆ˜ ì¶”ê°€
            for news_item in self.news_data:
                title = news_item.get('title', '')

                if 'VIX' in title:  # í”„ë¡ì‹œ ë‰´ìŠ¤ì¸ ê²½ìš°
                    # VIX ê¸°ë°˜ ê°ì„± (VIX ë†’ìœ¼ë©´ ë¶€ì •ì )
                    vix_level = news_item.get('vix_level', 15.0)
                    sentiment = -np.tanh((vix_level - 15) / 10)  # -1 ~ +1
                else:
                    # ì‹¤ì œ ë‰´ìŠ¤ íƒ€ì´í‹€ ë¶„ì„
                    try:
                        blob = TextBlob(title)
                        sentiment = blob.sentiment.polarity  # -1 (ë¶€ì •) ~ +1 (ê¸ì •)
                    except:
                        sentiment = 0.0

                news_item['sentiment'] = sentiment

            print(f"âœ… ê°ì„± ë¶„ì„ ì™„ë£Œ: {len(self.news_data)}ê°œ ë‰´ìŠ¤")
            return True

        except Exception as e:
            print(f"âŒ ê°ì„± ë¶„ì„ ì‹¤íŒ¨: {e}")
            return False

    def aggregate_daily_sentiment(self):
        """ì¼ë³„ ê°ì„± ì§€í‘œ ì§‘ê³„"""
        print("ğŸ“Š ì¼ë³„ ê°ì„± íŠ¹ì„± ì§‘ê³„ ì¤‘...")

        try:
            if not self.news_data:
                print("âŒ ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ")
                return False

            # DataFrame ë³€í™˜
            news_df = pd.DataFrame(self.news_data)

            # ë‚ ì§œ ì²˜ë¦¬ - ì´ë¯¸ datetimeì´ë©´ ê·¸ëŒ€ë¡œ, ì•„ë‹ˆë©´ ë³€í™˜
            if not pd.api.types.is_datetime64_any_dtype(news_df['date']):
                news_df['date'] = pd.to_datetime(news_df['date'])

            # ì‹œê°„ ì œê±°í•˜ê³  ë‚ ì§œë§Œ
            news_df['date'] = news_df['date'].dt.tz_localize(None).dt.normalize()

            # ì¼ë³„ ì§‘ê³„
            daily_sentiment = news_df.groupby('date').agg({
                'sentiment': ['mean', 'std', 'min', 'max', 'count']
            }).reset_index()

            daily_sentiment.columns = ['date', 'sentiment_mean', 'sentiment_std',
                                      'sentiment_min', 'sentiment_max', 'news_count']

            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            daily_sentiment['sentiment_std'] = daily_sentiment['sentiment_std'].fillna(0)

            # ì¶”ê°€ íŠ¹ì„± ìƒì„±
            daily_sentiment['sentiment_range'] = daily_sentiment['sentiment_max'] - daily_sentiment['sentiment_min']
            daily_sentiment['sentiment_ma_5'] = daily_sentiment['sentiment_mean'].rolling(5).mean()
            daily_sentiment['sentiment_ma_20'] = daily_sentiment['sentiment_mean'].rolling(20).mean()
            daily_sentiment['sentiment_momentum'] = daily_sentiment['sentiment_mean'] - daily_sentiment['sentiment_ma_5']

            # ë‰´ìŠ¤ ë³¼ë¥¨ íŠ¹ì„±
            daily_sentiment['news_volume_ma_10'] = daily_sentiment['news_count'].rolling(10).mean()
            daily_sentiment['news_volume_ratio'] = daily_sentiment['news_count'] / daily_sentiment['news_volume_ma_10']
            daily_sentiment['news_volume_ratio'] = daily_sentiment['news_volume_ratio'].fillna(1.0)

            # ë‚ ì§œ ì¸ë±ìŠ¤ ì„¤ì •
            daily_sentiment.set_index('date', inplace=True)

            self.sentiment_features = daily_sentiment
            print(f"âœ… ì¼ë³„ ê°ì„± íŠ¹ì„±: {len(self.sentiment_features)} ì¼, {self.sentiment_features.shape[1]} íŠ¹ì„±")
            return True

        except Exception as e:
            print(f"âŒ ê°ì„± ì§‘ê³„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False

    def create_integrated_dataset(self):
        """ê°€ê²© ë°ì´í„° + ê°ì„± íŠ¹ì„± í†µí•© (ì‹œê°„ì  ë¶„ë¦¬ ë³´ì¥)"""
        print("ğŸ”— í†µí•© ë°ì´í„°ì…‹ ìƒì„± ì¤‘ (ì‹œê°„ì  ë¶„ë¦¬ ê²€ì¦)...")

        try:
            if self.price_data is None or self.sentiment_features is None:
                print("âŒ ê°€ê²© ë°ì´í„°ì™€ ê°ì„± íŠ¹ì„± ëª¨ë‘ í•„ìš”")
                return False

            # ë””ë²„ê¹…: ì¸ë±ìŠ¤ íƒ€ì… í™•ì¸
            print(f"   ê°€ê²© ë°ì´í„° ì¸ë±ìŠ¤ íƒ€ì…: {type(self.price_data.index)}")
            print(f"   ê°€ê²© ë°ì´í„° ì²« ë‚ ì§œ: {self.price_data.index[0]}")
            print(f"   ê°ì„± ë°ì´í„° ì¸ë±ìŠ¤ íƒ€ì…: {type(self.sentiment_features.index)}")
            print(f"   ê°ì„± ë°ì´í„° ì²« ë‚ ì§œ: {self.sentiment_features.index[0]}")

            # ì¸ë±ìŠ¤ ì •ê·œí™” (ë‘˜ ë‹¤ timezone ì—†ëŠ” datetimeìœ¼ë¡œ, ì‹œê°„ ì œê±°)
            self.price_data.index = pd.to_datetime(self.price_data.index).tz_localize(None).normalize()
            self.sentiment_features.index = pd.to_datetime(self.sentiment_features.index).tz_localize(None).normalize()

            # ê³µí†µ ë‚ ì§œë¡œ ì •ë ¬
            common_dates = self.price_data.index.intersection(self.sentiment_features.index)
            print(f"   ê³µí†µ ë‚ ì§œ ìˆ˜: {len(common_dates)}")

            price_aligned = self.price_data.loc[common_dates]
            sentiment_aligned = self.sentiment_features.loc[common_dates]

            # í†µí•©
            integrated = pd.concat([price_aligned, sentiment_aligned], axis=1)

            # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ì™„ì „í•œ ì‹œê°„ì  ë¶„ë¦¬)
            # tì¼ ê°ì„± íŠ¹ì„± â†’ t+1ì¼ ìˆ˜ìµë¥  ì˜ˆì¸¡
            integrated['target_return_1d'] = integrated['returns'].shift(-1)
            integrated['target_return_5d'] = integrated['returns'].rolling(5).sum().shift(-5)
            integrated['target_direction_1d'] = (integrated['target_return_1d'] > 0).astype(int)

            # íƒ€ê²Ÿ ê°€ê²©
            integrated['target_price_1d'] = integrated['close'].shift(-1)

            # ìµœì¢… ì •ë¦¬ (NaN ì œê±°)
            integrated = integrated.dropna()

            print(f"\nâœ… í†µí•© ë°ì´í„°ì…‹ ì™„ì„±:")
            print(f"   ğŸ“Š ìƒ˜í”Œ ìˆ˜: {len(integrated):,}")
            print(f"   ğŸ“Š íŠ¹ì„± ìˆ˜: {integrated.shape[1]}")
            print(f"   ğŸ“Š ê¸°ê°„: {integrated.index.min()} ~ {integrated.index.max()}")

            # ë°ì´í„° ëˆ„ì¶œ ê²€ì¦
            self._verify_no_data_leakage(integrated)

            # ì €ì¥
            self._save_dataset(integrated)

            return integrated

        except Exception as e:
            print(f"âŒ í†µí•© ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def _verify_no_data_leakage(self, df):
        """ë°ì´í„° ëˆ„ì¶œ ê²€ì¦"""
        print("\nğŸ” ë°ì´í„° ëˆ„ì¶œ ê²€ì¦ ì¤‘...")

        # ê°ì„± íŠ¹ì„± ì»¬ëŸ¼
        sentiment_cols = [col for col in df.columns if 'sentiment' in col or 'news' in col]

        # íƒ€ê²Ÿê³¼ì˜ ìƒê´€ê´€ê³„ (ë„ˆë¬´ ë†’ìœ¼ë©´ ì˜ì‹¬)
        if 'target_return_1d' in df.columns:
            for col in sentiment_cols[:5]:  # ì£¼ìš” íŠ¹ì„±ë§Œ
                corr = df[col].corr(df['target_return_1d'])
                print(f"   {col:30s} â†” target_return_1d: {corr:+.4f}")

                if abs(corr) > 0.3:
                    print(f"   âš ï¸  ë†’ì€ ìƒê´€ê´€ê³„ ê°ì§€: {col} ({corr:.4f})")

        print("âœ… ë°ì´í„° ëˆ„ì¶œ ê²€ì¦ ì™„ë£Œ")

    def _save_dataset(self, df):
        """ë°ì´í„°ì…‹ ì €ì¥"""
        try:
            save_path = "data/training/spy_news_sentiment_dataset.csv"
            df.to_csv(save_path)
            print(f"\nğŸ’¾ ë°ì´í„°ì…‹ ì €ì¥: {save_path}")

            # ë©”íƒ€ë°ì´í„°
            import json
            metadata = {
                'dataset_info': {
                    'ticker': self.ticker,
                    'samples': len(df),
                    'features': df.shape[1],
                    'start_date': str(df.index.min()),
                    'end_date': str(df.index.max()),
                    'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                },
                'data_sources': {
                    'price': f'{self.ticker} via yfinance',
                    'news': 'yfinance news API or VIX-based proxy',
                    'sentiment_analysis': 'TextBlob polarity score'
                },
                'target_variables': [
                    'target_return_1d',
                    'target_return_5d',
                    'target_direction_1d',
                    'target_price_1d'
                ],
                'temporal_separation': 'Complete (t features â†’ t+1 target)',
                'sentiment_features': [col for col in df.columns if 'sentiment' in col or 'news' in col]
            }

            with open("data/raw/news_sentiment_metadata.json", 'w') as f:
                json.dump(metadata, f, indent=2)
            print(f"ğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥: data/raw/news_sentiment_metadata.json")

        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")

    def run_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("="*60)
        print("ğŸš€ ì‹¤ì œ ë‰´ìŠ¤ ê¸°ë°˜ ê°ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print("="*60)
        print(f"ğŸ“… ê¸°ê°„: {self.start_date} ~ {self.end_date}")
        print(f"ğŸ¯ ëª©í‘œ: LLM ê°ì„±ì§€í‘œë¡œ ì£¼ê°€ ì˜ˆì¸¡ ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸\n")

        steps = [
            ("ê°€ê²© ë°ì´í„° ìˆ˜ì§‘", self.fetch_spy_price_data),
            ("ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘", self.fetch_news_from_yfinance),
            ("ê°ì„± ë¶„ì„ (TextBlob)", self.analyze_sentiment_with_textblob),
            ("ì¼ë³„ ê°ì„± ì§‘ê³„", self.aggregate_daily_sentiment),
            ("í†µí•© ë°ì´í„°ì…‹ ìƒì„±", self.create_integrated_dataset)
        ]

        for step_name, step_func in steps:
            print(f"\n{'='*60}")
            print(f"ğŸ”„ {step_name}")
            print(f"{'='*60}")

            result = step_func()
            if result is False:
                print(f"\nâŒ {step_name} ì‹¤íŒ¨ - íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
                return False

        print("\n" + "="*60)
        print("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("="*60)
        return True

if __name__ == "__main__":
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = RealNewsSentimentPipeline(
        ticker="SPY",
        start_date="2015-01-01",
        end_date="2024-12-31"
    )

    success = pipeline.run_pipeline()

    if success:
        print("\në‹¤ìŒ ë‹¨ê³„: ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ")
        print("  python3 src/models/news_sentiment_price_prediction.py")
