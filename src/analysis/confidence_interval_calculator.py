#!/usr/bin/env python3
"""
ğŸ”¢ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°ê¸°
í•™ìˆ  ë…¼ë¬¸ì„ ìœ„í•œ ì •í™•í•œ ì‹ ë¢°êµ¬ê°„ ê³„ì‚° ë„êµ¬

ì£¼ìš” ê¸°ëŠ¥:
- ë‹¤ì–‘í•œ í†µê³„ëŸ‰ì˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
- Bootstrap ì‹ ë¢°êµ¬ê°„
- ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œë³„ ì‹ ë¢°êµ¬ê°„
- ê¸ˆìœµ ì‹œê³„ì—´ íŠ¹í™” ì‹ ë¢°êµ¬ê°„
"""

import numpy as np
import pandas as pd
import scipy.stats as stats
from scipy.stats import t, norm, chi2
from typing import Tuple, Dict, List, Optional, Union
import warnings
from sklearn.utils import resample
warnings.filterwarnings('ignore')

class ConfidenceIntervalCalculator:
    """
    ë‹¤ì–‘í•œ í†µê³„ëŸ‰ì— ëŒ€í•œ ì‹ ë¢°êµ¬ê°„ ê³„ì‚° í´ë˜ìŠ¤

    ê¸ˆìœµ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í‰ê°€ì— íŠ¹í™”ëœ ì‹ ë¢°êµ¬ê°„ ê³„ì‚° ë„êµ¬
    """

    def __init__(self, confidence_level: float = 0.95):
        """
        ì´ˆê¸°í™”

        Args:
            confidence_level: ì‹ ë¢°ìˆ˜ì¤€ (ê¸°ë³¸ê°’: 0.95, ì¦‰ 95%)
        """
        self.confidence_level = confidence_level
        self.alpha = 1 - confidence_level

    def mean_ci(self, data: np.ndarray, method: str = "parametric") -> Dict:
        """
        í‰ê· ì˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°

        Args:
            data: ë°ì´í„° ë°°ì—´
            method: ê³„ì‚° ë°©ë²• ("parametric", "bootstrap")

        Returns:
            ì‹ ë¢°êµ¬ê°„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        n = len(data)
        mean = np.mean(data)

        if method == "parametric":
            # ëª¨ìˆ˜ì  ë°©ë²• (t-ë¶„í¬ ê¸°ë°˜)
            std_err = stats.sem(data)  # í‘œì¤€ì˜¤ì°¨
            t_critical = t.ppf(1 - self.alpha/2, n-1)
            margin_error = t_critical * std_err

            ci_lower = mean - margin_error
            ci_upper = mean + margin_error

            method_used = f"t-distribution (df={n-1})"

        elif method == "bootstrap":
            # Bootstrap ë°©ë²•
            ci_lower, ci_upper = self._bootstrap_ci(data, np.mean)
            method_used = "Bootstrap"

        else:
            raise ValueError("methodëŠ” 'parametric' ë˜ëŠ” 'bootstrap'ì´ì–´ì•¼ í•©ë‹ˆë‹¤")

        return {
            'statistic': 'mean',
            'value': mean,
            'confidence_level': self.confidence_level,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'method': method_used,
            'sample_size': n,
            'standard_error': stats.sem(data) if method == "parametric" else None
        }

    def proportion_ci(self, successes: int, total: int, method: str = "wilson") -> Dict:
        """
        ë¹„ìœ¨ì˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ì˜ˆ: ì •í™•ë„, ë°©í–¥ ì˜ˆì¸¡ ì •í™•ë„)

        Args:
            successes: ì„±ê³µ íšŸìˆ˜
            total: ì „ì²´ ì‹œë„ íšŸìˆ˜
            method: ê³„ì‚° ë°©ë²• ("wilson", "agresti_coull", "clopper_pearson")

        Returns:
            ì‹ ë¢°êµ¬ê°„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        if successes > total:
            raise ValueError("ì„±ê³µ íšŸìˆ˜ê°€ ì „ì²´ ì‹œë„ íšŸìˆ˜ë³´ë‹¤ í´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        p = successes / total
        z_critical = norm.ppf(1 - self.alpha/2)

        if method == "wilson":
            # Wilson Score Interval (ê¶Œì¥)
            denominator = 1 + z_critical**2 / total
            center = (p + z_critical**2 / (2 * total)) / denominator
            margin = z_critical * np.sqrt(p * (1 - p) / total + z_critical**2 / (4 * total**2)) / denominator

            ci_lower = center - margin
            ci_upper = center + margin
            method_used = "Wilson Score Interval"

        elif method == "agresti_coull":
            # Agresti-Coull Interval
            n_tilde = total + z_critical**2
            p_tilde = (successes + z_critical**2 / 2) / n_tilde
            margin = z_critical * np.sqrt(p_tilde * (1 - p_tilde) / n_tilde)

            ci_lower = p_tilde - margin
            ci_upper = p_tilde + margin
            method_used = "Agresti-Coull Interval"

        elif method == "clopper_pearson":
            # Clopper-Pearson Exact Interval
            if successes == 0:
                ci_lower = 0
            else:
                ci_lower = stats.beta.ppf(self.alpha/2, successes, total - successes + 1)

            if successes == total:
                ci_upper = 1
            else:
                ci_upper = stats.beta.ppf(1 - self.alpha/2, successes + 1, total - successes)

            method_used = "Clopper-Pearson Exact"

        else:
            raise ValueError("methodëŠ” 'wilson', 'agresti_coull', ë˜ëŠ” 'clopper_pearson'ì´ì–´ì•¼ í•©ë‹ˆë‹¤")

        # 0ê³¼ 1 ì‚¬ì´ë¡œ ì œí•œ
        ci_lower = max(0, ci_lower)
        ci_upper = min(1, ci_upper)

        return {
            'statistic': 'proportion',
            'value': p,
            'successes': successes,
            'total': total,
            'confidence_level': self.confidence_level,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'method': method_used
        }

    def correlation_ci(self, correlation: float, n: int) -> Dict:
        """
        ìƒê´€ê³„ìˆ˜ì˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (Fisher's z-transformation)

        Args:
            correlation: í‘œë³¸ ìƒê´€ê³„ìˆ˜
            n: í‘œë³¸ í¬ê¸°

        Returns:
            ì‹ ë¢°êµ¬ê°„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        if abs(correlation) >= 1:
            raise ValueError("ìƒê´€ê³„ìˆ˜ëŠ” -1ê³¼ 1 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤")

        if n < 4:
            raise ValueError("ìƒê´€ê³„ìˆ˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°ì„ ìœ„í•´ ìµœì†Œ 4ê°œ ê´€ì¸¡ê°’ì´ í•„ìš”í•©ë‹ˆë‹¤")

        # Fisher's z-transformation
        z_r = 0.5 * np.log((1 + correlation) / (1 - correlation))

        # í‘œì¤€ì˜¤ì°¨
        se_z = 1 / np.sqrt(n - 3)

        # z ì‹ ë¢°êµ¬ê°„
        z_critical = norm.ppf(1 - self.alpha/2)
        z_lower = z_r - z_critical * se_z
        z_upper = z_r + z_critical * se_z

        # ì—­ë³€í™˜ìœ¼ë¡œ r ì‹ ë¢°êµ¬ê°„
        ci_lower = (np.exp(2 * z_lower) - 1) / (np.exp(2 * z_lower) + 1)
        ci_upper = (np.exp(2 * z_upper) - 1) / (np.exp(2 * z_upper) + 1)

        return {
            'statistic': 'correlation',
            'value': correlation,
            'confidence_level': self.confidence_level,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'method': "Fisher's z-transformation",
            'sample_size': n,
            'fisher_z': z_r,
            'standard_error_z': se_z
        }

    def variance_ci(self, data: np.ndarray) -> Dict:
        """
        ë¶„ì‚°ì˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ì¹´ì´ì œê³± ë¶„í¬ ê¸°ë°˜)

        Args:
            data: ë°ì´í„° ë°°ì—´

        Returns:
            ì‹ ë¢°êµ¬ê°„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        n = len(data)
        sample_var = np.var(data, ddof=1)
        df = n - 1

        # ì¹´ì´ì œê³± ë¶„í¬ì˜ ì„ê³„ê°’
        chi2_lower = chi2.ppf(self.alpha/2, df)
        chi2_upper = chi2.ppf(1 - self.alpha/2, df)

        # ë¶„ì‚°ì˜ ì‹ ë¢°êµ¬ê°„
        ci_lower = (df * sample_var) / chi2_upper
        ci_upper = (df * sample_var) / chi2_lower

        return {
            'statistic': 'variance',
            'value': sample_var,
            'confidence_level': self.confidence_level,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'method': f"Chi-square distribution (df={df})",
            'sample_size': n,
            'degrees_of_freedom': df
        }

    def model_performance_ci(self, y_true: np.ndarray, y_pred: np.ndarray,
                           metric: str = "mae", n_bootstrap: int = 1000) -> Dict:
        """
        ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œì˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (Bootstrap ë°©ë²•)

        Args:
            y_true: ì‹¤ì œ ê°’
            y_pred: ì˜ˆì¸¡ ê°’
            metric: ì„±ëŠ¥ ì§€í‘œ ("mae", "mse", "rmse", "r2", "mape")
            n_bootstrap: Bootstrap ë°˜ë³µ íšŸìˆ˜

        Returns:
            ì‹ ë¢°êµ¬ê°„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        n = len(y_true)
        if len(y_pred) != n:
            raise ValueError("y_trueì™€ y_predì˜ ê¸¸ì´ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜
        def calculate_metric(y_t, y_p):
            if metric == "mae":
                return np.mean(np.abs(y_t - y_p))
            elif metric == "mse":
                return np.mean((y_t - y_p)**2)
            elif metric == "rmse":
                return np.sqrt(np.mean((y_t - y_p)**2))
            elif metric == "r2":
                ss_res = np.sum((y_t - y_p)**2)
                ss_tot = np.sum((y_t - np.mean(y_t))**2)
                return 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
            elif metric == "mape":
                return np.mean(np.abs((y_t - y_p) / y_t)) * 100
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì§€í‘œì…ë‹ˆë‹¤: {metric}")

        # ì›ë³¸ ì„±ëŠ¥
        original_score = calculate_metric(y_true, y_pred)

        # Bootstrap ì‹ ë¢°êµ¬ê°„
        bootstrap_scores = []
        for _ in range(n_bootstrap):
            # ë³µì› ì¶”ì¶œ
            indices = np.random.choice(n, size=n, replace=True)
            y_true_boot = y_true[indices]
            y_pred_boot = y_pred[indices]

            boot_score = calculate_metric(y_true_boot, y_pred_boot)
            bootstrap_scores.append(boot_score)

        bootstrap_scores = np.array(bootstrap_scores)

        # ë°±ë¶„ìœ„ìˆ˜ë¡œ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
        alpha_lower = (self.alpha / 2) * 100
        alpha_upper = (1 - self.alpha / 2) * 100

        ci_lower = np.percentile(bootstrap_scores, alpha_lower)
        ci_upper = np.percentile(bootstrap_scores, alpha_upper)

        return {
            'statistic': f'{metric.upper()}',
            'value': original_score,
            'confidence_level': self.confidence_level,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'method': f"Bootstrap (n={n_bootstrap})",
            'sample_size': n,
            'bootstrap_std': np.std(bootstrap_scores),
            'bootstrap_mean': np.mean(bootstrap_scores)
        }

    def sharpe_ratio_ci(self, returns: np.ndarray, risk_free_rate: float = 0.02) -> Dict:
        """
        ìƒ¤í”„ ë¹„ìœ¨ì˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°

        Args:
            returns: ìˆ˜ìµë¥  ë°°ì—´
            risk_free_rate: ë¬´ìœ„í—˜ ì´ììœ¨ (ì—°ìœ¨)

        Returns:
            ì‹ ë¢°êµ¬ê°„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        n = len(returns)
        excess_returns = returns - risk_free_rate / 252  # ì¼ì¼ ë¬´ìœ„í—˜ ì´ììœ¨

        mean_excess = np.mean(excess_returns)
        std_excess = np.std(excess_returns, ddof=1)

        if std_excess == 0:
            raise ValueError("ìˆ˜ìµë¥ ì˜ í‘œì¤€í¸ì°¨ê°€ 0ì…ë‹ˆë‹¤")

        sharpe_ratio = mean_excess / std_excess * np.sqrt(252)  # ì—°í™˜ì‚°

        # Bootstrap ì‹ ë¢°êµ¬ê°„
        def calculate_sharpe(sample_returns):
            sample_excess = sample_returns - risk_free_rate / 252
            sample_mean = np.mean(sample_excess)
            sample_std = np.std(sample_excess, ddof=1)
            if sample_std == 0:
                return 0
            return sample_mean / sample_std * np.sqrt(252)

        ci_lower, ci_upper = self._bootstrap_ci(returns, calculate_sharpe)

        return {
            'statistic': 'Sharpe Ratio',
            'value': sharpe_ratio,
            'confidence_level': self.confidence_level,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'method': "Bootstrap",
            'sample_size': n,
            'risk_free_rate': risk_free_rate,
            'mean_excess_return': mean_excess,
            'excess_return_std': std_excess
        }

    def maximum_drawdown_ci(self, returns: np.ndarray) -> Dict:
        """
        ìµœëŒ€ ë‚™í­(MDD)ì˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°

        Args:
            returns: ìˆ˜ìµë¥  ë°°ì—´

        Returns:
            ì‹ ë¢°êµ¬ê°„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        def calculate_mdd(sample_returns):
            cumulative = np.cumprod(1 + sample_returns)
            running_max = np.maximum.accumulate(cumulative)
            drawdowns = (cumulative - running_max) / running_max
            return abs(np.min(drawdowns)) if len(drawdowns) > 0 else 0

        mdd = calculate_mdd(returns)
        ci_lower, ci_upper = self._bootstrap_ci(returns, calculate_mdd)

        return {
            'statistic': 'Maximum Drawdown',
            'value': mdd,
            'confidence_level': self.confidence_level,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'method': "Bootstrap",
            'sample_size': len(returns)
        }

    def _bootstrap_ci(self, data: np.ndarray, statistic_func, n_bootstrap: int = 1000) -> Tuple[float, float]:
        """
        Bootstrap ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ë‚´ë¶€ ë©”ì„œë“œ)

        Args:
            data: ë°ì´í„° ë°°ì—´
            statistic_func: í†µê³„ëŸ‰ ê³„ì‚° í•¨ìˆ˜
            n_bootstrap: Bootstrap ë°˜ë³µ íšŸìˆ˜

        Returns:
            (ì‹ ë¢°êµ¬ê°„ í•˜í•œ, ì‹ ë¢°êµ¬ê°„ ìƒí•œ)
        """
        bootstrap_stats = []

        for _ in range(n_bootstrap):
            # ë³µì› ì¶”ì¶œ
            bootstrap_sample = resample(data, n_samples=len(data), replace=True)
            stat = statistic_func(bootstrap_sample)
            bootstrap_stats.append(stat)

        bootstrap_stats = np.array(bootstrap_stats)

        # ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°
        alpha_lower = (self.alpha / 2) * 100
        alpha_upper = (1 - self.alpha / 2) * 100

        ci_lower = np.percentile(bootstrap_stats, alpha_lower)
        ci_upper = np.percentile(bootstrap_stats, alpha_upper)

        return ci_lower, ci_upper

    def batch_calculate(self, data_dict: Dict[str, np.ndarray],
                       statistics: List[str] = ["mean", "variance"]) -> Dict:
        """
        ì—¬ëŸ¬ ë°ì´í„°ì— ëŒ€í•´ ì—¬ëŸ¬ í†µê³„ëŸ‰ì˜ ì‹ ë¢°êµ¬ê°„ì„ ì¼ê´„ ê³„ì‚°

        Args:
            data_dict: ë°ì´í„°ëª…ì„ í‚¤ë¡œ í•˜ê³  ë°ì´í„° ë°°ì—´ì„ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
            statistics: ê³„ì‚°í•  í†µê³„ëŸ‰ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì „ì²´ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        results = {}

        for data_name, data in data_dict.items():
            results[data_name] = {}

            for stat in statistics:
                try:
                    if stat == "mean":
                        result = self.mean_ci(data)
                    elif stat == "variance":
                        result = self.variance_ci(data)
                    elif stat == "sharpe_ratio":
                        result = self.sharpe_ratio_ci(data)
                    elif stat == "maximum_drawdown":
                        result = self.maximum_drawdown_ci(data)
                    else:
                        print(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í†µê³„ëŸ‰ì…ë‹ˆë‹¤: {stat}")
                        continue

                    results[data_name][stat] = result

                except Exception as e:
                    print(f"ì˜¤ë¥˜ ë°œìƒ ({data_name}, {stat}): {str(e)}")
                    results[data_name][stat] = {"error": str(e)}

        return results

def main():
    """í…ŒìŠ¤íŠ¸ ë° ì˜ˆì œ ì‹¤í–‰"""
    print("ğŸ”¢ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    np.random.seed(42)

    # ëª¨ë¸ ì„±ëŠ¥ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
    mae_scores = np.random.gamma(2, 0.01, 50)  # MAE ì ìˆ˜ë“¤
    accuracy_data = np.random.binomial(1, 0.75, 100)  # ì •í™•ë„ ë°ì´í„° (75% ì„±ê³µë¥ )
    returns = np.random.normal(0.001, 0.02, 252)  # ì¼ì¼ ìˆ˜ìµë¥  (1ë…„)

    calc = ConfidenceIntervalCalculator(confidence_level=0.95)

    # 1. í‰ê· ì˜ ì‹ ë¢°êµ¬ê°„
    print("\n1. MAE ì ìˆ˜ í‰ê· ì˜ ì‹ ë¢°êµ¬ê°„")
    print("-" * 40)
    mean_ci = calc.mean_ci(mae_scores, method="parametric")
    print(f"í‰ê· : {mean_ci['value']:.6f}")
    print(f"95% ì‹ ë¢°êµ¬ê°„: [{mean_ci['ci_lower']:.6f}, {mean_ci['ci_upper']:.6f}]")
    print(f"ë°©ë²•: {mean_ci['method']}")

    # 2. ë¹„ìœ¨ì˜ ì‹ ë¢°êµ¬ê°„
    print("\n2. ì •í™•ë„ì˜ ì‹ ë¢°êµ¬ê°„")
    print("-" * 40)
    successes = np.sum(accuracy_data)
    prop_ci = calc.proportion_ci(successes, len(accuracy_data), method="wilson")
    print(f"ì •í™•ë„: {prop_ci['value']:.3f}")
    print(f"95% ì‹ ë¢°êµ¬ê°„: [{prop_ci['ci_lower']:.3f}, {prop_ci['ci_upper']:.3f}]")
    print(f"ë°©ë²•: {prop_ci['method']}")

    # 3. ìƒ¤í”„ ë¹„ìœ¨ì˜ ì‹ ë¢°êµ¬ê°„
    print("\n3. ìƒ¤í”„ ë¹„ìœ¨ì˜ ì‹ ë¢°êµ¬ê°„")
    print("-" * 40)
    sharpe_ci = calc.sharpe_ratio_ci(returns, risk_free_rate=0.02)
    print(f"ìƒ¤í”„ ë¹„ìœ¨: {sharpe_ci['value']:.3f}")
    print(f"95% ì‹ ë¢°êµ¬ê°„: [{sharpe_ci['ci_lower']:.3f}, {sharpe_ci['ci_upper']:.3f}]")

    # 4. ìµœëŒ€ ë‚™í­ì˜ ì‹ ë¢°êµ¬ê°„
    print("\n4. ìµœëŒ€ ë‚™í­ì˜ ì‹ ë¢°êµ¬ê°„")
    print("-" * 40)
    mdd_ci = calc.maximum_drawdown_ci(returns)
    print(f"MDD: {mdd_ci['value']:.3f}")
    print(f"95% ì‹ ë¢°êµ¬ê°„: [{mdd_ci['ci_lower']:.3f}, {mdd_ci['ci_upper']:.3f}]")

    # 5. ìƒê´€ê³„ìˆ˜ì˜ ì‹ ë¢°êµ¬ê°„
    print("\n5. ìƒê´€ê³„ìˆ˜ì˜ ì‹ ë¢°êµ¬ê°„")
    print("-" * 40)
    corr_ci = calc.correlation_ci(0.65, n=50)
    print(f"ìƒê´€ê³„ìˆ˜: {corr_ci['value']:.3f}")
    print(f"95% ì‹ ë¢°êµ¬ê°„: [{corr_ci['ci_lower']:.3f}, {corr_ci['ci_upper']:.3f}]")

if __name__ == "__main__":
    main()