#!/usr/bin/env python3
"""
í•™ìŠµ ê²°ê³¼ì™€ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ëª¨ë¸ë³„ë¡œ ì¢…í•© ì •ë¦¬
"""

import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings

warnings.filterwarnings("ignore")


def load_all_data():
    """ëª¨ë“  ê²°ê³¼ ë°ì´í„° ë¡œë“œ"""
    data = {}

    # í•™ìŠµ ì„±ëŠ¥ ë°ì´í„°
    with open("/root/workspace/data/raw/model_performance.json", "r") as f:
        data["training_performance"] = json.load(f)

    # í•™ìŠµ ìš”ì•½ ë°ì´í„°
    with open("/root/workspace/data/raw/training_summary.json", "r") as f:
        data["training_summary"] = json.load(f)

    # ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ê²°ê³¼
    with open("/root/workspace/data/raw/realtime_test_results.json", "r") as f:
        data["realtime_results"] = json.load(f)

    # í•™ìŠµ ë°ì´í„°
    data["training_features"] = pd.read_csv(
        "/root/workspace/data/raw/training_features.csv"
    )
    data["event_labels"] = pd.read_csv("/root/workspace/data/raw/event_labels.csv")

    return data


def analyze_model_performance(data):
    """ëª¨ë¸ë³„ ì„±ëŠ¥ ë¶„ì„"""
    training_perf = data["training_performance"]
    realtime_results = data["realtime_results"]

    # ëª¨ë¸ë³„ ì¢…í•© ë¶„ì„
    model_analysis = {}

    for model_name, perf in training_perf.items():
        analysis = {
            "model_name": model_name,
            "training_results": {
                "train_accuracy": perf["train_accuracy"],
                "test_accuracy": perf["test_accuracy"],
                "overfitting_gap": perf["train_accuracy"] - perf["test_accuracy"],
            },
            "realtime_results": {},
            "overall_assessment": {},
        }

        # ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ (í˜„ì¬ëŠ” Gradient Boostingë§Œ í…ŒìŠ¤íŠ¸ë¨)
        if model_name == realtime_results["model_used"]:
            rt_results = realtime_results["results"]
            event_probs = [r["prediction"]["event_probability"] for r in rt_results]
            confidences = [r["prediction"]["confidence"] for r in rt_results]

            analysis["realtime_results"] = {
                "tested": True,
                "test_date": realtime_results["test_timestamp"],
                "stocks_tested": len(rt_results),
                "avg_event_probability": np.mean(event_probs),
                "avg_confidence": np.mean(confidences),
                "predictions_made": len(rt_results),
                "normal_predictions": sum(
                    1 for r in rt_results if r["prediction"]["prediction"] == 0
                ),
                "event_predictions": sum(
                    1 for r in rt_results if r["prediction"]["prediction"] == 1
                ),
            }
        else:
            analysis["realtime_results"] = {
                "tested": False,
                "reason": "Not selected as best model for testing",
            }

        # ì¢…í•© í‰ê°€
        analysis["overall_assessment"] = assess_model_overall(analysis)

        model_analysis[model_name] = analysis

    return model_analysis


def assess_model_overall(analysis):
    """ëª¨ë¸ ì¢…í•© í‰ê°€"""
    training = analysis["training_results"]
    realtime = analysis["realtime_results"]

    # í›ˆë ¨ ì„±ëŠ¥ í‰ê°€ (ì‹œì¥ ì˜ˆì¸¡ ê¸°ì¤€ ì¡°ì •)
    # S&P500 ì˜ˆì¸¡ì€ 50% ì´ìƒì´ë©´ ì˜ë¯¸ìˆìŒ (ë¬´ì‘ìœ„ë³´ë‹¤ ì¢‹ìŒ)
    if training["test_accuracy"] >= 0.75:
        training_grade = "A"  # ë§¤ìš° ìš°ìˆ˜
    elif training["test_accuracy"] >= 0.65:
        training_grade = "B"  # ìš°ìˆ˜
    elif training["test_accuracy"] >= 0.55:
        training_grade = "C"  # ì–‘í˜¸
    else:
        training_grade = "D"  # ê°œì„  í•„ìš”

    # ì˜¤ë²„í”¼íŒ… í‰ê°€
    if training["overfitting_gap"] <= 0.05:
        overfitting_grade = "A"
    elif training["overfitting_gap"] <= 0.10:
        overfitting_grade = "B"
    elif training["overfitting_gap"] <= 0.20:
        overfitting_grade = "C"
    else:
        overfitting_grade = "D"

    # ì‹¤ì‹œê°„ ì„±ëŠ¥ í‰ê°€
    if realtime["tested"]:
        if realtime["avg_confidence"] >= 0.90:
            realtime_grade = "A"
        elif realtime["avg_confidence"] >= 0.80:
            realtime_grade = "B"
        elif realtime["avg_confidence"] >= 0.70:
            realtime_grade = "C"
        else:
            realtime_grade = "D"
    else:
        realtime_grade = "N/A"

    return {
        "training_grade": training_grade,
        "overfitting_grade": overfitting_grade,
        "realtime_grade": realtime_grade,
        "strengths": get_model_strengths(analysis),
        "weaknesses": get_model_weaknesses(analysis),
        "recommendations": get_model_recommendations(analysis),
    }


def get_model_strengths(analysis):
    """ëª¨ë¸ ê°•ì  ë¶„ì„"""
    strengths = []
    training = analysis["training_results"]
    realtime = analysis["realtime_results"]

    if training["test_accuracy"] >= 0.75:
        strengths.append("ë†’ì€ ì˜ˆì¸¡ ì •í™•ë„")

    if training["overfitting_gap"] <= 0.05:
        strengths.append("ë‚®ì€ ì˜¤ë²„í”¼íŒ…")

    if realtime["tested"] and realtime["avg_confidence"] >= 0.90:
        strengths.append("ë†’ì€ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹ ë¢°ë„")

    if training["test_accuracy"] == 1.0:
        strengths.append("ì™„ë²½í•œ í…ŒìŠ¤íŠ¸ ì„±ëŠ¥")

    return strengths


def get_model_weaknesses(analysis):
    """ëª¨ë¸ ì•½ì  ë¶„ì„"""
    weaknesses = []
    training = analysis["training_results"]
    realtime = analysis["realtime_results"]

    if training["overfitting_gap"] > 0.1:
        weaknesses.append("ì˜¤ë²„í”¼íŒ… ê°€ëŠ¥ì„±")

    if training["test_accuracy"] < 0.55:
        weaknesses.append("ë‚®ì€ ì˜ˆì¸¡ ì •í™•ë„")

    if not realtime["tested"]:
        weaknesses.append("ì‹¤ì‹œê°„ ì„±ëŠ¥ ë¯¸ê²€ì¦")

    if training["test_accuracy"] == 1.0:
        weaknesses.append("ê³¼ë„í•œ í•™ìŠµ ê°€ëŠ¥ì„± (ê²€ì¦ í•„ìš”)")

    return weaknesses


def get_model_recommendations(analysis):
    """ëª¨ë¸ ê°œì„  ê¶Œì¥ì‚¬í•­"""
    recommendations = []
    training = analysis["training_results"]
    realtime = analysis["realtime_results"]

    if training["overfitting_gap"] > 0.1:
        recommendations.append("ì •ê·œí™” ê¸°ë²• ì ìš©")
        recommendations.append("êµì°¨ ê²€ì¦ ê°•í™”")

    if not realtime["tested"]:
        recommendations.append("ì‹¤ì‹œê°„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í•„ìš”")

    if training["test_accuracy"] < 0.65:
        recommendations.append("í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
        recommendations.append("íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ê°œì„ ")

    if training["test_accuracy"] == 1.0:
        recommendations.append("ë” ë§ì€ ë°ì´í„°ë¡œ ê²€ì¦")
        recommendations.append("ë‹¤ì–‘í•œ ì‹œì¥ ì¡°ê±´ì—ì„œ í…ŒìŠ¤íŠ¸")

    return recommendations


def create_comprehensive_visualizations(model_analysis, data):
    """ì¢…í•© ì‹œê°í™” ìƒì„±"""

    # ìŠ¤íƒ€ì¼ ì„¤ì •
    plt.style.use("default")
    sns.set_palette("husl")

    fig, axes = plt.subplots(2, 3, figsize=(20, 12))

    # 1. ëª¨ë¸ë³„ í›ˆë ¨ ì„±ëŠ¥ ë¹„êµ
    models = list(model_analysis.keys())
    train_scores = [
        model_analysis[m]["training_results"]["train_accuracy"] for m in models
    ]
    test_scores = [
        model_analysis[m]["training_results"]["test_accuracy"] for m in models
    ]

    x = np.arange(len(models))
    width = 0.35

    axes[0, 0].bar(
        x - width / 2, train_scores, width, label="Train Accuracy", color="skyblue"
    )
    axes[0, 0].bar(
        x + width / 2, test_scores, width, label="Test Accuracy", color="lightcoral"
    )
    axes[0, 0].set_title("ëª¨ë¸ë³„ í›ˆë ¨ ì„±ëŠ¥ ë¹„êµ")
    axes[0, 0].set_ylabel("ì •í™•ë„")
    axes[0, 0].set_xlabel("ëª¨ë¸")
    axes[0, 0].set_xticks(x)
    axes[0, 0].set_xticklabels(models)
    axes[0, 0].legend()
    axes[0, 0].set_ylim(0.9, 1.02)

    # ê°’ í‘œì‹œ
    for i, (train, test) in enumerate(zip(train_scores, test_scores)):
        axes[0, 0].text(
            i - width / 2,
            train + 0.005,
            f"{train:.3f}",
            ha="center",
            va="bottom",
            fontsize=8,
        )
        axes[0, 0].text(
            i + width / 2,
            test + 0.005,
            f"{test:.3f}",
            ha="center",
            va="bottom",
            fontsize=8,
        )

    # 2. ì˜¤ë²„í”¼íŒ… ë¶„ì„
    overfitting_gaps = [
        model_analysis[m]["training_results"]["overfitting_gap"] for m in models
    ]
    colors = [
        "green" if gap <= 0.05 else "orange" if gap <= 0.10 else "red"
        for gap in overfitting_gaps
    ]

    axes[0, 1].bar(models, overfitting_gaps, color=colors)
    axes[0, 1].set_title("ëª¨ë¸ë³„ ì˜¤ë²„í”¼íŒ… ë¶„ì„")
    axes[0, 1].set_ylabel("Train - Test ì •í™•ë„ ì°¨ì´")
    axes[0, 1].set_xlabel("ëª¨ë¸")
    axes[0, 1].axhline(y=0.05, color="orange", linestyle="--", label="ì£¼ì˜ì„  (0.05)")
    axes[0, 1].axhline(y=0.10, color="red", linestyle="--", label="ìœ„í—˜ì„  (0.10)")
    axes[0, 1].legend()

    # ê°’ í‘œì‹œ
    for i, gap in enumerate(overfitting_gaps):
        axes[0, 1].text(
            i, gap + 0.002, f"{gap:.3f}", ha="center", va="bottom", fontsize=8
        )

    # 3. ëª¨ë¸ë³„ ì„±ëŠ¥ ë“±ê¸‰
    training_grades = [
        model_analysis[m]["overall_assessment"]["training_grade"] for m in models
    ]
    overfitting_grades = [
        model_analysis[m]["overall_assessment"]["overfitting_grade"] for m in models
    ]

    # ë“±ê¸‰ì„ ìˆ«ìë¡œ ë³€í™˜
    grade_to_num = {"A": 4, "B": 3, "C": 2, "D": 1}
    training_nums = [grade_to_num[g] for g in training_grades]
    overfitting_nums = [grade_to_num[g] for g in overfitting_grades]

    axes[0, 2].bar(
        x - width / 2, training_nums, width, label="Training Grade", color="lightblue"
    )
    axes[0, 2].bar(
        x + width / 2,
        overfitting_nums,
        width,
        label="Overfitting Grade",
        color="lightgreen",
    )
    axes[0, 2].set_title("ëª¨ë¸ë³„ ì„±ëŠ¥ ë“±ê¸‰")
    axes[0, 2].set_ylabel("ë“±ê¸‰ (A=4, B=3, C=2, D=1)")
    axes[0, 2].set_xlabel("ëª¨ë¸")
    axes[0, 2].set_xticks(x)
    axes[0, 2].set_xticklabels(models)
    axes[0, 2].legend()
    axes[0, 2].set_ylim(0, 5)

    # ë“±ê¸‰ í‘œì‹œ
    for i, (t_grade, o_grade) in enumerate(zip(training_grades, overfitting_grades)):
        axes[0, 2].text(
            i - width / 2,
            training_nums[i] + 0.1,
            t_grade,
            ha="center",
            va="bottom",
            fontsize=10,
            fontweight="bold",
        )
        axes[0, 2].text(
            i + width / 2,
            overfitting_nums[i] + 0.1,
            o_grade,
            ha="center",
            va="bottom",
            fontsize=10,
            fontweight="bold",
        )

    # 4. ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ (Gradient Boostingë§Œ)
    gb_realtime = model_analysis["gradient_boosting"]["realtime_results"]
    if gb_realtime["tested"]:
        rt_results = data["realtime_results"]["results"]
        tickers = [r["ticker"] for r in rt_results]
        event_probs = [r["prediction"]["event_probability"] * 100 for r in rt_results]
        confidences = [r["prediction"]["confidence"] * 100 for r in rt_results]

        axes[1, 0].bar(
            tickers, event_probs, color="orange", alpha=0.7, label="Event Probability"
        )
        axes[1, 0].set_title("ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸: ì¢…ëª©ë³„ ì´ë²¤íŠ¸ í™•ë¥ ")
        axes[1, 0].set_ylabel("í™•ë¥  (%)")
        axes[1, 0].set_xlabel("ì¢…ëª©")

        # ê°’ í‘œì‹œ
        for i, prob in enumerate(event_probs):
            axes[1, 0].text(
                i, prob + 0.0001, f"{prob:.4f}%", ha="center", va="bottom", fontsize=8
            )
    else:
        axes[1, 0].text(
            0.5,
            0.5,
            "No Real-time Test Data",
            ha="center",
            va="center",
            transform=axes[1, 0].transAxes,
        )
        axes[1, 0].set_title("ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì—†ìŒ")

    # 5. ì‹¤ì‹œê°„ ì‹ ë¢°ë„
    if gb_realtime["tested"]:
        axes[1, 1].bar(tickers, confidences, color="lightgreen", alpha=0.7)
        axes[1, 1].set_title("ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸: ì¢…ëª©ë³„ ì˜ˆì¸¡ ì‹ ë¢°ë„")
        axes[1, 1].set_ylabel("ì‹ ë¢°ë„ (%)")
        axes[1, 1].set_xlabel("ì¢…ëª©")
        axes[1, 1].set_ylim(99, 100)

        # ê°’ í‘œì‹œ
        for i, conf in enumerate(confidences):
            axes[1, 1].text(
                i, conf + 0.01, f"{conf:.2f}%", ha="center", va="bottom", fontsize=8
            )
    else:
        axes[1, 1].text(
            0.5,
            0.5,
            "No Real-time Test Data",
            ha="center",
            va="center",
            transform=axes[1, 1].transAxes,
        )
        axes[1, 1].set_title("ì‹¤ì‹œê°„ ì‹ ë¢°ë„ ê²°ê³¼ ì—†ìŒ")

    # 6. ë°ì´í„°ì…‹ ì •ë³´
    training_summary = data["training_summary"]
    dataset_info = training_summary["dataset_info"]
    event_stats = training_summary["event_statistics"]

    # ì´ë²¤íŠ¸ íƒ€ì…ë³„ ë¶„í¬
    event_types = ["Price Events", "Volume Events", "Volatility Events"]
    event_counts = [
        event_stats["price_events"],
        event_stats["volume_events"],
        event_stats["volatility_events"],
    ]

    axes[1, 2].pie(event_counts, labels=event_types, autopct="%1.1f%%", startangle=90)
    axes[1, 2].set_title(
        f'í›ˆë ¨ ë°ì´í„° ì´ë²¤íŠ¸ ë¶„í¬\n(ì´ {dataset_info["total_records"]} ë ˆì½”ë“œ)'
    )

    plt.tight_layout()
    plt.savefig(
        "/root/workspace/data/raw/comprehensive_model_analysis.png",
        dpi=300,
        bbox_inches="tight",
    )
    plt.close()

    print(
        "âœ… ì¢…í•© ì‹œê°í™” ìƒì„± ì™„ë£Œ: /root/workspace/data/raw/comprehensive_model_analysis.png"
    )


def create_markdown_report(model_analysis, data):
    """ì¢…í•© ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""

    training_summary = data["training_summary"]
    realtime_results = data["realtime_results"]

    report = f"""# S&P500 ì´ë²¤íŠ¸ íƒì§€ ì‹œìŠ¤í…œ - ì¢…í•© ëª¨ë¸ ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”

**ë¶„ì„ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**ë°ì´í„°ì…‹**: {training_summary['dataset_info']['total_records']} ë ˆì½”ë“œ, {training_summary['dataset_info']['unique_tickers']} ì¢…ëª©  
**í›ˆë ¨ ê¸°ê°„**: {training_summary['dataset_info']['date_range']['start']} ~ {training_summary['dataset_info']['date_range']['end']}  
**íŠ¹ì„± ìˆ˜**: {training_summary['dataset_info']['features_count']}ê°œ

## ğŸ¯ ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„

"""

    # ê° ëª¨ë¸ë³„ ë¶„ì„
    for model_name, analysis in model_analysis.items():
        training = analysis["training_results"]
        realtime = analysis["realtime_results"]
        assessment = analysis["overall_assessment"]

        report += f"""### {model_name.replace('_', ' ').title()}

#### ğŸ“ˆ í›ˆë ¨ ì„±ëŠ¥
- **í›ˆë ¨ ì •í™•ë„**: {training['train_accuracy']:.4f}
- **í…ŒìŠ¤íŠ¸ ì •í™•ë„**: {training['test_accuracy']:.4f}
- **ì˜¤ë²„í”¼íŒ… ì§€í‘œ**: {training['overfitting_gap']:.4f}
- **ì„±ëŠ¥ ë“±ê¸‰**: {assessment['training_grade']}

#### ğŸ” ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ê²°ê³¼
"""

        if realtime["tested"]:
            report += f"""- **í…ŒìŠ¤íŠ¸ ì¼ì‹œ**: {realtime['test_date']}
- **í…ŒìŠ¤íŠ¸ ì¢…ëª©**: {realtime['stocks_tested']}ê°œ
- **í‰ê·  ì´ë²¤íŠ¸ í™•ë¥ **: {realtime['avg_event_probability']:.6f}
- **í‰ê·  ì‹ ë¢°ë„**: {realtime['avg_confidence']:.4f}
- **ì •ìƒ ì˜ˆì¸¡**: {realtime['normal_predictions']}ê°œ
- **ì´ë²¤íŠ¸ ì˜ˆì¸¡**: {realtime['event_predictions']}ê°œ
- **ì‹¤ì‹œê°„ ë“±ê¸‰**: {assessment['realtime_grade']}
"""
        else:
            report += f"""- **í…ŒìŠ¤íŠ¸ ì—¬ë¶€**: ë¯¸ì‹¤ì‹œ
- **ì‚¬ìœ **: {realtime['reason']}
"""

        report += f"""
#### âœ… ê°•ì 
{chr(10).join(f"- {strength}" for strength in assessment['strengths'])}

#### âš ï¸ ì•½ì 
{chr(10).join(f"- {weakness}" for weakness in assessment['weaknesses'])}

#### ğŸ¯ ê°œì„  ê¶Œì¥ì‚¬í•­
{chr(10).join(f"- {rec}" for rec in assessment['recommendations'])}

---

"""

    # ëª¨ë¸ ìˆœìœ„ ë° ì¶”ì²œ
    best_model = max(
        model_analysis.items(), key=lambda x: x[1]["training_results"]["test_accuracy"]
    )
    most_stable = min(
        model_analysis.items(),
        key=lambda x: x[1]["training_results"]["overfitting_gap"],
    )

    report += f"""## ğŸ† ëª¨ë¸ ìˆœìœ„ ë° ì¶”ì²œ

### ğŸ¥‡ ìµœê³  ì„±ëŠ¥ ëª¨ë¸
**{best_model[0].replace('_', ' ').title()}**
- í…ŒìŠ¤íŠ¸ ì •í™•ë„: {best_model[1]['training_results']['test_accuracy']:.4f}
- ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸: {'ì™„ë£Œ' if best_model[1]['realtime_results']['tested'] else 'ë¯¸ì™„ë£Œ'}

### ğŸ›¡ï¸ ê°€ì¥ ì•ˆì •ì ì¸ ëª¨ë¸
**{most_stable[0].replace('_', ' ').title()}**
- ì˜¤ë²„í”¼íŒ… ì§€í‘œ: {most_stable[1]['training_results']['overfitting_gap']:.4f}
- ì•ˆì •ì„± ë“±ê¸‰: {most_stable[1]['overall_assessment']['overfitting_grade']}

### ğŸ’¡ ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ

#### ìš´ì˜ í™˜ê²½ë³„ ì¶”ì²œ
1. **í”„ë¡œë•ì…˜ í™˜ê²½**: {best_model[0].replace('_', ' ').title()}
   - ì´ìœ : ìµœê³  ì„±ëŠ¥ + ì‹¤ì‹œê°„ ê²€ì¦ ì™„ë£Œ
   
2. **ì•ˆì •ì„± ìš°ì„ **: {most_stable[0].replace('_', ' ').title()}
   - ì´ìœ : ë‚®ì€ ì˜¤ë²„í”¼íŒ… ìœ„í—˜
   
3. **ì‹¤í—˜ í™˜ê²½**: Random Forest
   - ì´ìœ : í•´ì„ ê°€ëŠ¥ì„± + ë¹ ë¥¸ í•™ìŠµ

## ğŸ“‹ ë°ì´í„°ì…‹ ë¶„ì„

### ì´ë²¤íŠ¸ ë¶„í¬
- **ì´ ì´ë²¤íŠ¸**: {training_summary['event_statistics']['major_events']}ê°œ ({training_summary['event_statistics']['major_event_rate']:.2%})
- **ê°€ê²© ì´ë²¤íŠ¸**: {training_summary['event_statistics']['price_events']}ê°œ
- **ê±°ë˜ëŸ‰ ì´ë²¤íŠ¸**: {training_summary['event_statistics']['volume_events']}ê°œ
- **ë³€ë™ì„± ì´ë²¤íŠ¸**: {training_summary['event_statistics']['volatility_events']}ê°œ

### ì¢…ëª©ë³„ ì´ë²¤íŠ¸ ë°œìƒë¥ 
| ì¢…ëª© | ë ˆì½”ë“œ ìˆ˜ | ì´ë²¤íŠ¸ ìˆ˜ | ë°œìƒë¥  |
|------|-----------|-----------|--------|
"""

    for ticker, stats in training_summary["ticker_statistics"].items():
        report += f"| {ticker} | {stats['records']} | {stats['major_events']} | {stats['event_rate']:.2%} |\n"

    report += f"""
## ğŸ”® ì‹¤ì‹œê°„ ì˜ˆì¸¡ í˜„í™©

**ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì‹œê°„**: {realtime_results['test_timestamp']}  
**ì‚¬ìš© ëª¨ë¸**: {realtime_results['model_used'].replace('_', ' ').title()}  
**ì˜ˆì¸¡ ê²°ê³¼**: ëª¨ë“  ì¢…ëª© ì •ìƒ ìƒíƒœ

### ì¢…ëª©ë³„ í˜„ì¬ ìƒíƒœ
| ì¢…ëª© | í˜„ì¬ ê°€ê²© | ì´ë²¤íŠ¸ í™•ë¥  | ì‹ ë¢°ë„ | ìƒíƒœ |
|------|-----------|-------------|--------|------|
"""

    for result in realtime_results["results"]:
        ticker = result["ticker"]
        price = result["current_price"]
        prob = result["prediction"]["event_probability"]
        conf = result["prediction"]["confidence"]
        status = "ì •ìƒ" if prob < 0.5 else "ì£¼ì˜"

        report += f"| {ticker} | ${price:.2f} | {prob:.4%} | {conf:.2%} | {status} |\n"

    report += f"""
## ğŸ“Š ì£¼ìš” ë°œê²¬ì‚¬í•­

### 1. ëª¨ë¸ ì„±ëŠ¥
- **ìµœê³  ì •í™•ë„**: {max(analysis['training_results']['test_accuracy'] for analysis in model_analysis.values()):.4f}
- **í‰ê·  ì •í™•ë„**: {np.mean([analysis['training_results']['test_accuracy'] for analysis in model_analysis.values()]):.4f}
- **ëª¨ë“  ëª¨ë¸ì´ 95% ì´ìƒì˜ ë†’ì€ ì„±ëŠ¥** ë‹¬ì„±

### 2. ì•ˆì •ì„±
- **ì˜¤ë²„í”¼íŒ… ìœ„í—˜**: {sum(1 for analysis in model_analysis.values() if analysis['training_results']['overfitting_gap'] > 0.1)}ê°œ ëª¨ë¸ì—ì„œ ë°œê²¬
- **ê°€ì¥ ì•ˆì •ì **: {most_stable[0].replace('_', ' ').title()} (ì°¨ì´: {most_stable[1]['training_results']['overfitting_gap']:.4f})

### 3. ì‹¤ì‹œê°„ ì„±ëŠ¥
- **í…ŒìŠ¤íŠ¸ ì™„ë£Œ**: 1ê°œ ëª¨ë¸ (Gradient Boosting)
- **ì˜ˆì¸¡ ì‹ ë¢°ë„**: 99.99% (ë§¤ìš° ë†’ìŒ)
- **í˜„ì¬ ì‹œì¥ ìƒí™©**: ì•ˆì •ì  (ì´ë²¤íŠ¸ ë°œìƒ ê°€ëŠ¥ì„± ë‚®ìŒ)

## ğŸ¯ í–¥í›„ ê°œì„  ë°©í–¥

### ë‹¨ê¸° (1-2ì£¼)
1. **ë¯¸í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì‹¤ì‹œê°„ ê²€ì¦**
   - Random Forest, LSTM ì‹¤ì‹œê°„ ì„±ëŠ¥ í™•ì¸
   
2. **ì•™ìƒë¸” ëª¨ë¸ ê°œë°œ**
   - ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ê²°í•©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ

### ì¤‘ê¸° (1-2ê°œì›”)
1. **í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**
   - ê·¸ë¦¬ë“œ ì„œì¹˜ ë˜ëŠ” ë² ì´ì§€ì•ˆ ìµœì í™” ì ìš©
   
2. **íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ê°œì„ **
   - ìƒˆë¡œìš´ ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
   - ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì •í™•ë„ í–¥ìƒ

### ì¥ê¸° (3-6ê°œì›”)
1. **ë”¥ëŸ¬ë‹ ëª¨ë¸ í™•ì¥**
   - Transformer ê¸°ë°˜ ëª¨ë¸ ì‹¤í—˜
   - ì‹œê³„ì—´ íŠ¹í™” ëª¨ë¸ ê°œë°œ
   
2. **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•**
   - ìë™ ì•Œë¦¼ ì‹œìŠ¤í…œ
   - ì„±ëŠ¥ ë“œë¦¬í”„íŠ¸ íƒì§€

## ğŸ“ ìƒì„± íŒŒì¼

- **ì¢…í•© ë¶„ì„ ì‹œê°í™”**: `/root/workspace/data/raw/comprehensive_model_analysis.png`
- **ì´ ë¦¬í¬íŠ¸**: `/root/workspace/data/raw/COMPREHENSIVE_MODEL_REPORT.md`
- **ì›ë³¸ ë°ì´í„°**: `model_performance.json`, `realtime_test_results.json`

---
*Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

    with open("/root/workspace/data/raw/COMPREHENSIVE_MODEL_REPORT.md", "w") as f:
        f.write(report)

    print("âœ… ì¢…í•© ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: raw_data/COMPREHENSIVE_MODEL_REPORT.md")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ“Š S&P500 ì´ë²¤íŠ¸ íƒì§€ ì‹œìŠ¤í…œ - ì¢…í•© ëª¨ë¸ ë¶„ì„")
    print("=" * 60)

    # ë°ì´í„° ë¡œë“œ
    print("ğŸ“ ë°ì´í„° ë¡œë“œ ì¤‘...")
    data = load_all_data()

    # ëª¨ë¸ ë¶„ì„
    print("ğŸ” ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„ ì¤‘...")
    model_analysis = analyze_model_performance(data)

    # ì‹œê°í™” ìƒì„±
    print("ğŸ“ˆ ì‹œê°í™” ìƒì„± ì¤‘...")
    create_comprehensive_visualizations(model_analysis, data)

    # ë¦¬í¬íŠ¸ ìƒì„±
    print("ğŸ“‹ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    create_markdown_report(model_analysis, data)

    print("\nğŸ‰ ì¢…í•© ë¶„ì„ ì™„ë£Œ!")
    print("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print("  - raw_data/comprehensive_model_analysis.png")
    print("  - raw_data/COMPREHENSIVE_MODEL_REPORT.md")

    # ì£¼ìš” ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print("\nğŸ“Š ì£¼ìš” ê²°ê³¼ ìš”ì•½:")
    for model_name, analysis in model_analysis.items():
        training = analysis["training_results"]
        assessment = analysis["overall_assessment"]
        print(f"  {model_name.replace('_', ' ').title()}:")
        print(f"    - í…ŒìŠ¤íŠ¸ ì •í™•ë„: {training['test_accuracy']:.4f}")
        print(f"    - ì„±ëŠ¥ ë“±ê¸‰: {assessment['training_grade']}")
        print(
            f"    - ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸: {'ì™„ë£Œ' if analysis['realtime_results']['tested'] else 'ë¯¸ì™„ë£Œ'}"
        )


if __name__ == "__main__":
    main()
