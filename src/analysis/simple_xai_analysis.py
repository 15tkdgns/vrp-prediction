#!/usr/bin/env python3
"""
Simple XAI Analysis for SPY Volatility Prediction
ì˜ì¡´ì„± ë¬¸ì œ ì—†ì´ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ XAI ë¶„ì„
"""

import os
import sys
import numpy as np
import pandas as pd
import warnings
import json
from datetime import datetime
from pathlib import Path

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append('/root/workspace')

try:
    import shap
    from sklearn.linear_model import Ridge
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import r2_score, mean_squared_error
    from sklearn.inspection import partial_dependence, permutation_importance
    DEPENDENCIES_OK = True
    print("âœ… ëª¨ë“  XAI ì˜ì¡´ì„± ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âŒ ì˜ì¡´ì„± ë¶€ì¡±: {e}")
    DEPENDENCIES_OK = False

try:
    import yfinance as yf
    YFINANCE_OK = True
except ImportError:
    YFINANCE_OK = False

class SimpleXAIAnalyzer:
    """ê°„ë‹¨í•œ XAI ë¶„ì„ê¸° - ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥"""

    def __init__(self):
        print("ğŸš€ Simple XAI Analyzer ì´ˆê¸°í™”...")
        self.model = None
        self.scaler = None
        self.feature_names = []
        self.X_train = None
        self.y_train = None
        self.X_test = None
        self.y_test = None

    def generate_spy_features(self, start_date='2020-01-01', end_date='2024-01-01'):
        """SPY ë°ì´í„° ë¡œë“œ ë° íŠ¹ì„± ìƒì„±"""
        print("ğŸ“Š SPY ë°ì´í„° ë¡œë“œ ë° íŠ¹ì„± ìƒì„± ì¤‘...")

        if YFINANCE_OK:
            try:
                spy = yf.Ticker("SPY")
                data = spy.history(start=start_date, end=end_date)
                prices = data['Close']
                print(f"âœ… ì‹¤ì œ SPY ë°ì´í„°: {len(data)} ê´€ì¸¡ì¹˜")
            except Exception as e:
                print(f"âš ï¸ yfinance ì˜¤ë¥˜: {e}, ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì‚¬ìš©")
                dates = pd.date_range(start=start_date, end=end_date, freq='D')
                np.random.seed(42)
                prices = pd.Series(100 * np.exp(np.cumsum(np.random.normal(0.0003, 0.015, len(dates)))),
                                 index=dates)
        else:
            print("ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ SPY ë°ì´í„° ìƒì„± ì¤‘...")
            dates = pd.date_range(start=start_date, end=end_date, freq='D')
            np.random.seed(42)
            prices = pd.Series(100 * np.exp(np.cumsum(np.random.normal(0.0003, 0.015, len(dates)))),
                             index=dates)

        # ìˆ˜ìµë¥  ê³„ì‚°
        returns = prices.pct_change()

        # íŠ¹ì„± ìƒì„±
        features = pd.DataFrame(index=prices.index)

        print("ğŸ”§ íŠ¹ì„± ìƒì„± ì¤‘...")

        # 1. ë³€ë™ì„± íŠ¹ì„± (í•µì‹¬)
        for window in [5, 10, 20]:
            features[f'vol_{window}'] = returns.rolling(window).std() * np.sqrt(252)

        # 2. ìˆ˜ìµë¥  ì§€ì—° íŠ¹ì„±
        for lag in [1, 2, 3]:
            features[f'return_lag_{lag}'] = returns.shift(lag)

        # 3. Z-ìŠ¤ì½”ì–´ íŠ¹ì„±
        for window in [10, 20]:
            mean_ret = returns.rolling(window).mean()
            std_ret = returns.rolling(window).std()
            features[f'zscore_{window}'] = (returns - mean_ret) / std_ret

        # 4. ëª¨ë©˜í…€ íŠ¹ì„±
        for window in [10, 20]:
            features[f'momentum_{window}'] = (prices / prices.shift(window) - 1) * 100

        # 5. ë³€ë™ì„± ë¹„ìœ¨
        features['vol_5_20_ratio'] = features['vol_5'] / features['vol_20']

        # 6. ë³€ë™ì„± ì²´ì œ
        vol_median = features['vol_20'].rolling(252).median()
        features['vol_regime'] = (features['vol_20'] > vol_median).astype(int)

        # 7. íƒ€ê²Ÿ: 5ì¼ í›„ ë³€ë™ì„±
        target = returns.rolling(5).std().shift(-5) * np.sqrt(252)

        # ê²°ì¸¡ì¹˜ ì œê±°
        combined = pd.concat([features, target], axis=1).dropna()
        X = combined[features.columns]
        y = combined.iloc[:, -1]  # íƒ€ê²Ÿ

        self.feature_names = list(X.columns)
        print(f"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: {X.shape[0]}ê°œ ìƒ˜í”Œ, {X.shape[1]}ê°œ íŠ¹ì„±")

        return X, y

    def train_ridge_model(self, X, y, test_size=0.2, alpha=1.0):
        """Ridge ëª¨ë¸ í›ˆë ¨"""
        print("ğŸ”„ Ridge ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")

        # ì‹œê°„ì  ë¶„í• 
        split_idx = int(len(X) * (1 - test_size))
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

        # í‘œì¤€í™”
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Ridge ëª¨ë¸ í›ˆë ¨
        model = Ridge(alpha=alpha, random_state=42)
        model.fit(X_train_scaled, y_train)

        # ì˜ˆì¸¡ ë° ì„±ëŠ¥
        y_test_pred = model.predict(X_test_scaled)
        test_r2 = r2_score(y_test, y_test_pred)
        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

        # ì €ì¥
        self.model = model
        self.scaler = scaler
        self.X_train = X_train
        self.X_test = X_test
        self.y_train = y_train
        self.y_test = y_test

        print(f"âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        print(f"ğŸ“Š Test RÂ²: {test_r2:.4f}")
        print(f"ğŸ“Š Test RMSE: {test_rmse:.4f}")

        return {
            'test_r2': test_r2,
            'test_rmse': test_rmse,
            'train_samples': len(X_train),
            'test_samples': len(X_test)
        }

    def analyze_shap(self, sample_size=500):
        """SHAP ë¶„ì„"""
        print("ğŸ” SHAP ë¶„ì„ ì‹œì‘...")

        if not DEPENDENCIES_OK:
            print("âŒ SHAP ë¶„ì„ ë¶ˆê°€ - ì˜ì¡´ì„± ë¶€ì¡±")
            return {}

        try:
            # ìƒ˜í”Œ ì„ íƒ
            X_sample = self.X_train.tail(sample_size) if len(self.X_train) > sample_size else self.X_train
            X_sample_scaled = self.scaler.transform(X_sample)

            # SHAP LinearExplainer
            explainer = shap.LinearExplainer(self.model, X_sample_scaled)
            shap_values = explainer.shap_values(X_sample_scaled)

            # íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°
            feature_importance = np.abs(shap_values).mean(axis=0)

            importance_df = pd.DataFrame({
                'feature': self.feature_names,
                'importance': feature_importance
            }).sort_values('importance', ascending=False)

            print(f"âœ… SHAP ë¶„ì„ ì™„ë£Œ ({len(X_sample)}ê°œ ìƒ˜í”Œ)")
            print("ğŸ† Top 5 ì¤‘ìš” íŠ¹ì„±:")
            for i, row in importance_df.head().iterrows():
                print(f"  {row['feature']}: {row['importance']:.4f}")

            return {
                'feature_importance': importance_df.to_dict('records'),
                'expected_value': float(explainer.expected_value),
                'sample_size': len(X_sample)
            }

        except Exception as e:
            print(f"âŒ SHAP ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

    def analyze_ridge_coefficients(self):
        """Ridge íšŒê·€ ê³„ìˆ˜ ë¶„ì„ (SHAP ëŒ€ì•ˆ)"""
        print("ğŸ“Š Ridge ê³„ìˆ˜ ê¸°ë°˜ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„...")

        if self.model is None:
            return {}

        # Ridge ê³„ìˆ˜
        coefficients = self.model.coef_

        # ì ˆëŒ€ê°’ ê¸°ì¤€ ì¤‘ìš”ë„
        abs_coeffs = np.abs(coefficients)

        importance_df = pd.DataFrame({
            'feature': self.feature_names,
            'coefficient': coefficients,
            'abs_importance': abs_coeffs
        }).sort_values('abs_importance', ascending=False)

        print("âœ… Ridge ê³„ìˆ˜ ë¶„ì„ ì™„ë£Œ")
        print("ğŸ† Top 5 ì¤‘ìš” íŠ¹ì„± (Ridge ê³„ìˆ˜ ê¸°ì¤€):")
        for i, row in importance_df.head().iterrows():
            print(f"  {row['feature']}: {row['coefficient']:.4f} (|{row['abs_importance']:.4f}|)")

        return importance_df.to_dict('records')

    def analyze_permutation_importance(self, n_repeats=5):
        """Permutation Importance ë¶„ì„"""
        print("ğŸ”„ Permutation Importance ë¶„ì„ ì‹œì‘...")

        if not DEPENDENCIES_OK:
            print("âŒ Permutation ë¶„ì„ ë¶ˆê°€")
            return {}

        try:
            X_test_scaled = self.scaler.transform(self.X_test)

            perm_importance = permutation_importance(
                self.model, X_test_scaled, self.y_test,
                n_repeats=n_repeats, random_state=42, scoring='r2'
            )

            importance_results = []
            for i, feature_name in enumerate(self.feature_names):
                importance_results.append({
                    'feature': feature_name,
                    'importance_mean': float(perm_importance.importances_mean[i]),
                    'importance_std': float(perm_importance.importances_std[i])
                })

            importance_results.sort(key=lambda x: x['importance_mean'], reverse=True)

            print("âœ… Permutation Importance ë¶„ì„ ì™„ë£Œ")
            print("ğŸ† Top 5 ì¤‘ìš” íŠ¹ì„± (Permutation ê¸°ì¤€):")
            for result in importance_results[:5]:
                print(f"  {result['feature']}: {result['importance_mean']:.4f} Â± {result['importance_std']:.4f}")

            return importance_results

        except Exception as e:
            print(f"âŒ Permutation ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

    def generate_financial_insights(self, shap_results=None, coeff_results=None, perm_results=None):
        """ê¸ˆìœµ ë„ë©”ì¸ íŠ¹í™” ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        print("ğŸ’¡ ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")

        insights = {}

        # ëª¨ë¸ ì„±ëŠ¥ í•´ì„
        if self.model is not None:
            test_r2 = r2_score(self.y_test, self.model.predict(self.scaler.transform(self.X_test)))

            if test_r2 > 0.3:
                performance_level = "ìš°ìˆ˜"
                business_value = "VIX ì˜µì…˜, ë™ì  í—¤ì§•ì— ì§ì ‘ í™œìš© ê°€ëŠ¥"
            elif test_r2 > 0.15:
                performance_level = "ì–‘í˜¸"
                business_value = "ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë³´ì¡° ë„êµ¬ë¡œ í™œìš©"
            else:
                performance_level = "ê°œì„  í•„ìš”"
                business_value = "ì¶”ê°€ ì—°êµ¬ í•„ìš”"

            insights['model_performance'] = {
                'r2_score': float(test_r2),
                'level': performance_level,
                'business_value': business_value
            }

        # íŠ¹ì„±ë³„ ê¸ˆìœµ í•´ì„
        top_features = []

        if shap_results and 'feature_importance' in shap_results:
            top_features = [f['feature'] for f in shap_results['feature_importance'][:5]]
        elif coeff_results:
            top_features = [f['feature'] for f in coeff_results[:5]]
        elif perm_results:
            top_features = [f['feature'] for f in perm_results[:5]]

        feature_insights = []
        for feature in top_features:
            insight = {
                'feature': feature,
                'category': self._categorize_feature(feature),
                'financial_meaning': self._get_financial_meaning(feature),
                'trading_application': self._get_trading_application(feature)
            }
            feature_insights.append(insight)

        insights['feature_insights'] = feature_insights

        # ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì¸ì‚¬ì´íŠ¸
        vol_features = [f for f in top_features if 'vol' in f.lower()]
        return_features = [f for f in top_features if 'return' in f.lower()]

        insights['risk_insights'] = {
            'volatility_focus': len(vol_features) / len(top_features) if top_features else 0,
            'return_focus': len(return_features) / len(top_features) if top_features else 0,
            'primary_risk_factor': 'Volatility' if len(vol_features) > len(return_features) else 'Returns'
        }

        print("âœ… ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ")
        return insights

    def _categorize_feature(self, feature_name):
        """íŠ¹ì„± ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        if 'vol' in feature_name.lower():
            return 'volatility'
        elif 'return' in feature_name.lower():
            return 'returns'
        elif 'momentum' in feature_name.lower():
            return 'momentum'
        elif 'zscore' in feature_name.lower():
            return 'technical'
        else:
            return 'other'

    def _get_financial_meaning(self, feature_name):
        """íŠ¹ì„±ì˜ ê¸ˆìœµì  ì˜ë¯¸"""
        meanings = {
            'vol_5': 'ë‹¨ê¸° ë³€ë™ì„± - ìµœê·¼ 5ì¼ ì‹œì¥ ë¶ˆí™•ì‹¤ì„±',
            'vol_10': 'ì¤‘ê¸° ë³€ë™ì„± - ìµœê·¼ 10ì¼ ì‹œì¥ ë¶ˆí™•ì‹¤ì„±',
            'vol_20': 'ì›”ê°„ ë³€ë™ì„± - ìµœê·¼ 20ì¼ ì‹œì¥ ë¶ˆí™•ì‹¤ì„±',
            'return_lag_1': 'ì „ì¼ ìˆ˜ìµë¥  - ë‹¨ê¸° ëª¨ë©˜í…€/ì—­ëª¨ë©˜í…€ íš¨ê³¼',
            'return_lag_2': '2ì¼ ì „ ìˆ˜ìµë¥  - ë‹¨ê¸° ì‹œê³„ì—´ íŒ¨í„´',
            'momentum_10': '10ì¼ ëª¨ë©˜í…€ - ì¤‘ê¸° ê°€ê²© ì¶”ì„¸',
            'momentum_20': '20ì¼ ëª¨ë©˜í…€ - ì¥ê¸° ê°€ê²© ì¶”ì„¸',
            'vol_regime': 'ë³€ë™ì„± ì²´ì œ - ê³ /ì € ë³€ë™ì„± ìƒíƒœ êµ¬ë¶„'
        }
        return meanings.get(feature_name, f'{feature_name}ì˜ ì‹œì¥ ì˜í–¥')

    def _get_trading_application(self, feature_name):
        """íŠ¸ë ˆì´ë”© ì‘ìš©"""
        applications = {
            'vol_5': 'VIX ì˜µì…˜ ê±°ë˜, ë‹¨ê¸° í—¤ì§•',
            'vol_10': 'ì¤‘ê¸° ë³€ë™ì„± ê±°ë˜, ì˜µì…˜ ì „ëµ',
            'vol_20': 'ì›”ê°„ ì˜µì…˜, í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹±',
            'return_lag_1': 'ì¼ì¤‘ ê±°ë˜, ë‹¨ê¸° ë°˜ì „ ì „ëµ',
            'momentum_10': 'ì¶”ì„¸ ì¶”ì¢… ì „ëµ',
            'momentum_20': 'ì¥ê¸° ì¶”ì„¸ ì „ëµ',
            'vol_regime': 'ë™ì  í¬ì§€ì…˜ ì¡°ì •, ë¦¬ìŠ¤í¬ ì˜ˆì‚° ë°°ë¶„'
        }
        return applications.get(feature_name, 'ì¼ë°˜ì  ê±°ë˜ ì „ëµ í™œìš©')

    def save_results(self, results, filename='xai_analysis_results.json'):
        """ê²°ê³¼ ì €ì¥"""
        output_dir = Path('/root/workspace/data/xai_analysis')
        output_dir.mkdir(exist_ok=True)

        filepath = output_dir / filename

        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        results['metadata'] = {
            'analysis_date': datetime.now().isoformat(),
            'model_type': 'Ridge Regression',
            'target': '5-day future volatility',
            'features_count': len(self.feature_names)
        }

        with open(filepath, 'w') as f:
            json.dump(results, f, indent=2)

        print(f"âœ… ê²°ê³¼ ì €ì¥: {filepath}")
        return str(filepath)

    def run_comprehensive_analysis(self):
        """ì¢…í•© XAI ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ ì¢…í•© XAI ë¶„ì„ ì‹œì‘...")
        print("=" * 60)

        results = {}

        try:
            # 1. ë°ì´í„° ì¤€ë¹„
            X, y = self.generate_spy_features()
            results['data_info'] = {
                'samples': len(X),
                'features': len(self.feature_names),
                'feature_names': self.feature_names
            }

            # 2. ëª¨ë¸ í›ˆë ¨
            model_results = self.train_ridge_model(X, y)
            results['model_performance'] = model_results

            # 3. SHAP ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)
            shap_results = self.analyze_shap()
            if shap_results:
                results['shap_analysis'] = shap_results

            # 4. Ridge ê³„ìˆ˜ ë¶„ì„
            coeff_results = self.analyze_ridge_coefficients()
            if coeff_results:
                results['coefficient_analysis'] = coeff_results

            # 5. Permutation Importance
            perm_results = self.analyze_permutation_importance()
            if perm_results:
                results['permutation_analysis'] = perm_results

            # 6. ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸
            insights = self.generate_financial_insights(shap_results, coeff_results, perm_results)
            results['financial_insights'] = insights

            # 7. ê²°ê³¼ ì €ì¥
            results_file = self.save_results(results)
            results['results_file'] = results_file

            # ìš”ì•½ ì¶œë ¥
            print("\n" + "=" * 60)
            print("ğŸ“Š XAI ë¶„ì„ ì™„ë£Œ ìš”ì•½:")
            print(f"ğŸ“ˆ Test RÂ²: {model_results['test_r2']:.4f}")
            print(f"ğŸ¯ ë¶„ì„ íŠ¹ì„± ìˆ˜: {len(self.feature_names)}")

            if shap_results:
                top_feature = shap_results['feature_importance'][0]['feature']
                print(f"ğŸ† ìµœê³  ì¤‘ìš” íŠ¹ì„± (SHAP): {top_feature}")
            elif coeff_results:
                print(f"ğŸ† ìµœê³  ì¤‘ìš” íŠ¹ì„± (Ridge): {coeff_results[0]['feature']}")

            if insights and 'model_performance' in insights:
                print(f"ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜: {insights['model_performance']['business_value']}")

            print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {results_file}")
            print("\nğŸ‰ ì¢…í•© XAI ë¶„ì„ ì™„ë£Œ!")

            return results

        except Exception as e:
            print(f"âŒ XAI ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Simple XAI Analysis ì‹œì‘...")

    analyzer = SimpleXAIAnalyzer()
    results = analyzer.run_comprehensive_analysis()

    return analyzer, results


if __name__ == '__main__':
    analyzer, results = main()