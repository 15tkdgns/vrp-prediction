#!/usr/bin/env python3
"""
XAI Dashboard Connector
ê²€ì¦ëœ XAI ë¶„ì„ ê²°ê³¼ë¥¼ ëŒ€ì‹œë³´ë“œì™€ ì—°ë™í•˜ëŠ” ëª¨ë“ˆ
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

class XAIDashboardConnector:
    """XAI ë¶„ì„ ê²°ê³¼ë¥¼ ëŒ€ì‹œë³´ë“œ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, xai_results_file: str = None):
        """
        XAI Dashboard Connector ì´ˆê¸°í™”

        Args:
            xai_results_file: XAI ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ê²½ë¡œ
        """
        self.xai_results_file = xai_results_file
        self.xai_data = None
        self.dashboard_data = {}

        if xai_results_file:
            self.load_xai_results(xai_results_file)

    def load_xai_results(self, filepath: str):
        """XAI ë¶„ì„ ê²°ê³¼ ë¡œë“œ"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                self.xai_data = json.load(f)
            print(f"âœ… XAI ë¶„ì„ ê²°ê³¼ ë¡œë“œ: {filepath}")
        except Exception as e:
            print(f"âŒ XAI ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def prepare_feature_importance_chart(self, top_n: int = 10) -> Dict:
        """íŠ¹ì„± ì¤‘ìš”ë„ ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„"""
        if not self.xai_data or 'shap_analysis' not in self.xai_data:
            return {}

        shap_analysis = self.xai_data['shap_analysis']
        feature_importance = shap_analysis.get('feature_importance', [])

        # Top N íŠ¹ì„± ì„ íƒ
        top_features = feature_importance[:top_n]

        chart_data = {
            'type': 'horizontal_bar',
            'title': f'Top {top_n} Feature Importance (SHAP)',
            'subtitle': 'Based on absolute SHAP values',
            'data': {
                'labels': [f['feature'] for f in top_features],
                'values': [f['shap_importance'] for f in top_features],
                'colors': self._generate_colors(len(top_features)),
                'tooltips': [self._generate_tooltip(f) for f in top_features]
            },
            'options': {
                'responsive': True,
                'maintainAspectRatio': False,
                'scales': {
                    'x': {'beginAtZero': True, 'title': {'display': True, 'text': 'SHAP Importance'}},
                    'y': {'title': {'display': True, 'text': 'Features'}}
                }
            }
        }

        return chart_data

    def prepare_feature_groups_analysis(self) -> Dict:
        """íŠ¹ì„± ê·¸ë£¹ë³„ ë¶„ì„ ë°ì´í„° ì¤€ë¹„"""
        if not self.xai_data or 'shap_analysis' not in self.xai_data:
            return {}

        shap_analysis = self.xai_data['shap_analysis']
        group_analysis = shap_analysis.get('group_analysis', {})

        if not group_analysis:
            return {}

        groups_data = []
        for group_name, group_info in group_analysis.items():
            groups_data.append({
                'group': group_name.title(),
                'importance': group_info['importance'],
                'feature_count': group_info['feature_count'],
                'features': group_info['features'][:3],  # Top 3 features per group
                'percentage': (group_info['importance'] / sum(g['importance'] for g in group_analysis.values())) * 100
            })

        # ì¤‘ìš”ë„ë¡œ ì •ë ¬
        groups_data.sort(key=lambda x: x['importance'], reverse=True)

        return {
            'type': 'pie_and_table',
            'title': 'Feature Groups Analysis',
            'subtitle': 'Importance distribution across feature categories',
            'pie_data': {
                'labels': [g['group'] for g in groups_data],
                'values': [g['percentage'] for g in groups_data],
                'colors': self._generate_colors(len(groups_data))
            },
            'table_data': groups_data
        }

    def prepare_model_performance_summary(self) -> Dict:
        """ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½ ë°ì´í„° ì¤€ë¹„"""
        if not self.xai_data:
            return {}

        model_perf = self.xai_data.get('model_performance', {})
        insights = self.xai_data.get('professional_insights', {})

        executive_summary = insights.get('executive_summary', {})
        performance_insights = insights.get('model_performance_insights', {})

        summary_data = {
            'model_metrics': {
                'test_r2': model_perf.get('test_r2', 0),
                'train_r2': model_perf.get('train_r2', 0),
                'test_rmse': model_perf.get('test_rmse', 0),
                'best_alpha': model_perf.get('best_alpha', 1.0),
                'n_features': model_perf.get('n_features', 0),
                'test_samples': model_perf.get('test_samples', 0)
            },
            'business_assessment': {
                'quality': executive_summary.get('model_quality', 'Unknown'),
                'predictive_power': executive_summary.get('predictive_power', 'Unknown'),
                'readiness': executive_summary.get('business_readiness', 'Unknown'),
                'r2_interpretation': performance_insights.get('r2_interpretation', 'Unknown')
            },
            'key_metrics_cards': [
                {
                    'title': 'Test RÂ²',
                    'value': f"{model_perf.get('test_r2', 0):.4f}",
                    'subtitle': 'Prediction Accuracy',
                    'color': self._get_performance_color(model_perf.get('test_r2', 0)),
                    'icon': 'ğŸ“ˆ'
                },
                {
                    'title': 'Model Quality',
                    'value': executive_summary.get('model_quality', 'Unknown'),
                    'subtitle': 'Business Assessment',
                    'color': 'success' if 'Excellent' in str(executive_summary.get('model_quality', '')) else 'primary',
                    'icon': 'ğŸ†'
                },
                {
                    'title': 'Features',
                    'value': str(model_perf.get('n_features', 0)),
                    'subtitle': 'Variables Analyzed',
                    'color': 'info',
                    'icon': 'ğŸ¯'
                },
                {
                    'title': 'Readiness',
                    'value': executive_summary.get('business_readiness', 'Unknown'),
                    'subtitle': 'Deployment Status',
                    'color': 'success' if 'Ready' in str(executive_summary.get('business_readiness', '')) else 'warning',
                    'icon': 'ğŸš€'
                }
            ]
        }

        return summary_data

    def prepare_business_insights(self) -> Dict:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë°ì´í„° ì¤€ë¹„"""
        if not self.xai_data:
            return {}

        insights = self.xai_data.get('professional_insights', {})

        # ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ì„¹ì…˜ë“¤
        sections = {
            'executive_summary': {
                'title': 'Executive Summary',
                'icon': 'ğŸ‘”',
                'data': insights.get('executive_summary', {})
            },
            'feature_insights': {
                'title': 'Feature Insights',
                'icon': 'ğŸ”',
                'data': insights.get('feature_insights', [])[:5]  # Top 5
            },
            'risk_management': {
                'title': 'Risk Management',
                'icon': 'âš ï¸',
                'data': insights.get('risk_management_insights', {})
            },
            'trading_strategies': {
                'title': 'Trading Strategies',
                'icon': 'ğŸ“Š',
                'data': insights.get('trading_strategy_insights', {})
            }
        }

        # í•µì‹¬ ë°œê²¬ì‚¬í•­ (Key Findings)
        key_findings = []
        if 'shap_analysis' in self.xai_data:
            top_feature = self.xai_data['shap_analysis']['feature_importance'][0]
            key_findings.append({
                'title': 'Most Important Feature',
                'description': f"{top_feature['feature']} dominates predictions with {top_feature['shap_importance']:.4f} importance",
                'impact': 'High',
                'category': 'Feature Analysis'
            })

        model_r2 = self.xai_data.get('model_performance', {}).get('test_r2', 0)
        if model_r2 > 0.3:
            key_findings.append({
                'title': 'Excellent Predictive Power',
                'description': f"Model explains {model_r2*100:.1f}% of volatility variation - outstanding for financial markets",
                'impact': 'Very High',
                'category': 'Model Performance'
            })

        return {
            'sections': sections,
            'key_findings': key_findings,
            'summary_stats': {
                'total_features_analyzed': len(insights.get('feature_insights', [])),
                'business_ready': 'Production Ready' in str(insights.get('executive_summary', {}).get('business_readiness', '')),
                'analysis_date': self.xai_data.get('metadata', {}).get('analysis_timestamp', datetime.now().isoformat())
            }
        }

    def prepare_temporal_analysis(self) -> Dict:
        """ì‹œê°„ì  ë¶„ì„ ë°ì´í„° ì¤€ë¹„"""
        if not self.xai_data or 'shap_analysis' not in self.xai_data:
            return {}

        temporal_analysis = self.xai_data['shap_analysis'].get('temporal_analysis', {})

        if not temporal_analysis:
            return {}

        # ìµœê·¼ vs ê³¼ê±° íŠ¹ì„± ì¤‘ìš”ë„ ë¹„êµ
        recent_features = temporal_analysis.get('recent_period_top_features', [])
        past_features = temporal_analysis.get('past_period_top_features', [])

        comparison_data = {
            'type': 'comparison_chart',
            'title': 'Feature Importance: Recent vs Past',
            'subtitle': 'Evolution of feature importance over time',
            'data': {
                'recent': {
                    'labels': [f['feature'] for f in recent_features[:5]],
                    'values': [f['importance'] for f in recent_features[:5]]
                },
                'past': {
                    'labels': [f['feature'] for f in past_features[:5]],
                    'values': [f['importance'] for f in past_features[:5]]
                }
            }
        }

        return comparison_data

    def prepare_interaction_network(self) -> Dict:
        """íŠ¹ì„± ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬ ë°ì´í„° ì¤€ë¹„"""
        if not self.xai_data or 'shap_analysis' not in self.xai_data:
            return {}

        interaction_analysis = self.xai_data['shap_analysis'].get('interaction_analysis', [])

        if not interaction_analysis:
            return {}

        # ë„¤íŠ¸ì›Œí¬ ë…¸ë“œ ë° ì—£ì§€ ì¤€ë¹„
        nodes = set()
        edges = []

        for interaction in interaction_analysis[:8]:  # Top 8 interactions
            feature1 = interaction['feature_1']
            feature2 = interaction['feature_2']
            strength = interaction['interaction_strength']

            nodes.add(feature1)
            nodes.add(feature2)

            edges.append({
                'source': feature1,
                'target': feature2,
                'weight': strength,
                'correlation': interaction['correlation']
            })

        network_data = {
            'type': 'network_graph',
            'title': 'Feature Interactions Network',
            'subtitle': 'Correlations between top features in SHAP space',
            'nodes': [{'id': node, 'label': node} for node in nodes],
            'edges': edges,
            'options': {
                'physics': True,
                'interaction': {'hover': True},
                'layout': {'improvedLayout': True}
            }
        }

        return network_data

    def create_dashboard_json(self) -> Dict:
        """ëŒ€ì‹œë³´ë“œìš© ì¢…í•© JSON ë°ì´í„° ìƒì„±"""
        dashboard_data = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'source': 'Verified XAI Analysis',
                'model_type': 'Ridge Regression',
                'target': '5-day Future Volatility'
            },
            'feature_importance': self.prepare_feature_importance_chart(),
            'feature_groups': self.prepare_feature_groups_analysis(),
            'model_performance': self.prepare_model_performance_summary(),
            'business_insights': self.prepare_business_insights(),
            'temporal_analysis': self.prepare_temporal_analysis(),
            'interaction_network': self.prepare_interaction_network()
        }

        return dashboard_data

    def save_dashboard_data(self, output_file: str = None) -> str:
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        dashboard_data = self.create_dashboard_json()

        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"/root/workspace/data/processed/xai_dashboard_data_{timestamp}.json"

        output_path = Path(output_file)
        output_path.parent.mkdir(exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(dashboard_data, f, indent=2, ensure_ascii=False)

        print(f"âœ… ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì €ì¥: {output_path}")
        return str(output_path)

    def _generate_colors(self, n_colors: int) -> List[str]:
        """ì°¨íŠ¸ìš© ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ìƒì„±"""
        colors = [
            '#FF6384', '#36A2EB', '#FFCE56', '#4BC0C0',
            '#9966FF', '#FF9F40', '#FF6384', '#C9CBCF',
            '#4BC0C0', '#FF6384', '#36A2EB', '#FFCE56'
        ]
        return colors[:n_colors] if n_colors <= len(colors) else colors * (n_colors // len(colors) + 1)

    def _generate_tooltip(self, feature_info: Dict) -> str:
        """íŠ¹ì„±ë³„ íˆ´íŒ í…ìŠ¤íŠ¸ ìƒì„±"""
        feature_name = feature_info['feature']
        importance = feature_info['shap_importance']

        return f"{feature_name}<br>Importance: {importance:.4f}<br>Click for details"

    def _get_performance_color(self, r2_score: float) -> str:
        """RÂ² ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜"""
        if r2_score > 0.3:
            return 'success'
        elif r2_score > 0.2:
            return 'warning'
        elif r2_score > 0.1:
            return 'info'
        else:
            return 'danger'

    def generate_summary_report(self) -> str:
        """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        if not self.xai_data:
            return "XAI ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        model_perf = self.xai_data.get('model_performance', {})
        shap_analysis = self.xai_data.get('shap_analysis', {})

        report = f"""
ğŸ† XAI ë¶„ì„ ìš”ì•½ ë³´ê³ ì„œ
========================

ğŸ“Š ëª¨ë¸ ì„±ëŠ¥:
- Test RÂ²: {model_perf.get('test_r2', 0):.4f}
- Train RÂ²: {model_perf.get('train_r2', 0):.4f}
- ìµœì  Alpha: {model_perf.get('best_alpha', 1.0)}
- íŠ¹ì„± ìˆ˜: {model_perf.get('n_features', 0)}

ğŸ¯ ì£¼ìš” ë°œê²¬:
"""

        if 'feature_importance' in shap_analysis:
            top_3 = shap_analysis['feature_importance'][:3]
            for i, feature in enumerate(top_3, 1):
                report += f"- {i}ìœ„: {feature['feature']} ({feature['shap_importance']:.4f})\n"

        insights = self.xai_data.get('professional_insights', {})
        executive_summary = insights.get('executive_summary', {})

        report += f"""
ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ í‰ê°€:
- ëª¨ë¸ í’ˆì§ˆ: {executive_summary.get('model_quality', 'Unknown')}
- ë°°í¬ ì¤€ë¹„ë„: {executive_summary.get('business_readiness', 'Unknown')}
- ì˜ˆì¸¡ë ¥: {executive_summary.get('predictive_power', 'Unknown')}
"""

        return report


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”— XAI Dashboard Connector ì‹œì‘...")

    # ìµœì‹  XAI ë¶„ì„ íŒŒì¼ ì°¾ê¸°
    xai_dir = Path("/root/workspace/data/xai_analysis")
    if not xai_dir.exists():
        print("âŒ XAI ë¶„ì„ ë””ë ‰í† ë¦¬ ì—†ìŒ")
        return

    xai_files = list(xai_dir.glob("verified_xai_analysis_*.json"))
    if not xai_files:
        print("âŒ XAI ë¶„ì„ íŒŒì¼ ì—†ìŒ")
        return

    # ê°€ì¥ ìµœì‹  íŒŒì¼ ì„ íƒ
    latest_file = max(xai_files, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“„ ìµœì‹  XAI íŒŒì¼ ì„ íƒ: {latest_file}")

    # Connector ì´ˆê¸°í™” ë° ë°ì´í„° ë³€í™˜
    connector = XAIDashboardConnector(str(latest_file))

    # ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±
    dashboard_data = connector.create_dashboard_json()

    # ì €ì¥
    dashboard_file = connector.save_dashboard_data()

    # ìš”ì•½ ë³´ê³ ì„œ ì¶œë ¥
    print("\n" + "="*50)
    print(connector.generate_summary_report())
    print("="*50)

    print(f"\nâœ… ëŒ€ì‹œë³´ë“œ ì—°ë™ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
    print(f"ğŸ“ ëŒ€ì‹œë³´ë“œ ë°ì´í„° íŒŒì¼: {dashboard_file}")

    return connector


if __name__ == '__main__':
    connector = main()