#!/usr/bin/env python3
"""
ðŸ”’ Ultra Leak-Free Data Processor
ì™„ì „í•œ ë°ì´í„° ìœ ì¶œ ì œê±°ë¥¼ ìœ„í•œ ì´ˆê°•ë ¥ ì²˜ë¦¬ê¸°
"""

import numpy as np
import pandas as pd
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class UltraLeakFreeProcessor:
    """
    ì´ˆê°•ë ¥ ë¬´ëˆ„ì¶œ ë°ì´í„° ì²˜ë¦¬ê¸°
    - ì›ì‹œ ê°€ê²© ë°ì´í„°ì—ì„œ ì‹œìž‘
    - ëª¨ë“  íŠ¹ì§•ì„ ì²˜ìŒë¶€í„° ì•ˆì „í•˜ê²Œ ìƒì„±
    - ì—„ê²©í•œ ì‹œê°„ì  ìˆœì„œ ì¤€ìˆ˜
    """

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.feature_log = []
        self.validation_log = []

    def load_raw_price_data(self, input_file):
        """ì›ì‹œ ê°€ê²© ë°ì´í„°ë§Œ ë¡œë“œ"""
        print("ðŸ“Š ì›ì‹œ ê°€ê²© ë°ì´í„° ë¡œë“œ...")

        df = pd.read_csv(input_file)
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date').reset_index(drop=True)

        # í•„ìˆ˜ ì»¬ëŸ¼ë§Œ ì„ íƒ (ê¸°ì¡´ íŒŒìƒ íŠ¹ì§•ë“¤ ëª¨ë‘ ì œê±°)
        essential_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
        available_columns = [col for col in essential_columns if col in df.columns]

        df_clean = df[available_columns].copy()

        print(f"âœ… ë¡œë“œëœ ì»¬ëŸ¼: {available_columns}")
        print(f"âœ… ë°ì´í„° í¬ê¸°: {df_clean.shape}")
        print(f"âœ… ê¸°ê°„: {df_clean['Date'].min()} ~ {df_clean['Date'].max()}")

        return df_clean

    def create_ultra_safe_returns(self, df):
        """ì™„ì „ížˆ ì•ˆì „í•œ ìˆ˜ìµë¥  ê³„ì‚°"""
        print("ðŸ”’ ì•ˆì „í•œ ìˆ˜ìµë¥  ê³„ì‚°...")

        # pct_change()ëŠ” ì²« ë²ˆì§¸ í–‰ì„ NaNìœ¼ë¡œ ë§Œë“¦ (ì˜¬ë°”ë¦„)
        df['Returns'] = df['Close'].pct_change()

        # ê²€ì¦: ì²« ë²ˆì§¸ í–‰ì€ ë°˜ë“œì‹œ NaN
        assert pd.isna(df['Returns'].iloc[0]), "Returns[0]ì´ NaNì´ ì•„ë‹˜!"

        self.feature_log.append("Returns: ì²« ë²ˆì§¸ í–‰ NaN í™•ì¸")
        return df

    def create_ultra_safe_moving_averages(self, df):
        """ì™„ì „ížˆ ì•ˆì „í•œ ì´ë™í‰ê·  ìƒì„±"""
        print("ðŸ”’ ì™„ì „ížˆ ì•ˆì „í•œ ì´ë™í‰ê·  ìƒì„±...")

        windows = [5, 10, 20, 50]

        for window in windows:
            ma_col = f"MA_{window}"

            # ì•ˆì „í•œ ì´ë™í‰ê· : min_periods=windowë¡œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìžˆì„ ë•Œë§Œ ê³„ì‚°
            df[ma_col] = df['Close'].rolling(window=window, min_periods=window).mean()

            # ì—„ê²©í•œ ê²€ì¦: ì²« (window-1)ê°œ í–‰ì€ ë°˜ë“œì‹œ NaN
            expected_nan_count = window - 1
            actual_nan_count = df[ma_col].iloc[:window].isna().sum()

            if actual_nan_count != window:
                # ê°•ì œë¡œ ì•ˆì „í•˜ê²Œ ë§Œë“¤ê¸°
                df[ma_col].iloc[:window] = np.nan
                print(f"ðŸ”§ {ma_col}: ì²« {window}ê°œ í–‰ì„ ê°•ì œë¡œ NaN ì„¤ì •")

            # ìµœì¢… ê²€ì¦
            assert df[ma_col].iloc[:window].isna().all(), f"{ma_col} ì²« {window}ê°œ í–‰ì´ NaNì´ ì•„ë‹˜!"

            self.feature_log.append(f"{ma_col}: ì²« {window}í–‰ NaN í™•ì¸")

        return df

    def create_ultra_safe_rsi(self, df):
        """ì™„ì „ížˆ ì•ˆì „í•œ RSI ìƒì„±"""
        print("ðŸ”’ ì™„ì „ížˆ ì•ˆì „í•œ RSI ìƒì„±...")

        window = 14

        # RSI ê³„ì‚°
        delta = df['Close'].diff()  # ì²« ë²ˆì§¸ í–‰ NaN
        gain = (delta.where(delta > 0, 0)).rolling(window=window, min_periods=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window, min_periods=window).mean()

        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))

        # ì´ˆê°•ë ¥ ê²€ì¦ ë° ìˆ˜ì •
        # diff(1) + rolling(14) = ìµœì†Œ 14ê°œ í–‰ì´ NaNì´ì–´ì•¼ í•¨
        required_nan_rows = window
        df['RSI'].iloc[:required_nan_rows] = np.nan

        # ìµœì¢… ê²€ì¦
        assert df['RSI'].iloc[:required_nan_rows].isna().all(), f"RSI ì²« {required_nan_rows}í–‰ì´ NaNì´ ì•„ë‹˜!"

        self.feature_log.append(f"RSI: ì²« {required_nan_rows}í–‰ NaN í™•ì¸ (ê°•ì œ ìˆ˜ì •)")
        return df

    def create_ultra_safe_bollinger_bands(self, df):
        """ì™„ì „ížˆ ì•ˆì „í•œ ë³¼ë¦°ì €ë°´ë“œ ìƒì„±"""
        print("ðŸ”’ ì™„ì „ížˆ ì•ˆì „í•œ ë³¼ë¦°ì €ë°´ë“œ ìƒì„±...")

        window = 20

        # ì´ë™í‰ê· ê³¼ í‘œì¤€íŽ¸ì°¨
        rolling_mean = df['Close'].rolling(window=window, min_periods=window).mean()
        rolling_std = df['Close'].rolling(window=window, min_periods=window).std()

        df['BB_upper'] = rolling_mean + (rolling_std * 2)
        df['BB_lower'] = rolling_mean - (rolling_std * 2)
        df['BB_middle'] = rolling_mean
        df['BB_width'] = df['BB_upper'] - df['BB_lower']

        # BB í¬ì§€ì…˜ ê³„ì‚° (0~1 ì‚¬ì´)
        df['BB_position'] = (df['Close'] - df['BB_lower']) / (df['BB_upper'] - df['BB_lower'])

        # ì´ˆê°•ë ¥ ê²€ì¦ ë° ìˆ˜ì •
        bb_cols = ['BB_upper', 'BB_lower', 'BB_middle', 'BB_width', 'BB_position']
        required_nan_rows = window

        for col in bb_cols:
            df[col].iloc[:required_nan_rows] = np.nan
            assert df[col].iloc[:required_nan_rows].isna().all(), f"{col} ì²« {required_nan_rows}í–‰ì´ NaNì´ ì•„ë‹˜!"
            self.feature_log.append(f"{col}: ì²« {required_nan_rows}í–‰ NaN í™•ì¸")

        return df

    def create_ultra_safe_volatility(self, df):
        """ì™„ì „ížˆ ì•ˆì „í•œ ë³€ë™ì„± ì§€í‘œ"""
        print("ðŸ”’ ì™„ì „ížˆ ì•ˆì „í•œ ë³€ë™ì„± ì§€í‘œ ìƒì„±...")

        windows = [5, 10, 20]

        for window in windows:
            vol_col = f"Volatility_{window}"

            # Returns ê¸°ë°˜ ë³€ë™ì„± (ì´ë¯¸ ReturnsëŠ” ì²« ë²ˆì§¸ê°€ NaN)
            df[vol_col] = df['Returns'].rolling(window=window, min_periods=window).std()

            # ì´ˆê°•ë ¥ ê²€ì¦ ë° ìˆ˜ì •
            # Returnsê°€ ì²« ë²ˆì§¸ NaN + rolling window = window+1ê°œ í–‰ì´ NaNì´ì–´ì•¼ í•¨
            required_nan_rows = window + 1
            df[vol_col].iloc[:required_nan_rows] = np.nan

            assert df[vol_col].iloc[:required_nan_rows].isna().all(), f"{vol_col} ì²« {required_nan_rows}í–‰ì´ NaNì´ ì•„ë‹˜!"
            self.feature_log.append(f"{vol_col}: ì²« {required_nan_rows}í–‰ NaN í™•ì¸")

        return df

    def create_ultra_safe_volume_features(self, df):
        """ì™„ì „ížˆ ì•ˆì „í•œ ê±°ëž˜ëŸ‰ íŠ¹ì§•"""
        print("ðŸ”’ ì™„ì „ížˆ ì•ˆì „í•œ ê±°ëž˜ëŸ‰ íŠ¹ì§• ìƒì„±...")

        windows = [10, 20]

        for window in windows:
            # ê±°ëž˜ëŸ‰ ì´ë™í‰ê· 
            vol_ma_col = f"Volume_MA_{window}"
            df[vol_ma_col] = df['Volume'].rolling(window=window, min_periods=window).mean()

            # ê±°ëž˜ëŸ‰ ë¹„ìœ¨
            vol_ratio_col = f"Volume_ratio_{window}"
            df[vol_ratio_col] = df['Volume'] / df[vol_ma_col]

            # ì´ˆê°•ë ¥ ê²€ì¦ ë° ìˆ˜ì •
            required_nan_rows = window
            for col in [vol_ma_col, vol_ratio_col]:
                df[col].iloc[:required_nan_rows] = np.nan
                assert df[col].iloc[:required_nan_rows].isna().all(), f"{col} ì²« {required_nan_rows}í–‰ì´ NaNì´ ì•„ë‹˜!"
                self.feature_log.append(f"{col}: ì²« {required_nan_rows}í–‰ NaN í™•ì¸")

        return df

    def create_ultra_safe_atr(self, df):
        """ì™„ì „ížˆ ì•ˆì „í•œ ATR ìƒì„±"""
        print("ðŸ”’ ì™„ì „ížˆ ì•ˆì „í•œ ATR ìƒì„±...")

        window = 14

        # True Range ê³„ì‚°
        high_low = df['High'] - df['Low']
        high_close = np.abs(df['High'] - df['Close'].shift(1))
        low_close = np.abs(df['Low'] - df['Close'].shift(1))

        true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        df['ATR'] = true_range.rolling(window=window, min_periods=window).mean()

        # ì´ˆê°•ë ¥ ê²€ì¦ ë° ìˆ˜ì •
        # shift(1) + rolling(14) = 15ê°œ í–‰ì´ NaNì´ì–´ì•¼ í•¨
        required_nan_rows = window + 1
        df['ATR'].iloc[:required_nan_rows] = np.nan

        assert df['ATR'].iloc[:required_nan_rows].isna().all(), f"ATR ì²« {required_nan_rows}í–‰ì´ NaNì´ ì•„ë‹˜!"
        self.feature_log.append(f"ATR: ì²« {required_nan_rows}í–‰ NaN í™•ì¸")

        return df

    def create_ultra_safe_momentum(self, df):
        """ì™„ì „ížˆ ì•ˆì „í•œ ëª¨ë©˜í…€ íŠ¹ì§•"""
        print("ðŸ”’ ì™„ì „ížˆ ì•ˆì „í•œ ëª¨ë©˜í…€ íŠ¹ì§• ìƒì„±...")

        periods = [5, 10]

        for period in periods:
            mom_col = f"Price_momentum_{period}"
            df[mom_col] = df['Close'] / df['Close'].shift(period) - 1

            # ì´ˆê°•ë ¥ ê²€ì¦ ë° ìˆ˜ì •
            required_nan_rows = period + 1  # shiftë¡œ ì¸í•œ NaN
            df[mom_col].iloc[:required_nan_rows] = np.nan

            assert df[mom_col].iloc[:required_nan_rows].isna().all(), f"{mom_col} ì²« {required_nan_rows}í–‰ì´ NaNì´ ì•„ë‹˜!"
            self.feature_log.append(f"{mom_col}: ì²« {required_nan_rows}í–‰ NaN í™•ì¸")

        return df

    def create_ultra_safe_lag_features(self, df):
        """ì™„ì „ížˆ ì•ˆì „í•œ Lag íŠ¹ì§•ë“¤"""
        print("ðŸ”’ ì™„ì „ížˆ ì•ˆì „í•œ Lag íŠ¹ì§• ìƒì„±...")

        # Lagë¥¼ ì ìš©í•  ê¸°ë³¸ íŠ¹ì§•ë“¤
        base_features = ['Returns', 'RSI', 'Volatility_20', 'BB_position']
        max_lag = 3

        for base_feature in base_features:
            if base_feature not in df.columns:
                continue

            for lag in range(1, max_lag + 1):
                lag_col = f"{base_feature}_lag_{lag}"

                # ì™„ì „ížˆ ì•ˆì „í•œ lag ì ìš©
                df[lag_col] = df[base_feature].shift(lag)

                # ì´ˆê°•ë ¥ ê²€ì¦
                # ì›ë³¸ íŠ¹ì§•ì˜ ì²« ìœ íš¨ ì¸ë±ìŠ¤ + lag
                base_first_valid = df[base_feature].first_valid_index()
                if base_first_valid is not None:
                    expected_first_valid = base_first_valid + lag
                    # ì²« expected_first_validê°œ í–‰ì€ NaNì´ì–´ì•¼ í•¨
                    df[lag_col].iloc[:expected_first_valid+1] = np.nan

                # ìµœì¢… ê²€ì¦: ì²« lagê°œ í–‰ì€ ë°˜ë“œì‹œ NaN
                assert df[lag_col].iloc[:lag].isna().all(), f"{lag_col} ì²« {lag}í–‰ì´ NaNì´ ì•„ë‹˜!"

                self.feature_log.append(f"{lag_col}: ì™„ì „í•œ ì‹œê°„ì  ë¶„ë¦¬ í™•ì¸")

        return df

    def ultra_final_cleanup(self, df):
        """ì´ˆê°•ë ¥ ìµœì¢… ì •ë¦¬"""
        print("ðŸ”’ ì´ˆê°•ë ¥ ìµœì¢… ë°ì´í„° ì •ë¦¬...")

        # ì•ˆì „í•œ íŠ¹ì§•ë“¤ë§Œ ì„ íƒ
        safe_features = [
            'Date', 'Close', 'Volume', 'Returns',
            'MA_5', 'MA_10', 'MA_20', 'MA_50',
            'RSI', 'BB_position',
            'Volatility_5', 'Volatility_10', 'Volatility_20',
            'Volume_MA_10', 'Volume_MA_20', 'Volume_ratio_10', 'Volume_ratio_20',
            'ATR',
            'Price_momentum_5', 'Price_momentum_10',
            'Returns_lag_1', 'Returns_lag_2', 'Returns_lag_3',
            'RSI_lag_1', 'RSI_lag_2', 'RSI_lag_3',
            'Volatility_20_lag_1', 'Volatility_20_lag_2', 'Volatility_20_lag_3',
            'BB_position_lag_1', 'BB_position_lag_2', 'BB_position_lag_3'
        ]

        # ì¡´ìž¬í•˜ëŠ” íŠ¹ì§•ë“¤ë§Œ ì„ íƒ
        available_features = [col for col in safe_features if col in df.columns]
        df_final = df[available_features].copy()

        # ëª¨ë“  ê³„ì‚°ì´ ì™„ë£Œëœ í›„ NaN ì œê±°
        original_len = len(df_final)
        df_clean = df_final.dropna()
        removed_rows = original_len - len(df_clean)

        print(f"\\nðŸ“Š ìµœì¢… ì •ë¦¬ ê²°ê³¼:")
        print(f"   ì›ëž˜ í–‰ ìˆ˜: {original_len}")
        print(f"   ì œê±°ëœ í–‰ ìˆ˜: {removed_rows}")
        print(f"   ìµœì¢… í–‰ ìˆ˜: {len(df_clean)}")
        print(f"   ìµœì¢… íŠ¹ì§• ìˆ˜: {len(available_features)}")

        return df_clean, available_features

    def ultra_validation_check(self, df):
        """ì´ˆê°•ë ¥ ìµœì¢… ê²€ì¦"""
        print("ðŸ” ì´ˆê°•ë ¥ ìµœì¢… ê²€ì¦...")

        issues = []

        # 1. ëª¨ë“  lag íŠ¹ì§• ê²€ì¦
        for col in df.columns:
            if '_lag_' in col:
                try:
                    lag_num = int(col.split('_')[-1])
                    first_valid = df[col].first_valid_index()

                    # ì²« ë²ˆì§¸ ìœ íš¨ê°’ì´ lag_numë³´ë‹¤ ìž‘ìœ¼ë©´ ë¬¸ì œ
                    if first_valid is not None and first_valid < lag_num:
                        issues.append(f"âŒ {col}: {first_valid}ë²ˆì§¸ë¶€í„° ê°’ (ìµœì†Œ {lag_num}ë²ˆì§¸ë¶€í„°)")
                except:
                    continue

        # 2. ì´ë™í‰ê·  ê²€ì¦
        for col in df.columns:
            if col.startswith('MA_'):
                try:
                    window = int(col.split('_')[1])
                    first_valid = df[col].first_valid_index()

                    if first_valid is not None and first_valid < window - 1:
                        issues.append(f"âŒ {col}: {first_valid}ë²ˆì§¸ë¶€í„° ê°’ (ìµœì†Œ {window-1}ë²ˆì§¸ë¶€í„°)")
                except:
                    continue

        # 3. Returns ê²€ì¦
        if 'Returns' in df.columns:
            if df.index[0] in df['Returns'].index and not pd.isna(df['Returns'].iloc[0]):
                issues.append("âŒ Returns[0]ì´ NaNì´ ì•„ë‹˜")

        # 4. ê¸°íƒ€ íŠ¹ì§•ë“¤ ê²€ì¦
        special_checks = {
            'RSI': 14,
            'BB_position': 20,
            'ATR': 15,
            'Volatility_20': 21
        }

        for col, expected_start in special_checks.items():
            if col in df.columns:
                first_valid = df[col].first_valid_index()
                if first_valid is not None and first_valid < expected_start - 1:
                    issues.append(f"âŒ {col}: {first_valid}ë²ˆì§¸ë¶€í„° ê°’ (ìµœì†Œ {expected_start-1}ë²ˆì§¸ë¶€í„°)")

        # ê²°ê³¼ ì¶œë ¥
        if len(issues) == 0:
            print("   âœ… ëª¨ë“  ê²€ì¦ í†µê³¼! ì™„ì „í•œ ë°ì´í„° ë¬´ê²°ì„± ë‹¬ì„±!")
        else:
            print(f"   âŒ {len(issues)}ê°œ ì´ìŠˆ ë°œê²¬:")
            for issue in issues:
                print(f"     {issue}")

        return len(issues) == 0

    def create_ultra_leak_free_dataset(self, input_file, output_file):
        """ì™„ì „ížˆ ëˆ„ì¶œ ì—†ëŠ” ë°ì´í„°ì…‹ ìƒì„±"""
        print("ðŸ”’" + "="*60)
        print("ðŸ”’ ì´ˆê°•ë ¥ ë¬´ëˆ„ì¶œ ë°ì´í„°ì…‹ ìƒì„± ì‹œìž‘")
        print("ðŸ”’" + "="*60)

        # 1. ì›ì‹œ ê°€ê²© ë°ì´í„°ë§Œ ë¡œë“œ
        df = self.load_raw_price_data(input_file)

        # 2. ëª¨ë“  íŠ¹ì§•ì„ ì²˜ìŒë¶€í„° ì•ˆì „í•˜ê²Œ ìƒì„±
        df = self.create_ultra_safe_returns(df)
        df = self.create_ultra_safe_moving_averages(df)
        df = self.create_ultra_safe_rsi(df)
        df = self.create_ultra_safe_bollinger_bands(df)
        df = self.create_ultra_safe_volatility(df)
        df = self.create_ultra_safe_volume_features(df)
        df = self.create_ultra_safe_atr(df)
        df = self.create_ultra_safe_momentum(df)
        df = self.create_ultra_safe_lag_features(df)

        # 3. ìµœì¢… ì •ë¦¬
        df_final, features = self.ultra_final_cleanup(df)

        # 4. ì´ˆê°•ë ¥ ê²€ì¦
        validation_passed = self.ultra_validation_check(df_final)

        if validation_passed:
            print("\\nðŸŽ‰ ì™„ì „í•œ ë°ì´í„° ë¬´ê²°ì„± ë‹¬ì„±!")
        else:
            print("\\nâš ï¸ ì¼ë¶€ ê²€ì¦ ì‹¤íŒ¨ - ì¶”ê°€ ìˆ˜ì • í•„ìš”")

        # 5. íŠ¹ì§• ìƒì„± ë¡œê·¸ ì¶œë ¥
        print(f"\\nðŸ“‹ íŠ¹ì§• ìƒì„± ë¡œê·¸:")
        for log in self.feature_log:
            print(f"   âœ… {log}")

        # 6. ì €ìž¥
        df_final.to_csv(output_file, index=False)
        print(f"\\nðŸ’¾ ì´ˆê°•ë ¥ ë¬´ëˆ„ì¶œ ë°ì´í„°ì…‹ ì €ìž¥: {output_file}")
        print(f"   ðŸ“Š í¬ê¸°: {df_final.shape}")
        print(f"   ðŸ“… ê¸°ê°„: {df_final['Date'].min()} ~ {df_final['Date'].max()}")

        return df_final


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    processor = UltraLeakFreeProcessor()

    input_file = "/root/workspace/data/training/sp500_2020_2024_enhanced.csv"
    output_file = "/root/workspace/data/training/sp500_ultra_leak_free.csv"

    # ì´ˆê°•ë ¥ ë¬´ëˆ„ì¶œ ë°ì´í„°ì…‹ ìƒì„±
    df_ultra_safe = processor.create_ultra_leak_free_dataset(input_file, output_file)

    print("\\nðŸŽ‰ ì´ˆê°•ë ¥ ë¬´ëˆ„ì¶œ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
    return df_ultra_safe


if __name__ == "__main__":
    df_ultra_safe = main()