import requests
import json
import pandas as pd
from datetime import datetime, timedelta
import yfinance as yf
from textblob import TextBlob
import logging
import os
from dotenv import load_dotenv

# 환경변수 로드
load_dotenv()


class APIManager:
    def __init__(self):
        self.apis = {
            "news": {
                "primary": "yahoo_rss",
                "secondary": "free_news_api",
                "backup": "web_scraping",
            },
            "market_data": {"primary": "yfinance", "secondary": "alpha_vantage_free"},
            "sp500_data": {
                "ALPHA_VANTAGE": {
                    "base_url": "https://www.alphavantage.co/query",
                    "api_key": os.getenv("ALPHA_VANTAGE_KEY"),
                },
                "TWELVE_DATA": {
                    "base_url": "https://api.twelvedata.com",
                    "api_key": os.getenv("TWELVE_DATA_KEY"),
                },
                "FINNHUB": {
                    "base_url": "https://finnhub.io/api/v1",
                    "api_key": os.getenv("FINNHUB_KEY"),
                },
                "MARKETAUX": {
                    "base_url": "https://api.marketaux.com/v1",
                    "api_key": os.getenv("MARKETAUX_KEY"),
                },
                "POLYGON": {
                    "base_url": "https://api.polygon.io",
                    "api_key": os.getenv("POLYGON_KEY"),
                },
                "FMP": {
                    "base_url": "https://financialmodelingprep.com/api/v3",
                    "api_key": os.getenv("FMP_KEY"),
                },
                "IEX_CLOUD": {
                    "base_url": "https://cloud.iexapis.com/stable",
                    "api_key": os.getenv("IEX_CLOUD_KEY"),
                },
            },
        }
        # API keys should ideally be loaded from environment variables or a secure key management system
        # rather than hardcoded in the file.

        self.logger = logging.getLogger(__name__)

    def get_news_data_marketaux(self, ticker, limit=10):
        """Marketaux API를 통한 뉴스 데이터 수집"""
        try:
            api_key = self.apis["sp500_data"]["MARKETAUX"]["api_key"]
            url = f"{self.apis['sp500_data']['MARKETAUX']['base_url']}/news/all?symbols={ticker}&filter_entities=true&language=en&api_token={api_key}"

            response = requests.get(url)
            if not response.ok:
                self.logger.error(
                    f"Marketaux API request failed with status {response.status_code}: {response.text}"
                )
                return []

            self.logger.info(
                f"Marketaux API raw response text for {ticker}: {response.text[:500]}..."
            )  # Log raw response
            data = response.json()
            self.logger.info(
                f"Marketaux API parsed JSON data for {ticker}: {data}"
            )  # Log parsed JSON data

            if data.get("meta", {}).get("found", 0) > 0:
                news_data = []
                for article in data.get("data", [])[:limit]:
                    if not isinstance(article, dict):
                        self.logger.warning(
                            f"Marketaux API: Expected dict for article, got {type(article)}: {article}"
                        )
                        continue

                    title = article.get("title", "")
                    description = article.get("description", "")
                    full_text = f"{title} {description}"

                    blob = TextBlob(full_text)
                    sentiment = blob.sentiment.polarity

                    news_data.append(
                        {
                            "ticker": ticker,
                            "title": title,
                            "description": description,
                            "url": article.get("url", ""),
                            "publishedAt": article.get("published_at", ""),
                            "source": article.get("source", {}).get("name", "Unknown"),
                            "sentiment_label": (
                                "positive"
                                if sentiment > 0.1
                                else "negative" if sentiment < -0.1 else "neutral"
                            ),
                            "sentiment_score": abs(sentiment),
                            "polarity": sentiment,
                            "text_length": len(full_text),
                        }
                    )
                return news_data
        except json.JSONDecodeError as e:
            self.logger.error(
                f"Marketaux 뉴스 수집 실패: JSON 디코딩 오류 - {e}. 전체 응답: {response.text}"
            )
        except Exception as e:
            self.logger.error(f"Marketaux 뉴스 수집 실패: {e}")
        return []

    def get_news_data_yahoo_rss(self, ticker, limit=10):
        """Yahoo Finance RSS 뉴스 데이터 수집"""
        try:
            import feedparser

            # Yahoo Finance RSS URL
            rss_url = f"https://feeds.finance.yahoo.com/rss/2.0/headline?s={ticker}&region=US&lang=en-US"

            feed = feedparser.parse(rss_url)
            news_data = []

            for entry in feed.entries[:limit]:
                # 감성 분석 (TextBlob 사용)
                title = entry.title
                summary = entry.summary if hasattr(entry, "summary") else ""
                full_text = f"{title} {summary}"

                blob = TextBlob(full_text)
                sentiment = blob.sentiment.polarity

                # 감성 라벨 변환
                if sentiment > 0.1:
                    sentiment_label = "positive"
                elif sentiment < -0.1:
                    sentiment_label = "negative"
                else:
                    sentiment_label = "neutral"

                news_data.append(
                    {
                        "ticker": ticker,
                        "title": title,
                        "description": summary,
                        "url": entry.link,
                        "sentiment_label": sentiment_label,
                        "sentiment_score": abs(sentiment),
                        "polarity": sentiment,
                        "text_length": len(full_text),
                    }
                )

            return news_data

        except Exception as e:
            self.logger.error(f"Yahoo RSS 뉴스 수집 실패: {e}")
            return []

    def get_news_data_free_api(self, ticker, limit=10):
        """무료 뉴스 API 사용"""
        try:
            # NewsData.io 무료 API (일일 200회 제한)
            url = f"https://newsdata.io/api/1/news?apikey=FREE&q={ticker}&language=en&category=business"

            response = requests.get(url)
            data = response.json()

            if data.get("status") == "success":
                news_data = []

                for article in data.get("results", [])[:limit]:
                    # 감성 분석
                    title = article.get("title", "")
                    description = article.get("description", "")
                    full_text = f"{title} {description}"

                    blob = TextBlob(full_text)
                    sentiment = blob.sentiment.polarity

                    news_data.append(
                        {
                            "ticker": ticker,
                            "title": title,
                            "description": description,
                            "url": article.get("link", ""),
                            "publishedAt": article.get("pubDate", ""),
                            "source": article.get("source_id", "Unknown"),
                            "sentiment_label": (
                                "positive"
                                if sentiment > 0.1
                                else "negative" if sentiment < -0.1 else "neutral"
                            ),
                            "sentiment_score": abs(sentiment),
                            "polarity": sentiment,
                            "text_length": len(full_text),
                        }
                    )

                return news_data

        except Exception as e:
            self.logger.error(f"무료 뉴스 API 수집 실패: {e}")

        return []

    def get_news_data_web_scraping(self, ticker, limit=5):
        """웹 스크래핑 백업 방법"""
        try:
            from bs4 import BeautifulSoup

            # Google News 검색
            url = f"https://news.google.com/search?q={ticker}&hl=en-US&gl=US&ceid=US:en"

            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }

            response = requests.get(url, headers=headers)
            soup = BeautifulSoup(response.content, "html.parser")

            news_data = []
            articles = soup.find_all("article")[:limit]

            for article in articles:
                try:
                    title_elem = article.find("h3")
                    title = title_elem.get_text() if title_elem else "No title"

                    # 감성 분석
                    blob = TextBlob(title)
                    sentiment = blob.sentiment.polarity

                    news_data.append(
                        {
                            "ticker": ticker,
                            "title": title,
                            "description": title,  # 제목만 사용
                            "url": "",
                            "publishedAt": datetime.now().isoformat(),
                            "source": "Google News",
                            "sentiment_label": (
                                "positive"
                                if sentiment > 0.1
                                else "negative" if sentiment < -0.1 else "neutral"
                            ),
                            "sentiment_score": abs(sentiment),
                            "polarity": sentiment,
                            "text_length": len(title),
                        }
                    )

                except Exception:
                    continue

            return news_data

        except Exception as e:
            self.logger.error(f"웹 스크래핑 실패: {e}")
            return []

    def get_market_data_yfinance(self, ticker, period="1d", interval="1m"):
        """YFinance를 통한 시장 데이터 수집"""
        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period=period, interval=interval)

            if hist.empty:
                return None

            return hist

        except Exception as e:
            self.logger.error(f"YFinance 데이터 수집 실패: {e}")
            return None

    def get_market_data_alpha_vantage_free(self, ticker):
        """Alpha Vantage 무료 API"""
        try:
            # 무료 API 키 (제한적)
            api_key = "demo"  # 실제로는 회원가입 필요
            url = f"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol={ticker}&apikey={api_key}"

            response = requests.get(url)
            data = response.json()

            if "Global Quote" in data:
                quote = data["Global Quote"]

                # DataFrame 형태로 변환
                df_data = {
                    "Open": [float(quote["02. open"])],
                    "High": [float(quote["03. high"])],
                    "Low": [float(quote["04. low"])],
                    "Close": [float(quote["05. price"])],
                    "Volume": [int(quote["06. volume"])],
                }

                df = pd.DataFrame(df_data)
                df.index = [datetime.now()]

                return df

        except Exception as e:
            self.logger.error(f"Alpha Vantage 데이터 수집 실패: {e}")

        return None

    def get_news_data(self, ticker, limit=10):
        """뉴스 데이터 수집 (폴백 방식)"""
        # 1차: Marketaux API
        news_data = self.get_news_data_marketaux(ticker, limit)

        if not news_data:
            # 2차: Yahoo RSS
            news_data = self.get_news_data_yahoo_rss(ticker, limit)

        if not news_data:
            # 3차: 무료 API
            news_data = self.get_news_data_free_api(ticker, limit)

        if not news_data:
            # 4차: 웹 스크래핑
            news_data = self.get_news_data_web_scraping(ticker, limit)

        return news_data

    def get_market_data_polygon(
        self, ticker, multiplier=1, timespan="day", from_date=None, to_date=None
    ):
        """Polygon.io API를 통한 시장 데이터 수집"""
        try:
            api_key = self.apis["sp500_data"]["POLYGON"]["api_key"]
            base_url = self.apis["sp500_data"]["POLYGON"]["base_url"]

            if from_date is None:
                from_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
            if to_date is None:
                to_date = datetime.now().strftime("%Y-%m-%d")

            url = f"{base_url}/v2/aggs/ticker/{ticker}/range/{multiplier}/{timespan}/{from_date}/{to_date}?adjusted=true&sort=asc&limit=50000&apiKey={api_key}"

            self.logger.info(
                f"Polygon.io API request URL for {ticker}: {url}"
            )  # Log Polygon.io URL
            response = requests.get(url)
            if not response.ok:
                self.logger.error(
                    f"Polygon.io API request failed with status {response.status_code}: {response.text}"
                )
                return None

            data = response.json()
            self.logger.info(
                f"Polygon.io API parsed JSON data for {ticker}: {data}"
            )  # Log Polygon.io JSON data

            if data.get("status") == "OK" and data.get("resultsCount", 0) > 0:
                df_data = []
                for result in data["results"]:
                    df_data.append(
                        {
                            "Date": datetime.fromtimestamp(result["t"] / 1000).strftime(
                                "%Y-%m-%d %H:%M:%S"
                            ),
                            "Open": result["o"],
                            "High": result["h"],
                            "Low": result["l"],
                            "Close": result["c"],
                            "Volume": result["v"],
                        }
                    )
                df = pd.DataFrame(df_data)
                df["Date"] = pd.to_datetime(df["Date"])
                df.reset_index(inplace=True)  # 인덱스를 컬럼으로 변환
                return df
        except Exception as e:
            self.logger.error(f"Polygon.io 데이터 수집 실패: {e}")
        return None

    def get_market_data(self, ticker, period="1d", interval="1m"):
        """시장 데이터 수집 (폴백 방식)"""
        # 1차: YFinance
        data = self.get_market_data_yfinance(ticker, period, interval)

        if data is None:
            # 2차: Polygon.io
            data = self.get_market_data_polygon(ticker)

        if data is None:
            # 3차: Alpha Vantage
            data = self.get_market_data_alpha_vantage_free(ticker)

        return data


# 의존성 설치를 위한 추가 요구사항
additional_requirements = """
feedparser>=6.0.0
beautifulsoup4>=4.11.0
requests>=2.28.0
"""

if __name__ == "__main__":
    api_manager = APIManager()

    # 테스트
    print("API 테스트 시작...")

    # 뉴스 데이터 테스트
    news = api_manager.get_news_data("AAPL", 5)
    print(f"뉴스 데이터: {len(news)}개")

    # 시장 데이터 테스트
    market = api_manager.get_market_data("AAPL")
    print(f"시장 데이터: {market is not None}")

    print("API 테스트 완료")
