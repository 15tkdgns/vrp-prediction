"""
ê²½ì‚¬í•˜ê°•ë²• í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œìŠ¤í…œ v4
ê°œì„ ì‚¬í•­: V2 ê¸°ë°˜ìœ¼ë¡œ ë” ì •êµí•œ íƒìƒ‰ ë° ì¶”ê°€ íŠ¹ì„±

V2 ì„±ê³µ ìš”ì¸:
- 31ê°œ íŠ¹ì„± ì‚¬ìš©
- alpha = 19.5 ë°œê²¬
- RÂ² = 0.3256 ë‹¬ì„±

V4 ê°œì„ ì‚¬í•­:
- V2 ê¸°ë°˜ìœ¼ë¡œ ë” ë§ì€ íŠ¹ì„± ì¶”ê°€ (35ê°œ+)
- ë” ì •êµí•œ alpha íƒìƒ‰ ë²”ìœ„
- ì•™ìƒë¸” íŠ¹ì„± ì¶”ê°€
- ë” ê¸´ patienceë¡œ ê¸€ë¡œë²Œ ìµœì í•´ íƒìƒ‰
"""

import numpy as np
import pandas as pd
import yfinance as yf
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
import json
import time
from datetime import datetime
import logging
import warnings
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/workspace/data/raw/gradient_optimization_v4.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class PurgedKFoldPyTorch:
    """PyTorch ê¸°ë°˜ Purged K-Fold Cross-Validation"""

    def __init__(self, n_splits=5, purge_length=5, embargo_length=5):
        self.n_splits = n_splits
        self.purge_length = purge_length
        self.embargo_length = embargo_length

    def split(self, X):
        """ì‹œê³„ì—´ ë°ì´í„°ë¥¼ purged ë°©ì‹ìœ¼ë¡œ ë¶„í• """
        n_samples = len(X)
        indices = np.arange(n_samples)

        test_size = n_samples // self.n_splits
        splits = []

        for i in range(self.n_splits):
            test_start = i * test_size
            test_end = min((i + 1) * test_size, n_samples)
            test_indices = indices[test_start:test_end]

            purge_start = test_end
            purge_end = min(test_end + self.purge_length, n_samples)
            embargo_end = min(purge_end + self.embargo_length, n_samples)

            train_indices = np.concatenate([
                indices[:test_start],
                indices[embargo_end:]
            ])

            if len(train_indices) > 0 and len(test_indices) > 0:
                splits.append((train_indices, test_indices))

        return splits

class DifferentiableRidge(nn.Module):
    """ë¯¸ë¶„ê°€ëŠ¥í•œ Ridge Regression êµ¬í˜„"""

    def __init__(self, n_features):
        super().__init__()
        self.weights = nn.Parameter(torch.randn(n_features, 1) * 0.01)
        self.bias = nn.Parameter(torch.zeros(1))
        # log(alpha)ë¡œ íŒŒë¼ë¯¸í„°í™”
        self.log_alpha = nn.Parameter(torch.tensor(np.log(19.5)))  # V2 ìµœì ê°’ì—ì„œ ì‹œì‘

    def forward(self, X):
        return X @ self.weights + self.bias

    def get_alpha(self):
        return torch.exp(self.log_alpha)

    def ridge_loss(self, X, y):
        """Ridge regression ì†ì‹¤í•¨ìˆ˜"""
        predictions = self.forward(X)
        mse_loss = torch.mean((predictions - y) ** 2)
        l2_penalty = self.get_alpha() * torch.sum(self.weights ** 2)
        return mse_loss + l2_penalty

class GradientHyperparameterOptimizerV4:
    """ê²½ì‚¬í•˜ê°•ë²• ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ê¸° v4"""

    def __init__(self, learning_rate=0.02, max_iterations=300, patience=75):
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.patience = patience
        self.cv = PurgedKFoldPyTorch()
        self.scaler = StandardScaler()
        self.history = []

    def load_spy_data(self):
        """SPY ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        logger.info("ğŸ“Š SPY ë°ì´í„° ë¡œë”© ì¤‘...")

        spy = yf.Ticker("SPY")
        data = spy.history(start="2015-01-01", end="2024-12-31")
        data['returns'] = np.log(data['Close'] / data['Close'].shift(1))
        data = data.dropna()

        logger.info(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(data)}ê°œ ê´€ì¸¡ì¹˜")
        return data

    def create_enhanced_features(self, data):
        """í™•ì¥ëœ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (35ê°œ+ íŠ¹ì„±)"""
        logger.info("ğŸ”§ í™•ì¥ëœ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (35ê°œ+ íŠ¹ì„±)...")

        returns = data['returns']
        features = pd.DataFrame(index=data.index)

        # 1. ê¸°ë³¸ ë³€ë™ì„± íŠ¹ì„± (â‰¤ t)
        for window in [3, 5, 10, 15, 20, 30, 50]:
            features[f'volatility_{window}'] = returns.rolling(window).std()

        # 2. ê³ ì°¨ ëª¨ë©˜íŠ¸ (â‰¤ t)
        for window in [5, 10, 15, 20]:
            features[f'skew_{window}'] = returns.rolling(window).skew()
            features[f'kurt_{window}'] = returns.rolling(window).kurt()

        # 3. ë˜ê·¸ íŠ¹ì„± (ê³¼ê±°ë§Œ)
        for lag in [1, 2, 3, 5, 7]:
            features[f'return_lag_{lag}'] = returns.shift(lag)
            features[f'vol_lag_{lag}'] = features['volatility_5'].shift(lag)

        # 4. ë³€ë™ì„± ë¹„ìœ¨ (ê³¼ê±°ë§Œ)
        features['vol_ratio_5_20'] = features['volatility_5'] / (features['volatility_20'] + 1e-8)
        features['vol_ratio_10_50'] = features['volatility_10'] / (features['volatility_50'] + 1e-8)
        features['vol_ratio_3_15'] = features['volatility_3'] / (features['volatility_15'] + 1e-8)

        # 5. í†µê³„ì  íŠ¹ì„± (ê³¼ê±°ë§Œ)
        for window in [10, 20, 30]:
            ma = returns.rolling(window).mean()
            std = returns.rolling(window).std()
            features[f'zscore_{window}'] = (returns - ma) / (std + 1e-8)
            features[f'sharpe_{window}'] = ma / (std + 1e-8)

        # 6. ëª¨ë©˜í…€ ë° ì´ë™í‰ê·  (ê³¼ê±°ë§Œ)
        for window in [3, 5, 10, 15, 20]:
            features[f'momentum_{window}'] = returns.rolling(window).sum()
            features[f'sma_{window}'] = returns.rolling(window).mean()

        # 7. ë¶„ìœ„ìˆ˜ íŠ¹ì„± (ê³¼ê±°ë§Œ)
        for window in [10, 20, 30]:
            features[f'q25_{window}'] = returns.rolling(window).quantile(0.25)
            features[f'q75_{window}'] = returns.rolling(window).quantile(0.75)
            features[f'iqr_{window}'] = features[f'q75_{window}'] - features[f'q25_{window}']

        # 8. ê·¹ê°’ ë° ë“œë¡œìš°ë‹¤ìš´ (ê³¼ê±°ë§Œ)
        for window in [5, 10, 20]:
            features[f'max_drawdown_{window}'] = returns.rolling(window).apply(
                lambda x: (x.cumsum() - x.cumsum().cummax()).min()
            )
            features[f'max_return_{window}'] = returns.rolling(window).max()
            features[f'min_return_{window}'] = returns.rolling(window).min()

        # 9. ë³€ë™ì„± ì²´ì œ ê°ì§€ (ê³¼ê±°ë§Œ)
        short_vol = features['volatility_5']
        long_vol = features['volatility_20']
        features['vol_regime'] = (short_vol > long_vol).astype(int)
        features['vol_expansion'] = (short_vol / long_vol > 1.5).astype(int)

        # 10. ìƒí˜¸ì‘ìš© íŠ¹ì„± (ê³ ê¸‰)
        features['vol_momentum'] = features['volatility_10'] * features['momentum_10']
        features['return_vol_interaction'] = features['return_lag_1'] * features['volatility_5']

        # íƒ€ê²Ÿ: 5ì¼ í›„ ë³€ë™ì„± (â‰¥ t+1)
        target = []
        for i in range(len(returns)):
            if i + 5 < len(returns):
                future_vol = returns.iloc[i+1:i+6].std()
                target.append(future_vol)
            else:
                target.append(np.nan)

        features['target_vol_5d'] = target

        # NaN ì œê±°
        features = features.dropna()

        X = features.drop('target_vol_5d', axis=1)
        y = features['target_vol_5d']

        logger.info(f"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: {X.shape[1]}ê°œ íŠ¹ì„±, {len(X)}ê°œ ìƒ˜í”Œ")
        return X, y

    def objective_function(self, X, y, log_alpha_value):
        """ëª©ì í•¨ìˆ˜: Purged K-Fold CVì˜ ìŒì˜ RÂ² ìŠ¤ì½”ì–´"""
        X_tensor = torch.FloatTensor(X)
        y_tensor = torch.FloatTensor(y.values).reshape(-1, 1)

        cv_scores = []
        splits = self.cv.split(X)

        for train_idx, test_idx in splits:
            if len(train_idx) < 20 or len(test_idx) < 10:  # ë” ì—„ê²©í•œ ìµœì†Œ ìš”êµ¬ì‚¬í•­
                continue

            X_train, X_test = X_tensor[train_idx], X_tensor[test_idx]
            y_train, y_test = y_tensor[train_idx], y_tensor[test_idx]

            # Ridge ëª¨ë¸ ìƒì„±
            model = DifferentiableRidge(X.shape[1])
            model.log_alpha.data = torch.tensor(log_alpha_value)

            # ë” ê°•ë ¥í•œ ìµœì í™”
            optimizer = optim.LBFGS([model.weights, model.bias], lr=0.1, max_iter=20)

            def closure():
                optimizer.zero_grad()
                loss = model.ridge_loss(X_train, y_train)
                loss.backward()
                return loss

            # ì¶©ë¶„í•œ í›ˆë ¨
            for _ in range(100):  # V2: 50íšŒ â†’ V4: 100íšŒ
                optimizer.step(closure)

            # ì˜ˆì¸¡ ë° í‰ê°€
            with torch.no_grad():
                predictions = model.forward(X_test).numpy().flatten()
                r2 = r2_score(y_test.numpy().flatten(), predictions)
                cv_scores.append(r2)

        mean_r2 = np.mean(cv_scores) if cv_scores else -1.0
        return -mean_r2

    def optimize(self):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤í–‰"""
        logger.info("ğŸš€ ê²½ì‚¬í•˜ê°•ë²• ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” v4 ì‹œì‘")
        logger.info("ğŸ¯ v4 ëª©í‘œ: RÂ² > 0.33 (V2 ëŒ€ë¹„ ì¶”ê°€ ê°œì„ )")

        # ë°ì´í„° ì¤€ë¹„
        data = self.load_spy_data()
        X, y = self.create_enhanced_features(data)

        # í‘œì¤€í™”
        X_scaled = self.scaler.fit_transform(X)

        # V2 ìµœì ê°’ì—ì„œ ì‹œì‘
        log_alpha = torch.tensor(np.log(19.5), requires_grad=True)
        optimizer = optim.Adam([log_alpha], lr=self.learning_rate)

        best_score = float('inf')
        best_alpha = 19.5
        patience_counter = 0

        logger.info(f"ğŸ“ˆ ìµœì í™” ì‹œì‘: ì´ˆê¸° alpha = {torch.exp(log_alpha).item():.4f}")
        logger.info(f"ğŸ“Š V2 ì„±ëŠ¥ ê¸°ì¤€: RÂ² = 0.3256")

        for iteration in range(self.max_iterations):
            start_time = time.time()

            # ëª©ì í•¨ìˆ˜ ê³„ì‚°
            score = self.objective_function(X_scaled, y, log_alpha.item())

            # ê²½ì‚¬ ê³„ì‚° (ìˆ˜ì¹˜ ë¯¸ë¶„)
            eps = 1e-7  # ë” ì‘ì€ eps
            score_plus = self.objective_function(X_scaled, y, log_alpha.item() + eps)
            score_minus = self.objective_function(X_scaled, y, log_alpha.item() - eps)
            gradient = (score_plus - score_minus) / (2 * eps)

            # ì ì‘ì  í•™ìŠµë¥ 
            if patience_counter > 20:
                current_lr = self.learning_rate * 0.5
            elif patience_counter > 10:
                current_lr = self.learning_rate * 0.8
            else:
                current_lr = self.learning_rate

            # ê²½ì‚¬í•˜ê°•ë²• ì—…ë°ì´íŠ¸
            with torch.no_grad():
                log_alpha -= current_lr * gradient
                # V2 ê²°ê³¼ ê¸°ì¤€ ì œí•œëœ íƒìƒ‰ (5 ~ 100)
                log_alpha.clamp_(np.log(5.0), np.log(100.0))

            current_alpha = torch.exp(log_alpha).item()
            elapsed_time = time.time() - start_time

            # ìµœì ê°’ ì—…ë°ì´íŠ¸
            if score < best_score:
                best_score = score
                best_alpha = current_alpha
                patience_counter = 0

                current_r2 = -score
                if current_r2 > 0.33:
                    logger.info(f"ğŸš€ V4 ëª©í‘œ ë‹¬ì„±! RÂ² = {current_r2:.6f} > 0.33")
            else:
                patience_counter += 1

            # ë¡œê¹…
            if iteration % 5 == 0:
                current_r2 = -score
                best_r2 = -best_score
                logger.info(
                    f"ë°˜ë³µ {iteration:4d}: Î±={current_alpha:.6f}, "
                    f"RÂ²={current_r2:.6f}, ìµœì RÂ²={best_r2:.6f}, "
                    f"lr={current_lr:.4f}, ì‹œê°„={elapsed_time:.2f}s"
                )

            # íˆìŠ¤í† ë¦¬ ì €ì¥
            self.history.append({
                'iteration': iteration,
                'alpha': current_alpha,
                'score': score,
                'best_score': best_score,
                'best_alpha': best_alpha,
                'learning_rate': current_lr,
                'timestamp': datetime.now().isoformat()
            })

            # ì¡°ê¸° ì¢…ë£Œ
            if patience_counter >= self.patience:
                logger.info(f"ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ: {self.patience}ë²ˆ ì—°ì† ê°œì„  ì—†ìŒ")
                break

        # ìµœì¢… ê²°ê³¼
        final_r2 = -best_score
        logger.info(f"âœ… v4 ìµœì í™” ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ìµœì  alpha: {best_alpha:.6f}")
        logger.info(f"ğŸ“Š ìµœì  RÂ²: {final_r2:.6f}")

        return best_alpha, final_r2, self.history

    def save_results(self, best_alpha, best_score, history):
        """ê²°ê³¼ ì €ì¥"""
        results = {
            'version': 'v4',
            'improvements': [
                'í™•ì¥ëœ 35ê°œ+ íŠ¹ì„± ì‚¬ìš©',
                'V2 ìµœì ê°’(Î±=19.5)ì—ì„œ ì‹œì‘',
                'ë” ê°•ë ¥í•œ ëª¨ë¸ í›ˆë ¨ (100íšŒ)',
                'ì ì‘ì  í•™ìŠµë¥  ì ìš©',
                'ë” ê¸´ patience (75íšŒ)'
            ],
            'optimization_completed': datetime.now().isoformat(),
            'best_hyperparameters': {
                'alpha': float(best_alpha),
                'model_type': 'Ridge'
            },
            'best_performance': {
                'r2_score': float(best_score),
                'method': 'Purged_K_Fold_CV'
            },
            'baseline_comparison': {
                'original_baseline_r2': 0.3113,
                'v2_baseline_r2': 0.3256,
                'v4_optimized_r2': float(best_score),
                'improvement_from_original': float(best_score - 0.3113),
                'improvement_from_v2': float(best_score - 0.3256),
                'improvement_percent': float(((best_score - 0.3113) / 0.3113) * 100)
            },
            'optimization_history': history,
            'configuration': {
                'learning_rate': self.learning_rate,
                'max_iterations': self.max_iterations,
                'patience': self.patience
            }
        }

        # ê²°ê³¼ ì €ì¥
        save_path = '/root/workspace/data/raw/gradient_optimization_results_v4.json'
        with open(save_path, 'w') as f:
            json.dump(results, f, indent=2)

        logger.info(f"ğŸ’¾ v4 ê²°ê³¼ ì €ì¥ë¨: {save_path}")
        return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸ¯ ê²½ì‚¬í•˜ê°•ë²• í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” v4 ì‹œì‘")
    logger.info("ğŸ”§ v4 ê°œì„ ì‚¬í•­: í™•ì¥ëœ íŠ¹ì„± + V2 ê¸°ë°˜ ì‹œì‘")

    optimizer = GradientHyperparameterOptimizerV4(
        learning_rate=0.02,
        max_iterations=300,
        patience=75
    )

    try:
        best_alpha, best_score, history = optimizer.optimize()
        results = optimizer.save_results(best_alpha, best_score, history)

        # ì„±ëŠ¥ ë¹„êµ
        v2_r2 = 0.3256
        improvement = best_score - v2_r2
        improvement_pct = (improvement / v2_r2) * 100

        logger.info("ğŸ“ˆ v4 ì„±ëŠ¥ ë¹„êµ:")
        logger.info(f"   V2 ëª¨ë¸: RÂ² = {v2_r2:.4f}")
        logger.info(f"   V4 ëª¨ë¸: RÂ² = {best_score:.4f}")
        logger.info(f"   V2 ëŒ€ë¹„: {improvement:+.4f} ({improvement_pct:+.2f}%)")

        if best_score > v2_r2:
            logger.info("ğŸ‰ v4 ì„±ê³µ: V2 ì„±ëŠ¥ ì´ˆê³¼!")
        else:
            logger.info("âš ï¸ v4 ì•„ì‰¬ì›€: V5ë¡œ ì¶”ê°€ ê°œì„ ")

        return results

    except Exception as e:
        logger.error(f"âŒ v4 ìµœì í™” ì‹¤íŒ¨: {str(e)}")
        raise

if __name__ == "__main__":
    main()