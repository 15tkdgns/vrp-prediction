"""
V6 ê³¼ì í•© ë°©ì§€ ê°•í™” ëª¨ë¸
V2ì—ì„œ ë°œê²¬ëœ ì‹¬ê°í•œ ê³¼ì í•© ë¬¸ì œ(ìœ„í—˜ë„ 83.3%) í•´ê²°

V6 í•µì‹¬ ê°œì„ ì‚¬í•­:
1. ê°•í•œ ì •ê·œí™”: alpha ë²”ìœ„ 50-500 (V2: 19.5)
2. íŠ¹ì„± ìˆ˜ ëŒ€í­ ê°ì†Œ: 15ê°œ í•µì‹¬ íŠ¹ì„± (V2: 30ê°œ)
3. ë” ì—„ê²©í•œ ì‹œê°„ì  ë¶„ë¦¬: purge=10, embargo=10 (V2: 5, 5)
4. ì¡°ê¸° ì¢…ë£Œ ê°•í™”: patience=25 (V2: 75)
5. ë” ë³´ìˆ˜ì ì¸ ê²€ì¦

ëª©í‘œ: ê³¼ì í•© ìœ„í—˜ë„ < 20%, ì•ˆì •ì ì¸ ì¼ë°˜í™” ì„±ëŠ¥
"""

import numpy as np
import pandas as pd
import yfinance as yf
import json
import time
from datetime import datetime
import logging
import warnings
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score

warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/workspace/data/raw/anti_overfitting_v6.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class StrictPurgedKFold:
    """ë” ì—„ê²©í•œ Purged K-Fold (ê³¼ì í•© ë°©ì§€ ê°•í™”)"""

    def __init__(self, n_splits=5, purge_length=10, embargo_length=10):
        self.n_splits = n_splits
        self.purge_length = purge_length  # V2: 5 â†’ V6: 10
        self.embargo_length = embargo_length  # V2: 5 â†’ V6: 10

    def split(self, X, y=None):
        n_samples = len(X)
        indices = np.arange(n_samples)
        test_size = n_samples // self.n_splits
        splits = []

        for i in range(self.n_splits):
            test_start = i * test_size
            test_end = min((i + 1) * test_size, n_samples)
            test_indices = indices[test_start:test_end]

            # ë” ê¸´ ê²©ë¦¬ êµ¬ê°„
            purge_start = test_end
            purge_end = min(test_end + self.purge_length, n_samples)
            embargo_end = min(purge_end + self.embargo_length, n_samples)

            train_indices = np.concatenate([
                indices[:test_start],
                indices[embargo_end:]
            ])

            if len(train_indices) >= 50 and len(test_indices) >= 20:  # ë” ì—„ê²©í•œ ìµœì†Œ í¬ê¸°
                splits.append((train_indices, test_indices))

        return splits

class ConservativeRidge(nn.Module):
    """ê³¼ì í•© ë°©ì§€ ê°•í™” Ridge ëª¨ë¸"""

    def __init__(self, n_features, alpha):
        super().__init__()
        self.linear = nn.Linear(n_features, 1, bias=False)
        self.alpha = alpha

        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”: ë” ì‘ì€ ê°’ìœ¼ë¡œ ì‹œì‘ (ê³¼ì í•© ë°©ì§€)
        nn.init.normal_(self.linear.weight, mean=0.0, std=0.01)

    def forward(self, X):
        return self.linear(X).squeeze()

    def loss(self, X, y):
        pred = self.forward(X)
        mse_loss = F.mse_loss(pred, y)
        # ë” ê°•í•œ L2 ì •ê·œí™”
        l2_penalty = self.alpha * torch.sum(self.linear.weight ** 2)
        return mse_loss + l2_penalty

class AntiOverfittingOptimizerV6:
    """V6 ê³¼ì í•© ë°©ì§€ ê°•í™” ìµœì í™”ê¸°"""

    def __init__(self):
        self.cv = StrictPurgedKFold()
        self.scaler = StandardScaler()
        self.history = []
        self.best_model = None
        self.best_alpha = None
        self.best_score = -float('inf')

    def load_spy_data(self):
        """SPY ë°ì´í„° ë¡œë“œ"""
        logger.info("ğŸ“Š SPY ë°ì´í„° ë¡œë”©...")

        spy = yf.Ticker("SPY")
        data = spy.history(start="2015-01-01", end="2024-12-31")
        data['returns'] = np.log(data['Close'] / data['Close'].shift(1))
        data = data.dropna()

        logger.info(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(data)}ê°œ ê´€ì¸¡ì¹˜")
        return data

    def create_core_features_only(self, data):
        """í•µì‹¬ íŠ¹ì„±ë§Œ 15ê°œ ì„ ë³„ (ê³¼ì í•© ë°©ì§€)"""
        logger.info("ğŸ”§ V6 í•µì‹¬ íŠ¹ì„± 15ê°œ ì„ ë³„...")

        returns = data['returns']
        features = pd.DataFrame(index=data.index)

        # 1. í•µì‹¬ ë³€ë™ì„± íŠ¹ì„± (5ê°œ) - ê°€ì¥ ì¤‘ìš”í•œ ê²ƒë§Œ
        features['vol_5'] = returns.rolling(5).std()
        features['vol_10'] = returns.rolling(10).std()
        features['vol_20'] = returns.rolling(20).std()
        features['vol_30'] = returns.rolling(30).std()
        features['vol_50'] = returns.rolling(50).std()

        # 2. í•µì‹¬ ë˜ê·¸ íŠ¹ì„± (3ê°œ) - ë‹¨ê¸°ë§Œ
        features['return_lag_1'] = returns.shift(1)
        features['return_lag_2'] = returns.shift(2)
        features['return_lag_3'] = returns.shift(3)

        # 3. í•µì‹¬ í†µê³„ íŠ¹ì„± (3ê°œ)
        ma_10 = returns.rolling(10).mean()
        std_10 = returns.rolling(10).std()
        features['zscore_10'] = (returns - ma_10) / (std_10 + 1e-8)
        features['sharpe_10'] = (ma_10 * np.sqrt(252)) / (std_10 + 1e-8)
        features['skew_10'] = returns.rolling(10).skew()

        # 4. í•µì‹¬ ë³€ë™ì„± ë¹„ìœ¨ (2ê°œ)
        features['vol_5_20_ratio'] = features['vol_5'] / (features['vol_20'] + 1e-8)
        features['vol_10_30_ratio'] = features['vol_10'] / (features['vol_30'] + 1e-8)

        # 5. í•µì‹¬ ì²´ì œ ë³€ìˆ˜ (2ê°œ)
        features['vol_regime_short'] = (features['vol_5'] > features['vol_20']).astype(float)
        features['vol_expansion'] = features['vol_5'] / (features['vol_50'] + 1e-8)

        # íƒ€ê²Ÿ: 5ì¼ í›„ ë³€ë™ì„±
        target = []
        for i in range(len(returns)):
            if i + 5 < len(returns):
                future_vol = returns.iloc[i+1:i+6].std()
                target.append(future_vol)
            else:
                target.append(np.nan)

        features['target_vol_5d'] = target
        features = features.dropna()

        X = features.drop('target_vol_5d', axis=1)
        y = features['target_vol_5d']

        logger.info(f"âœ… V6 í•µì‹¬ íŠ¹ì„±: {X.shape[1]}ê°œ, ìƒ˜í”Œ: {len(X)}ê°œ (ê³¼ì í•© ë°©ì§€ ì„¤ê³„)")
        return X, y

    def objective_function(self, alpha_tensor):
        """PyTorch ê¸°ë°˜ ëª©ì í•¨ìˆ˜ (ê°•í™”ëœ ì •ê·œí™”)"""
        alpha = float(alpha_tensor.item())

        if alpha < 50:  # V6: ìµœì†Œ alpha = 50 (V2: 0.1)
            return torch.tensor(-10.0)

        model = ConservativeRidge(self.X_scaled.shape[1], alpha)
        optimizer = optim.Adam(model.parameters(), lr=0.01)  # ë” ì‘ì€ í•™ìŠµë¥ 

        # êµì°¨ê²€ì¦
        cv_scores = []
        splits = list(self.cv.split(self.X_scaled))

        for train_idx, val_idx in splits:
            if len(train_idx) < 50 or len(val_idx) < 20:
                continue

            X_train = torch.FloatTensor(self.X_scaled[train_idx])
            y_train = torch.FloatTensor(self.y.iloc[train_idx].values)
            X_val = torch.FloatTensor(self.X_scaled[val_idx])
            y_val = torch.FloatTensor(self.y.iloc[val_idx].values)

            # ëª¨ë¸ í›ˆë ¨ (ë” ì ì€ ì—í¬í¬ë¡œ ê³¼ì í•© ë°©ì§€)
            model.train()
            for epoch in range(20):  # V2: 50 â†’ V6: 20
                optimizer.zero_grad()
                loss = model.loss(X_train, y_train)
                loss.backward()
                optimizer.step()

            # ê²€ì¦
            model.eval()
            with torch.no_grad():
                val_pred = model(X_val)
                r2 = r2_score(y_val.numpy(), val_pred.numpy())
                cv_scores.append(r2)

        mean_r2 = np.mean(cv_scores) if cv_scores else -1.0
        return torch.tensor(-mean_r2)  # ìµœì†Œí™” ë¬¸ì œ

    def optimize_conservative(self):
        """ë³´ìˆ˜ì  ìµœì í™” (ê³¼ì í•© ë°©ì§€ ê°•í™”)"""
        logger.info("ğŸš€ V6 ê³¼ì í•© ë°©ì§€ ê°•í™” ìµœì í™” ì‹œì‘")
        logger.info("ğŸ¯ ëª©í‘œ: ê³¼ì í•© ìœ„í—˜ë„ < 20%, ì•ˆì •ì  ì¼ë°˜í™” ì„±ëŠ¥")

        # ë°ì´í„° ì¤€ë¹„
        data = self.load_spy_data()
        X, y = self.create_core_features_only(data)
        self.X_scaled = self.scaler.fit_transform(X)
        self.y = y

        logger.info("ğŸ“ˆ ë³´ìˆ˜ì  ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹œì‘ (alpha: 50-500)")

        # ë³´ìˆ˜ì  alpha íƒìƒ‰ (ê°•í•œ ì •ê·œí™” ë²”ìœ„)
        alpha_candidates = [50, 75, 100, 150, 200, 250, 300, 400, 500]

        best_alpha = None
        best_score = -float('inf')
        iteration = 0

        for alpha in alpha_candidates:
            iteration += 1
            start_time = time.time()

            # ëª©ì í•¨ìˆ˜ í‰ê°€
            alpha_tensor = torch.tensor(float(alpha), requires_grad=False)
            score_tensor = self.objective_function(alpha_tensor)
            score = -float(score_tensor.item())  # RÂ² ë³µì›
            elapsed = time.time() - start_time

            # ìµœì ê°’ ì—…ë°ì´íŠ¸
            if score > best_score:
                best_score = score
                best_alpha = alpha

            # ê¸°ë¡ ì €ì¥
            self.history.append({
                'iteration': iteration,
                'alpha': alpha,
                'r2_score': score,
                'best_score': best_score,
                'best_alpha': best_alpha,
                'timestamp': datetime.now().isoformat()
            })

            logger.info(f"ë°˜ë³µ {iteration:2d}: Î±={alpha:6.1f}, RÂ²={score:.6f}, ìµœì RÂ²={best_score:.6f}, ì‹œê°„={elapsed:.1f}s")

            # ëª©í‘œ ë‹¬ì„± ì²´í¬ (ë³´ìˆ˜ì  ê¸°ì¤€)
            if score > 0.25:  # V6: ë” ë³´ìˆ˜ì  ëª©í‘œ
                logger.info(f"ğŸ¯ V6 ëª©í‘œ ë‹¬ì„±! RÂ² = {score:.6f} > 0.25 (ê³¼ì í•© ì•ˆì „)")

        logger.info(f"âœ… V6 ìµœì í™” ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ìµœì  alpha: {best_alpha}")
        logger.info(f"ğŸ“Š ìµœì  RÂ²: {best_score:.6f}")

        self.best_alpha = best_alpha
        self.best_score = best_score

        return best_alpha, best_score, self.history

    def save_results(self, best_alpha, best_score, history):
        """V6 ê²°ê³¼ ì €ì¥"""
        results = {
            'version': 'v6_anti_overfitting',
            'motivation': 'V2_overfitting_risk_83_3_percent_fix',
            'improvements': [
                'ê°•í•œ ì •ê·œí™”: alpha 50-500 (V2: 0.1-100)',
                'í•µì‹¬ íŠ¹ì„±ë§Œ 15ê°œ (V2: 30ê°œ)',
                'ì—„ê²©í•œ ì‹œê°„ì  ë¶„ë¦¬: purge=10, embargo=10 (V2: 5, 5)',
                'ë³´ìˆ˜ì  í›ˆë ¨: 20 epochs (V2: 50 epochs)',
                'ë” ì—„ê²©í•œ ê²€ì¦ ê¸°ì¤€'
            ],
            'optimization_completed': datetime.now().isoformat(),
            'best_hyperparameters': {
                'alpha': float(best_alpha),
                'model_type': 'Conservative_Ridge',
                'n_features': 15,
                'purge_length': 10,
                'embargo_length': 10
            },
            'best_performance': {
                'r2_score': float(best_score),
                'method': 'Strict_Purged_K_Fold_CV'
            },
            'overfitting_prevention': {
                'v2_overfitting_risk': 0.833,  # 83.3%
                'v6_target_risk': '<0.20',    # < 20%
                'regularization_strength': f'{best_alpha}x_stronger_than_baseline',
                'feature_reduction': '50%_feature_reduction',
                'temporal_separation': '2x_longer_purge_embargo'
            },
            'version_comparison': {
                'v2_r2': 0.3256,
                'v2_overfitting': True,
                'v2_risk': 0.833,
                'v6_r2': float(best_score),
                'v6_overfitting': 'TBD_validation_required',
                'improvement_focus': 'overfitting_prevention_over_raw_performance'
            },
            'optimization_history': history
        }

        # ê²°ê³¼ ì €ì¥
        save_path = '/root/workspace/data/raw/anti_overfitting_results_v6.json'
        with open(save_path, 'w') as f:
            json.dump(results, f, indent=2)

        logger.info(f"ğŸ’¾ V6 ê²°ê³¼ ì €ì¥ë¨: {save_path}")
        return results

def main():
    """V6 ë©”ì¸ ì‹¤í–‰"""
    logger.info("ğŸ¯ V6 ê³¼ì í•© ë°©ì§€ ê°•í™” ëª¨ë¸ ì‹œì‘")
    logger.info("âš ï¸ V2 ê³¼ì í•© ìœ„í—˜ë„ 83.3% ë¬¸ì œ í•´ê²° ëª©í‘œ")

    optimizer = AntiOverfittingOptimizerV6()

    try:
        best_alpha, best_score, history = optimizer.optimize_conservative()
        results = optimizer.save_results(best_alpha, best_score, history)

        # V2ì™€ ë¹„êµ
        v2_score = 0.3256
        v2_overfitting_risk = 0.833

        logger.info("ğŸ“ˆ V6 vs V2 ë¹„êµ:")
        logger.info(f"   V2 ì„±ëŠ¥: RÂ² = {v2_score:.4f} (ê³¼ì í•© ìœ„í—˜ {v2_overfitting_risk:.1%})")
        logger.info(f"   V6 ì„±ëŠ¥: RÂ² = {best_score:.4f} (ê³¼ì í•© ë°©ì§€ ì„¤ê³„)")
        logger.info(f"   ì„±ëŠ¥ ì°¨ì´: {best_score - v2_score:+.4f}")

        if best_score > 0.25:
            logger.info("ğŸ‰ V6 ì„±ê³µ: ì•ˆì •ì  ì„±ëŠ¥ + ê³¼ì í•© ë°©ì§€!")
        elif best_score > 0.20:
            logger.info("âœ… V6 ì–‘í˜¸: ë³´ìˆ˜ì ì´ì§€ë§Œ ì•ˆì „í•œ ëª¨ë¸")
        else:
            logger.info("âš ï¸ V6 ê°œì„  í•„ìš”: ì¶”ê°€ ìµœì í™” ê³ ë ¤")

        logger.info("ğŸ” ë‹¤ìŒ ë‹¨ê³„: V6 ê³¼ì í•© ê²€ì¦ + ë‹¤ë¥¸ ëª¨ë¸ë“¤ ì²´í¬")
        return results

    except Exception as e:
        logger.error(f"âŒ V6 ìµœì í™” ì‹¤íŒ¨: {str(e)}")
        raise

if __name__ == "__main__":
    main()