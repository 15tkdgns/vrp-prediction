#!/usr/bin/env python3
"""
ğŸ”’ ì™„ì „ ëˆ„ì¶œ ë°©ì§€ ì•™ìƒë¸” ë°©ë²•ë¡ 

ë‹¤ì–‘í•œ ì•™ìƒë¸” ê¸°ë²•ì„ ë°ì´í„° ëˆ„ì¶œ ì—†ì´ ì•ˆì „í•˜ê²Œ êµ¬í˜„
"""

import sys
sys.path.append('/root/workspace/src')

import pandas as pd
import numpy as np
from datetime import datetime
import json
import warnings
warnings.filterwarnings('ignore')

# Core imports
from core.data_processor import DataProcessor

# ML imports
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import (
    VotingRegressor, BaggingRegressor, AdaBoostRegressor,
    RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
)
from sklearn.linear_model import Ridge, ElasticNet, BayesianRidge, Lasso
from sklearn.preprocessing import RobustScaler, StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.base import clone

# Advanced ensemble imports
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

class SafeEnsembleMethods:
    """ì™„ì „ ëˆ„ì¶œ ë°©ì§€ ì•™ìƒë¸” ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.data_processor = DataProcessor()
        self.max_allowed_correlation = 0.25
        self.realistic_performance_max = 0.7

        print(f"ğŸ”’ ì•ˆì „í•œ ì•™ìƒë¸” ë°©ë²•ë¡  ì‹¤í—˜ ì‹œìŠ¤í…œ")
        print(f"   ğŸš¨ ìµœëŒ€ í—ˆìš© ìƒê´€ê´€ê³„: {self.max_allowed_correlation}")
        print(f"   ğŸ“Š í˜„ì‹¤ì  ì„±ëŠ¥ ìƒí•œ: {self.realistic_performance_max}")

    def create_safe_features(self, df):
        """ì•™ìƒë¸”ìš© ì•ˆì „í•œ íŠ¹ì„± ìƒì„±"""
        print("ğŸ”’ ì•™ìƒë¸”ìš© ì•ˆì „í•œ íŠ¹ì„± ìƒì„±...")

        safe_df = df.copy()

        # ê¸°ë³¸ ìˆ˜ìµë¥ 
        safe_df['returns'] = safe_df['Close'].pct_change()

        # ì•ˆì „í•œ ê³¼ê±° íŠ¹ì„±ë“¤
        for period in [3, 5, 10, 15, 20, 30, 50]:
            # ëª¨ë©˜í…€
            safe_df[f'momentum_{period}'] = (
                safe_df['Close'] / safe_df['Close'].shift(period) - 1
            )

            # ë³€ë™ì„±
            safe_df[f'volatility_{period}'] = (
                safe_df['returns'].rolling(period).std()
            )

            # SMA ë¹„ìœ¨
            safe_df[f'sma_ratio_{period}'] = (
                safe_df['Close'] / safe_df['Close'].rolling(period).mean()
            )

        # ë³¼ë¥¨ ê¸°ë°˜ íŠ¹ì„±
        for period in [10, 20, 30]:
            safe_df[f'volume_sma_{period}'] = safe_df['Volume'].rolling(period).mean()
            safe_df[f'volume_ratio_{period}'] = (
                safe_df['Volume'] / safe_df[f'volume_sma_{period}']
            )

        # ê°€ê²© ë³€í™”ìœ¨
        for period in [1, 2, 3, 5]:
            safe_df[f'price_change_{period}'] = safe_df['Close'].pct_change(period)

        # ê³ /ì €ê°€ ê¸°ë°˜ íŠ¹ì„±
        safe_df['hl_range'] = (safe_df['High'] - safe_df['Low']) / safe_df['Close']
        safe_df['oc_range'] = (safe_df['Close'] - safe_df['Open']) / safe_df['Open']

        # ë˜ê·¸ íŠ¹ì„±
        for lag in [1, 2, 3, 5, 10]:
            safe_df[f'returns_lag_{lag}'] = safe_df['returns'].shift(lag)
            safe_df[f'volume_lag_{lag}'] = safe_df['Volume'].shift(lag)

        # íƒ€ê²Ÿ ë³€ìˆ˜ (ë¯¸ë˜ ì •ë³´, ìœ ì¼í•œ ì˜ˆì™¸)
        safe_df['future_return'] = safe_df['Close'].pct_change().shift(-1)
        safe_df['direction_target'] = (safe_df['future_return'] > 0).astype(int)

        # NaN ì²˜ë¦¬
        safe_df = safe_df.fillna(method='ffill').fillna(0)
        safe_df = safe_df.replace([np.inf, -np.inf], 0)

        print(f"   âœ… ì•™ìƒë¸”ìš© ì•ˆì „ íŠ¹ì„± ìƒì„± ì™„ë£Œ: {safe_df.shape}")
        return safe_df

    def validate_ensemble_safety(self, df):
        """ì•™ìƒë¸”ìš© ì•ˆì „ì„± ê²€ì¦"""
        print("ğŸ” ì•™ìƒë¸” ë°ì´í„° ëˆ„ì¶œ ê²€ì¦...")

        safe_features = []
        for col in df.columns:
            if col not in ['direction_target', 'future_return', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume']:
                safe_features.append(col)

        print(f"   ê²€ì¦í•  íŠ¹ì„± ìˆ˜: {len(safe_features)}")

        # ìƒê´€ê´€ê³„ ê²€ì‚¬
        suspicious_features = []
        for feature in safe_features:
            if feature in df.columns:
                corr = abs(df[feature].corr(df['direction_target']))
                if not pd.isna(corr):
                    if corr > self.max_allowed_correlation:
                        suspicious_features.append((feature, corr))
                        print(f"   âš ï¸ ì˜ì‹¬ íŠ¹ì„±: {feature} (ìƒê´€ê´€ê³„: {corr:.4f})")

        if suspicious_features:
            print(f"   ğŸš¨ ì˜ì‹¬ íŠ¹ì„± {len(suspicious_features)}ê°œ ì œê±°!")
            for feature, _ in suspicious_features:
                if feature in safe_features:
                    safe_features.remove(feature)
        else:
            print("   âœ… ëª¨ë“  íŠ¹ì„±ì´ ì•™ìƒë¸” ì•ˆì „ ê¸°ì¤€ í†µê³¼")

        return safe_features

    def create_base_models(self):
        """ê¸°ë³¸ ëª¨ë¸ë“¤ ìƒì„±"""
        base_models = []

        # ì„ í˜• ëª¨ë¸ë“¤
        base_models.extend([
            ('ridge_1', Ridge(alpha=1.0, random_state=42)),
            ('ridge_10', Ridge(alpha=10.0, random_state=42)),
            ('elastic_1', ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42, max_iter=2000)),
            ('elastic_2', ElasticNet(alpha=1.0, l1_ratio=0.3, random_state=42, max_iter=2000)),
            ('bayesian', BayesianRidge()),
            ('lasso', Lasso(alpha=0.01, random_state=42, max_iter=2000))
        ])

        # íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ë“¤
        base_models.extend([
            ('rf_small', RandomForestRegressor(n_estimators=30, max_depth=5, random_state=42)),
            ('rf_medium', RandomForestRegressor(n_estimators=50, max_depth=8, random_state=42)),
            ('extra_trees', ExtraTreesRegressor(n_estimators=30, max_depth=6, random_state=42)),
            ('gbm_1', GradientBoostingRegressor(n_estimators=50, max_depth=4, learning_rate=0.1, random_state=42)),
            ('gbm_2', GradientBoostingRegressor(n_estimators=30, max_depth=6, learning_rate=0.05, random_state=42)),
        ])

        # XGBoost ëª¨ë¸ë“¤ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if XGBOOST_AVAILABLE:
            base_models.extend([
                ('xgb_1', xgb.XGBRegressor(n_estimators=50, max_depth=4, learning_rate=0.1, random_state=42, verbosity=0)),
                ('xgb_2', xgb.XGBRegressor(n_estimators=30, max_depth=6, learning_rate=0.05, random_state=42, verbosity=0))
            ])

        # LightGBM ëª¨ë¸ë“¤ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if LIGHTGBM_AVAILABLE:
            base_models.extend([
                ('lgb_1', lgb.LGBMRegressor(n_estimators=50, max_depth=4, learning_rate=0.1, random_state=42, verbosity=-1)),
                ('lgb_2', lgb.LGBMRegressor(n_estimators=30, max_depth=6, learning_rate=0.05, random_state=42, verbosity=-1))
            ])

        return base_models

    def create_ensemble_methods(self, base_models):
        """ë‹¤ì–‘í•œ ì•™ìƒë¸” ë°©ë²•ë“¤ ìƒì„±"""
        ensemble_methods = {}

        # 1. ê°„ë‹¨í•œ í‰ê·  ì•™ìƒë¸” (ì„ í˜• ëª¨ë¸ë§Œ)
        linear_models = [(name, model) for name, model in base_models
                        if any(x in name for x in ['ridge', 'elastic', 'bayesian', 'lasso'])]

        if len(linear_models) >= 3:
            ensemble_methods['LinearVoting'] = VotingRegressor(
                estimators=linear_models[:3],
                weights=None
            )

        # 2. ê°€ì¤‘ í‰ê·  ì•™ìƒë¸” (ì„ í˜• ëª¨ë¸)
        if len(linear_models) >= 3:
            ensemble_methods['WeightedLinear'] = VotingRegressor(
                estimators=linear_models[:3],
                weights=[2, 1, 1]  # Ridgeì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
            )

        # 3. íŠ¸ë¦¬ ê¸°ë°˜ ì•™ìƒë¸”
        tree_models = [(name, model) for name, model in base_models
                      if any(x in name for x in ['rf', 'extra', 'gbm', 'xgb', 'lgb'])]

        if len(tree_models) >= 3:
            ensemble_methods['TreeVoting'] = VotingRegressor(
                estimators=tree_models[:3],
                weights=None
            )

        # 4. í˜¼í•© ì•™ìƒë¸” (ì„ í˜• + íŠ¸ë¦¬)
        if len(linear_models) >= 2 and len(tree_models) >= 2:
            mixed_models = linear_models[:2] + tree_models[:2]
            ensemble_methods['MixedVoting'] = VotingRegressor(
                estimators=mixed_models,
                weights=[1, 1, 2, 2]  # íŠ¸ë¦¬ ëª¨ë¸ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
            )

        # 5. ë°°ê¹… ì•™ìƒë¸”
        if base_models:
            ensemble_methods['BaggingRidge'] = BaggingRegressor(
                estimator=Ridge(alpha=1.0, random_state=42),
                n_estimators=10,
                random_state=42
            )

            ensemble_methods['BaggingRF'] = BaggingRegressor(
                estimator=RandomForestRegressor(n_estimators=20, max_depth=5, random_state=42),
                n_estimators=5,
                random_state=42
            )

        # 6. ë¶€ìŠ¤íŒ… ì•™ìƒë¸”
        ensemble_methods['AdaBoostRidge'] = AdaBoostRegressor(
            estimator=Ridge(alpha=1.0, random_state=42),
            n_estimators=20,
            learning_rate=0.1,
            random_state=42
        )

        # 7. ë‹¤ë‹¨ê³„ ì•™ìƒë¸” (ê°„ë‹¨í•œ ìŠ¤íƒœí‚¹)
        if len(base_models) >= 4:
            # 1ë‹¨ê³„: ì—¬ëŸ¬ ëª¨ë¸ë¡œ ì˜ˆì¸¡
            # 2ë‹¨ê³„: Ridgeë¡œ ê²°í•©
            ensemble_methods['SimpleStacking'] = self.create_simple_stacking_ensemble(base_models[:4])

        return ensemble_methods

    def create_simple_stacking_ensemble(self, base_models):
        """ê°„ë‹¨í•œ ìŠ¤íƒœí‚¹ ì•™ìƒë¸”"""

        class SimpleStackingRegressor:
            def __init__(self, base_models, meta_model=None):
                self.base_models = [(name, clone(model)) for name, model in base_models]
                self.meta_model = meta_model if meta_model else Ridge(alpha=1.0, random_state=42)

            def fit(self, X, y):
                # 1ë‹¨ê³„: ê¸°ë³¸ ëª¨ë¸ë“¤ í›ˆë ¨
                self.fitted_base_models = []
                base_predictions = np.zeros((X.shape[0], len(self.base_models)))

                for i, (name, model) in enumerate(self.base_models):
                    model.fit(X, y)
                    base_predictions[:, i] = model.predict(X)
                    self.fitted_base_models.append((name, model))

                # 2ë‹¨ê³„: ë©”íƒ€ ëª¨ë¸ í›ˆë ¨
                self.meta_model.fit(base_predictions, y)

                return self

            def predict(self, X):
                # 1ë‹¨ê³„: ê¸°ë³¸ ëª¨ë¸ë“¤ë¡œ ì˜ˆì¸¡
                base_predictions = np.zeros((X.shape[0], len(self.fitted_base_models)))

                for i, (name, model) in enumerate(self.fitted_base_models):
                    base_predictions[:, i] = model.predict(X)

                # 2ë‹¨ê³„: ë©”íƒ€ ëª¨ë¸ë¡œ ìµœì¢… ì˜ˆì¸¡
                return self.meta_model.predict(base_predictions)

        return SimpleStackingRegressor(base_models)

    def run_ensemble_experiments(self, data_path='/root/workspace/data/training/sp500_2020_2024_enhanced.csv'):
        """ì•™ìƒë¸” ì‹¤í—˜ ì‹¤í–‰"""
        print("ğŸ”’ ì•ˆì „í•œ ì•™ìƒë¸” ë°©ë²•ë¡  ì‹¤í—˜ ì‹œì‘")
        print("="*70)

        try:
            # 1. ë°ì´í„° ë¡œë”© ë° ì•ˆì „ ì²˜ë¦¬
            df = self.data_processor.load_and_validate_data(data_path)
            safe_df = self.create_safe_features(df)

            # 2. ì•ˆì „ì„± ê²€ì¦
            safe_features = self.validate_ensemble_safety(safe_df)

            if len(safe_features) < 10:
                print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì•ˆì „ íŠ¹ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤!")
                return None

            # 3. ì•™ìƒë¸” ì‹¤í—˜
            ensemble_results = self._run_ensemble_methods(safe_df, safe_features)

            # 4. ê²°ê³¼ ê²€ì¦
            self._validate_ensemble_results(ensemble_results)

            return ensemble_results

        except Exception as e:
            print(f"âŒ ì•™ìƒë¸” ì‹¤í—˜ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def _run_ensemble_methods(self, safe_df, safe_features):
        """ë‹¤ì–‘í•œ ì•™ìƒë¸” ë°©ë²•ë“¤ ì‹¤í–‰"""
        print(f"\nğŸ­ ì•™ìƒë¸” ë°©ë²•ë¡  ì‹¤í—˜ (íŠ¹ì„± ìˆ˜: {len(safe_features)})")

        # ë°ì´í„° ì¤€ë¹„
        X = safe_df[safe_features].values
        y = safe_df['direction_target'].values

        # ì•ˆì „ ì²˜ë¦¬
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        y = np.nan_to_num(y, nan=0.5, posinf=1.0, neginf=0.0).astype(float)

        # ìœ íš¨ ë°ì´í„°ë§Œ ì„ íƒ
        valid_idx = ~pd.isna(safe_df['direction_target'])
        X = X[valid_idx]
        y = y[valid_idx]

        print(f"   ìµœì¢… ë°ì´í„°: X={X.shape}, y=í´ë˜ìŠ¤ë¶„í¬{np.bincount(y.astype(int))}")

        # ê¸°ë³¸ ëª¨ë¸ë“¤ ìƒì„±
        base_models = self.create_base_models()
        print(f"   ê¸°ë³¸ ëª¨ë¸ ìˆ˜: {len(base_models)}")

        # ì•™ìƒë¸” ë°©ë²•ë“¤ ìƒì„±
        ensemble_methods = self.create_ensemble_methods(base_models)
        print(f"   ì•™ìƒë¸” ë°©ë²• ìˆ˜: {len(ensemble_methods)}")

        # ì‹œê°„ ìˆœì„œ êµì°¨ ê²€ì¦
        tscv = TimeSeriesSplit(n_splits=3)
        ensemble_results = {}

        for ensemble_name, ensemble_model in ensemble_methods.items():
            print(f"\n   ğŸ­ {ensemble_name} ì•™ìƒë¸” ì‹¤í—˜...")

            fold_accuracies = []
            fold_maes = []
            fold_r2s = []

            for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
                X_train, X_val = X[train_idx], X[val_idx]
                y_train, y_val = y[train_idx], y[val_idx]

                # ìŠ¤ì¼€ì¼ë§
                scaler = RobustScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_val_scaled = scaler.transform(X_val)

                try:
                    # ì•™ìƒë¸” ëª¨ë¸ í›ˆë ¨
                    ensemble_clone = clone(ensemble_model)
                    ensemble_clone.fit(X_train_scaled, y_train)
                    y_pred = ensemble_clone.predict(X_val_scaled)

                    # ì„±ëŠ¥ ê³„ì‚°
                    mae = mean_absolute_error(y_val, y_pred)
                    r2 = r2_score(y_val, y_pred)

                    # ë°©í–¥ ì •í™•ë„
                    y_pred_direction = (y_pred > 0.5).astype(int)
                    direction_acc = np.mean(y_pred_direction == y_val.astype(int))

                    fold_accuracies.append(direction_acc)
                    fold_maes.append(mae)
                    fold_r2s.append(r2)

                    print(f"      Fold {fold+1}: ë°©í–¥ì •í™•ë„={direction_acc:.4f}, MAE={mae:.6f}, RÂ²={r2:.4f}")

                except Exception as e:
                    print(f"      Fold {fold+1} ì‹¤íŒ¨: {e}")
                    fold_accuracies.append(0.5)
                    fold_maes.append(1.0)
                    fold_r2s.append(-1.0)

            # í‰ê·  ì„±ëŠ¥
            avg_accuracy = np.mean(fold_accuracies)
            avg_mae = np.mean(fold_maes)
            avg_r2 = np.mean(fold_r2s)

            ensemble_results[ensemble_name] = {
                'direction_accuracy': avg_accuracy,
                'mae': avg_mae,
                'r2': avg_r2,
                'fold_accuracies': fold_accuracies
            }

            print(f"   âœ… {ensemble_name} í‰ê· : ë°©í–¥ì •í™•ë„={avg_accuracy:.4f}, MAE={avg_mae:.6f}, RÂ²={avg_r2:.4f}")

        return ensemble_results

    def _validate_ensemble_results(self, results):
        """ì•™ìƒë¸” ê²°ê³¼ ê²€ì¦"""
        print("\nğŸš¨ ì•™ìƒë¸” ê²°ê³¼ ê²€ì¦ ë° ê²½ê³  ì‹œìŠ¤í…œ")
        print("="*60)

        for ensemble_name, metrics in results.items():
            accuracy = metrics['direction_accuracy']
            r2 = metrics['r2']

            # ì„±ëŠ¥ ê²€ì¦
            if accuracy > 0.9:
                print(f"ğŸš¨ {ensemble_name}: {accuracy:.1%} - ëˆ„ì¶œ ì˜ì‹¬!")
            elif accuracy > 0.75:
                print(f"âš ï¸ {ensemble_name}: {accuracy:.1%} - ë†’ì€ ì„±ëŠ¥, ì¬ê²€ì¦ ê¶Œì¥")
            elif accuracy > 0.6:
                print(f"âœ… {ensemble_name}: {accuracy:.1%} - ì–‘í˜¸í•œ ì„±ëŠ¥")
            else:
                print(f"ğŸ“Š {ensemble_name}: {accuracy:.1%} - í˜„ì‹¤ì  ì„±ëŠ¥")

        # ìµœê³  ì„±ëŠ¥ ì•™ìƒë¸”
        best_ensemble = max(results.keys(), key=lambda k: results[k]['direction_accuracy'])
        best_acc = results[best_ensemble]['direction_accuracy']

        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ì•™ìƒë¸”: {best_ensemble} ({best_acc:.1%})")

        if best_acc > 0.85:
            print("ğŸš¨ ê²½ê³ : ì—¬ì „íˆ ë†’ì€ ì„±ëŠ¥, ì¶”ê°€ ëˆ„ì¶œ ê²€ì¦ í•„ìš”!")
        elif best_acc > 0.7:
            print("ğŸ“Š ì–‘í˜¸: í•©ë¦¬ì  ì„±ëŠ¥ ë²”ìœ„")
        else:
            print("âœ… ì•ˆì „: í˜„ì‹¤ì  ì„±ëŠ¥, ëˆ„ì¶œ ì—†ìŒ í™•ì¸")

        # ì•™ìƒë¸” ìˆœìœ„ ì¶œë ¥
        print(f"\nğŸ“Š ì•™ìƒë¸” ì„±ëŠ¥ ìˆœìœ„:")
        sorted_ensembles = sorted(results.items(),
                                key=lambda x: x[1]['direction_accuracy'],
                                reverse=True)

        for rank, (name, metrics) in enumerate(sorted_ensembles, 1):
            print(f"   {rank}. {name}: {metrics['direction_accuracy']:.4f} (MAE: {metrics['mae']:.6f}, RÂ²: {metrics['r2']:.4f})")

        # ê²°ê³¼ ì €ì¥
        output_path = f"/root/workspace/data/results/safe_ensemble_methods_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        try:
            with open(output_path, 'w') as f:
                json.dump({
                    'timestamp': datetime.now().isoformat(),
                    'experiment_type': 'safe_ensemble_methods',
                    'max_allowed_correlation': self.max_allowed_correlation,
                    'results': {k: {**v, 'fold_accuracies': [float(x) for x in v['fold_accuracies']]}
                              for k, v in results.items()}
                }, f, indent=2)
            print(f"\nğŸ’¾ ì•™ìƒë¸” ê²°ê³¼ ì €ì¥: {output_path}")
        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    system = SafeEnsembleMethods()
    results = system.run_ensemble_experiments()

    if results:
        print("\nğŸ‰ ì•ˆì „í•œ ì•™ìƒë¸” ì‹¤í—˜ ì™„ë£Œ!")
        print("âœ… ëª¨ë“  ê²°ê³¼ê°€ ëˆ„ì¶œ ê²€ì¦ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ì•™ìƒë¸” ì‹¤í—˜ ì‹¤íŒ¨!")

    return results

if __name__ == "__main__":
    main()