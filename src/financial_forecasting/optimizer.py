"""
Financial Performance Metrics Optimization

ê¸ˆìœµ ì„±ê³¼ ì§€í‘œ ê¸°ë°˜ ëª¨ë¸ ìµœì í™”:
1. FinancialObjectiveOptimizer: ìƒ¤í”„/ì†Œë¥´í‹°ë…¸/MDD ê¸°ë°˜ ëª©ì í•¨ìˆ˜ ìµœì í™”
2. HyperparameterOptimizer: ê¸ˆìœµ ì§€í‘œ ê¸°ì¤€ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
3. EnsembleOptimizer: í¬íŠ¸í´ë¦¬ì˜¤ ì´ë¡  ê¸°ë°˜ ëª¨ë¸ ì•™ìƒë¸” ìµœì í™”
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union, Callable, Any
from dataclasses import dataclass
from abc import ABC, abstractmethod
import warnings
warnings.filterwarnings('ignore')

try:
    from scipy.optimize import minimize, differential_evolution
    from scipy.stats import norm
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    print("âš ï¸ scipy not available, using simplified optimization")

try:
    from sklearn.model_selection import ParameterGrid
    from sklearn.metrics import make_scorer
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("âš ï¸ sklearn not available for parameter grid search")

from .core import FinancialMetrics
from .validation import WalkForwardValidator, FinancialBacktester


@dataclass
class OptimizationResult:
    """ìµœì í™” ê²°ê³¼"""
    best_params: Dict[str, Any]
    best_score: float
    optimization_history: List[Dict]
    convergence_info: Dict
    financial_metrics: Dict


@dataclass
class EnsembleWeights:
    """ì•™ìƒë¸” ê°€ì¤‘ì¹˜"""
    weights: np.ndarray
    expected_return: float
    expected_risk: float
    sharpe_ratio: float
    diversification_ratio: float


class FinancialObjectiveOptimizer:
    """
    Financial Performance Based Objective Function Optimizer

    ì „í†µì  ML ì§€í‘œ(MSE, ì •í™•ë„) ëŒ€ì‹  ì‹¤ì œ ê¸ˆìœµ ì„±ê³¼ ì§€í‘œë¡œ ìµœì í™”:
    - ìƒ¤í”„ ë¹„ìœ¨ ìµœëŒ€í™”
    - ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨ ìµœëŒ€í™”
    - ìµœëŒ€ ë‚™í­(MDD) ìµœì†Œí™”
    - ì¹¼ë§ˆ ë¹„ìœ¨ ìµœëŒ€í™”
    - ë³µí•© ëª©ì í•¨ìˆ˜ ìµœì í™”
    """

    def __init__(
        self,
        objective_weights: Optional[Dict[str, float]] = None,
        risk_free_rate: float = 0.02
    ):
        """
        Args:
            objective_weights: ëª©ì í•¨ìˆ˜ ê°€ì¤‘ì¹˜
                {
                    'sharpe': 0.4,      # ìƒ¤í”„ ë¹„ìœ¨
                    'sortino': 0.3,     # ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨
                    'calmar': 0.2,      # ì¹¼ë§ˆ ë¹„ìœ¨
                    'mdd_penalty': 0.1  # MDD í˜ë„í‹°
                }
            risk_free_rate: ë¬´ìœ„í—˜ ìˆ˜ìµë¥ 
        """
        if objective_weights is None:
            objective_weights = {
                'sharpe': 0.5,
                'sortino': 0.3,
                'calmar': 0.2,
                'mdd_penalty': 0.0
            }

        self.objective_weights = objective_weights
        self.risk_free_rate = risk_free_rate

    def calculate_financial_objective(
        self,
        predictions: np.ndarray,
        actual_returns: np.ndarray,
        prices: Optional[np.ndarray] = None
    ) -> float:
        """
        ê¸ˆìœµ ì„±ê³¼ ê¸°ë°˜ ëª©ì í•¨ìˆ˜ ê³„ì‚°

        Args:
            predictions: ëª¨ë¸ ì˜ˆì¸¡ê°’ (ìˆ˜ìµë¥  ë˜ëŠ” ë°©í–¥)
            actual_returns: ì‹¤ì œ ìˆ˜ìµë¥ 
            prices: ê°€ê²© ë°ì´í„° (ì„ íƒì )

        Returns:
            ë³µí•© ëª©ì í•¨ìˆ˜ ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        """
        try:
            # ì˜ˆì¸¡ ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
            if len(predictions) != len(actual_returns):
                # ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ì§§ì€ ìª½ì— ë§ì¶¤
                min_len = min(len(predictions), len(actual_returns))
                predictions = predictions[:min_len]
                actual_returns = actual_returns[:min_len]

            # ê±°ë˜ ì‹ í˜¸ ìƒì„± (ì˜ˆì¸¡ ê°’ì´ ì„ê³„ì¹˜ ì´ìƒì´ë©´ ë§¤ìˆ˜)
            signal_threshold = np.median(predictions)
            signals = np.where(predictions > signal_threshold, 1, 0)

            # ì „ëµ ìˆ˜ìµë¥  ê³„ì‚° (ì‹ í˜¸ * ì‹¤ì œ ìˆ˜ìµë¥ )
            strategy_returns = signals * actual_returns

            # ìˆ˜ìµë¥ ì´ 0ì¸ ê²½ìš° ì²˜ë¦¬
            if len(strategy_returns) == 0 or np.std(strategy_returns) == 0:
                return -1.0  # ìµœì•… ì ìˆ˜

            # pandas Seriesë¡œ ë³€í™˜
            returns_series = pd.Series(strategy_returns)

            # ê¸ˆìœµ ì„±ê³¼ ì§€í‘œ ê³„ì‚°
            metrics = FinancialMetrics.calculate_comprehensive_metrics(
                returns_series, self.risk_free_rate
            )

            # ë³µí•© ëª©ì í•¨ìˆ˜ ê³„ì‚°
            objective_score = 0.0

            # ìƒ¤í”„ ë¹„ìœ¨ (ì •ê·œí™”: ì¼ë°˜ì ìœ¼ë¡œ -2 ~ 3 ë²”ìœ„)
            sharpe_normalized = np.clip(metrics.sharpe_ratio / 3.0, -1, 1)
            objective_score += self.objective_weights.get('sharpe', 0) * sharpe_normalized

            # ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨ (ì •ê·œí™”: ì¼ë°˜ì ìœ¼ë¡œ -3 ~ 4 ë²”ìœ„)
            sortino_normalized = np.clip(metrics.sortino_ratio / 4.0, -1, 1)
            objective_score += self.objective_weights.get('sortino', 0) * sortino_normalized

            # ì¹¼ë§ˆ ë¹„ìœ¨ (ì •ê·œí™”: ì¼ë°˜ì ìœ¼ë¡œ -2 ~ 2 ë²”ìœ„)
            calmar_normalized = np.clip(metrics.calmar_ratio / 2.0, -1, 1)
            objective_score += self.objective_weights.get('calmar', 0) * calmar_normalized

            # MDD í˜ë„í‹° (0 ~ 1 ë²”ìœ„, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë‚®ì€ MDD)
            mdd_penalty = 1.0 - np.clip(metrics.max_drawdown, 0, 1)
            objective_score += self.objective_weights.get('mdd_penalty', 0) * mdd_penalty

            return objective_score

        except Exception as e:
            print(f"âš ï¸ ëª©ì í•¨ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return -1.0  # ìµœì•… ì ìˆ˜ ë°˜í™˜

    def create_sklearn_scorer(self) -> Callable:
        """scikit-learn í˜¸í™˜ ìŠ¤ì½”ì–´ëŸ¬ ìƒì„±"""
        def financial_scorer(y_true, y_pred):
            return self.calculate_financial_objective(y_pred, y_true)

        if SKLEARN_AVAILABLE:
            return make_scorer(financial_scorer, greater_is_better=True)
        else:
            return financial_scorer


class HyperparameterOptimizer:
    """
    Financial Metrics Based Hyperparameter Optimization

    ê¸ˆìœµ ì„±ê³¼ ì§€í‘œë¥¼ ëª©ì í•¨ìˆ˜ë¡œ í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”:
    - Grid Search with Financial Objective
    - Bayesian Optimization (ê¸ˆìœµ ì§€í‘œ ê¸°ë°˜)
    - Differential Evolution
    - Walk-Forward Validation ê²°í•©
    """

    def __init__(
        self,
        objective_optimizer: FinancialObjectiveOptimizer,
        validator: WalkForwardValidator,
        optimization_method: str = "grid_search"  # "grid_search", "differential_evolution"
    ):
        self.objective_optimizer = objective_optimizer
        self.validator = validator
        self.optimization_method = optimization_method

    def optimize_hyperparameters(
        self,
        model_class: type,
        X: pd.DataFrame,
        y: pd.Series,
        param_grid: Dict[str, List],
        cv_folds: int = 5,
        n_jobs: int = 1
    ) -> OptimizationResult:
        """
        í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ìˆ˜í–‰

        Args:
            model_class: ëª¨ë¸ í´ë˜ìŠ¤
            X: íŠ¹ì„± ë°ì´í„°
            y: íƒ€ê²Ÿ ë°ì´í„° (ìˆ˜ìµë¥ )
            param_grid: íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
            cv_folds: CV í´ë“œ ìˆ˜
            n_jobs: ë³‘ë ¬ ì‘ì—… ìˆ˜

        Returns:
            ìµœì í™” ê²°ê³¼
        """
        print(f"ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘ ({self.optimization_method})")
        print(f"   ëª¨ë¸: {model_class.__name__}")
        print(f"   íŒŒë¼ë¯¸í„° ì¡°í•©: {self._count_combinations(param_grid)}ê°œ")

        if self.optimization_method == "grid_search":
            return self._grid_search_optimization(model_class, X, y, param_grid, cv_folds)
        elif self.optimization_method == "differential_evolution":
            return self._differential_evolution_optimization(model_class, X, y, param_grid, cv_folds)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ìµœì í™” ë°©ë²•: {self.optimization_method}")

    def _grid_search_optimization(
        self,
        model_class: type,
        X: pd.DataFrame,
        y: pd.Series,
        param_grid: Dict[str, List],
        cv_folds: int
    ) -> OptimizationResult:
        """ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™”"""
        if not SKLEARN_AVAILABLE:
            raise ImportError("sklearnì´ í•„ìš”í•©ë‹ˆë‹¤")

        best_score = -np.inf
        best_params = None
        optimization_history = []

        # íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
        param_combinations = list(ParameterGrid(param_grid))

        for i, params in enumerate(param_combinations):
            try:
                print(f"   ì§„í–‰ë¥ : {i+1}/{len(param_combinations)} - {params}")

                # ëª¨ë¸ ìƒì„±
                model = model_class(**params)

                # Walk-Forward Validation
                cv_results = self.validator.validate(model, X, y)

                if not cv_results:
                    continue

                # ëª¨ë“  í´ë“œì˜ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ê²°í•©
                all_predictions = np.concatenate([r.predictions for r in cv_results])
                all_actuals = np.concatenate([r.actuals for r in cv_results])

                # ê¸ˆìœµ ëª©ì í•¨ìˆ˜ ì ìˆ˜ ê³„ì‚°
                score = self.objective_optimizer.calculate_financial_objective(
                    all_predictions, all_actuals
                )

                # ê¸°ë¡
                optimization_history.append({
                    'params': params.copy(),
                    'score': score,
                    'cv_results': len(cv_results)
                })

                # ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
                if score > best_score:
                    best_score = score
                    best_params = params.copy()
                    print(f"   âœ… ìƒˆë¡œìš´ ìµœê³  ì ìˆ˜: {score:.4f}")

            except Exception as e:
                print(f"   âŒ íŒŒë¼ë¯¸í„° {params} ì‹¤íŒ¨: {e}")
                continue

        # ìµœì¢… ê²°ê³¼
        result = OptimizationResult(
            best_params=best_params or {},
            best_score=best_score,
            optimization_history=optimization_history,
            convergence_info={'method': 'grid_search', 'total_combinations': len(param_combinations)},
            financial_metrics={}
        )

        print(f"ğŸ¯ ìµœì í™” ì™„ë£Œ:")
        print(f"   ìµœê³  ì ìˆ˜: {best_score:.4f}")
        print(f"   ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")

        return result

    def _differential_evolution_optimization(
        self,
        model_class: type,
        X: pd.DataFrame,
        y: pd.Series,
        param_bounds: Dict[str, Tuple[float, float]],
        cv_folds: int
    ) -> OptimizationResult:
        """Differential Evolution ìµœì í™”"""
        if not SCIPY_AVAILABLE:
            raise ImportError("scipyê°€ í•„ìš”í•©ë‹ˆë‹¤")

        param_names = list(param_bounds.keys())
        bounds = list(param_bounds.values())

        optimization_history = []

        def objective_function(params_array):
            try:
                # íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
                params = dict(zip(param_names, params_array))

                # ì •ìˆ˜í˜• íŒŒë¼ë¯¸í„° ì²˜ë¦¬
                for key, value in params.items():
                    if key in ['n_estimators', 'max_depth', 'min_samples_split']:
                        params[key] = int(value)

                # ëª¨ë¸ ìƒì„± ë° ê²€ì¦
                model = model_class(**params)
                cv_results = self.validator.validate(model, X, y)

                if not cv_results:
                    return 1.0  # ìµœì•… ì ìˆ˜ (ìµœì†Œí™” ë¬¸ì œì´ë¯€ë¡œ)

                # ì˜ˆì¸¡ê°’ ê²°í•©
                all_predictions = np.concatenate([r.predictions for r in cv_results])
                all_actuals = np.concatenate([r.actuals for r in cv_results])

                # ê¸ˆìœµ ëª©ì í•¨ìˆ˜ ì ìˆ˜ (ìµœëŒ€í™” â†’ ìµœì†Œí™”ë¡œ ë³€í™˜)
                score = self.objective_optimizer.calculate_financial_objective(
                    all_predictions, all_actuals
                )

                optimization_history.append({
                    'params': params.copy(),
                    'score': score
                })

                return -score  # ìµœì†Œí™” ë¬¸ì œë¡œ ë³€í™˜

            except Exception as e:
                print(f"âš ï¸ ëª©ì í•¨ìˆ˜ í‰ê°€ ì‹¤íŒ¨: {e}")
                return 1.0

        # Differential Evolution ì‹¤í–‰
        result = differential_evolution(
            objective_function,
            bounds,
            maxiter=50,
            popsize=10,
            seed=42
        )

        # ìµœì  íŒŒë¼ë¯¸í„° ë³µì›
        best_params = dict(zip(param_names, result.x))
        for key, value in best_params.items():
            if key in ['n_estimators', 'max_depth', 'min_samples_split']:
                best_params[key] = int(value)

        optimization_result = OptimizationResult(
            best_params=best_params,
            best_score=-result.fun,  # ì›ë˜ ì ìˆ˜ë¡œ ë³µì›
            optimization_history=optimization_history,
            convergence_info={
                'method': 'differential_evolution',
                'success': result.success,
                'message': result.message,
                'iterations': result.nit
            },
            financial_metrics={}
        )

        print(f"ğŸ¯ Differential Evolution ì™„ë£Œ:")
        print(f"   ìµœê³  ì ìˆ˜: {-result.fun:.4f}")
        print(f"   ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")

        return optimization_result

    def _count_combinations(self, param_grid: Dict[str, List]) -> int:
        """íŒŒë¼ë¯¸í„° ì¡°í•© ìˆ˜ ê³„ì‚°"""
        count = 1
        for values in param_grid.values():
            count *= len(values)
        return count


class EnsembleOptimizer:
    """
    Portfolio Theory Based Ensemble Optimization

    í¬íŠ¸í´ë¦¬ì˜¤ ì´ë¡ ì„ ì ìš©í•œ ëª¨ë¸ ì•™ìƒë¸” ìµœì í™”:
    - ë§ˆì½”ìœ„ì¸  í‰ê· -ë¶„ì‚° ìµœì í™”
    - ë¦¬ìŠ¤í¬ íŒ¨ë¦¬í‹° (Risk Parity)
    - ìµœëŒ€ ë‹¤ê°í™” (Maximum Diversification)
    - ìµœì†Œ ë¶„ì‚° (Minimum Variance)
    """

    def __init__(self, risk_aversion: float = 1.0):
        """
        Args:
            risk_aversion: ìœ„í—˜ íšŒí”¼ ê³„ìˆ˜ (ë†’ì„ìˆ˜ë¡ ë³´ìˆ˜ì )
        """
        self.risk_aversion = risk_aversion

    def optimize_ensemble_weights(
        self,
        model_predictions: Dict[str, np.ndarray],
        actual_returns: np.ndarray,
        method: str = "markowitz"  # "markowitz", "risk_parity", "max_diversification", "min_variance"
    ) -> EnsembleWeights:
        """
        ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”

        Args:
            model_predictions: ëª¨ë¸ë³„ ì˜ˆì¸¡ê°’ ë”•ì…”ë„ˆë¦¬
            actual_returns: ì‹¤ì œ ìˆ˜ìµë¥ 
            method: ìµœì í™” ë°©ë²•

        Returns:
            ìµœì  ì•™ìƒë¸” ê°€ì¤‘ì¹˜
        """
        model_names = list(model_predictions.keys())
        n_models = len(model_names)

        # ê° ëª¨ë¸ì˜ ì „ëµ ìˆ˜ìµë¥  ê³„ì‚°
        strategy_returns_matrix = []
        for model_name, predictions in model_predictions.items():
            # ì‹ í˜¸ ìƒì„± (ì„ê³„ì¹˜ ê¸°ë°˜)
            threshold = np.median(predictions)
            signals = np.where(predictions > threshold, 1, 0)

            # ì „ëµ ìˆ˜ìµë¥ 
            strategy_returns = signals * actual_returns
            strategy_returns_matrix.append(strategy_returns)

        returns_matrix = np.array(strategy_returns_matrix).T  # (ì‹œê°„, ëª¨ë¸)

        # ìˆ˜ìµë¥  ë° ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°
        mean_returns = np.mean(returns_matrix, axis=0)
        cov_matrix = np.cov(returns_matrix.T)

        # ìµœì í™” ë°©ë²•ë³„ ê°€ì¤‘ì¹˜ ê³„ì‚°
        if method == "markowitz":
            weights = self._markowitz_optimization(mean_returns, cov_matrix)
        elif method == "risk_parity":
            weights = self._risk_parity_optimization(cov_matrix)
        elif method == "max_diversification":
            weights = self._max_diversification_optimization(mean_returns, cov_matrix)
        elif method == "min_variance":
            weights = self._min_variance_optimization(cov_matrix)
        else:
            # ê· ë“± ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’)
            weights = np.ones(n_models) / n_models

        # í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ê³„ì‚°
        portfolio_returns = returns_matrix @ weights
        expected_return = np.mean(portfolio_returns) * 252  # ì—°í™˜ì‚°
        expected_risk = np.std(portfolio_returns) * np.sqrt(252)  # ì—°í™˜ì‚°
        sharpe_ratio = expected_return / expected_risk if expected_risk > 0 else 0

        # ë‹¤ê°í™” ë¹„ìœ¨ ê³„ì‚°
        individual_risks = np.sqrt(np.diag(cov_matrix)) * np.sqrt(252)
        weighted_avg_risk = weights @ individual_risks
        diversification_ratio = weighted_avg_risk / expected_risk if expected_risk > 0 else 1

        result = EnsembleWeights(
            weights=weights,
            expected_return=expected_return,
            expected_risk=expected_risk,
            sharpe_ratio=sharpe_ratio,
            diversification_ratio=diversification_ratio
        )

        print(f"ğŸ“Š ì•™ìƒë¸” ìµœì í™” ì™„ë£Œ ({method}):")
        print(f"   ì˜ˆìƒ ìˆ˜ìµë¥ : {expected_return:.2%}")
        print(f"   ì˜ˆìƒ ìœ„í—˜: {expected_risk:.2%}")
        print(f"   ìƒ¤í”„ ë¹„ìœ¨: {sharpe_ratio:.3f}")
        print(f"   ë‹¤ê°í™” ë¹„ìœ¨: {diversification_ratio:.3f}")
        for i, (name, weight) in enumerate(zip(model_names, weights)):
            print(f"   {name}: {weight:.3f}")

        return result

    def _markowitz_optimization(self, mean_returns: np.ndarray, cov_matrix: np.ndarray) -> np.ndarray:
        """ë§ˆì½”ìœ„ì¸  í‰ê· -ë¶„ì‚° ìµœì í™”"""
        if not SCIPY_AVAILABLE:
            return np.ones(len(mean_returns)) / len(mean_returns)

        n = len(mean_returns)

        # ëª©ì í•¨ìˆ˜: ê¸°ëŒ€ìˆ˜ìµë¥  ìµœëŒ€í™” - ìœ„í—˜íšŒí”¼ê³„ìˆ˜ * ë¶„ì‚°
        def objective(weights):
            portfolio_return = weights @ mean_returns
            portfolio_variance = weights @ cov_matrix @ weights
            return -(portfolio_return - 0.5 * self.risk_aversion * portfolio_variance)

        # ì œì•½ì¡°ê±´: ê°€ì¤‘ì¹˜ í•© = 1, ê°€ì¤‘ì¹˜ >= 0
        constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}
        bounds = [(0, 1) for _ in range(n)]

        # ìµœì í™” ì‹¤í–‰
        result = minimize(
            objective,
            x0=np.ones(n) / n,
            bounds=bounds,
            constraints=constraints,
            method='SLSQP'
        )

        return result.x if result.success else np.ones(n) / n

    def _risk_parity_optimization(self, cov_matrix: np.ndarray) -> np.ndarray:
        """ë¦¬ìŠ¤í¬ íŒ¨ë¦¬í‹° ìµœì í™” (ê° ëª¨ë¸ì˜ ìœ„í—˜ ê¸°ì—¬ë„ ë™ì¼)"""
        if not SCIPY_AVAILABLE:
            return np.ones(len(cov_matrix)) / len(cov_matrix)

        n = len(cov_matrix)

        def objective(weights):
            # ê° ìì‚°ì˜ í•œê³„ ìœ„í—˜ ê¸°ì—¬ë„
            portfolio_variance = weights @ cov_matrix @ weights
            marginal_contrib = cov_matrix @ weights
            contrib = weights * marginal_contrib / portfolio_variance

            # ìœ„í—˜ ê¸°ì—¬ë„ì˜ ë¶„ì‚° ìµœì†Œí™”
            target = 1.0 / n
            return np.sum((contrib - target) ** 2)

        constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}
        bounds = [(0.01, 1) for _ in range(n)]

        result = minimize(
            objective,
            x0=np.ones(n) / n,
            bounds=bounds,
            constraints=constraints,
            method='SLSQP'
        )

        return result.x if result.success else np.ones(n) / n

    def _max_diversification_optimization(self, mean_returns: np.ndarray, cov_matrix: np.ndarray) -> np.ndarray:
        """ìµœëŒ€ ë‹¤ê°í™” ìµœì í™”"""
        if not SCIPY_AVAILABLE:
            return np.ones(len(mean_returns)) / len(mean_returns)

        n = len(cov_matrix)

        def objective(weights):
            # ë‹¤ê°í™” ë¹„ìœ¨ = (ê°€ì¤‘í‰ê·  ë³€ë™ì„±) / (í¬íŠ¸í´ë¦¬ì˜¤ ë³€ë™ì„±)
            individual_vols = np.sqrt(np.diag(cov_matrix))
            weighted_avg_vol = weights @ individual_vols
            portfolio_vol = np.sqrt(weights @ cov_matrix @ weights)
            return -weighted_avg_vol / portfolio_vol  # ìµœëŒ€í™”ë¥¼ ìœ„í•´ ìŒìˆ˜

        constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}
        bounds = [(0, 1) for _ in range(n)]

        result = minimize(
            objective,
            x0=np.ones(n) / n,
            bounds=bounds,
            constraints=constraints,
            method='SLSQP'
        )

        return result.x if result.success else np.ones(n) / n

    def _min_variance_optimization(self, cov_matrix: np.ndarray) -> np.ndarray:
        """ìµœì†Œ ë¶„ì‚° ìµœì í™”"""
        if not SCIPY_AVAILABLE:
            return np.ones(len(cov_matrix)) / len(cov_matrix)

        n = len(cov_matrix)

        def objective(weights):
            return weights @ cov_matrix @ weights

        constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}
        bounds = [(0, 1) for _ in range(n)]

        result = minimize(
            objective,
            x0=np.ones(n) / n,
            bounds=bounds,
            constraints=constraints,
            method='SLSQP'
        )

        return result.x if result.success else np.ones(n) / n