"""
Advanced Financial Forecasting Pipeline

ì™„ì „í•œ ì—”ë“œíˆ¬ì—”ë“œ ê¸ˆìœµ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸:
1. ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ (ë¡œê·¸ ìˆ˜ìµë¥  ë³€í™˜)
2. ëŒ€ì²´ ë°ì´í„° í†µí•© (FRED, FinBERT, HMM)
3. ê³ ê¸‰ ëª¨ë¸ í›ˆë ¨ (ARIMA-GARCH, TFT, MDN)
4. ê¸ˆìœµ ì„±ê³¼ ê¸°ë°˜ ìµœì í™”
5. Walk-Forward ê²€ì¦
6. ë°±í…ŒìŠ¤íŒ… ë° ë¦¬ìŠ¤í¬ í‰ê°€
7. ì¢…í•© ì„±ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
import warnings
warnings.filterwarnings('ignore')

try:
    import yfinance as yf
    YFINANCE_AVAILABLE = True
except ImportError:
    YFINANCE_AVAILABLE = False
    print("âš ï¸ yfinance not available, using simulated data")

from .core import LogReturnProcessor, TimeSeriesSafeValidator, FinancialMetrics
from .features import AlternativeDataIntegrator, SentimentAnalyzer, MarketRegimeDetector
from .models import ARIMAGARCHModel, TemporalFusionTransformer, MixtureDensityNetwork
from .validation import WalkForwardValidator, FinancialBacktester, RiskMetricsCalculator
from .optimizer import FinancialObjectiveOptimizer, HyperparameterOptimizer, EnsembleOptimizer


@dataclass
class PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    # ë°ì´í„° ì„¤ì •
    symbol: str = "SPY"
    start_date: str = "2020-01-01"
    end_date: Optional[str] = None

    # ëª¨ë¸ ì„¤ì •
    models_to_train: List[str] = None

    # ê²€ì¦ ì„¤ì •
    train_size: int = 252
    test_size: int = 21
    walk_forward_steps: int = 21

    # ìµœì í™” ì„¤ì •
    optimize_hyperparameters: bool = True
    optimization_method: str = "grid_search"

    # ë°±í…ŒìŠ¤íŒ… ì„¤ì •
    initial_capital: float = 100000.0
    transaction_cost: float = 0.001

    # API í‚¤ (ì„ íƒì )
    fred_api_key: Optional[str] = None
    news_api_key: Optional[str] = None

    def __post_init__(self):
        if self.models_to_train is None:
            self.models_to_train = ["arima_garch", "tft", "mdn"]


@dataclass
class PipelineResult:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼"""
    data_summary: Dict
    model_results: Dict
    optimization_results: Dict
    validation_results: Dict
    backtest_results: Dict
    risk_metrics: Dict
    ensemble_weights: Optional[Any]
    final_recommendations: Dict


class AdvancedFinancialPipeline:
    """
    Advanced Financial Forecasting Pipeline

    ê·¼ë³¸ì  ì ‘ê·¼ë²• ë³€ê²½ì„ êµ¬í˜„í•œ ì™„ì „í•œ íŒŒì´í”„ë¼ì¸:
    - ê°€ê²© â†’ ë¡œê·¸ ìˆ˜ìµë¥  ì˜ˆì¸¡ íŒ¨ëŸ¬ë‹¤ì„
    - í†µê³„ì  ì •ìƒì„± ë° ì‹œê³„ì—´ ì•ˆì „ì„±
    - ê³ ê¸‰ ê³„ëŸ‰ê²½ì œ/ë”¥ëŸ¬ë‹ ëª¨ë¸
    - ê¸ˆìœµ ì„±ê³¼ ì§€í‘œ ê¸°ë°˜ ìµœì í™”
    - í¬ê´„ì  ë¦¬ìŠ¤í¬ ê´€ë¦¬
    """

    def __init__(self, config: PipelineConfig):
        self.config = config

        # í•µì‹¬ êµ¬ì„±ìš”ì†Œ ì´ˆê¸°í™”
        self.log_processor = LogReturnProcessor()
        self.time_validator = TimeSeriesSafeValidator()
        self.data_integrator = AlternativeDataIntegrator(config.fred_api_key)
        self.sentiment_analyzer = SentimentAnalyzer()
        self.regime_detector = MarketRegimeDetector()

        # ê²€ì¦ ë° ìµœì í™” êµ¬ì„±ìš”ì†Œ
        self.walk_forward_validator = WalkForwardValidator(
            initial_train_size=config.train_size,
            test_size=config.test_size,
            step_size=config.walk_forward_steps
        )
        self.financial_objective = FinancialObjectiveOptimizer()
        self.hyperparameter_optimizer = HyperparameterOptimizer(
            self.financial_objective,
            self.walk_forward_validator,
            config.optimization_method
        )

        # ë°±í…ŒìŠ¤íŒ… ë° ë¦¬ìŠ¤í¬ êµ¬ì„±ìš”ì†Œ
        self.backtester = FinancialBacktester(
            initial_capital=config.initial_capital,
            transaction_cost=config.transaction_cost
        )
        self.risk_calculator = RiskMetricsCalculator()
        self.ensemble_optimizer = EnsembleOptimizer()

    def run_complete_pipeline(self) -> PipelineResult:
        """ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ Advanced Financial Forecasting Pipeline ì‹œì‘")
        print("=" * 60)

        try:
            # 1. ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
            print("\nğŸ“Š 1ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬")
            data_summary, processed_data = self._collect_and_preprocess_data()

            # 2. ëŒ€ì²´ ë°ì´í„° í†µí•©
            print("\nğŸ”— 2ë‹¨ê³„: ëŒ€ì²´ ë°ì´í„° í†µí•©")
            enhanced_data = self._integrate_alternative_data(processed_data)

            # 3. ëª¨ë¸ í›ˆë ¨ ë° ìµœì í™”
            print("\nğŸ¤– 3ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨ ë° ìµœì í™”")
            model_results, optimization_results = self._train_and_optimize_models(enhanced_data)

            # 4. Walk-Forward ê²€ì¦
            print("\nğŸ”„ 4ë‹¨ê³„: Walk-Forward ê²€ì¦")
            validation_results = self._perform_walk_forward_validation(enhanced_data, model_results)

            # 5. ë°±í…ŒìŠ¤íŒ…
            print("\nğŸ“ˆ 5ë‹¨ê³„: ë°±í…ŒìŠ¤íŒ… ë° ì„±ê³¼ í‰ê°€")
            backtest_results = self._perform_backtesting(enhanced_data, model_results)

            # 6. ë¦¬ìŠ¤í¬ í‰ê°€
            print("\nâš ï¸ 6ë‹¨ê³„: ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°")
            risk_metrics = self._calculate_risk_metrics(backtest_results)

            # 7. ì•™ìƒë¸” ìµœì í™”
            print("\nğŸ¯ 7ë‹¨ê³„: ì•™ìƒë¸” ìµœì í™”")
            ensemble_weights = self._optimize_ensemble(enhanced_data, model_results)

            # 8. ìµœì¢… ê¶Œì¥ì‚¬í•­ ìƒì„±
            print("\nğŸ“‹ 8ë‹¨ê³„: ìµœì¢… ê¶Œì¥ì‚¬í•­ ìƒì„±")
            final_recommendations = self._generate_recommendations(
                validation_results, backtest_results, risk_metrics, ensemble_weights
            )

            # ê²°ê³¼ íŒ¨í‚¤ì§•
            result = PipelineResult(
                data_summary=data_summary,
                model_results=model_results,
                optimization_results=optimization_results,
                validation_results=validation_results,
                backtest_results=backtest_results,
                risk_metrics=risk_metrics,
                ensemble_weights=ensemble_weights,
                final_recommendations=final_recommendations
            )

            print("\nâœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            print("=" * 60)

            return result

        except Exception as e:
            print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise

    def _collect_and_preprocess_data(self) -> Tuple[Dict, pd.DataFrame]:
        """ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬"""
        if YFINANCE_AVAILABLE:
            # yfinanceë¡œ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
            ticker = yf.Ticker(self.config.symbol)
            data = ticker.history(
                start=self.config.start_date,
                end=self.config.end_date
            )
            prices = data['Close']
        else:
            # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
            print("âš ï¸ yfinance ì—†ì–´ì„œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì‚¬ìš©")
            dates = pd.date_range(
                start=self.config.start_date,
                end=self.config.end_date or pd.Timestamp.now(),
                freq='D'
            )
            # í˜„ì‹¤ì ì¸ ê°€ê²© ì‹œë®¬ë ˆì´ì…˜ (ê¸°í•˜ ë¸Œë¼ìš´ ìš´ë™)
            returns = np.random.normal(0.0008, 0.02, len(dates))  # ì¼ì¼ ìˆ˜ìµë¥ 
            prices = pd.Series(100 * np.exp(np.cumsum(returns)), index=dates, name='Close')

        # ì‹œê°„ ìˆœì„œ ê²€ì¦
        is_valid = self.time_validator.validate_temporal_order(
            pd.DataFrame({'Close': prices})
        )

        if not is_valid:
            print("âš ï¸ ì‹œê°„ ìˆœì„œ ë¬¸ì œ ê°ì§€, ë°ì´í„° ì •ë ¬ ì¤‘...")
            prices = prices.sort_index()

        # ë¡œê·¸ ìˆ˜ìµë¥  ë³€í™˜
        log_returns = self.log_processor.price_to_log_returns(prices)

        # ì •ìƒì„± ê²€ì¦ ë° í™•ë³´
        stationary_returns, transformations = self.log_processor.ensure_stationarity(log_returns)

        # ê¸°ë³¸ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        processed_data = self._calculate_technical_indicators(prices, stationary_returns)

        data_summary = {
            'symbol': self.config.symbol,
            'period': f"{prices.index[0]} ~ {prices.index[-1]}",
            'observations': len(prices),
            'price_range': f"${prices.min():.2f} ~ ${prices.max():.2f}",
            'transformations_applied': transformations,
            'stationarity_achieved': len(transformations) > 0,
            'missing_values': processed_data.isnull().sum().sum()
        }

        print(f"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   ê¸°ê°„: {data_summary['period']}")
        print(f"   ê´€ì¸¡ì¹˜: {data_summary['observations']}ê°œ")
        print(f"   ë³€í™˜: {transformations}")

        return data_summary, processed_data

    def _calculate_technical_indicators(self, prices: pd.Series, returns: pd.Series) -> pd.DataFrame:
        """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
        data = pd.DataFrame({
            'price': prices,
            'log_returns': returns
        })

        # ì´ë™í‰ê· 
        data['ma_5'] = prices.rolling(5).mean()
        data['ma_20'] = prices.rolling(20).mean()
        data['ma_50'] = prices.rolling(50).mean()

        # ë³€ë™ì„± ì§€í‘œ
        data['volatility_5d'] = returns.rolling(5).std()
        data['volatility_20d'] = returns.rolling(20).std()

        # ëª¨ë©˜í…€ ì§€í‘œ
        data['rsi'] = self._calculate_rsi(prices, window=14)
        data['price_momentum_5d'] = prices.pct_change(5)
        data['price_momentum_20d'] = prices.pct_change(20)

        # ë³¼ë¦°ì € ë°´ë“œ
        bb_ma = prices.rolling(20).mean()
        bb_std = prices.rolling(20).std()
        data['bb_upper'] = bb_ma + 2 * bb_std
        data['bb_lower'] = bb_ma - 2 * bb_std
        data['bb_position'] = (prices - bb_lower) / (bb_upper - bb_lower)

        # íƒ€ê²Ÿ ë³€ìˆ˜: ë‹¤ìŒ ê¸°ê°„ ë¡œê·¸ ìˆ˜ìµë¥ 
        data['target_return'] = returns.shift(-1)

        return data.dropna()

    def _calculate_rsi(self, prices: pd.Series, window: int = 14) -> pd.Series:
        """RSI ê³„ì‚°"""
        delta = prices.diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)

        avg_gain = gain.rolling(window).mean()
        avg_loss = loss.rolling(window).mean()

        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))
        return rsi

    def _integrate_alternative_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """ëŒ€ì²´ ë°ì´í„° í†µí•©"""
        enhanced_data = data.copy()

        try:
            # ê±°ì‹œê²½ì œ ì§€í‘œ í†µí•©
            macro_data = self.data_integrator.fetch_macro_indicators(
                start_date=self.config.start_date,
                end_date=self.config.end_date
            )

            # ê³µí†µ ë‚ ì§œë¡œ ë³‘í•©
            enhanced_data = enhanced_data.join(macro_data, how='left')
            enhanced_data = enhanced_data.fillna(method='ffill')

            print(f"âœ… ê±°ì‹œê²½ì œ ì§€í‘œ {len(macro_data.columns)}ê°œ í†µí•© ì™„ë£Œ")

        except Exception as e:
            print(f"âš ï¸ ê±°ì‹œê²½ì œ ì§€í‘œ í†µí•© ì‹¤íŒ¨: {e}")

        try:
            # ì„¼í‹°ë©˜íŠ¸ ë°ì´í„° í†µí•©
            sentiment_data = self.sentiment_analyzer.generate_sentiment_time_series(
                start_date=self.config.start_date,
                end_date=self.config.end_date,
                simulate=True  # ì‹¤ì œ ë‰´ìŠ¤ API ì—†ìœ¼ë¯€ë¡œ ì‹œë®¬ë ˆì´ì…˜
            )

            enhanced_data = enhanced_data.join(sentiment_data, how='left')
            enhanced_data = enhanced_data.fillna(method='ffill')

            print(f"âœ… ì„¼í‹°ë©˜íŠ¸ ì§€í‘œ {len(sentiment_data.columns)}ê°œ í†µí•© ì™„ë£Œ")

        except Exception as e:
            print(f"âš ï¸ ì„¼í‹°ë©˜íŠ¸ ë°ì´í„° í†µí•© ì‹¤íŒ¨: {e}")

        try:
            # ì‹œì¥ ë ˆì§ ê°ì§€
            regime_data = self.regime_detector.predict_regime(
                enhanced_data['log_returns'],
                enhanced_data['volatility_20d']
            )

            enhanced_data = enhanced_data.join(regime_data, how='left')
            enhanced_data = enhanced_data.fillna(method='ffill')

            print(f"âœ… ì‹œì¥ ë ˆì§ ë°ì´í„° í†µí•© ì™„ë£Œ")

        except Exception as e:
            print(f"âš ï¸ ì‹œì¥ ë ˆì§ ê°ì§€ ì‹¤íŒ¨: {e}")

        # ìµœì¢… ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        enhanced_data = enhanced_data.dropna()

        print(f"âœ… ëŒ€ì²´ ë°ì´í„° í†µí•© ì™„ë£Œ: {len(enhanced_data.columns)}ê°œ íŠ¹ì„±, {len(enhanced_data)}ê°œ ê´€ì¸¡ì¹˜")

        return enhanced_data

    def _train_and_optimize_models(self, data: pd.DataFrame) -> Tuple[Dict, Dict]:
        """ëª¨ë¸ í›ˆë ¨ ë° ìµœì í™”"""
        model_results = {}
        optimization_results = {}

        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        feature_columns = [col for col in data.columns if col != 'target_return']
        X = data[feature_columns]
        y = data['target_return']

        print(f"   íŠ¹ì„± ìˆ˜: {len(feature_columns)}")
        print(f"   ìƒ˜í”Œ ìˆ˜: {len(X)}")

        for model_name in self.config.models_to_train:
            try:
                print(f"\nğŸ”§ {model_name} ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")

                if model_name == "arima_garch":
                    model, optimization_result = self._train_arima_garch(X, y)
                elif model_name == "tft":
                    model, optimization_result = self._train_tft(X, y)
                elif model_name == "mdn":
                    model, optimization_result = self._train_mdn(X, y)
                else:
                    print(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {model_name}")
                    continue

                model_results[model_name] = model
                optimization_results[model_name] = optimization_result

                print(f"âœ… {model_name} í›ˆë ¨ ì™„ë£Œ")

            except Exception as e:
                print(f"âŒ {model_name} í›ˆë ¨ ì‹¤íŒ¨: {e}")
                continue

        return model_results, optimization_results

    def _train_arima_garch(self, X: pd.DataFrame, y: pd.Series) -> Tuple[Any, Dict]:
        """ARIMA-GARCH ëª¨ë¸ í›ˆë ¨"""
        # ê°„ë‹¨í•œ ARIMA-GARCH êµ¬í˜„ (ì‹œë®¬ë ˆì´ì…˜)
        from sklearn.linear_model import Ridge

        model = Ridge(alpha=1.0)

        # ê¸°ë³¸ í›ˆë ¨
        model.fit(X.iloc[:-50], y.iloc[:-50])  # ë§ˆì§€ë§‰ 50ê°œëŠ” í…ŒìŠ¤íŠ¸ìš© ë³´ì¡´

        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ì˜µì…˜)
        optimization_result = {}
        if self.config.optimize_hyperparameters:
            param_grid = {'alpha': [0.1, 1.0, 10.0, 100.0]}

            try:
                opt_result = self.hyperparameter_optimizer.optimize_hyperparameters(
                    Ridge, X.iloc[:-50], y.iloc[:-50], param_grid
                )
                model = Ridge(**opt_result.best_params)
                model.fit(X.iloc[:-50], y.iloc[:-50])
                optimization_result = opt_result.__dict__
            except Exception as e:
                print(f"âš ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤íŒ¨: {e}")

        return model, optimization_result

    def _train_tft(self, X: pd.DataFrame, y: pd.Series) -> Tuple[Any, Dict]:
        """TFT ëª¨ë¸ í›ˆë ¨ (ê°„ë‹¨í•œ ëŒ€ì²´ êµ¬í˜„)"""
        from sklearn.ensemble import RandomForestRegressor

        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X.iloc[:-50], y.iloc[:-50])

        optimization_result = {}
        if self.config.optimize_hyperparameters:
            param_grid = {
                'n_estimators': [50, 100, 200],
                'max_depth': [5, 10, 15]
            }

            try:
                opt_result = self.hyperparameter_optimizer.optimize_hyperparameters(
                    RandomForestRegressor, X.iloc[:-50], y.iloc[:-50], param_grid
                )
                model = RandomForestRegressor(**opt_result.best_params, random_state=42)
                model.fit(X.iloc[:-50], y.iloc[:-50])
                optimization_result = opt_result.__dict__
            except Exception as e:
                print(f"âš ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤íŒ¨: {e}")

        return model, optimization_result

    def _train_mdn(self, X: pd.DataFrame, y: pd.Series) -> Tuple[Any, Dict]:
        """MDN ëª¨ë¸ í›ˆë ¨ (ê°„ë‹¨í•œ ëŒ€ì²´ êµ¬í˜„)"""
        from sklearn.ensemble import GradientBoostingRegressor

        model = GradientBoostingRegressor(n_estimators=100, random_state=42)
        model.fit(X.iloc[:-50], y.iloc[:-50])

        optimization_result = {}
        if self.config.optimize_hyperparameters:
            param_grid = {
                'n_estimators': [50, 100, 200],
                'learning_rate': [0.05, 0.1, 0.2],
                'max_depth': [3, 5, 7]
            }

            try:
                opt_result = self.hyperparameter_optimizer.optimize_hyperparameters(
                    GradientBoostingRegressor, X.iloc[:-50], y.iloc[:-50], param_grid
                )
                model = GradientBoostingRegressor(**opt_result.best_params, random_state=42)
                model.fit(X.iloc[:-50], y.iloc[:-50])
                optimization_result = opt_result.__dict__
            except Exception as e:
                print(f"âš ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤íŒ¨: {e}")

        return model, optimization_result

    def _perform_walk_forward_validation(self, data: pd.DataFrame, models: Dict) -> Dict:
        """Walk-Forward ê²€ì¦ ìˆ˜í–‰"""
        validation_results = {}

        feature_columns = [col for col in data.columns if col != 'target_return']
        X = data[feature_columns]
        y = data['target_return']

        for model_name, model in models.items():
            try:
                print(f"   {model_name} Walk-Forward ê²€ì¦ ì¤‘...")

                cv_results = self.walk_forward_validator.validate(model, X, y)
                summary = self.walk_forward_validator.summarize_results(cv_results)

                validation_results[model_name] = {
                    'cv_results': cv_results,
                    'summary': summary
                }

                print(f"   âœ… {model_name}: í…ŒìŠ¤íŠ¸ ì ìˆ˜ {summary.get('test_score_mean', 0):.4f} "
                      f"(Â±{summary.get('test_score_std', 0):.4f})")

            except Exception as e:
                print(f"   âŒ {model_name} ê²€ì¦ ì‹¤íŒ¨: {e}")

        return validation_results

    def _perform_backtesting(self, data: pd.DataFrame, models: Dict) -> Dict:
        """ë°±í…ŒìŠ¤íŒ… ìˆ˜í–‰"""
        backtest_results = {}

        prices = data['price']
        feature_columns = [col for col in data.columns if col != 'target_return']
        X = data[feature_columns]

        for model_name, model in models.items():
            try:
                print(f"   {model_name} ë°±í…ŒìŠ¤íŒ… ì¤‘...")

                # ì˜ˆì¸¡ ì‹ í˜¸ ìƒì„±
                predictions = model.predict(X)

                # ë§¤ë§¤ ì‹ í˜¸ ìƒì„± (ì˜ˆì¸¡ê°’ì´ ì–‘ìˆ˜ë©´ ë§¤ìˆ˜, ìŒìˆ˜ë©´ ë§¤ë„)
                signals = pd.Series(
                    np.where(predictions > 0, 1, -1),
                    index=X.index
                )

                # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
                backtest_result = self.backtester.backtest_strategy(
                    prices, signals, f"{model_name}_strategy"
                )

                backtest_results[model_name] = backtest_result

                print(f"   âœ… {model_name}: ì´ìˆ˜ìµë¥  {backtest_result.total_return:.2%}, "
                      f"ìƒ¤í”„ë¹„ìœ¨ {backtest_result.sharpe_ratio:.3f}")

            except Exception as e:
                print(f"   âŒ {model_name} ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨: {e}")

        return backtest_results

    def _calculate_risk_metrics(self, backtest_results: Dict) -> Dict:
        """ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°"""
        risk_metrics = {}

        for model_name, backtest_result in backtest_results.items():
            try:
                portfolio_returns = backtest_result.portfolio_value.pct_change().dropna()

                # ë²¤ì¹˜ë§ˆí¬ëŠ” ë§¤ìˆ˜ í›„ ë³´ìœ  ì „ëµìœ¼ë¡œ ì„¤ì •
                comprehensive_metrics = self.risk_calculator.calculate_comprehensive_risk_metrics(
                    portfolio_returns
                )

                risk_report = self.risk_calculator.generate_risk_report(portfolio_returns)

                risk_metrics[model_name] = {
                    'comprehensive_metrics': comprehensive_metrics,
                    'detailed_report': risk_report
                }

                print(f"   âœ… {model_name} ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚° ì™„ë£Œ")

            except Exception as e:
                print(f"   âŒ {model_name} ë¦¬ìŠ¤í¬ ê³„ì‚° ì‹¤íŒ¨: {e}")

        return risk_metrics

    def _optimize_ensemble(self, data: pd.DataFrame, models: Dict) -> Optional[Any]:
        """ì•™ìƒë¸” ìµœì í™”"""
        try:
            feature_columns = [col for col in data.columns if col != 'target_return']
            X = data[feature_columns]
            y = data['target_return']

            # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ìˆ˜ì§‘
            model_predictions = {}
            for model_name, model in models.items():
                predictions = model.predict(X)
                model_predictions[model_name] = predictions

            # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”
            ensemble_weights = self.ensemble_optimizer.optimize_ensemble_weights(
                model_predictions, y.values, method="markowitz"
            )

            print(f"   âœ… ì•™ìƒë¸” ìµœì í™” ì™„ë£Œ: ìƒ¤í”„ë¹„ìœ¨ {ensemble_weights.sharpe_ratio:.3f}")

            return ensemble_weights

        except Exception as e:
            print(f"   âŒ ì•™ìƒë¸” ìµœì í™” ì‹¤íŒ¨: {e}")
            return None

    def _generate_recommendations(
        self,
        validation_results: Dict,
        backtest_results: Dict,
        risk_metrics: Dict,
        ensemble_weights: Optional[Any]
    ) -> Dict:
        """ìµœì¢… ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = {
            'best_individual_model': None,
            'model_rankings': [],
            'risk_assessment': {},
            'ensemble_recommendation': {},
            'deployment_readiness': {},
            'next_steps': []
        }

        # ëª¨ë¸ ìˆœìœ„ ë§¤ê¸°ê¸° (ìƒ¤í”„ ë¹„ìœ¨ ê¸°ì¤€)
        model_scores = {}
        for model_name in backtest_results.keys():
            if model_name in backtest_results:
                sharpe_ratio = backtest_results[model_name].sharpe_ratio
                total_return = backtest_results[model_name].total_return
                max_drawdown = backtest_results[model_name].max_drawdown

                # ë³µí•© ì ìˆ˜ ê³„ì‚° (ìƒ¤í”„ ë¹„ìœ¨ + ìˆ˜ìµë¥  - ë‚™í­ í˜ë„í‹°)
                composite_score = sharpe_ratio + total_return - max_drawdown
                model_scores[model_name] = {
                    'composite_score': composite_score,
                    'sharpe_ratio': sharpe_ratio,
                    'total_return': total_return,
                    'max_drawdown': max_drawdown
                }

        # ìˆœìœ„ ì •ë ¬
        sorted_models = sorted(
            model_scores.items(),
            key=lambda x: x[1]['composite_score'],
            reverse=True
        )

        recommendations['model_rankings'] = sorted_models
        recommendations['best_individual_model'] = sorted_models[0][0] if sorted_models else None

        # ë¦¬ìŠ¤í¬ í‰ê°€
        recommendations['risk_assessment'] = {
            'low_risk_models': [
                model for model, metrics in model_scores.items()
                if metrics['max_drawdown'] < 0.15
            ],
            'high_return_models': [
                model for model, metrics in model_scores.items()
                if metrics['total_return'] > 0.1
            ],
            'balanced_models': [
                model for model, metrics in model_scores.items()
                if metrics['sharpe_ratio'] > 0.5 and metrics['max_drawdown'] < 0.2
            ]
        }

        # ì•™ìƒë¸” ê¶Œì¥ì‚¬í•­
        if ensemble_weights:
            recommendations['ensemble_recommendation'] = {
                'use_ensemble': True,
                'expected_sharpe': ensemble_weights.sharpe_ratio,
                'diversification_benefit': ensemble_weights.diversification_ratio > 1.1,
                'weights': dict(zip(backtest_results.keys(), ensemble_weights.weights))
            }

        # ë°°í¬ ì¤€ë¹„ë„ í‰ê°€
        for model_name in backtest_results.keys():
            stability_score = 0

            # ê²€ì¦ ì•ˆì •ì„± í™•ì¸
            if model_name in validation_results:
                test_score_std = validation_results[model_name]['summary'].get('test_score_std', 1.0)
                stability_score += 50 if test_score_std < 0.1 else 0

            # ë°±í…ŒìŠ¤íŒ… ì„±ê³¼ í™•ì¸
            if model_name in backtest_results:
                sharpe = backtest_results[model_name].sharpe_ratio
                stability_score += 50 if sharpe > 0.5 else 25 if sharpe > 0 else 0

            deployment_ready = stability_score >= 75

            recommendations['deployment_readiness'][model_name] = {
                'ready': deployment_ready,
                'stability_score': stability_score,
                'confidence_level': 'High' if stability_score >= 75 else 'Medium' if stability_score >= 50 else 'Low'
            }

        # ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­
        recommendations['next_steps'] = [
            "ì‹¤ì‹œê°„ ë°ì´í„° í”¼ë“œ êµ¬ì¶•",
            "í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬ ì¤€ë¹„",
            "ëª¨ë‹ˆí„°ë§ ë° ì•ŒëŒ ì‹œìŠ¤í…œ êµ¬ì¶•",
            "ì„±ê³¼ ì¶”ì  ëŒ€ì‹œë³´ë“œ ê°œë°œ",
            "ì •ê¸° ëª¨ë¸ ì¬í›ˆë ¨ ìŠ¤ì¼€ì¤„ ì„¤ì •"
        ]

        return recommendations


def run_example_pipeline():
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜ˆì œ"""
    print("ğŸ“ˆ Advanced Financial Forecasting Pipeline ì˜ˆì œ ì‹¤í–‰")

    # ì„¤ì • ìƒì„±
    config = PipelineConfig(
        symbol="SPY",
        start_date="2022-01-01",
        end_date="2024-01-01",
        models_to_train=["arima_garch", "tft", "mdn"],
        optimize_hyperparameters=True,
        initial_capital=100000.0
    )

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = AdvancedFinancialPipeline(config)
    result = pipeline.run_complete_pipeline()

    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½")
    print("="*60)

    print(f"\nğŸ“ˆ ë°ì´í„° ìš”ì•½:")
    for key, value in result.data_summary.items():
        print(f"   {key}: {value}")

    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {result.final_recommendations.get('best_individual_model', 'N/A')}")

    print(f"\nğŸ“Š ëª¨ë¸ ìˆœìœ„:")
    for i, (model_name, metrics) in enumerate(result.final_recommendations.get('model_rankings', []), 1):
        print(f"   {i}. {model_name}: ìƒ¤í”„ë¹„ìœ¨ {metrics['sharpe_ratio']:.3f}, "
              f"ìˆ˜ìµë¥  {metrics['total_return']:.2%}")

    if result.ensemble_weights:
        print(f"\nğŸ¯ ì•™ìƒë¸” ê¶Œì¥:")
        print(f"   ì˜ˆìƒ ìƒ¤í”„ë¹„ìœ¨: {result.ensemble_weights.sharpe_ratio:.3f}")
        print(f"   ë‹¤ê°í™” íš¨ê³¼: {result.ensemble_weights.diversification_ratio:.3f}")

    return result


if __name__ == "__main__":
    # ì˜ˆì œ ì‹¤í–‰
    result = run_example_pipeline()