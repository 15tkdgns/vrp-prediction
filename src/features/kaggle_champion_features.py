#!/usr/bin/env python3
"""
ğŸ† ìºê¸€ ì±”í”¼ì–¸ íŠ¹ì„± ê³µí•™ ì‹œìŠ¤í…œ

Optiver 1ë“± ì†”ë£¨ì…˜ ê¸°ë°˜ 300ê°œ ê³ ê¸‰ íŠ¹ì„± ìƒì„±
FFT, ì›¨ì´ë¸”ë¦¿, ê·¸ë˜í”„ íŠ¹ì„± ë“± ìµœì‹  ê¸°ë²• ì ìš©
"""

import numpy as np
import pandas as pd
from scipy import signal
from scipy.fft import fft, fftfreq
from scipy.stats import skew, kurtosis, pearsonr
import networkx as nx
from sklearn.preprocessing import StandardScaler, RobustScaler
import warnings
warnings.filterwarnings('ignore')

class KaggleChampionFeatures:
    """ìºê¸€ ìš°ìŠ¹ì ê¸°ë²• ê¸°ë°˜ ê³ ê¸‰ íŠ¹ì„± ìƒì„±"""

    def __init__(self, lookback_window=21):
        self.lookback_window = lookback_window
        self.scaler = RobustScaler()
        print(f"ğŸ† ìºê¸€ ì±”í”¼ì–¸ íŠ¹ì„± ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ìœˆë„ìš°: {lookback_window}ì¼)")

    def generate_champion_features(self, df, cache_results=True):
        """300ê°œ ê³ ê¸‰ íŠ¹ì„± ìƒì„± (Optiver ìš°ìŠ¹ ê¸°ë²•)"""
        print("ğŸ”¥ 300ê°œ ê³ ê¸‰ íŠ¹ì„± ìƒì„± ì‹œì‘...")

        df = df.copy()
        features_df = df.copy()

        # ê¸°ë³¸ ì „ì²˜ë¦¬
        features_df = self._preprocess_data(features_df)

        # 1. ê°€ê²© ê¸°ë°˜ íŠ¹ì„± (50ê°œ)
        features_df = self._create_price_features(features_df)

        # 2. ë³¼ë¥¨ ê¸°ë°˜ íŠ¹ì„± (40ê°œ)
        features_df = self._create_volume_features(features_df)

        # 3. ë³€ë™ì„± íŠ¹ì„± (30ê°œ)
        features_df = self._create_volatility_features(features_df)

        # 4. ëª¨ë©˜í…€ íŠ¹ì„± (40ê°œ)
        features_df = self._create_momentum_features(features_df)

        # 5. FFT/ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì„± (25ê°œ)
        features_df = self._create_frequency_features(features_df)

        # 6. ì›¨ì´ë¸”ë¦¿ íŠ¹ì„± (20ê°œ)
        features_df = self._create_wavelet_features(features_df)

        # 7. í†µê³„ì  íŠ¹ì„± (30ê°œ)
        features_df = self._create_statistical_features(features_df)

        # 8. êµì°¨ íŠ¹ì„± (25ê°œ)
        features_df = self._create_cross_features(features_df)

        # 9. ê·¸ë˜í”„/ë„¤íŠ¸ì›Œí¬ íŠ¹ì„± (15ê°œ)
        features_df = self._create_graph_features(features_df)

        # 10. ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ (25ê°œ)
        features_df = self._create_advanced_indicators(features_df)

        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        features_df = self._handle_missing_values(features_df)

        print(f"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: {features_df.shape[1]}ê°œ íŠ¹ì„±")
        return features_df

    def _preprocess_data(self, df):
        """ê¸°ë³¸ ì „ì²˜ë¦¬"""
        # ê¸°ë³¸ ê°€ê²© íŠ¹ì„±
        df['returns'] = df['Close'].pct_change()
        df['log_returns'] = np.log(df['Close'] / df['Close'].shift(1))
        df['true_range'] = np.maximum(
            df['High'] - df['Low'],
            np.maximum(
                abs(df['High'] - df['Close'].shift(1)),
                abs(df['Low'] - df['Close'].shift(1))
            )
        )

        # ê°€ê²© ì •ê·œí™”
        df['norm_close'] = df['Close'] / df['Close'].rolling(20).mean()
        df['norm_volume'] = df['Volume'] / df['Volume'].rolling(20).mean()

        return df

    def _create_price_features(self, df):
        """1. ê°€ê²© ê¸°ë°˜ íŠ¹ì„± (50ê°œ)"""
        print("   ğŸ“ˆ ê°€ê²© íŠ¹ì„± ìƒì„±...")

        # ë‹¤ì–‘í•œ ê¸°ê°„ ìˆ˜ìµë¥ 
        periods = [1, 2, 3, 5, 8, 13, 21, 34, 55]
        for period in periods:
            df[f'return_{period}d'] = df['Close'].pct_change(period)
            df[f'log_return_{period}d'] = np.log(df['Close'] / df['Close'].shift(period))

        # OHLC ê´€ë ¨ íŠ¹ì„±
        df['hl_ratio'] = (df['High'] - df['Low']) / df['Close']
        df['oc_ratio'] = (df['Open'] - df['Close']) / df['Close']
        df['upper_shadow'] = (df['High'] - np.maximum(df['Open'], df['Close'])) / df['Close']
        df['lower_shadow'] = (np.minimum(df['Open'], df['Close']) - df['Low']) / df['Close']
        df['body_ratio'] = abs(df['Open'] - df['Close']) / (df['High'] - df['Low'] + 1e-8)

        # ê°€ê²© ìœ„ì¹˜ íŠ¹ì„±
        windows = [5, 10, 20, 50]
        for window in windows:
            high_roll = df['High'].rolling(window)
            low_roll = df['Low'].rolling(window)
            df[f'price_position_{window}'] = (df['Close'] - low_roll.min()) / (high_roll.max() - low_roll.min() + 1e-8)
            df[f'high_low_ratio_{window}'] = df['High'] / df['Low']

        # ê°­ íŠ¹ì„±
        df['gap_up'] = np.maximum(0, df['Open'] - df['Close'].shift(1)) / df['Close'].shift(1)
        df['gap_down'] = np.maximum(0, df['Close'].shift(1) - df['Open']) / df['Close'].shift(1)

        # ê°€ê²© ê°€ì†ë„
        for period in [3, 5, 10]:
            df[f'price_acceleration_{period}'] = df['Close'].diff(period) - df['Close'].diff(period).shift(period)

        return df

    def _create_volume_features(self, df):
        """2. ë³¼ë¥¨ ê¸°ë°˜ íŠ¹ì„± (40ê°œ)"""
        print("   ğŸ“Š ë³¼ë¥¨ íŠ¹ì„± ìƒì„±...")

        # ê¸°ë³¸ ë³¼ë¥¨ íŠ¹ì„±
        windows = [5, 10, 20, 50]
        for window in windows:
            vol_roll = df['Volume'].rolling(window)
            df[f'volume_sma_{window}'] = vol_roll.mean()
            df[f'volume_std_{window}'] = vol_roll.std()
            df[f'volume_ratio_{window}'] = df['Volume'] / df[f'volume_sma_{window}']
            df[f'volume_zscore_{window}'] = (df['Volume'] - df[f'volume_sma_{window}']) / df[f'volume_std_{window}']

        # VWAP ê´€ë ¨
        df['typical_price'] = (df['High'] + df['Low'] + df['Close']) / 3
        for window in [5, 10, 20]:
            vwap = (df['typical_price'] * df['Volume']).rolling(window).sum() / df['Volume'].rolling(window).sum()
            df[f'vwap_{window}'] = vwap
            df[f'vwap_ratio_{window}'] = df['Close'] / vwap

        # Volume-Price Trend (VPT)
        df['vpt'] = (df['Volume'] * df['returns']).cumsum()
        for window in [10, 20]:
            df[f'vpt_sma_{window}'] = df['vpt'].rolling(window).mean()

        # On-Balance Volume (OBV)
        df['obv'] = (df['Volume'] * np.where(df['returns'] > 0, 1, -1)).cumsum()
        for window in [10, 20]:
            df[f'obv_sma_{window}'] = df['obv'].rolling(window).mean()

        # Volume Rate of Change
        for period in [5, 10, 20]:
            df[f'volume_roc_{period}'] = df['Volume'].pct_change(period)

        # Accumulation/Distribution Line
        df['ad_line'] = ((df['Close'] - df['Low']) - (df['High'] - df['Close'])) / (df['High'] - df['Low'] + 1e-8) * df['Volume']
        df['ad_line'] = df['ad_line'].cumsum()

        return df

    def _create_volatility_features(self, df):
        """3. ë³€ë™ì„± íŠ¹ì„± (30ê°œ)"""
        print("   ğŸ“ˆ ë³€ë™ì„± íŠ¹ì„± ìƒì„±...")

        # ë‹¤ì–‘í•œ ê¸°ê°„ ë³€ë™ì„±
        windows = [5, 10, 20, 30, 60]
        for window in windows:
            returns_roll = df['returns'].rolling(window)
            df[f'volatility_{window}'] = returns_roll.std()
            df[f'realized_vol_{window}'] = np.sqrt((df['returns']**2).rolling(window).sum())

        # True Range ê¸°ë°˜ ë³€ë™ì„±
        for window in [5, 10, 20]:
            df[f'atr_{window}'] = df['true_range'].rolling(window).mean()
            df[f'atr_ratio_{window}'] = df['true_range'] / df[f'atr_{window}']

        # ë³€ë™ì„±ì˜ ë³€ë™ì„±
        for window in [10, 20]:
            vol_col = f'volatility_{window}'
            df[f'vol_of_vol_{window}'] = df[vol_col].rolling(window).std()

        # ê³ ë³€ë™ì„±/ì €ë³€ë™ì„± ê¸°ê°„
        df['high_vol_20'] = (df['volatility_20'] > df['volatility_20'].rolling(60).quantile(0.8)).astype(int)
        df['low_vol_20'] = (df['volatility_20'] < df['volatility_20'].rolling(60).quantile(0.2)).astype(int)

        # Parkinson ë³€ë™ì„± ì¶”ì •ê¸°
        for window in [5, 10, 20]:
            hl_ratio = np.log(df['High'] / df['Low'])
            df[f'parkinson_vol_{window}'] = np.sqrt((hl_ratio**2).rolling(window).mean() / (4 * np.log(2)))

        return df

    def _create_momentum_features(self, df):
        """4. ëª¨ë©˜í…€ íŠ¹ì„± (40ê°œ)"""
        print("   ğŸš€ ëª¨ë©˜í…€ íŠ¹ì„± ìƒì„±...")

        # RSI ë³€í˜•
        rsi_periods = [7, 14, 21, 30]
        for period in rsi_periods:
            df[f'rsi_{period}'] = self._calculate_rsi(df['Close'], period)
            df[f'rsi_smooth_{period}'] = df[f'rsi_{period}'].rolling(3).mean()

        # Stochastic Oscillator
        for k_period, d_period in [(14, 3), (21, 5)]:
            lowest_low = df['Low'].rolling(k_period).min()
            highest_high = df['High'].rolling(k_period).max()
            k_percent = 100 * (df['Close'] - lowest_low) / (highest_high - lowest_low + 1e-8)
            df[f'stoch_k_{k_period}'] = k_percent
            df[f'stoch_d_{k_period}_{d_period}'] = k_percent.rolling(d_period).mean()

        # Williams %R
        for period in [14, 21]:
            highest_high = df['High'].rolling(period).max()
            lowest_low = df['Low'].rolling(period).min()
            df[f'williams_r_{period}'] = -100 * (highest_high - df['Close']) / (highest_high - lowest_low + 1e-8)

        # MACD ë³€í˜•
        ema_fast = df['Close'].ewm(span=12).mean()
        ema_slow = df['Close'].ewm(span=26).mean()
        macd = ema_fast - ema_slow
        signal_line = macd.ewm(span=9).mean()
        df['macd'] = macd
        df['macd_signal'] = signal_line
        df['macd_histogram'] = macd - signal_line
        df['macd_ratio'] = macd / (signal_line + 1e-8)

        # Commodity Channel Index (CCI)
        for period in [14, 20]:
            typical_price = (df['High'] + df['Low'] + df['Close']) / 3
            sma_tp = typical_price.rolling(period).mean()
            mad = typical_price.rolling(period).apply(lambda x: np.abs(x - x.mean()).mean())
            df[f'cci_{period}'] = (typical_price - sma_tp) / (0.015 * mad + 1e-8)

        # Rate of Change (ROC)
        for period in [5, 10, 20, 30]:
            df[f'roc_{period}'] = df['Close'].pct_change(period) * 100

        # ê°€ê²© ëª¨ë©˜í…€
        for short, long in [(5, 20), (10, 30), (20, 50)]:
            df[f'price_momentum_{short}_{long}'] = df['Close'].rolling(short).mean() / df['Close'].rolling(long).mean() - 1

        return df

    def _create_frequency_features(self, df):
        """5. FFT/ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì„± (25ê°œ)"""
        print("   ğŸŒŠ ì£¼íŒŒìˆ˜ ë„ë©”ì¸ íŠ¹ì„± ìƒì„±...")

        # ê°€ê²© ì‹œê³„ì—´ FFT
        for window in [20, 50]:
            rolling_fft = df['Close'].rolling(window).apply(
                lambda x: self._extract_fft_features(x.values) if len(x) == window else np.nan
            )
            df[f'fft_dominant_freq_{window}'] = rolling_fft

        # ìˆ˜ìµë¥  ì‹œê³„ì—´ FFT
        for window in [20, 30]:
            rolling_fft = df['returns'].rolling(window).apply(
                lambda x: self._extract_fft_features(x.values) if len(x) == window else np.nan
            )
            df[f'returns_fft_dominant_{window}'] = rolling_fft

        # ìŠ¤í™íŠ¸ëŸ¼ ì—ë„ˆì§€
        for window in [20, 50]:
            rolling_energy = df['returns'].rolling(window).apply(
                lambda x: self._calculate_spectral_energy(x.values) if len(x) == window else np.nan
            )
            df[f'spectral_energy_{window}'] = rolling_energy

        # ìŠ¤í™íŠ¸ëŸ¼ ì¤‘ì‹¬
        for window in [20, 30]:
            rolling_centroid = df['Close'].rolling(window).apply(
                lambda x: self._calculate_spectral_centroid(x.values) if len(x) == window else np.nan
            )
            df[f'spectral_centroid_{window}'] = rolling_centroid

        return df

    def _create_wavelet_features(self, df):
        """6. ì›¨ì´ë¸”ë¦¿ íŠ¹ì„± (20ê°œ)"""
        print("   ã€°ï¸ ì›¨ì´ë¸”ë¦¿ íŠ¹ì„± ìƒì„±...")

        # ì›¨ì´ë¸”ë¦¿ ë³€í™˜ (ê°„ë‹¨í•œ ê·¼ì‚¬ì¹˜)
        for window in [20, 50]:
            # Daubechies ì›¨ì´ë¸”ë¦¿ ê·¼ì‚¬ (simplified)
            rolling_wavelet = df['Close'].rolling(window).apply(
                lambda x: self._extract_wavelet_features(x.values) if len(x) == window else np.nan
            )
            df[f'wavelet_energy_{window}'] = rolling_wavelet

        # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ë¶„ì„
        for scale in [2, 4, 8]:
            # ê°„ë‹¨í•œ ë‹¤ìš´ìƒ˜í”Œë§ ê¸°ë°˜ ë©€í‹°ìŠ¤ì¼€ì¼
            downsampled = df['Close'].iloc[::scale]
            upsampled = downsampled.reindex(df.index, method='ffill')
            df[f'multiscale_{scale}'] = df['Close'] - upsampled

        return df

    def _create_statistical_features(self, df):
        """7. í†µê³„ì  íŠ¹ì„± (30ê°œ)"""
        print("   ğŸ“Š í†µê³„ì  íŠ¹ì„± ìƒì„±...")

        # ê³ ì°¨ ëª¨ë©˜íŠ¸
        windows = [10, 20, 50]
        for window in windows:
            returns_roll = df['returns'].rolling(window)
            df[f'skewness_{window}'] = returns_roll.skew()
            df[f'kurtosis_{window}'] = returns_roll.kurt()

        # ë¶„ìœ„ìˆ˜ íŠ¹ì„±
        for window in [20, 50]:
            price_roll = df['Close'].rolling(window)
            df[f'price_q25_{window}'] = price_roll.quantile(0.25)
            df[f'price_q75_{window}'] = price_roll.quantile(0.75)
            df[f'price_iqr_{window}'] = df[f'price_q75_{window}'] - df[f'price_q25_{window}']

        # ìê¸°ìƒê´€
        for lag in [1, 5, 10]:
            df[f'autocorr_lag_{lag}'] = df['returns'].rolling(20).apply(
                lambda x: x.autocorr(lag) if len(x) >= lag + 1 else np.nan
            )

        # Hurst ì§€ìˆ˜ (ê°„ë‹¨í•œ ê·¼ì‚¬)
        for window in [50, 100]:
            df[f'hurst_{window}'] = df['Close'].rolling(window).apply(
                lambda x: self._calculate_hurst(x.values) if len(x) == window else np.nan
            )

        return df

    def _create_cross_features(self, df):
        """8. êµì°¨ íŠ¹ì„± (25ê°œ)"""
        print("   ğŸ”— êµì°¨ íŠ¹ì„± ìƒì„±...")

        # ê°€ê²©-ë³¼ë¥¨ êµì°¨
        df['price_volume_trend'] = df['Close'] * df['Volume']
        df['price_volume_corr_20'] = df['Close'].rolling(20).corr(df['Volume'])

        # ë³€ë™ì„±-ìˆ˜ìµë¥  êµì°¨
        df['vol_return_ratio'] = df['volatility_20'] / (abs(df['returns']) + 1e-8)
        df['vol_return_corr_20'] = df['volatility_20'].rolling(20).corr(df['returns'])

        # ë‹¤ì¤‘ ì‹œê°„í”„ë ˆì„ êµì°¨
        df['short_long_ratio'] = df['Close'].rolling(5).mean() / df['Close'].rolling(20).mean()
        df['momentum_vol_ratio'] = df['roc_10'] / (df['volatility_10'] + 1e-8)

        # ê¸°ìˆ ì  ì§€í‘œ êµì°¨
        df['rsi_vol_cross'] = df['rsi_14'] * df['volatility_20']
        df['macd_rsi_cross'] = df['macd'] * df['rsi_14']

        return df

    def _create_graph_features(self, df):
        """9. ê·¸ë˜í”„/ë„¤íŠ¸ì›Œí¬ íŠ¹ì„± (15ê°œ)"""
        print("   ğŸ•¸ï¸ ê·¸ë˜í”„ íŠ¹ì„± ìƒì„±...")

        # ê°€ê²© ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„± (ê°„ë‹¨í•œ ê·¼ì‚¬)
        for window in [20, 50]:
            # ê°€ê²© ë³€í™”ì˜ ë°©í–¥ì„± ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬
            price_changes = df['Close'].diff().rolling(window)
            df[f'network_degree_{window}'] = price_changes.apply(
                lambda x: len(x[x > 0]) / len(x) if len(x) > 0 else 0.5
            )

        # ìƒê´€ê´€ê³„ ê¸°ë°˜ ì—°ê²°ì„±
        for window in [30, 60]:
            # ê°€ê²©ê³¼ ë³¼ë¥¨ì˜ ì—°ê²°ê°•ë„
            corr_strength = df['Close'].rolling(window).corr(df['Volume'])
            df[f'connection_strength_{window}'] = abs(corr_strength)

        return df

    def _create_advanced_indicators(self, df):
        """10. ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ (25ê°œ)"""
        print("   ğŸ¯ ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ ìƒì„±...")

        # Bollinger Bands
        for window, std_mult in [(20, 2), (50, 2.5)]:
            sma = df['Close'].rolling(window).mean()
            std = df['Close'].rolling(window).std()
            df[f'bb_upper_{window}'] = sma + (std_mult * std)
            df[f'bb_lower_{window}'] = sma - (std_mult * std)
            df[f'bb_position_{window}'] = (df['Close'] - df[f'bb_lower_{window}']) / (df[f'bb_upper_{window}'] - df[f'bb_lower_{window}'] + 1e-8)
            df[f'bb_width_{window}'] = (df[f'bb_upper_{window}'] - df[f'bb_lower_{window}']) / sma

        # Donchian Channels
        for window in [20, 50]:
            df[f'donchian_high_{window}'] = df['High'].rolling(window).max()
            df[f'donchian_low_{window}'] = df['Low'].rolling(window).min()
            df[f'donchian_position_{window}'] = (df['Close'] - df[f'donchian_low_{window}']) / (df[f'donchian_high_{window}'] - df[f'donchian_low_{window}'] + 1e-8)

        # Ichimoku Components
        tenkan_period, kijun_period = 9, 26
        tenkan_sen = (df['High'].rolling(tenkan_period).max() + df['Low'].rolling(tenkan_period).min()) / 2
        kijun_sen = (df['High'].rolling(kijun_period).max() + df['Low'].rolling(kijun_period).min()) / 2
        df['ichimoku_tenkan'] = tenkan_sen
        df['ichimoku_kijun'] = kijun_sen
        df['ichimoku_span_a'] = ((tenkan_sen + kijun_sen) / 2).shift(26)
        df['ichimoku_cloud_position'] = df['Close'] - df['ichimoku_span_a']

        return df

    def _handle_missing_values(self, df):
        """ê²°ì¸¡ê°’ ì²˜ë¦¬"""
        print("   ğŸ”§ ê²°ì¸¡ê°’ ì²˜ë¦¬...")

        # Forward fill í›„ backward fill
        df = df.fillna(method='ffill').fillna(method='bfill')

        # ì—¬ì „íˆ ë‚¨ì€ ê²°ì¸¡ê°’ì„ 0ìœ¼ë¡œ ì²˜ë¦¬
        df = df.fillna(0)

        # ë¬´í•œê°’ ì²˜ë¦¬
        df = df.replace([np.inf, -np.inf], 0)

        return df

    # í—¬í¼ ë©”ì„œë“œë“¤
    def _calculate_rsi(self, prices, window=14):
        """RSI ê³„ì‚°"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / (loss + 1e-8)
        return 100 - (100 / (1 + rs))

    def _extract_fft_features(self, signal_data):
        """FFT íŠ¹ì„± ì¶”ì¶œ"""
        try:
            fft_vals = np.abs(fft(signal_data))
            dominant_freq_idx = np.argmax(fft_vals[1:len(fft_vals)//2]) + 1
            return dominant_freq_idx / len(signal_data)
        except:
            return 0

    def _calculate_spectral_energy(self, signal_data):
        """ìŠ¤í™íŠ¸ëŸ¼ ì—ë„ˆì§€ ê³„ì‚°"""
        try:
            fft_vals = np.abs(fft(signal_data))
            return np.sum(fft_vals**2)
        except:
            return 0

    def _calculate_spectral_centroid(self, signal_data):
        """ìŠ¤í™íŠ¸ëŸ¼ ì¤‘ì‹¬ ê³„ì‚°"""
        try:
            fft_vals = np.abs(fft(signal_data))
            freqs = np.arange(len(fft_vals))
            return np.sum(freqs * fft_vals) / (np.sum(fft_vals) + 1e-8)
        except:
            return 0

    def _extract_wavelet_features(self, signal_data):
        """ì›¨ì´ë¸”ë¦¿ íŠ¹ì„± ì¶”ì¶œ (ê°„ë‹¨í•œ ê·¼ì‚¬)"""
        try:
            # ê°„ë‹¨í•œ ì›¨ì´ë¸”ë¦¿ ê·¼ì‚¬: high-pass filter
            diff_signal = np.diff(signal_data)
            return np.sum(diff_signal**2)
        except:
            return 0

    def _calculate_hurst(self, price_series):
        """Hurst ì§€ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ ê·¼ì‚¬)"""
        try:
            if len(price_series) < 10:
                return 0.5

            log_price = np.log(price_series)
            returns = np.diff(log_price)

            # R/S í†µê³„ ê³„ì‚°
            n = len(returns)
            mean_return = np.mean(returns)
            cumulative_deviations = np.cumsum(returns - mean_return)
            R = np.max(cumulative_deviations) - np.min(cumulative_deviations)
            S = np.std(returns)

            if S == 0:
                return 0.5

            rs = R / S
            return np.log(rs) / np.log(n) if rs > 0 else 0.5
        except:
            return 0.5

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    # ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    print("ğŸ§ª ìºê¸€ ì±”í”¼ì–¸ íŠ¹ì„± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸...")

    # ë”ë¯¸ ë°ì´í„° ìƒì„±
    dates = pd.date_range('2020-01-01', '2024-01-01', freq='D')
    np.random.seed(42)

    sample_df = pd.DataFrame({
        'Date': dates,
        'Open': 100 + np.cumsum(np.random.normal(0, 1, len(dates))),
        'High': 105 + np.cumsum(np.random.normal(0, 1, len(dates))),
        'Low': 95 + np.cumsum(np.random.normal(0, 1, len(dates))),
        'Close': 100 + np.cumsum(np.random.normal(0, 1, len(dates))),
        'Volume': np.random.lognormal(10, 1, len(dates))
    })

    # íŠ¹ì„± ìƒì„±ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
    feature_generator = KaggleChampionFeatures()
    enhanced_df = feature_generator.generate_champion_features(sample_df)

    print(f"ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {enhanced_df.shape[0]}í–‰ x {enhanced_df.shape[1]}ì—´")
    print(f"ğŸ“Š ìƒì„±ëœ íŠ¹ì„± ìˆ˜: {enhanced_df.shape[1] - 6}ê°œ")  # ì›ë³¸ 6ê°œ ì œì™¸

    # íŠ¹ì„±ëª… í™•ì¸
    feature_names = [col for col in enhanced_df.columns if col not in ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]
    print(f"ğŸ” íŠ¹ì„± ì¹´í…Œê³ ë¦¬ë³„ ê°œìˆ˜:")

    categories = {
        'price': [f for f in feature_names if any(x in f for x in ['return', 'ratio', 'position', 'gap', 'acceleration'])],
        'volume': [f for f in feature_names if any(x in f for x in ['volume', 'vwap', 'vpt', 'obv', 'ad_line'])],
        'volatility': [f for f in feature_names if any(x in f for x in ['volatility', 'atr', 'parkinson', 'vol'])],
        'momentum': [f for f in feature_names if any(x in f for x in ['rsi', 'stoch', 'williams', 'macd', 'cci', 'roc'])],
        'frequency': [f for f in feature_names if any(x in f for x in ['fft', 'spectral'])],
        'wavelet': [f for f in feature_names if any(x in f for x in ['wavelet', 'multiscale'])],
        'statistical': [f for f in feature_names if any(x in f for x in ['skewness', 'kurtosis', 'iqr', 'autocorr', 'hurst'])],
        'cross': [f for f in feature_names if any(x in f for x in ['cross', 'trend', 'corr'])],
        'graph': [f for f in feature_names if any(x in f for x in ['network', 'connection'])],
        'advanced': [f for f in feature_names if any(x in f for x in ['bb_', 'donchian', 'ichimoku'])]
    }

    for category, features in categories.items():
        print(f"   {category}: {len(features)}ê°œ")

    return enhanced_df

if __name__ == "__main__":
    main()