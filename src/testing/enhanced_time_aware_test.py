#!/usr/bin/env python3
"""
Enhanced Time Aware Blending V9 vs V8 ë¹„êµ í…ŒìŠ¤íŠ¸
ëª©í‘œ: MDD < 0.6, Log Loss < 0.7
"""

import numpy as np
import pandas as pd
import json
from pathlib import Path
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import log_loss, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import RobustScaler
import sys
sys.path.append('/root/workspace')

from src.models.enhanced_time_aware_blending_v9 import create_enhanced_time_aware_blending_v9
from src.models.enhanced_time_aware_blending_v10 import create_enhanced_time_aware_blending_v10

class EnhancedTimeAwareComparison:
    def __init__(self):
        self.data_path = Path("/root/workspace/data")
        self.results_path = Path("/root/workspace/results/analysis")
        self.results_path.mkdir(parents=True, exist_ok=True)

    def load_training_data(self):
        """í›ˆë ¨ ë°ì´í„° ë¡œë“œ"""
        try:
            # SPY í›ˆë ¨ ë°ì´í„° ë¡œë“œ
            data_file = self.data_path / "training" / "sp500_2020_2024_enhanced.csv"
            if data_file.exists():
                df = pd.read_csv(data_file)
                print(f"âœ… í›ˆë ¨ ë°ì´í„° ë¡œë“œ: {len(df)} í–‰")
                return df
            else:
                print("âŒ í›ˆë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                return self.generate_synthetic_data()
        except Exception as e:
            print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return self.generate_synthetic_data()

    def generate_synthetic_data(self):
        """í•©ì„± ë°ì´í„° ìƒì„± (ì‹¤ì œ ì‹œì¥ íŠ¹ì„± ë°˜ì˜)"""
        np.random.seed(42)
        n_samples = 1000

        # ì‹œì¥ íŒ¨í„´ì„ ë°˜ì˜í•œ íŠ¹ì§• ìƒì„±
        dates = pd.date_range('2020-01-01', periods=n_samples, freq='D')

        # ê°€ê²© ë°ì´í„° (ëˆ„ì  ìˆ˜ìµë¥ )
        returns = np.random.normal(0.0005, 0.015, n_samples)  # ì—° 12.6% ìˆ˜ìµ, 23.7% ë³€ë™ì„±
        prices = 100 * np.cumprod(1 + returns)

        # ê¸°ìˆ ì  ì§€í‘œë“¤
        df = pd.DataFrame({
            'date': dates,
            'close': prices,
            'volume': np.random.lognormal(15, 0.5, n_samples),
            'returns': returns
        })

        # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        df['sma_5'] = df['close'].rolling(5).mean()
        df['sma_20'] = df['close'].rolling(20).mean()
        df['rsi'] = self.calculate_rsi(df['close'], 14)
        df['volatility'] = df['returns'].rolling(20).std()
        df['momentum'] = df['close'].pct_change(5)

        # ì§€ì—° íŠ¹ì§•ë“¤ (ë°ì´í„° ëˆ„ì¶œ ë°©ì§€)
        for lag in [1, 2, 3]:
            df[f'returns_lag_{lag}'] = df['returns'].shift(lag)
            df[f'volatility_lag_{lag}'] = df['volatility'].shift(lag)

        # íƒ€ê²Ÿ: ë‹¤ìŒë‚  ìˆ˜ìµë¥ 
        df['target'] = df['returns'].shift(-1)

        # ê²°ì¸¡ê°’ ì œê±°
        df = df.dropna()

        print(f"âœ… í•©ì„± ë°ì´í„° ìƒì„±: {len(df)} í–‰, {df.columns.tolist()}")
        return df

    def calculate_rsi(self, prices, window=14):
        """RSI ê³„ì‚°"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))

    def prepare_features_and_targets(self, df):
        """íŠ¹ì§•ê³¼ íƒ€ê²Ÿ ì¤€ë¹„"""
        # ì‹¤ì œ ë°ì´í„° ì»¬ëŸ¼ì— ë§ì¶° íŠ¹ì§• ì„ íƒ (ëˆ„ì¶œ ë°©ì§€)
        feature_columns = [
            'MA_20', 'MA_50', 'RSI', 'Volume', 'Volatility', 'ATR',
            'Returns_lag_1', 'Returns_lag_2', 'Returns_lag_3', 'Returns_lag_4', 'Returns_lag_5',
            'RSI_lag_1', 'RSI_lag_2', 'RSI_lag_3', 'RSI_lag_4', 'RSI_lag_5',
            'Volatility_lag_1', 'Volatility_lag_2', 'Volatility_lag_3', 'Volatility_lag_4', 'Volatility_lag_5',
            'BB_position', 'volume_ratio', 'vol_regime', 'trend_strength'
        ]

        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_features = [col for col in feature_columns if col in df.columns]
        print(f"ğŸ”§ ì „ì²´ ì»¬ëŸ¼: {len(df.columns)}")
        print(f"ğŸ”§ ìš”ì²­ëœ íŠ¹ì§•: {len(feature_columns)}")
        print(f"ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì§•: {len(available_features)}")

        if len(available_features) == 0:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì§•ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ íŠ¹ì§•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            # ê¸°ë³¸ íŠ¹ì§•ë“¤ ì„ íƒ
            basic_features = ['Close', 'Volume', 'Returns']
            available_features = [col for col in basic_features if col in df.columns]
            if 'Returns' in available_features:
                available_features.remove('Returns')  # íƒ€ê²Ÿì—ì„œ ì œì™¸

        X = df[available_features].values

        # íƒ€ê²Ÿ: í˜„ì¬ Returns ì‚¬ìš© (ë¯¸ë˜ ì˜ˆì¸¡ì´ ì•„ë‹Œ í˜„ì¬ ì›€ì§ì„ ì˜ˆì¸¡)
        if 'Returns' in df.columns:
            y = df['Returns'].values
        else:
            # Returnsê°€ ì—†ìœ¼ë©´ Close ê°€ê²© ë³€í™”ìœ¨ë¡œ ê³„ì‚°
            y = df['Close'].pct_change().values

        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        mask = ~(np.isnan(X).any(axis=1) | np.isnan(y))
        X = X[mask]
        y = y[mask]

        print(f"âœ… íŠ¹ì§• ì¤€ë¹„: {X.shape}, íƒ€ê²Ÿ: {y.shape}")
        print(f"ğŸ”§ ì‚¬ìš©ëœ íŠ¹ì§•: {available_features}")

        return X, y, available_features

    def calculate_advanced_metrics(self, y_true, y_pred, y_pred_proba=None):
        """ê³ ê¸‰ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
        metrics = {}

        # ê¸°ë³¸ íšŒê·€ ì§€í‘œ
        metrics['mae'] = mean_absolute_error(y_true, y_pred)
        metrics['mse'] = mean_squared_error(y_true, y_pred)
        metrics['rmse'] = np.sqrt(metrics['mse'])

        # ë°©í–¥ ì •í™•ë„
        direction_true = (y_true > 0).astype(int)
        direction_pred = (y_pred > 0).astype(int)
        metrics['direction_accuracy'] = np.mean(direction_true == direction_pred) * 100

        # Log Loss (í™•ë¥  ì˜ˆì¸¡ì´ ìˆëŠ” ê²½ìš°)
        if y_pred_proba is not None:
            try:
                metrics['log_loss'] = log_loss(direction_true, y_pred_proba)
            except:
                metrics['log_loss'] = None
        else:
            metrics['log_loss'] = None

        # MDD ê³„ì‚°
        cumulative_returns = np.cumprod(1 + y_pred)
        running_max = np.maximum.accumulate(cumulative_returns)
        drawdown = (cumulative_returns - running_max) / running_max
        metrics['max_drawdown'] = abs(np.min(drawdown))

        # ìƒ¤í”„ ë¹„ìœ¨
        if np.std(y_pred) > 0:
            metrics['sharpe_ratio'] = np.mean(y_pred) / np.std(y_pred) * np.sqrt(252)
        else:
            metrics['sharpe_ratio'] = 0

        # ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨
        negative_returns = y_pred[y_pred < 0]
        if len(negative_returns) > 0:
            downside_std = np.std(negative_returns) * np.sqrt(252)
            if downside_std > 0:
                metrics['sortino_ratio'] = np.mean(y_pred) * 252 / downside_std
            else:
                metrics['sortino_ratio'] = 0
        else:
            metrics['sortino_ratio'] = float('inf')

        return metrics

    def run_time_series_validation(self, X, y, n_splits=5):
        """ì‹œê³„ì—´ êµì°¨ ê²€ì¦"""
        print(f"ğŸ” ì‹œê³„ì—´ êµì°¨ ê²€ì¦ ì‹œì‘ (ë¶„í• : {n_splits})")

        tscv = TimeSeriesSplit(n_splits=n_splits)
        fold_results = []

        for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
            print(f"  ğŸ“Š Fold {fold + 1}/{n_splits} ì²˜ë¦¬ ì¤‘...")

            X_train, X_test = X[train_idx], X[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]

            # V9 ëª¨ë¸ í›ˆë ¨
            model_v9 = create_enhanced_time_aware_blending_v9()
            model_v9.fit(X_train, y_train)

            # ì˜ˆì¸¡ (ì´ë ¥ ì •ë³´ í¬í•¨)
            y_pred_v9 = model_v9.predict(X_test, y_history=y_train)
            y_pred_proba_v9 = model_v9.predict_proba(X_test, y_history=y_train)

            # ì„±ëŠ¥ ê³„ì‚°
            metrics_v9 = self.calculate_advanced_metrics(y_test, y_pred_v9, y_pred_proba_v9)
            metrics_v9['model'] = 'enhanced_time_aware_v9'
            metrics_v9['fold'] = fold + 1

            # ëª¨ë¸ ìƒíƒœ ì •ë³´
            summary_v9 = model_v9.get_performance_summary()
            metrics_v9.update(summary_v9)

            fold_results.append(metrics_v9)

            print(f"    âœ… V9 - MAE: {metrics_v9['mae']:.4f}, "
                  f"MDD: {metrics_v9['max_drawdown']:.4f}, "
                  f"Log Loss: {metrics_v9['log_loss']:.4f}")

            # V10 ëª¨ë¸ í›ˆë ¨
            model_v10 = create_enhanced_time_aware_blending_v10()
            model_v10.fit(X_train, y_train)

            # ì˜ˆì¸¡ (ì´ë ¥ ì •ë³´ í¬í•¨)
            y_pred_v10 = model_v10.predict(X_test, y_history=y_train)
            y_pred_proba_v10 = model_v10.predict_proba(X_test, y_history=y_train)

            # ì„±ëŠ¥ ê³„ì‚°
            metrics_v10 = self.calculate_advanced_metrics(y_test, y_pred_v10, y_pred_proba_v10)
            metrics_v10['model'] = 'enhanced_time_aware_v10'
            metrics_v10['fold'] = fold + 1

            # ëª¨ë¸ ìƒíƒœ ì •ë³´
            summary_v10 = model_v10.get_performance_summary()
            metrics_v10.update(summary_v10)

            fold_results.append(metrics_v10)

            print(f"    âœ… V10 - MAE: {metrics_v10['mae']:.4f}, "
                  f"MDD: {metrics_v10['max_drawdown']:.4f}, "
                  f"Log Loss: {metrics_v10['log_loss']:.4f}")

        return fold_results

    def analyze_results(self, fold_results):
        """ê²°ê³¼ ë¶„ì„"""
        print("\nğŸ“Š ê²°ê³¼ ë¶„ì„ ì¤‘...")

        df_results = pd.DataFrame(fold_results)

        # í‰ê·  ì„±ëŠ¥ ê³„ì‚°
        avg_metrics = {}
        for metric in ['mae', 'max_drawdown', 'log_loss', 'direction_accuracy', 'sharpe_ratio', 'sortino_ratio']:
            if metric in df_results.columns:
                values = df_results[metric].dropna()
                if len(values) > 0:
                    avg_metrics[f'{metric}_mean'] = np.mean(values)
                    avg_metrics[f'{metric}_std'] = np.std(values)
                    avg_metrics[f'{metric}_min'] = np.min(values)
                    avg_metrics[f'{metric}_max'] = np.max(values)

        return avg_metrics, df_results

    def save_results(self, avg_metrics, fold_results, comparison_df):
        """ê²°ê³¼ ì €ì¥"""
        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')

        # JSON ê²°ê³¼ ì €ì¥
        results = {
            'timestamp': timestamp,
            'model_name': 'enhanced_time_aware_blending_v9',
            'optimization_target': 'MDD_minimization_log_loss_reduction',
            'average_metrics': avg_metrics,
            'fold_results': fold_results,
            'goal_achievement': {
                'mdd_target': 0.6,
                'mdd_achieved': avg_metrics.get('max_drawdown_mean', 1.0),
                'mdd_success': avg_metrics.get('max_drawdown_mean', 1.0) < 0.6,
                'log_loss_target': 0.7,
                'log_loss_achieved': avg_metrics.get('log_loss_mean', 1.0),
                'log_loss_success': avg_metrics.get('log_loss_mean', 1.0) < 0.7
            }
        }

        # íŒŒì¼ ì €ì¥
        results_file = self.results_path / f"enhanced_time_aware_v9_results_{timestamp}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, default=str)

        print(f"ğŸ“Š ê²°ê³¼ ì €ì¥: {results_file}")

        # CSV ì €ì¥
        csv_file = self.results_path / f"enhanced_time_aware_v9_comparison_{timestamp}.csv"
        comparison_df.to_csv(csv_file, index=False)
        print(f"ğŸ“Š ë¹„êµ ê²°ê³¼ ì €ì¥: {csv_file}")

        return results

    def run_comprehensive_test(self):
        """ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ Enhanced Time Aware Blending V9 ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
        print("ğŸ¯ ëª©í‘œ: MDD < 0.6, Log Loss < 0.7\n")

        # ë°ì´í„° ë¡œë“œ
        df = self.load_training_data()
        X, y, features = self.prepare_features_and_targets(df)

        print(f"ğŸ“Š ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X.shape[0]} ìƒ˜í”Œ, {X.shape[1]} íŠ¹ì§•")

        # êµì°¨ ê²€ì¦ ì‹¤í–‰
        fold_results = self.run_time_series_validation(X, y, n_splits=5)

        # ê²°ê³¼ ë¶„ì„
        avg_metrics, comparison_df = self.analyze_results(fold_results)

        # ê²°ê³¼ ì €ì¥
        final_results = self.save_results(avg_metrics, fold_results, comparison_df)

        # ê²°ê³¼ ì¶œë ¥
        self.print_final_results(avg_metrics, final_results)

        return final_results

    def print_final_results(self, avg_metrics, results):
        """ìµœì¢… ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ† Enhanced Time Aware Blending V9 vs V10 ìµœì¢… ê²°ê³¼")
        print("="*80)

        # V9ì™€ V10 ê²°ê³¼ ë¶„ë¦¬
        df_results = pd.DataFrame(results['fold_results'])
        v9_results = df_results[df_results['model'] == 'enhanced_time_aware_v9']
        v10_results = df_results[df_results['model'] == 'enhanced_time_aware_v10']

        print(f"\nğŸ¯ ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ:")

        if len(v9_results) > 0:
            v9_log_loss = v9_results['log_loss'].mean()
            v9_mdd = v9_results['max_drawdown'].mean()
            v9_mae = v9_results['mae'].mean()

            print(f"\nğŸ“Š V9 ì„±ëŠ¥:")
            print(f"  Log Loss: {v9_log_loss:.4f} ({'âœ…' if v9_log_loss < 0.7 else 'âŒ'} < 0.7)")
            print(f"  MDD: {v9_mdd:.4f} ({'âœ…' if v9_mdd < 0.6 else 'âŒ'} < 0.6)")
            print(f"  MAE: {v9_mae:.4f}")
            print(f"  ë°©í–¥ ì •í™•ë„: {v9_results['direction_accuracy'].mean():.2f}%")

        if len(v10_results) > 0:
            v10_log_loss = v10_results['log_loss'].mean()
            v10_mdd = v10_results['max_drawdown'].mean()
            v10_mae = v10_results['mae'].mean()

            print(f"\nğŸ“Š V10 ì„±ëŠ¥:")
            print(f"  Log Loss: {v10_log_loss:.4f} ({'âœ…' if v10_log_loss < 0.7 else 'âŒ'} < 0.7)")
            print(f"  MDD: {v10_mdd:.4f} ({'âœ…' if v10_mdd < 0.6 else 'âŒ'} < 0.6)")
            print(f"  MAE: {v10_mae:.4f}")
            print(f"  ë°©í–¥ ì •í™•ë„: {v10_results['direction_accuracy'].mean():.2f}%")

        # ìŠ¹ì ê²°ì •
        if len(v9_results) > 0 and len(v10_results) > 0:
            v9_score = (1 if v9_log_loss < 0.7 else 0) + (1 if v9_mdd < 0.6 else 0)
            v10_score = (1 if v10_log_loss < 0.7 else 0) + (1 if v10_mdd < 0.6 else 0)

            print(f"\nğŸ† ëª©í‘œ ë‹¬ì„± ì ìˆ˜:")
            print(f"  V9: {v9_score}/2 (Log Loss: {'âœ…' if v9_log_loss < 0.7 else 'âŒ'}, MDD: {'âœ…' if v9_mdd < 0.6 else 'âŒ'})")
            print(f"  V10: {v10_score}/2 (Log Loss: {'âœ…' if v10_log_loss < 0.7 else 'âŒ'}, MDD: {'âœ…' if v10_mdd < 0.6 else 'âŒ'})")

            if v10_score > v9_score:
                print(f"\nğŸ‰ ìŠ¹ì: Enhanced Time Aware Blending V10!")
            elif v9_score > v10_score:
                print(f"\nğŸ‰ ìŠ¹ì: Enhanced Time Aware Blending V9!")
            else:
                if v10_log_loss < v9_log_loss:
                    print(f"\nğŸ‰ ìŠ¹ì: Enhanced Time Aware Blending V10 (ë” ë‚®ì€ Log Loss)")
                else:
                    print(f"\nğŸ‰ ìŠ¹ì: Enhanced Time Aware Blending V9 (ë” ë‚®ì€ Log Loss)")

        print(f"\nğŸ“Š ì¢…í•© í‰ê°€:")
        goal_achievement = results['goal_achievement']
        print(f"  MDD ëª©í‘œ < 0.6: {goal_achievement['mdd_achieved']:.4f} {'âœ…' if goal_achievement['mdd_success'] else 'âŒ'}")
        print(f"  Log Loss ëª©í‘œ < 0.7: {goal_achievement['log_loss_achieved']:.4f} {'âœ…' if goal_achievement['log_loss_success'] else 'âŒ'}")

if __name__ == "__main__":
    tester = EnhancedTimeAwareComparison()
    results = tester.run_comprehensive_test()