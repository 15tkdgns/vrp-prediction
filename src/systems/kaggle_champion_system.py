#!/usr/bin/env python3
"""
ğŸš€ ìºê¸€ ì±”í”¼ì–¸ í†µí•© ì£¼ê°€ì˜ˆì¸¡ ì‹œìŠ¤í…œ

184ê°œ ê³ ê¸‰ íŠ¹ì„± + Optiver ìš°ìŠ¹ ì•™ìƒë¸” + ì˜¨ë¼ì¸ í•™ìŠµ
ëª©í‘œ: 57.74% â†’ 95%+ ì •í™•ë„ ë‹¬ì„±
"""

import sys
sys.path.append('/root/workspace/src')

import numpy as np
import pandas as pd
import torch
from datetime import datetime
import json
import warnings
warnings.filterwarnings('ignore')

# ìì²´ ëª¨ë“ˆ import
from features.kaggle_champion_features import KaggleChampionFeatures
from core.data_processor import DataProcessor

# sklearn imports
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# ê°„ë‹¨í•œ ì‹ ê²½ë§ ëª¨ë¸ë“¤
import torch.nn as nn
import torch.optim as optim

class LightweightLSTM(nn.Module):
    """ê²½ëŸ‰í™”ëœ LSTM (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)"""

    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.2):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout,
            batch_first=True,
            bidirectional=True
        )
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_size * 2, 1)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        out = self.dropout(lstm_out[:, -1, :])  # ë§ˆì§€ë§‰ timestep
        return self.fc(out).squeeze()

class KaggleChampionSystem:
    """ìºê¸€ ì±”í”¼ì–¸ í†µí•© ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.feature_generator = KaggleChampionFeatures(lookback_window=21)
        self.data_processor = DataProcessor()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.models = {}
        self.performance_history = []

        print(f"ğŸš€ ìºê¸€ ì±”í”¼ì–¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"   ğŸ’¾ ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"   ğŸ¯ ëª©í‘œ: 57.74% â†’ 95%+ ì •í™•ë„")

    def prepare_champion_data(self, data_path):
        """ìºê¸€ ì±”í”¼ì–¸ ë°ì´í„° ì¤€ë¹„"""
        print("\nğŸ“Š ìºê¸€ ì±”í”¼ì–¸ ë°ì´í„° ì¤€ë¹„...")

        # ì›ë³¸ ë°ì´í„° ë¡œë”©
        df = self.data_processor.load_and_validate_data(data_path)
        if df is None:
            raise ValueError("ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")

        print(f"   ğŸ“ˆ ì›ë³¸ ë°ì´í„°: {df.shape}")

        # 184ê°œ ê³ ê¸‰ íŠ¹ì„± ìƒì„±
        enhanced_df = self.feature_generator.generate_champion_features(df)
        print(f"   ğŸ”¥ ê³ ê¸‰ íŠ¹ì„± ì™„ë£Œ: {enhanced_df.shape}")

        # íƒ€ê²Ÿ ë³€ìˆ˜ ì„¤ì •
        enhanced_df['future_return'] = enhanced_df['Close'].pct_change().shift(-1)
        enhanced_df['direction_target'] = (enhanced_df['future_return'] > 0).astype(int)

        # íŠ¹ì„± ì»¬ëŸ¼ ì¶”ì¶œ
        feature_columns = [col for col in enhanced_df.columns
                          if col not in ['Date', 'future_return', 'direction_target']
                          and not col.startswith('Open')
                          and not col.startswith('High')
                          and not col.startswith('Low')
                          and not col.startswith('Close')
                          and not col.startswith('Volume')]

        print(f"   âœ¨ ì‚¬ìš©í•  íŠ¹ì„±: {len(feature_columns)}ê°œ")

        # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
        sequence_length = 20
        X_sequences = []
        y_direction = []
        y_regression = []

        for i in range(sequence_length, len(enhanced_df) - 1):
            # íŠ¹ì„± ì‹œí€€ìŠ¤
            feature_seq = enhanced_df[feature_columns].iloc[i-sequence_length:i].values

            # íƒ€ê²Ÿë“¤
            direction_target = enhanced_df['direction_target'].iloc[i]
            regression_target = enhanced_df['future_return'].iloc[i]

            if not (pd.isna(direction_target) or pd.isna(regression_target)):
                X_sequences.append(feature_seq)
                y_direction.append(direction_target)
                y_regression.append(regression_target)

        X = np.array(X_sequences)
        y_direction = np.array(y_direction)
        y_regression = np.array(y_regression)

        # NaN ì²˜ë¦¬
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        y_direction = np.nan_to_num(y_direction, nan=0.5, posinf=1.0, neginf=0.0)
        y_regression = np.nan_to_num(y_regression, nan=0.0, posinf=0.0, neginf=0.0)

        print(f"   ğŸ¯ ìµœì¢… ë°ì´í„°: X={X.shape}, y_direction={y_direction.shape}")
        print(f"   ğŸ“Š ë°©í–¥ ë¶„í¬: ìƒìŠ¹={np.sum(y_direction)}, í•˜ë½={len(y_direction) - np.sum(y_direction)}")

        return X, y_direction, y_regression, feature_columns

    def train_lightweight_lstm(self, X_train, y_train, X_val, y_val, epochs=50):
        """ê²½ëŸ‰í™”ëœ LSTM í›ˆë ¨"""
        model = LightweightLSTM(input_size=X_train.shape[-1]).to(self.device)
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.BCEWithLogitsLoss()  # ë¶„ë¥˜ìš©

        # í…ì„œ ë³€í™˜
        X_train_tensor = torch.FloatTensor(X_train).to(self.device)
        y_train_tensor = torch.FloatTensor(y_train).to(self.device)
        X_val_tensor = torch.FloatTensor(X_val).to(self.device)

        model.train()
        for epoch in range(epochs):
            optimizer.zero_grad()
            outputs = model(X_train_tensor)
            loss = criterion(outputs, y_train_tensor)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

        # ì˜ˆì¸¡
        model.eval()
        with torch.no_grad():
            val_outputs = model(X_val_tensor)
            val_probs = torch.sigmoid(val_outputs).cpu().numpy()
            val_preds = (val_probs > 0.5).astype(int)

        return model, val_preds, val_probs

    def calculate_champion_metrics(self, y_true, y_pred, y_probs=None):
        """ìºê¸€ ì±”í”¼ì–¸ ì§€í‘œ ê³„ì‚°"""
        # ë°©í–¥ ì •í™•ë„
        direction_accuracy = np.mean(y_true == y_pred)

        # ê¸°íƒ€ ì§€í‘œ
        metrics = {
            'direction_accuracy': direction_accuracy,
            'precision': np.sum((y_pred == 1) & (y_true == 1)) / (np.sum(y_pred == 1) + 1e-8),
            'recall': np.sum((y_pred == 1) & (y_true == 1)) / (np.sum(y_true == 1) + 1e-8),
            'f1_score': 2 * metrics.get('precision', 0) * metrics.get('recall', 0) / (metrics.get('precision', 0) + metrics.get('recall', 0) + 1e-8) if 'precision' in locals() else 0
        }

        # F1 ê³„ì‚° ìˆ˜ì •
        precision = metrics['precision']
        recall = metrics['recall']
        metrics['f1_score'] = 2 * precision * recall / (precision + recall + 1e-8)

        # í™•ë¥ ì´ ìˆìœ¼ë©´ ë¡œê·¸ ì†ì‹¤ë„ ê³„ì‚°
        if y_probs is not None:
            y_probs_clipped = np.clip(y_probs, 1e-15, 1-1e-15)
            log_loss_val = -np.mean(y_true * np.log(y_probs_clipped) + (1 - y_true) * np.log(1 - y_probs_clipped))
            metrics['log_loss'] = log_loss_val

        return metrics

    def run_champion_experiment(self, data_path='/root/workspace/data/training/sp500_2020_2024_enhanced.csv'):
        """ìºê¸€ ì±”í”¼ì–¸ ì‹¤í—˜ ì‹¤í–‰"""
        print("ğŸ† ìºê¸€ ì±”í”¼ì–¸ ì‹¤í—˜ ì‹œì‘")
        print("="*70)

        try:
            # ë°ì´í„° ì¤€ë¹„
            X, y_direction, y_regression, feature_columns = self.prepare_champion_data(data_path)

            # êµì°¨ ê²€ì¦
            print(f"\nğŸ”¬ 3-Fold êµì°¨ ê²€ì¦ ì‹œì‘")
            tscv = TimeSeriesSplit(n_splits=3)
            all_results = []

            for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
                print(f"\nğŸ“Š Fold {fold+1}/3")

                X_train, X_val = X[train_idx], X[val_idx]
                y_train, y_val = y_direction[train_idx], y_direction[val_idx]

                fold_results = {}

                # 1. Random Forest (ë¹ ë¥¸ ë² ì´ìŠ¤ë¼ì¸)
                print("   ğŸŒ² Random Forest í›ˆë ¨...")
                try:
                    rf_model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
                    X_train_2d = X_train.reshape(X_train.shape[0], -1)
                    X_val_2d = X_val.reshape(X_val.shape[0], -1)

                    rf_model.fit(X_train_2d, y_train)
                    rf_probs = rf_model.predict(X_val_2d)
                    rf_preds = (rf_probs > 0.5).astype(int)

                    rf_metrics = self.calculate_champion_metrics(y_val, rf_preds, rf_probs)
                    fold_results['RandomForest'] = rf_metrics

                    print(f"      RandomForest: ì •í™•ë„={rf_metrics['direction_accuracy']:.4f}")

                except Exception as e:
                    print(f"      âš ï¸ RandomForest ì‹¤íŒ¨: {e}")

                # 2. ElasticNet
                print("   ğŸ“Š ElasticNet í›ˆë ¨...")
                try:
                    elastic_model = ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=1000)
                    X_train_2d = X_train[:, -1, :]  # ë§ˆì§€ë§‰ timestep
                    X_val_2d = X_val[:, -1, :]

                    elastic_model.fit(X_train_2d, y_train)
                    elastic_probs = elastic_model.predict(X_val_2d)
                    elastic_probs = np.clip(elastic_probs, 0, 1)  # 0-1 ë²”ìœ„ë¡œ í´ë¦¬í•‘
                    elastic_preds = (elastic_probs > 0.5).astype(int)

                    elastic_metrics = self.calculate_champion_metrics(y_val, elastic_preds, elastic_probs)
                    fold_results['ElasticNet'] = elastic_metrics

                    print(f"      ElasticNet: ì •í™•ë„={elastic_metrics['direction_accuracy']:.4f}")

                except Exception as e:
                    print(f"      âš ï¸ ElasticNet ì‹¤íŒ¨: {e}")

                # 3. Lightweight LSTM
                print("   ğŸ§  Lightweight LSTM í›ˆë ¨...")
                try:
                    lstm_model, lstm_preds, lstm_probs = self.train_lightweight_lstm(
                        X_train, y_train, X_val, y_val
                    )

                    lstm_metrics = self.calculate_champion_metrics(y_val, lstm_preds, lstm_probs)
                    fold_results['LightweightLSTM'] = lstm_metrics

                    print(f"      LightweightLSTM: ì •í™•ë„={lstm_metrics['direction_accuracy']:.4f}")

                except Exception as e:
                    print(f"      âš ï¸ LightweightLSTM ì‹¤íŒ¨: {e}")

                # 4. ê°„ë‹¨í•œ ì•™ìƒë¸” (í‰ê· )
                print("   ğŸ¯ ê°„ë‹¨í•œ ì•™ìƒë¸”...")
                try:
                    ensemble_probs = []
                    if 'RandomForest' in fold_results:
                        ensemble_probs.append(rf_probs)
                    if 'ElasticNet' in fold_results:
                        ensemble_probs.append(elastic_probs)
                    if 'LightweightLSTM' in fold_results:
                        ensemble_probs.append(lstm_probs)

                    if len(ensemble_probs) > 0:
                        avg_probs = np.mean(ensemble_probs, axis=0)
                        avg_preds = (avg_probs > 0.5).astype(int)

                        ensemble_metrics = self.calculate_champion_metrics(y_val, avg_preds, avg_probs)
                        fold_results['SimpleEnsemble'] = ensemble_metrics

                        print(f"      SimpleEnsemble: ì •í™•ë„={ensemble_metrics['direction_accuracy']:.4f}")

                except Exception as e:
                    print(f"      âš ï¸ SimpleEnsemble ì‹¤íŒ¨: {e}")

                all_results.append(fold_results)
                print(f"   âœ… Fold {fold+1} ì™„ë£Œ")

            # ìµœì¢… ê²°ê³¼ ìš”ì•½
            self._summarize_champion_results(all_results)

            return all_results

        except Exception as e:
            print(f"âŒ ìºê¸€ ì±”í”¼ì–¸ ì‹¤í—˜ ì‹¤íŒ¨: {str(e)}")
            return None

    def _summarize_champion_results(self, all_results):
        """ìºê¸€ ì±”í”¼ì–¸ ê²°ê³¼ ìš”ì•½"""
        print(f"\nğŸ† ìºê¸€ ì±”í”¼ì–¸ ì‹œìŠ¤í…œ ìµœì¢… ê²°ê³¼:")
        print("="*70)

        model_names = ['RandomForest', 'ElasticNet', 'LightweightLSTM', 'SimpleEnsemble']

        avg_performance = {}

        for model_name in model_names:
            direction_accuracies = []

            for fold_result in all_results:
                if model_name in fold_result:
                    acc = fold_result[model_name]['direction_accuracy']
                    if not (np.isnan(acc) or np.isinf(acc)):
                        direction_accuracies.append(acc)

            if direction_accuracies:
                avg_performance[model_name] = {
                    'avg_accuracy': np.mean(direction_accuracies),
                    'std_accuracy': np.std(direction_accuracies),
                    'max_accuracy': np.max(direction_accuracies)
                }

        # ì„±ëŠ¥ ì¶œë ¥
        print(f"ğŸ“Š ëª¨ë¸ë³„ ë°©í–¥ ì˜ˆì¸¡ ì •í™•ë„:")
        print("-" * 70)

        baseline_accuracy = 0.5774  # ê¸°ì¡´ ìµœê³  ì„±ëŠ¥

        for model_name, perf in avg_performance.items():
            avg_acc = perf['avg_accuracy']
            improvement = (avg_acc - baseline_accuracy) * 100
            icon = "ğŸ†" if avg_acc > 0.7 else "ğŸ“ˆ" if avg_acc > baseline_accuracy else "ğŸ“Š"

            print(f"{icon} {model_name:16s}: "
                  f"{avg_acc:.4f} Â± {perf['std_accuracy']:.4f} "
                  f"(ìµœê³ : {perf['max_accuracy']:.4f}) "
                  f"ê°œì„ : {improvement:+.2f}%p")

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
        if avg_performance:
            best_model = max(avg_performance.items(), key=lambda x: x[1]['avg_accuracy'])
            best_accuracy = best_model[1]['avg_accuracy']

            print(f"\nğŸ¥‡ ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model[0]}")
            print(f"   ğŸ¯ ë‹¬ì„± ì •í™•ë„: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)")
            print(f"   ğŸ“ˆ ê¸°ì¤€ì„  ê°œì„ : {(best_accuracy - baseline_accuracy)*100:+.2f}%p")

            if best_accuracy > 0.85:
                print(f"   ğŸ‰ ëª©í‘œ ë‹¬ì„±! (85%+ ì •í™•ë„)")
            elif best_accuracy > baseline_accuracy:
                print(f"   ğŸ“Š ê¸°ì¤€ì„  ê°œì„  ì„±ê³µ!")
            else:
                print(f"   âš ï¸ ì¶”ê°€ ìµœì í™” í•„ìš”")

        # ê²°ê³¼ ì €ì¥
        final_result = {
            'timestamp': datetime.now().isoformat(),
            'experiment_type': 'kaggle_champion_system',
            'feature_count': 184,
            'baseline_accuracy': baseline_accuracy,
            'performance': avg_performance,
            'detailed_results': all_results
        }

        output_path = f"/root/workspace/data/results/kaggle_champion_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_path, 'w') as f:
            json.dump(final_result, f, indent=2, default=str)

        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    system = KaggleChampionSystem()
    results = system.run_champion_experiment()

    print("\nğŸ‰ ìºê¸€ ì±”í”¼ì–¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return results

if __name__ == "__main__":
    main()