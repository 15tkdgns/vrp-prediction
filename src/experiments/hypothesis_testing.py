#!/usr/bin/env python3
"""
ğŸ”¬ ê°€ì„¤ ê²€ì¦ ì‹œìŠ¤í…œ
í•™ìˆ  ë…¼ë¬¸ì„ ìœ„í•œ ì²´ê³„ì ì¸ ê°€ì„¤ ì„¤ì • ë° ê²€ì¦ í”„ë ˆì„ì›Œí¬

ì£¼ìš” ê¸°ëŠ¥:
- ê°€ì„¤ ì„¤ì • ë° ê´€ë¦¬
- í†µê³„ì  ê²€ì¦ ìˆ˜í–‰
- íš¨ê³¼ í¬ê¸° ë¶„ì„
- ê²°ê³¼ í•´ì„ ë° ë³´ê³ 
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass
from enum import Enum
import scipy.stats as stats
from sklearn.model_selection import cross_val_score, TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

class HypothesisType(Enum):
    """ê°€ì„¤ ìœ í˜• ì—´ê±°í˜•"""
    ONE_SAMPLE = "one_sample"
    TWO_SAMPLE_PAIRED = "two_sample_paired"
    TWO_SAMPLE_INDEPENDENT = "two_sample_independent"
    MULTI_SAMPLE = "multi_sample"
    CORRELATION = "correlation"
    PROPORTION = "proportion"

class AlternativeHypothesis(Enum):
    """ëŒ€ë¦½ê°€ì„¤ ë°©í–¥ ì—´ê±°í˜•"""
    TWO_SIDED = "two-sided"
    GREATER = "greater"
    LESS = "less"

@dataclass
class Hypothesis:
    """
    ê°€ì„¤ ì •ì˜ í´ë˜ìŠ¤

    í•™ìˆ  ì—°êµ¬ë¥¼ ìœ„í•œ ëª…í™•í•œ ê°€ì„¤ êµ¬ì¡°í™”
    """
    id: str
    null_hypothesis: str
    alternative_hypothesis: str
    hypothesis_type: HypothesisType
    alternative_direction: AlternativeHypothesis
    significance_level: float = 0.05
    expected_effect_size: Optional[float] = None
    practical_significance_threshold: Optional[float] = None
    description: Optional[str] = None
    research_question: Optional[str] = None

@dataclass
class HypothesisTestResult:
    """
    ê°€ì„¤ ê²€ì¦ ê²°ê³¼ í´ë˜ìŠ¤
    """
    hypothesis_id: str
    test_statistic: float
    p_value: float
    effect_size: Optional[float]
    confidence_interval: Optional[Tuple[float, float]]
    is_statistically_significant: bool
    is_practically_significant: bool
    statistical_power: Optional[float]
    sample_size: int
    test_method: str
    interpretation: str
    recommendation: str

class FinancialMLHypothesisFramework:
    """
    ê¸ˆìœµ ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ ê°€ì„¤ ê²€ì¦ í”„ë ˆì„ì›Œí¬

    ì²´ê³„ì ì¸ ì‹¤í—˜ ì„¤ê³„ ë° ê°€ì„¤ ê²€ì¦ì„ ìœ„í•œ í†µí•© ì‹œìŠ¤í…œ
    """

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.hypotheses: Dict[str, Hypothesis] = {}
        self.results: Dict[str, HypothesisTestResult] = {}

        # ê¸ˆìœµ MLì„ ìœ„í•œ ì‚¬ì „ ì •ì˜ëœ ê°€ì„¤ë“¤
        self._initialize_financial_ml_hypotheses()

    def _initialize_financial_ml_hypotheses(self):
        """ê¸ˆìœµ MLì„ ìœ„í•œ ê¸°ë³¸ ê°€ì„¤ë“¤ ì´ˆê¸°í™”"""

        # H1: Purged CVê°€ ì¼ë°˜ CVë³´ë‹¤ í˜„ì‹¤ì  ì„±ëŠ¥ ì¶”ì •
        self.add_hypothesis(Hypothesis(
            id="H1_purged_cv_effectiveness",
            null_hypothesis="Purged Cross-Validationê³¼ ì¼ë°˜ Cross-Validationì˜ ì„±ëŠ¥ ì¶”ì •ì— ì°¨ì´ê°€ ì—†ë‹¤",
            alternative_hypothesis="Purged Cross-Validationì´ ì¼ë°˜ Cross-Validationë³´ë‹¤ í˜„ì‹¤ì ì¸ ì„±ëŠ¥ì„ ì¶”ì •í•œë‹¤",
            hypothesis_type=HypothesisType.TWO_SAMPLE_PAIRED,
            alternative_direction=AlternativeHypothesis.LESS,  # Purged CVê°€ ë” ë‚®ì€(í˜„ì‹¤ì ) ì„±ëŠ¥
            significance_level=0.05,
            expected_effect_size=0.3,
            practical_significance_threshold=0.05,  # 5% ì„±ëŠ¥ ì°¨ì´
            research_question="ë°ì´í„° ìœ ì¶œ ë°©ì§€ê°€ ì„±ëŠ¥ ì¶”ì •ì˜ í˜„ì‹¤ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?",
            description="Purged CVê°€ ê³¼ì í•©ì„ ë°©ì§€í•˜ì—¬ ë” í˜„ì‹¤ì ì¸ ì„±ëŠ¥ ì¶”ì •ì„ ì œê³µí•˜ëŠ”ì§€ ê²€ì¦"
        ))

        # H2: ì•™ìƒë¸” ë°©ë²•ì´ ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ ì•ˆì •ì 
        self.add_hypothesis(Hypothesis(
            id="H2_ensemble_stability",
            null_hypothesis="ì•™ìƒë¸” ëª¨ë¸ê³¼ ë‹¨ì¼ ëª¨ë¸ì˜ ì„±ëŠ¥ ë³€ë™ì„±ì— ì°¨ì´ê°€ ì—†ë‹¤",
            alternative_hypothesis="ì•™ìƒë¸” ëª¨ë¸ì´ ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ ë‚®ì€ ì„±ëŠ¥ ë³€ë™ì„±ì„ ë³´ì¸ë‹¤",
            hypothesis_type=HypothesisType.TWO_SAMPLE_PAIRED,
            alternative_direction=AlternativeHypothesis.LESS,  # ì•™ìƒë¸”ì´ ë” ë‚®ì€ ë³€ë™ì„±
            significance_level=0.05,
            expected_effect_size=0.4,
            practical_significance_threshold=0.1,  # 10% ë³€ë™ì„± ê°ì†Œ
            research_question="ì•™ìƒë¸” ë°©ë²•ì´ ì˜ˆì¸¡ ì•ˆì •ì„± í–¥ìƒì— ê¸°ì—¬í•˜ëŠ”ê°€?",
            description="ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”ì´ ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ ì„±ëŠ¥ ì•ˆì •ì„±ì„ ê°œì„ í•˜ëŠ”ì§€ ê²€ì¦"
        ))

        # H3: ì‹œê°„ ì¸ì‹ ë¸”ë Œë”©ì´ ì •ì  ê°€ì¤‘ì¹˜ë³´ë‹¤ ìš°ìˆ˜
        self.add_hypothesis(Hypothesis(
            id="H3_time_aware_superiority",
            null_hypothesis="ì‹œê°„ ì¸ì‹ ë¸”ë Œë”©ê³¼ ì •ì  ê°€ì¤‘ì¹˜ ì•™ìƒë¸”ì˜ ì„±ëŠ¥ì— ì°¨ì´ê°€ ì—†ë‹¤",
            alternative_hypothesis="ì‹œê°„ ì¸ì‹ ë¸”ë Œë”©ì´ ì •ì  ê°€ì¤‘ì¹˜ ì•™ìƒë¸”ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤",
            hypothesis_type=HypothesisType.TWO_SAMPLE_PAIRED,
            alternative_direction=AlternativeHypothesis.GREATER,  # ì‹œê°„ ì¸ì‹ì´ ë” ì¢‹ì€ ì„±ëŠ¥
            significance_level=0.05,
            expected_effect_size=0.2,
            practical_significance_threshold=0.02,  # 2% ì„±ëŠ¥ ê°œì„ 
            research_question="ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì •ì´ ì •ì  ì•™ìƒë¸” ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì˜¤ëŠ”ê°€?",
            description="ì‹œê°„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì ì‘ì´ ê³ ì • ê°€ì¤‘ì¹˜ ëŒ€ë¹„ ì„±ëŠ¥ ê°œì„ ì— ê¸°ì—¬í•˜ëŠ”ì§€ ê²€ì¦"
        ))

        # H4: íŠ¹ì§• ê°œìˆ˜ ì¦ê°€ê°€ ì„±ëŠ¥ í–¥ìƒìœ¼ë¡œ ì´ì–´ì§€ì§€ ì•ŠìŒ
        self.add_hypothesis(Hypothesis(
            id="H4_feature_curse_dimensionality",
            null_hypothesis="íŠ¹ì§• ê°œìˆ˜ì™€ ëª¨ë¸ ì„±ëŠ¥ ê°„ì— ìƒê´€ê´€ê³„ê°€ ì—†ë‹¤",
            alternative_hypothesis="íŠ¹ì§• ê°œìˆ˜ ì¦ê°€ê°€ ì¼ì • ì„ê³„ê°’ ì´í›„ ì„±ëŠ¥ ì €í•˜ë¥¼ ì•¼ê¸°í•œë‹¤",
            hypothesis_type=HypothesisType.CORRELATION,
            alternative_direction=AlternativeHypothesis.LESS,  # ìŒì˜ ìƒê´€ê´€ê³„
            significance_level=0.05,
            expected_effect_size=-0.3,
            practical_significance_threshold=0.1,
            research_question="ì°¨ì›ì˜ ì €ì£¼ê°€ ê¸ˆìœµ ì‹œê³„ì—´ ì˜ˆì¸¡ì—ì„œ ê´€ì°°ë˜ëŠ”ê°€?",
            description="ê³¼ë„í•œ íŠ¹ì§• ì‚¬ìš©ì´ ëª¨ë¸ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ë¶€ì •ì  ì˜í–¥ ê²€ì¦"
        ))

        # H5: ë°ì´í„° ìœ ì¶œ ì œê±°ê°€ í˜„ì‹¤ì  ì„±ëŠ¥ìœ¼ë¡œ ì´ì–´ì§
        self.add_hypothesis(Hypothesis(
            id="H5_data_leakage_impact",
            null_hypothesis="ë°ì´í„° ìœ ì¶œ ì œê±° ì „í›„ì˜ ì„±ëŠ¥ ì§€í‘œì— ì°¨ì´ê°€ ì—†ë‹¤",
            alternative_hypothesis="ë°ì´í„° ìœ ì¶œ ì œê±°ê°€ í˜„ì‹¤ì (ë‚®ì€) ì„±ëŠ¥ ì§€í‘œë¡œ ì´ì–´ì§„ë‹¤",
            hypothesis_type=HypothesisType.TWO_SAMPLE_PAIRED,
            alternative_direction=AlternativeHypothesis.LESS,  # ìœ ì¶œ ì œê±° í›„ ë” ë‚®ì€(í˜„ì‹¤ì ) ì„±ëŠ¥
            significance_level=0.05,
            expected_effect_size=0.8,  # í° íš¨ê³¼ ì˜ˆìƒ
            practical_significance_threshold=0.2,  # 20% ì„±ëŠ¥ ì°¨ì´
            research_question="ë°ì´í„° ìœ ì¶œì´ ì„±ëŠ¥ ê³¼ëŒ€í‰ê°€ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì˜ í¬ê¸°ëŠ”?",
            description="Look-ahead bias ì œê±°ê°€ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ì˜ í˜„ì‹¤ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì •ëŸ‰í™”"
        ))

    def add_hypothesis(self, hypothesis: Hypothesis):
        """ê°€ì„¤ ì¶”ê°€"""
        self.hypotheses[hypothesis.id] = hypothesis

    def test_purged_cv_effectiveness(self, purged_cv_scores: np.ndarray,
                                   regular_cv_scores: np.ndarray) -> HypothesisTestResult:
        """
        H1: Purged CV íš¨ê³¼ì„± ê²€ì¦

        Args:
            purged_cv_scores: Purged CV ì„±ëŠ¥ ì ìˆ˜ë“¤
            regular_cv_scores: ì¼ë°˜ CV ì„±ëŠ¥ ì ìˆ˜ë“¤

        Returns:
            ê°€ì„¤ ê²€ì¦ ê²°ê³¼
        """
        hypothesis = self.hypotheses["H1_purged_cv_effectiveness"]

        # ìŒì²´ t-ê²€ì • (Purged CVê°€ ë” ë‚®ì€ ì ìˆ˜ë¥¼ ê°€ì ¸ì•¼ í•¨ - í˜„ì‹¤ì )
        t_stat, p_value = stats.ttest_rel(regular_cv_scores, purged_cv_scores)

        # íš¨ê³¼ í¬ê¸° (Cohen's d)
        diff = regular_cv_scores - purged_cv_scores
        effect_size = np.mean(diff) / np.std(diff, ddof=1) if np.std(diff, ddof=1) != 0 else 0

        # ì‹ ë¢°êµ¬ê°„ (ì°¨ì´ì— ëŒ€í•œ)
        n = len(diff)
        se = stats.sem(diff)
        ci = stats.t.interval(0.95, n-1, loc=np.mean(diff), scale=se)

        # ì‹¤ìš©ì  ìœ ì˜ì„±
        practical_significant = abs(np.mean(diff)) >= hypothesis.practical_significance_threshold

        # í•´ì„
        if p_value < hypothesis.significance_level and t_stat > 0:
            interpretation = "Purged CVê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ê²Œ ë” ë‚®ì€(í˜„ì‹¤ì ) ì„±ëŠ¥ì„ ë³´ê³ í•¨"
            recommendation = "Purged CV ì‚¬ìš©ì„ ê°•ë ¥íˆ ê¶Œì¥. ì¼ë°˜ CVëŠ” ê³¼ì í•©ëœ ì„±ëŠ¥ ì¶”ì •"
        else:
            interpretation = "Purged CVì™€ ì¼ë°˜ CV ê°„ ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ"
            recommendation = "ì¶”ê°€ ë°ì´í„°ë¡œ ì¬ê²€ì¦ í•„ìš”"

        result = HypothesisTestResult(
            hypothesis_id=hypothesis.id,
            test_statistic=t_stat,
            p_value=p_value,
            effect_size=effect_size,
            confidence_interval=ci,
            is_statistically_significant=p_value < hypothesis.significance_level,
            is_practically_significant=practical_significant,
            statistical_power=None,  # ì¶”í›„ ê³„ì‚° ê°€ëŠ¥
            sample_size=len(purged_cv_scores),
            test_method="Paired t-test",
            interpretation=interpretation,
            recommendation=recommendation
        )

        self.results[hypothesis.id] = result
        return result

    def test_ensemble_stability(self, ensemble_scores: np.ndarray,
                              single_model_scores: np.ndarray) -> HypothesisTestResult:
        """
        H2: ì•™ìƒë¸” ì•ˆì •ì„± ê²€ì¦

        Args:
            ensemble_scores: ì•™ìƒë¸” ëª¨ë¸ì˜ ì„±ëŠ¥ ì ìˆ˜ë“¤
            single_model_scores: ë‹¨ì¼ ëª¨ë¸ì˜ ì„±ëŠ¥ ì ìˆ˜ë“¤

        Returns:
            ê°€ì„¤ ê²€ì¦ ê²°ê³¼
        """
        hypothesis = self.hypotheses["H2_ensemble_stability"]

        # ë¶„ì‚° ë¹„êµ (F-test)
        ensemble_var = np.var(ensemble_scores, ddof=1)
        single_var = np.var(single_model_scores, ddof=1)

        f_stat = single_var / ensemble_var if ensemble_var > 0 else np.inf
        df1, df2 = len(single_model_scores) - 1, len(ensemble_scores) - 1
        p_value = 1 - stats.f.cdf(f_stat, df1, df2)

        # íš¨ê³¼ í¬ê¸° (ë³€ë™ì„± ê°ì†Œ ë¹„ìœ¨)
        effect_size = (single_var - ensemble_var) / single_var if single_var > 0 else 0

        # ì‹ ë¢°êµ¬ê°„ (ë¶„ì‚° ë¹„ìœ¨ì— ëŒ€í•œ)
        ci_lower = f_stat / stats.f.ppf(0.975, df1, df2)
        ci_upper = f_stat / stats.f.ppf(0.025, df1, df2)

        # ì‹¤ìš©ì  ìœ ì˜ì„±
        practical_significant = effect_size >= hypothesis.practical_significance_threshold

        # í•´ì„
        if p_value < hypothesis.significance_level and f_stat > 1:
            interpretation = f"ì•™ìƒë¸”ì´ ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ {effect_size*100:.1f}% ë” ì•ˆì •ì "
            recommendation = "ì•™ìƒë¸” ë°©ë²• ì‚¬ìš© ê¶Œì¥. ì˜ˆì¸¡ ì•ˆì •ì„± í¬ê²Œ ê°œì„ "
        else:
            interpretation = "ì•™ìƒë¸”ê³¼ ë‹¨ì¼ ëª¨ë¸ ê°„ ì•ˆì •ì„± ì°¨ì´ ì—†ìŒ"
            recommendation = "ì•™ìƒë¸”ì˜ ì•ˆì •ì„± ì´ì  ì œí•œì "

        result = HypothesisTestResult(
            hypothesis_id=hypothesis.id,
            test_statistic=f_stat,
            p_value=p_value,
            effect_size=effect_size,
            confidence_interval=(ci_lower, ci_upper),
            is_statistically_significant=p_value < hypothesis.significance_level,
            is_practically_significant=practical_significant,
            statistical_power=None,
            sample_size=min(len(ensemble_scores), len(single_model_scores)),
            test_method="F-test for variance equality",
            interpretation=interpretation,
            recommendation=recommendation
        )

        self.results[hypothesis.id] = result
        return result

    def test_time_aware_superiority(self, time_aware_scores: np.ndarray,
                                  static_weight_scores: np.ndarray) -> HypothesisTestResult:
        """
        H3: ì‹œê°„ ì¸ì‹ ë¸”ë Œë”© ìš°ìˆ˜ì„± ê²€ì¦

        Args:
            time_aware_scores: ì‹œê°„ ì¸ì‹ ë¸”ë Œë”© ì„±ëŠ¥ ì ìˆ˜ë“¤
            static_weight_scores: ì •ì  ê°€ì¤‘ì¹˜ ì„±ëŠ¥ ì ìˆ˜ë“¤

        Returns:
            ê°€ì„¤ ê²€ì¦ ê²°ê³¼
        """
        hypothesis = self.hypotheses["H3_time_aware_superiority"]

        # ì¼ì¸¡ ìŒì²´ t-ê²€ì • (ì‹œê°„ ì¸ì‹ì´ ë” ì¢‹ì•„ì•¼ í•¨)
        t_stat, p_value_two_sided = stats.ttest_rel(time_aware_scores, static_weight_scores)
        p_value = p_value_two_sided / 2 if t_stat > 0 else 1 - p_value_two_sided / 2

        # íš¨ê³¼ í¬ê¸°
        diff = time_aware_scores - static_weight_scores
        effect_size = np.mean(diff) / np.std(diff, ddof=1) if np.std(diff, ddof=1) != 0 else 0

        # ì‹ ë¢°êµ¬ê°„
        n = len(diff)
        se = stats.sem(diff)
        ci = stats.t.interval(0.95, n-1, loc=np.mean(diff), scale=se)

        # ì‹¤ìš©ì  ìœ ì˜ì„±
        practical_significant = np.mean(diff) >= hypothesis.practical_significance_threshold

        # í•´ì„
        if p_value < hypothesis.significance_level and t_stat > 0:
            improvement = np.mean(diff) * 100
            interpretation = f"ì‹œê°„ ì¸ì‹ ë¸”ë Œë”©ì´ {improvement:.2f}% ì„±ëŠ¥ í–¥ìƒ"
            recommendation = "ì‹œê°„ ì¸ì‹ ë¸”ë Œë”© ì‚¬ìš© ê¶Œì¥. ë™ì  ê°€ì¤‘ì¹˜ì˜ ì´ì  í™•ì¸"
        else:
            interpretation = "ì‹œê°„ ì¸ì‹ ë¸”ë Œë”©ì˜ ìœ ì˜í•œ ì„±ëŠ¥ í–¥ìƒ ì—†ìŒ"
            recommendation = "ì •ì  ê°€ì¤‘ì¹˜ë„ ì¶©ë¶„íˆ íš¨ê³¼ì . ë³µì¡ì„± ëŒ€ë¹„ ì´ìµ ì œí•œì "

        result = HypothesisTestResult(
            hypothesis_id=hypothesis.id,
            test_statistic=t_stat,
            p_value=p_value,
            effect_size=effect_size,
            confidence_interval=ci,
            is_statistically_significant=p_value < hypothesis.significance_level,
            is_practically_significant=practical_significant,
            statistical_power=None,
            sample_size=len(time_aware_scores),
            test_method="One-sided paired t-test",
            interpretation=interpretation,
            recommendation=recommendation
        )

        self.results[hypothesis.id] = result
        return result

    def test_feature_curse_dimensionality(self, feature_counts: np.ndarray,
                                        performance_scores: np.ndarray) -> HypothesisTestResult:
        """
        H4: ì°¨ì›ì˜ ì €ì£¼ ê²€ì¦

        Args:
            feature_counts: íŠ¹ì§• ê°œìˆ˜ ë°°ì—´
            performance_scores: í•´ë‹¹ ì„±ëŠ¥ ì ìˆ˜ ë°°ì—´

        Returns:
            ê°€ì„¤ ê²€ì¦ ê²°ê³¼
        """
        hypothesis = self.hypotheses["H4_feature_curse_dimensionality"]

        # ìƒê´€ë¶„ì„
        correlation, p_value = stats.pearsonr(feature_counts, performance_scores)

        # íš¨ê³¼ í¬ê¸° (ìƒê´€ê³„ìˆ˜ ìì²´ê°€ íš¨ê³¼ í¬ê¸°)
        effect_size = correlation

        # ì‹ ë¢°êµ¬ê°„ (Fisher's z-transformation)
        n = len(feature_counts)
        z_r = 0.5 * np.log((1 + correlation) / (1 - correlation))
        se_z = 1 / np.sqrt(n - 3)
        z_critical = stats.norm.ppf(0.975)
        z_lower = z_r - z_critical * se_z
        z_upper = z_r + z_critical * se_z

        # ì—­ë³€í™˜
        ci_lower = (np.exp(2 * z_lower) - 1) / (np.exp(2 * z_lower) + 1)
        ci_upper = (np.exp(2 * z_upper) - 1) / (np.exp(2 * z_upper) + 1)

        # ì‹¤ìš©ì  ìœ ì˜ì„±
        practical_significant = abs(correlation) >= hypothesis.practical_significance_threshold

        # í•´ì„
        if p_value < hypothesis.significance_level and correlation < 0:
            interpretation = f"íŠ¹ì§• ì¦ê°€ì™€ ì„±ëŠ¥ ê°„ ìœ ì˜í•œ ìŒì˜ ìƒê´€ê´€ê³„ (r={correlation:.3f})"
            recommendation = "íŠ¹ì§• ì„ íƒ ì¤‘ìš”. ê³¼ë„í•œ íŠ¹ì§•ì€ ì„±ëŠ¥ ì €í•˜ ì•¼ê¸°"
        elif p_value < hypothesis.significance_level and correlation > 0:
            interpretation = f"íŠ¹ì§• ì¦ê°€ê°€ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬ (r={correlation:.3f})"
            recommendation = "ë” ë§ì€ íŠ¹ì§• ì‚¬ìš© ê³ ë ¤ ê°€ëŠ¥"
        else:
            interpretation = "íŠ¹ì§• ê°œìˆ˜ì™€ ì„±ëŠ¥ ê°„ ìœ ì˜í•œ ê´€ê³„ ì—†ìŒ"
            recommendation = "íŠ¹ì§• ê°œìˆ˜ë³´ë‹¤ íŠ¹ì§• í’ˆì§ˆì— ì§‘ì¤‘"

        result = HypothesisTestResult(
            hypothesis_id=hypothesis.id,
            test_statistic=correlation,
            p_value=p_value,
            effect_size=effect_size,
            confidence_interval=(ci_lower, ci_upper),
            is_statistically_significant=p_value < hypothesis.significance_level,
            is_practically_significant=practical_significant,
            statistical_power=None,
            sample_size=n,
            test_method="Pearson correlation test",
            interpretation=interpretation,
            recommendation=recommendation
        )

        self.results[hypothesis.id] = result
        return result

    def test_data_leakage_impact(self, pre_leakage_scores: np.ndarray,
                               post_leakage_scores: np.ndarray) -> HypothesisTestResult:
        """
        H5: ë°ì´í„° ìœ ì¶œ ì˜í–¥ ê²€ì¦

        Args:
            pre_leakage_scores: ë°ì´í„° ìœ ì¶œ ì œê±° ì „ ì„±ëŠ¥ ì ìˆ˜ë“¤
            post_leakage_scores: ë°ì´í„° ìœ ì¶œ ì œê±° í›„ ì„±ëŠ¥ ì ìˆ˜ë“¤

        Returns:
            ê°€ì„¤ ê²€ì¦ ê²°ê³¼
        """
        hypothesis = self.hypotheses["H5_data_leakage_impact"]

        # ìŒì²´ t-ê²€ì • (ìœ ì¶œ ì œê±° í›„ ë” ë‚®ì€ ì„±ëŠ¥ ì˜ˆìƒ)
        t_stat, p_value = stats.ttest_rel(pre_leakage_scores, post_leakage_scores)

        # íš¨ê³¼ í¬ê¸°
        diff = pre_leakage_scores - post_leakage_scores
        effect_size = np.mean(diff) / np.std(diff, ddof=1) if np.std(diff, ddof=1) != 0 else 0

        # ì‹ ë¢°êµ¬ê°„
        n = len(diff)
        se = stats.sem(diff)
        ci = stats.t.interval(0.95, n-1, loc=np.mean(diff), scale=se)

        # ì‹¤ìš©ì  ìœ ì˜ì„±
        practical_significant = abs(np.mean(diff)) >= hypothesis.practical_significance_threshold

        # í•´ì„
        if p_value < hypothesis.significance_level and t_stat > 0:
            overestimation = np.mean(diff) * 100
            interpretation = f"ë°ì´í„° ìœ ì¶œì´ ì„±ëŠ¥ì„ {overestimation:.1f}% ê³¼ëŒ€í‰ê°€"
            recommendation = "ë°ì´í„° ìœ ì¶œ ì œê±° í•„ìˆ˜. í˜„ì¬ ì„±ëŠ¥ì´ ë” í˜„ì‹¤ì "
        else:
            interpretation = "ë°ì´í„° ìœ ì¶œì˜ ìœ ì˜í•œ ì˜í–¥ ë°œê²¬ë˜ì§€ ì•ŠìŒ"
            recommendation = "í˜„ì¬ íŒŒì´í”„ë¼ì¸ì´ ì´ë¯¸ ì ì ˆíˆ ì„¤ê³„ë¨"

        result = HypothesisTestResult(
            hypothesis_id=hypothesis.id,
            test_statistic=t_stat,
            p_value=p_value,
            effect_size=effect_size,
            confidence_interval=ci,
            is_statistically_significant=p_value < hypothesis.significance_level,
            is_practically_significant=practical_significant,
            statistical_power=None,
            sample_size=len(pre_leakage_scores),
            test_method="Paired t-test",
            interpretation=interpretation,
            recommendation=recommendation
        )

        self.results[hypothesis.id] = result
        return result

    def generate_hypothesis_report(self) -> str:
        """ëª¨ë“  ê°€ì„¤ ê²€ì¦ ê²°ê³¼ ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        if not self.results:
            return "ê°€ì„¤ ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ê°€ì„¤ ê²€ì¦ì„ ìˆ˜í–‰í•˜ì„¸ìš”."

        report = ["ğŸ”¬ ê°€ì„¤ ê²€ì¦ ì¢…í•© ë³´ê³ ì„œ", "=" * 60, ""]

        # ê°€ì„¤ë³„ ê²°ê³¼ ìš”ì•½
        for hypothesis_id, result in self.results.items():
            hypothesis = self.hypotheses[hypothesis_id]

            report.append(f"## {hypothesis_id}: {hypothesis.research_question}")
            report.append("-" * 50)
            report.append(f"**ê·€ë¬´ê°€ì„¤**: {hypothesis.null_hypothesis}")
            report.append(f"**ëŒ€ë¦½ê°€ì„¤**: {hypothesis.alternative_hypothesis}")
            report.append("")

            # ê²€ì¦ ê²°ê³¼
            report.append("### ê²€ì¦ ê²°ê³¼:")
            report.append(f"- ê²€ì • í†µê³„ëŸ‰: {result.test_statistic:.4f}")
            report.append(f"- p-value: {result.p_value:.6f}")
            report.append(f"- íš¨ê³¼ í¬ê¸°: {result.effect_size:.4f}" if result.effect_size is not None else "- íš¨ê³¼ í¬ê¸°: N/A")

            if result.confidence_interval:
                report.append(f"- 95% ì‹ ë¢°êµ¬ê°„: [{result.confidence_interval[0]:.4f}, {result.confidence_interval[1]:.4f}]")

            report.append(f"- í‘œë³¸ í¬ê¸°: {result.sample_size}")
            report.append(f"- ê²€ì • ë°©ë²•: {result.test_method}")
            report.append("")

            # ìœ ì˜ì„± í‰ê°€
            stat_sig = "âœ… í†µê³„ì ìœ¼ë¡œ ìœ ì˜" if result.is_statistically_significant else "âŒ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ"
            prac_sig = "âœ… ì‹¤ìš©ì ìœ¼ë¡œ ìœ ì˜" if result.is_practically_significant else "âŒ ì‹¤ìš©ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ"

            report.append("### ìœ ì˜ì„± í‰ê°€:")
            report.append(f"- {stat_sig} (Î± = {hypothesis.significance_level})")
            report.append(f"- {prac_sig}")
            report.append("")

            # í•´ì„ ë° ê¶Œê³ 
            report.append("### í•´ì„:")
            report.append(f"{result.interpretation}")
            report.append("")
            report.append("### ê¶Œê³ ì‚¬í•­:")
            report.append(f"{result.recommendation}")
            report.append("")
            report.append("=" * 60)
            report.append("")

        # ì „ì²´ ê²°ë¡ 
        report.append("## ğŸ¯ ì „ì²´ ê²°ë¡ ")
        report.append("-" * 30)

        significant_hypotheses = [k for k, v in self.results.items() if v.is_statistically_significant]
        practical_hypotheses = [k for k, v in self.results.items() if v.is_practically_significant]

        report.append(f"- ì´ ê°€ì„¤ ìˆ˜: {len(self.results)}")
        report.append(f"- í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ê°€ì„¤: {len(significant_hypotheses)}ê°œ")
        report.append(f"- ì‹¤ìš©ì ìœ¼ë¡œ ìœ ì˜í•œ ê°€ì„¤: {len(practical_hypotheses)}ê°œ")
        report.append("")

        # í•µì‹¬ ë°œê²¬ì‚¬í•­
        if significant_hypotheses:
            report.append("### í•µì‹¬ ë°œê²¬ì‚¬í•­:")
            for hyp_id in significant_hypotheses:
                result = self.results[hyp_id]
                hypothesis = self.hypotheses[hyp_id]
                report.append(f"- **{hyp_id}**: {result.interpretation}")

        report.append("")
        report.append("### ë°©ë²•ë¡ ì  í•¨ì˜:")
        report.append("ì´ ê²°ê³¼ë“¤ì€ ê¸ˆìœµ ë¨¸ì‹ ëŸ¬ë‹ ì—°êµ¬ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ë¡ ì  ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤:")

        if "H1_purged_cv_effectiveness" in significant_hypotheses:
            report.append("- Purged Cross-Validation ì‚¬ìš© í•„ìˆ˜")

        if "H2_ensemble_stability" in significant_hypotheses:
            report.append("- ì•™ìƒë¸” ë°©ë²•ì„ í†µí•œ ì•ˆì •ì„± í™•ë³´ ê¶Œì¥")

        if "H5_data_leakage_impact" in significant_hypotheses:
            report.append("- ë°ì´í„° ìœ ì¶œ ë°©ì§€ê°€ í˜„ì‹¤ì  ì„±ëŠ¥ í‰ê°€ì˜ í•µì‹¬")

        return "\n".join(report)

def main():
    """í…ŒìŠ¤íŠ¸ ë° ì˜ˆì œ ì‹¤í–‰"""
    print("ğŸ”¬ ê°€ì„¤ ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # ê°€ì„¤ ê²€ì¦ í”„ë ˆì„ì›Œí¬ ì´ˆê¸°í™”
    framework = FinancialMLHypothesisFramework()

    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
    np.random.seed(42)

    # H1: Purged CV vs Regular CV
    regular_cv = np.random.normal(0.85, 0.05, 20)  # ê³¼ëŒ€í‰ê°€ëœ ì„±ëŠ¥
    purged_cv = np.random.normal(0.75, 0.04, 20)   # í˜„ì‹¤ì  ì„±ëŠ¥

    print("H1: Purged CV íš¨ê³¼ì„± ê²€ì¦")
    h1_result = framework.test_purged_cv_effectiveness(purged_cv, regular_cv)
    print(f"ê²°ê³¼: {h1_result.interpretation}")
    print(f"ê¶Œê³ : {h1_result.recommendation}")
    print()

    # H2: Ensemble vs Single Model
    ensemble_scores = np.random.normal(0.75, 0.02, 25)    # ë‚®ì€ ë³€ë™ì„±
    single_scores = np.random.normal(0.75, 0.06, 25)      # ë†’ì€ ë³€ë™ì„±

    print("H2: ì•™ìƒë¸” ì•ˆì •ì„± ê²€ì¦")
    h2_result = framework.test_ensemble_stability(ensemble_scores, single_scores)
    print(f"ê²°ê³¼: {h2_result.interpretation}")
    print(f"ê¶Œê³ : {h2_result.recommendation}")
    print()

    # H3: Time-aware vs Static weights
    time_aware = np.random.normal(0.77, 0.03, 20)
    static_weights = np.random.normal(0.75, 0.03, 20)

    print("H3: ì‹œê°„ ì¸ì‹ ë¸”ë Œë”© ìš°ìˆ˜ì„± ê²€ì¦")
    h3_result = framework.test_time_aware_superiority(time_aware, static_weights)
    print(f"ê²°ê³¼: {h3_result.interpretation}")
    print(f"ê¶Œê³ : {h3_result.recommendation}")
    print()

    # H4: Feature count vs Performance
    feature_counts = np.array([5, 10, 15, 20, 25, 30, 35, 40])
    # ì°¨ì›ì˜ ì €ì£¼ ì‹œë®¬ë ˆì´ì…˜ (20ê°œ ì´í›„ ì„±ëŠ¥ ì €í•˜)
    performance = 0.8 - 0.005 * np.maximum(0, feature_counts - 20) + np.random.normal(0, 0.02, len(feature_counts))

    print("H4: ì°¨ì›ì˜ ì €ì£¼ ê²€ì¦")
    h4_result = framework.test_feature_curse_dimensionality(feature_counts, performance)
    print(f"ê²°ê³¼: {h4_result.interpretation}")
    print(f"ê¶Œê³ : {h4_result.recommendation}")
    print()

    # H5: Data leakage impact
    pre_leakage = np.random.normal(0.95, 0.02, 15)   # ê³¼ëŒ€í‰ê°€
    post_leakage = np.random.normal(0.75, 0.03, 15)  # í˜„ì‹¤ì 

    print("H5: ë°ì´í„° ìœ ì¶œ ì˜í–¥ ê²€ì¦")
    h5_result = framework.test_data_leakage_impact(pre_leakage, post_leakage)
    print(f"ê²°ê³¼: {h5_result.interpretation}")
    print(f"ê¶Œê³ : {h5_result.recommendation}")
    print()

    # ì¢…í•© ë³´ê³ ì„œ ìƒì„±
    print("ğŸ“‹ ì¢…í•© ë³´ê³ ì„œ:")
    print("=" * 60)
    report = framework.generate_hypothesis_report()
    print(report)

if __name__ == "__main__":
    main()