#!/usr/bin/env python3
"""
RÂ² ê°œì„  ì‹¤í—˜ - ë‹¨ê³„ì  ì ‘ê·¼ë²•
ìŒìˆ˜ RÂ² ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì²´ê³„ì  ì‹¤í—˜

ì‹¤í—˜ ëª©í‘œ:
1. íƒ€ê²Ÿ ë³€ìˆ˜ ì¬ì„¤ê³„ë¡œ RÂ² > 0 ë‹¬ì„±
2. ì‹œì¥ ì²´ì œ ë¶„í• ë¡œ ì˜ˆì¸¡ë ¥ í–¥ìƒ
3. ì •ê·œí™” ìµœì í™”ë¡œ ê³¼ì í•© ë°©ì§€
4. ê²½ì œì  ì‹¤íš¨ì„± í‰ê°€
"""

import pandas as pd
import numpy as np
import warnings
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import joblib

warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class ExperimentConfig:
    """ì‹¤í—˜ ì„¤ì •"""
    data_path: str = "data/training/sp500_2020_2024_enhanced.csv"
    output_dir: str = "results/r2_improvement/"
    test_size: float = 0.2
    random_state: int = 42
    cv_folds: int = 5

class TargetVariableExperiment:
    """íƒ€ê²Ÿ ë³€ìˆ˜ ì¬ì„¤ê³„ ì‹¤í—˜"""

    def __init__(self, data: pd.DataFrame):
        self.data = data.copy()
        self.results = {}

    def create_alternative_targets(self) -> Dict[str, pd.Series]:
        """ë‹¤ì–‘í•œ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±"""
        logger.info("ğŸ¯ ë‹¤ì–‘í•œ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì¤‘...")

        targets = {}

        # í˜„ì¬ íƒ€ê²Ÿ (ì¼ì¼ ìˆ˜ìµë¥ )
        if 'Returns' in self.data.columns:
            targets['daily_returns'] = self.data['Returns'].copy()

        # 1. ì£¼ê°„/ì›”ê°„ ìˆ˜ìµë¥ 
        if 'Close' in self.data.columns:
            close = self.data['Close']

            # 3ì¼ ìˆ˜ìµë¥ 
            targets['returns_3d'] = (close.shift(-3) - close) / close

            # 5ì¼ ìˆ˜ìµë¥ 
            targets['returns_5d'] = (close.shift(-5) - close) / close

            # 7ì¼ ìˆ˜ìµë¥ 
            targets['returns_7d'] = (close.shift(-7) - close) / close

            # ë¡œê·¸ ìˆ˜ìµë¥ 
            targets['log_returns'] = np.log(close.shift(-1) / close)

            # 2. ë³€ë™ì„± ì¡°ì • ìˆ˜ìµë¥ 
            if 'Volatility' in self.data.columns:
                daily_ret = (close.shift(-1) - close) / close
                vol = self.data['Volatility'].rolling(20).mean()
                targets['vol_adjusted_returns'] = daily_ret / (vol + 1e-8)

            # 3. ë‹¤ìŒë‚  ë³€ë™ì„± ì˜ˆì¸¡
            high = self.data.get('High', close)
            low = self.data.get('Low', close)
            targets['next_day_volatility'] = (high.shift(-1) - low.shift(-1)) / close

            # 4. ìˆ˜ìµë¥  ë²”ìœ„
            targets['return_range'] = (high.shift(-1) - low.shift(-1)) / close

            # 5. ì ˆëŒ€ ìˆ˜ìµë¥ 
            targets['abs_returns'] = np.abs((close.shift(-1) - close) / close)

        # ê²°ì¸¡ì¹˜ ì œê±°
        for name, target in targets.items():
            targets[name] = target.dropna()
            logger.info(f"   ğŸ“Š {name}: {len(targets[name])} ìƒ˜í”Œ")

        return targets

    def evaluate_target_predictability(self, targets: Dict[str, pd.Series]) -> Dict[str, Dict]:
        """íƒ€ê²Ÿë³„ ì˜ˆì¸¡ ê°€ëŠ¥ì„± í‰ê°€"""
        logger.info("ğŸ“ˆ íƒ€ê²Ÿ ë³€ìˆ˜ë³„ ì˜ˆì¸¡ ê°€ëŠ¥ì„± í‰ê°€...")

        results = {}

        # ê¸°ë³¸ íŠ¹ì„± ì„ íƒ (ê°€ì¥ ì•ˆì „í•œ íŠ¹ì„±ë“¤ë§Œ)
        safe_features = [
            'MA_20', 'MA_50', 'RSI', 'Volatility', 'Volume_ratio',
            'Returns_lag_1', 'Returns_lag_2', 'Returns_lag_3'
        ]

        for target_name, target in targets.items():
            logger.info(f"ğŸ” {target_name} í‰ê°€ ì¤‘...")

            try:
                # ë°ì´í„° ì •ë ¬
                aligned_data = self.data.loc[target.index]

                # íŠ¹ì„± ì¶”ì¶œ
                available_features = [f for f in safe_features if f in aligned_data.columns]
                if len(available_features) < 3:
                    logger.warning(f"   âš ï¸ {target_name}: ì¶©ë¶„í•œ íŠ¹ì„± ì—†ìŒ")
                    continue

                X = aligned_data[available_features].fillna(method='ffill').fillna(0)
                y = target.values

                # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì„ íƒ
                valid_mask = ~(np.isnan(y) | np.isinf(y))
                X = X[valid_mask]
                y = y[valid_mask]

                if len(y) < 100:
                    logger.warning(f"   âš ï¸ {target_name}: ìƒ˜í”Œ ìˆ˜ ë¶€ì¡± ({len(y)})")
                    continue

                # ê°„ë‹¨í•œ Ridge íšŒê·€ë¡œ ì˜ˆì¸¡ë ¥ í…ŒìŠ¤íŠ¸
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)

                # ì‹œê³„ì—´ êµì°¨ê²€ì¦
                tscv = TimeSeriesSplit(n_splits=3)

                models = {
                    'Ridge': Ridge(alpha=1.0),
                    'Lasso': Lasso(alpha=0.01),
                    'ElasticNet': ElasticNet(alpha=0.01, l1_ratio=0.5)
                }

                target_results = {}

                for model_name, model in models.items():
                    scores = cross_val_score(model, X_scaled, y, cv=tscv, scoring='r2')
                    target_results[f'{model_name}_r2'] = {
                        'mean': np.mean(scores),
                        'std': np.std(scores),
                        'scores': scores.tolist()
                    }

                # ê¸°ë³¸ í†µê³„
                target_results['stats'] = {
                    'mean': np.mean(y),
                    'std': np.std(y),
                    'skew': float(pd.Series(y).skew()),
                    'kurtosis': float(pd.Series(y).kurtosis()),
                    'samples': len(y),
                    'features': len(available_features)
                }

                results[target_name] = target_results

                # ìµœê³  ì„±ê³¼ ì¶œë ¥
                best_r2 = max([target_results[f'{m}_r2']['mean'] for m in models.keys()])
                logger.info(f"   âœ… {target_name}: ìµœê³  RÂ² = {best_r2:.4f}")

            except Exception as e:
                logger.error(f"   âŒ {target_name}: {str(e)}")
                continue

        return results

class MarketRegimeModeling:
    """ì‹œì¥ ì²´ì œ ë¶„í•  ëª¨ë¸ë§"""

    def __init__(self, data: pd.DataFrame):
        self.data = data.copy()

    def identify_market_regimes(self) -> pd.Series:
        """ì‹œì¥ ì²´ì œ ì‹ë³„"""
        logger.info("ğŸŒŠ ì‹œì¥ ì²´ì œ ì‹ë³„ ì¤‘...")

        # VIX ê¸°ë°˜ ê³µí¬/íƒìš• êµ¬ë¶„ (VIX ì—†ìœ¼ë©´ ë³€ë™ì„± ì‚¬ìš©)
        if 'VIX' in self.data.columns:
            fear_indicator = self.data['VIX']
        else:
            fear_indicator = self.data['Volatility'].rolling(20).mean()

        # ì¶”ì„¸ ì‹ë³„ (MA ê¸°ë°˜)
        if 'MA_20' in self.data.columns and 'MA_50' in self.data.columns:
            trend = (self.data['MA_20'] / self.data['MA_50'] - 1) * 100
        else:
            trend = self.data['Close'].pct_change(20) * 100

        # ì²´ì œ ë¶„ë¥˜
        regimes = pd.Series(index=self.data.index, dtype=str)

        fear_threshold = fear_indicator.quantile(0.7)
        trend_up_threshold = 2.0  # 2% ì´ìƒ ìƒìŠ¹ ì¶”ì„¸
        trend_down_threshold = -2.0  # 2% ì´ìƒ í•˜ë½ ì¶”ì„¸

        # 4ê°€ì§€ ì²´ì œ ì •ì˜
        bull_calm = (trend > trend_up_threshold) & (fear_indicator < fear_threshold)
        bull_volatile = (trend > trend_up_threshold) & (fear_indicator >= fear_threshold)
        bear_calm = (trend < trend_down_threshold) & (fear_indicator < fear_threshold)
        bear_volatile = (trend < trend_down_threshold) & (fear_indicator >= fear_threshold)
        sideways = (trend >= trend_down_threshold) & (trend <= trend_up_threshold)

        regimes[bull_calm] = 'bull_calm'
        regimes[bull_volatile] = 'bull_volatile'
        regimes[bear_calm] = 'bear_calm'
        regimes[bear_volatile] = 'bear_volatile'
        regimes[sideways] = 'sideways'

        # í†µê³„ ì¶œë ¥
        regime_counts = regimes.value_counts()
        logger.info("ğŸ“Š ì‹œì¥ ì²´ì œ ë¶„í¬:")
        for regime, count in regime_counts.items():
            pct = count / len(regimes) * 100
            logger.info(f"   {regime}: {count}ê°œ ({pct:.1f}%)")

        return regimes

    def train_regime_specific_models(self, X: pd.DataFrame, y: pd.Series,
                                   regimes: pd.Series) -> Dict[str, object]:
        """ì²´ì œë³„ ëª¨ë¸ í›ˆë ¨"""
        logger.info("ğŸ¤– ì²´ì œë³„ ëª¨ë¸ í›ˆë ¨ ì¤‘...")

        models = {}
        regime_performance = {}

        # ì¸ë±ìŠ¤ ì •ë ¬
        common_index = X.index.intersection(y.index).intersection(regimes.index)
        X_aligned = X.loc[common_index]
        y_aligned = y.loc[common_index] if hasattr(y, 'loc') else pd.Series(y, index=X.index).loc[common_index]
        regimes_aligned = regimes.loc[common_index]

        for regime in regimes_aligned.unique():
            if pd.isna(regime):
                continue

            mask = regimes_aligned == regime
            if mask.sum() < 50:  # ìµœì†Œ ìƒ˜í”Œ ìˆ˜
                logger.warning(f"   âš ï¸ {regime}: ìƒ˜í”Œ ìˆ˜ ë¶€ì¡± ({mask.sum()})")
                continue

            X_regime = X_aligned[mask]
            y_regime = y_aligned[mask]

            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            valid_idx = ~(X_regime.isna().any(axis=1) | y_regime.isna())
            X_regime = X_regime[valid_idx]
            y_regime = y_regime[valid_idx]

            if len(y_regime) < 30:
                continue

            # ì •ê·œí™”
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X_regime)

            # Ridge íšŒê·€ í›ˆë ¨
            model = Ridge(alpha=1.0)
            model.fit(X_scaled, y_regime)

            # ì„±ëŠ¥ í‰ê°€
            y_pred = model.predict(X_scaled)
            r2 = r2_score(y_regime, y_pred)

            models[regime] = {
                'model': model,
                'scaler': scaler,
                'r2': r2,
                'samples': len(y_regime)
            }

            logger.info(f"   âœ… {regime}: RÂ² = {r2:.4f}, ìƒ˜í”Œ = {len(y_regime)}")

        return models

class R2ImprovementExperiment:
    """RÂ² ê°œì„  í†µí•© ì‹¤í—˜"""

    def __init__(self, config: ExperimentConfig):
        self.config = config
        self.results = {}

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        Path(config.output_dir).mkdir(parents=True, exist_ok=True)

    def load_data(self) -> pd.DataFrame:
        """ë°ì´í„° ë¡œë“œ"""
        logger.info(f"ğŸ“ ë°ì´í„° ë¡œë“œ: {self.config.data_path}")

        data = pd.read_csv(self.config.data_path, index_col=0, parse_dates=True)
        logger.info(f"   ğŸ“Š í˜•íƒœ: {data.shape}")
        logger.info(f"   ğŸ“… ê¸°ê°„: {data.index.min()} ~ {data.index.max()}")

        return data

    def run_experiments(self):
        """ì „ì²´ ì‹¤í—˜ ì‹¤í–‰"""
        logger.info("ğŸš€ RÂ² ê°œì„  ì‹¤í—˜ ì‹œì‘")

        # 1. ë°ì´í„° ë¡œë“œ
        data = self.load_data()

        # 2. íƒ€ê²Ÿ ë³€ìˆ˜ ì‹¤í—˜
        logger.info("\n" + "="*50)
        logger.info("ğŸ¯ Phase 1: íƒ€ê²Ÿ ë³€ìˆ˜ ìµœì í™”")
        logger.info("="*50)

        target_exp = TargetVariableExperiment(data)
        targets = target_exp.create_alternative_targets()
        target_results = target_exp.evaluate_target_predictability(targets)

        self.results['target_experiments'] = target_results

        # ìµœê³  ì„±ê³¼ íƒ€ê²Ÿ ì„ íƒ
        best_target = self.select_best_target(target_results)
        logger.info(f"ğŸ† ìµœê³  ì„±ê³¼ íƒ€ê²Ÿ: {best_target}")

        # 3. ì‹œì¥ ì²´ì œ ëª¨ë¸ë§
        logger.info("\n" + "="*50)
        logger.info("ğŸŒŠ Phase 2: ì‹œì¥ ì²´ì œ ë¶„í•  ëª¨ë¸ë§")
        logger.info("="*50)

        regime_modeling = MarketRegimeModeling(data)
        regimes = regime_modeling.identify_market_regimes()

        # 4. ìµœì¢… ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
        logger.info("\n" + "="*50)
        logger.info("ğŸ¤– Phase 3: í†µí•© ëª¨ë¸ í›ˆë ¨")
        logger.info("="*50)

        final_results = self.train_final_models(data, targets[best_target], regimes)
        self.results['final_models'] = final_results

        # 5. ê²°ê³¼ ì €ì¥
        self.save_results()

        # 6. ìš”ì•½ ë³´ê³ ì„œ
        self.generate_summary_report()

    def select_best_target(self, target_results: Dict) -> str:
        """ìµœê³  ì„±ê³¼ íƒ€ê²Ÿ ì„ íƒ"""
        best_score = -np.inf
        best_target = 'daily_returns'

        for target_name, results in target_results.items():
            # Ridge ëª¨ë¸ RÂ² ê¸°ì¤€
            if 'Ridge_r2' in results:
                score = results['Ridge_r2']['mean']
                if score > best_score:
                    best_score = score
                    best_target = target_name

        return best_target

    def train_final_models(self, data: pd.DataFrame, target: pd.Series,
                          regimes: pd.Series) -> Dict:
        """ìµœì¢… ëª¨ë¸ í›ˆë ¨"""

        # ì•ˆì „í•œ íŠ¹ì„± ì„ íƒ
        safe_features = [
            'MA_20', 'MA_50', 'RSI', 'Volatility', 'Volume_ratio',
            'Returns_lag_1', 'Returns_lag_2', 'Returns_lag_3',
            'BB_position', 'ATR'
        ]

        available_features = [f for f in safe_features if f in data.columns]

        # ë°ì´í„° ì •ë ¬
        aligned_data = data.loc[target.index]
        aligned_regimes = regimes.loc[target.index]

        X = aligned_data[available_features].fillna(method='ffill').fillna(0)
        y = target.values

        # ìœ íš¨ ë°ì´í„° ì„ íƒ
        valid_mask = ~(np.isnan(y) | np.isinf(y) | X.isna().any(axis=1))
        X = X[valid_mask]
        y = y[valid_mask]
        aligned_regimes = aligned_regimes[valid_mask]

        results = {}

        # 1. ì „ì²´ ë°ì´í„° ëª¨ë¸
        logger.info("ğŸ”§ ì „ì²´ ë°ì´í„° ëª¨ë¸ í›ˆë ¨...")
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        models = {
            'Ridge_optimized': Ridge(alpha=0.1),
            'Lasso_optimized': Lasso(alpha=0.001),
            'ElasticNet_optimized': ElasticNet(alpha=0.001, l1_ratio=0.5)
        }

        for name, model in models.items():
            # ì‹œê³„ì—´ êµì°¨ê²€ì¦
            tscv = TimeSeriesSplit(n_splits=5)
            scores = cross_val_score(model, X_scaled, y, cv=tscv, scoring='r2')

            # ì „ì²´ ë°ì´í„° í›ˆë ¨
            model.fit(X_scaled, y)
            y_pred = model.predict(X_scaled)

            results[name] = {
                'cv_r2_mean': np.mean(scores),
                'cv_r2_std': np.std(scores),
                'train_r2': r2_score(y, y_pred),
                'train_mse': mean_squared_error(y, y_pred),
                'train_mae': mean_absolute_error(y, y_pred),
                'model': model,
                'scaler': scaler
            }

            logger.info(f"   {name}: CV RÂ² = {np.mean(scores):.4f} Â± {np.std(scores):.4f}")

        # 2. ì²´ì œë³„ ëª¨ë¸
        logger.info("ğŸŒŠ ì²´ì œë³„ ëª¨ë¸ í›ˆë ¨...")
        regime_modeling = MarketRegimeModeling(data)
        regime_models = regime_modeling.train_regime_specific_models(X, pd.Series(y), aligned_regimes)

        results['regime_models'] = regime_models

        return results

    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        logger.info("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")

        # JSONìœ¼ë¡œ ì €ì¥ (ëª¨ë¸ ì œì™¸)
        import json

        # ëª¨ë¸ ê°ì²´ ì œê±°í•œ ê²°ê³¼ ìƒì„±
        save_results = {}
        for key, value in self.results.items():
            if key == 'final_models':
                save_results[key] = {}
                for model_name, model_data in value.items():
                    if model_name == 'regime_models':
                        save_results[key][model_name] = {
                            regime: {k: v for k, v in regime_data.items() if k not in ['model', 'scaler']}
                            for regime, regime_data in model_data.items()
                        }
                    else:
                        save_results[key][model_name] = {
                            k: v for k, v in model_data.items() if k not in ['model', 'scaler']
                        }
            else:
                save_results[key] = value

        with open(f"{self.config.output_dir}/experiment_results.json", 'w') as f:
            json.dump(save_results, f, indent=2, default=str)

        # ëª¨ë¸ë“¤ ë³„ë„ ì €ì¥
        if 'final_models' in self.results:
            for name, model_data in self.results['final_models'].items():
                if name != 'regime_models' and 'model' in model_data:
                    joblib.dump(model_data['model'], f"{self.config.output_dir}/{name}_model.pkl")
                    joblib.dump(model_data['scaler'], f"{self.config.output_dir}/{name}_scaler.pkl")

        logger.info(f"   ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.config.output_dir}")

    def generate_summary_report(self):
        """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š RÂ² ê°œì„  ì‹¤í—˜ ê²°ê³¼ ìš”ì•½")
        logger.info("="*60)

        # íƒ€ê²Ÿ ë³€ìˆ˜ ê²°ê³¼
        if 'target_experiments' in self.results:
            logger.info("\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ë³„ ìµœê³  RÂ² ì„±ê³¼:")
            for target, results in self.results['target_experiments'].items():
                if 'Ridge_r2' in results:
                    r2 = results['Ridge_r2']['mean']
                    samples = results['stats']['samples']
                    logger.info(f"   {target:20s}: RÂ² = {r2:7.4f} (ìƒ˜í”Œ: {samples})")

        # ìµœì¢… ëª¨ë¸ ê²°ê³¼
        if 'final_models' in self.results:
            logger.info("\nğŸ¤– ìµœì¢… ëª¨ë¸ ì„±ê³¼:")
            for name, results in self.results['final_models'].items():
                if name != 'regime_models' and 'cv_r2_mean' in results:
                    cv_r2 = results['cv_r2_mean']
                    cv_std = results['cv_r2_std']
                    train_r2 = results['train_r2']
                    logger.info(f"   {name:20s}: CV RÂ² = {cv_r2:7.4f} Â± {cv_std:.4f}, Train RÂ² = {train_r2:7.4f}")

        # ì²´ì œë³„ ëª¨ë¸ ê²°ê³¼
        if 'final_models' in self.results and 'regime_models' in self.results['final_models']:
            logger.info("\nğŸŒŠ ì²´ì œë³„ ëª¨ë¸ ì„±ê³¼:")
            for regime, model_data in self.results['final_models']['regime_models'].items():
                r2 = model_data['r2']
                samples = model_data['samples']
                logger.info(f"   {regime:15s}: RÂ² = {r2:7.4f} (ìƒ˜í”Œ: {samples})")

        # ê°œì„  ì—¬ë¶€ íŒë‹¨
        best_r2 = -np.inf
        if 'final_models' in self.results:
            for name, results in self.results['final_models'].items():
                if name != 'regime_models' and 'cv_r2_mean' in results:
                    best_r2 = max(best_r2, results['cv_r2_mean'])

        logger.info("\n" + "="*60)
        if best_r2 > 0:
            logger.info("ğŸ‰ ì„±ê³µ! ì–‘ìˆ˜ RÂ² ë‹¬ì„±!")
            logger.info(f"   ìµœê³  ì„±ê³¼: RÂ² = {best_r2:.4f}")
        else:
            logger.info("âš ï¸  ì—¬ì „íˆ ìŒìˆ˜ RÂ², ì¶”ê°€ ê°œì„  í•„ìš”")
            logger.info(f"   í˜„ì¬ ìµœê³ : RÂ² = {best_r2:.4f}")

        logger.info("="*60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    config = ExperimentConfig()
    experiment = R2ImprovementExperiment(config)
    experiment.run_experiments()


if __name__ == "__main__":
    main()