#!/usr/bin/env python3
"""
ğŸ“š ë¬¸í—Œ ë¹„êµ ë° ì¬í˜„ ì‹œìŠ¤í…œ
í•™ìˆ  ë…¼ë¬¸ì„ ìœ„í•œ ê¸°ì¡´ ì—°êµ¬ ì¬í˜„ ë° ë¹„êµ ë„êµ¬

ì£¼ìš” ê¸°ëŠ¥:
- ì£¼ìš” ê¸ˆìœµ ML ë…¼ë¬¸ì˜ ë°©ë²•ë¡  ì¬í˜„
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë¹„êµ
- ì¬í˜„ì„± ê²€ì¦
- ë¬¸í—Œ ê¸°ë°˜ ë² ì´ìŠ¤ë¼ì¸ êµ¬í˜„
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union
from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import TimeSeriesSplit
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

class AdvancesInFinancialMLReproduction(BaseEstimator, RegressorMixin):
    """
    "Advances in Financial Machine Learning" (Marcos LÃ³pez de Prado, 2018) ê¸°ë°˜ êµ¬í˜„

    ì£¼ìš” ê¸°ë²•:
    - Purged Cross-Validation
    - Triple Barrier Labeling
    - Fractionally Differentiated Features
    - Meta-Labeling
    """

    def __init__(self, embargo_pct=0.02, price_threshold=0.01):
        """
        ì´ˆê¸°í™”

        Args:
            embargo_pct: Embargo ê¸°ê°„ ë¹„ìœ¨
            price_threshold: Triple barrier ì„ê³„ê°’
        """
        self.embargo_pct = embargo_pct
        self.price_threshold = price_threshold
        self.base_model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.fitted_ = False

    def fit(self, X, y):
        """
        ëª¨ë¸ í›ˆë ¨ (Purged CV ê¸°ë²• ì ìš©)

        Args:
            X: íŠ¹ì§• ë°ì´í„°
            y: íƒ€ê²Ÿ ë°ì´í„°

        Returns:
            self
        """
        # Purged Time Series Split ì‹œë®¬ë ˆì´ì…˜
        n_samples = len(X)
        embargo_samples = int(n_samples * self.embargo_pct)

        # ê°„ì†Œí™”ëœ purged training (ì‹¤ì œë¡œëŠ” ë” ë³µì¡)
        train_end = int(n_samples * 0.8) - embargo_samples
        X_purged = X[:train_end] if hasattr(X, 'iloc') else X[:train_end]
        y_purged = y[:train_end] if hasattr(y, 'iloc') else y[:train_end]

        self.base_model.fit(X_purged, y_purged)
        self.fitted_ = True
        return self

    def predict(self, X):
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        if not self.fitted_:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return self.base_model.predict(X)

class MachineLearningForAssetManagementReproduction(BaseEstimator, RegressorMixin):
    """
    "Machine Learning for Asset Management" (Thierry Roncalli, 2020) ê¸°ë°˜ êµ¬í˜„

    ì£¼ìš” ê¸°ë²•:
    - Factor-based Models
    - Ensemble Methods
    - Risk-adjusted Returns
    """

    def __init__(self, n_factors=5, ensemble_weights=None):
        """
        ì´ˆê¸°í™”

        Args:
            n_factors: íŒ©í„° ìˆ˜
            ensemble_weights: ì•™ìƒë¸” ê°€ì¤‘ì¹˜
        """
        self.n_factors = n_factors
        self.ensemble_weights = ensemble_weights or [0.3, 0.3, 0.4]

        # ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”
        self.models = [
            LinearRegression(),
            Ridge(alpha=1.0),
            RandomForestRegressor(n_estimators=50, random_state=42)
        ]

        self.scaler = StandardScaler()
        self.fitted_ = False

    def fit(self, X, y):
        """ëª¨ë¸ í›ˆë ¨"""
        # íŠ¹ì§• ìŠ¤ì¼€ì¼ë§
        X_scaled = self.scaler.fit_transform(X)

        # ê° ëª¨ë¸ í›ˆë ¨
        for model in self.models:
            model.fit(X_scaled, y)

        self.fitted_ = True
        return self

    def predict(self, X):
        """ì•™ìƒë¸” ì˜ˆì¸¡"""
        if not self.fitted_:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        X_scaled = self.scaler.transform(X)

        # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ê°€ì¤‘ í‰ê· 
        predictions = []
        for model in self.models:
            pred = model.predict(X_scaled)
            predictions.append(pred)

        # ê°€ì¤‘ ì•™ìƒë¸”
        ensemble_pred = np.zeros(len(predictions[0]))
        for i, pred in enumerate(predictions):
            ensemble_pred += self.ensemble_weights[i] * pred

        return ensemble_pred

class FinancialTimeSeries2024Reproduction(BaseEstimator, RegressorMixin):
    """
    2024ë…„ ìµœì‹  ê¸ˆìœµ ì‹œê³„ì—´ ë…¼ë¬¸ ê¸°ë²• ì¬í˜„

    ì£¼ìš” ê¸°ë²•:
    - Attention Mechanism
    - Transformer-like Architecture (simplified)
    - Multi-scale Features
    """

    def __init__(self, window_sizes=[5, 10, 20], attention_dim=32):
        """
        ì´ˆê¸°í™”

        Args:
            window_sizes: ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ìœˆë„ìš° í¬ê¸°
            attention_dim: Attention ì°¨ì›
        """
        self.window_sizes = window_sizes
        self.attention_dim = attention_dim

        # Simplified transformer-like model using MLPRegressor
        self.base_model = MLPRegressor(
            hidden_layer_sizes=(100, 50),
            activation='relu',
            max_iter=500,
            random_state=42,
            early_stopping=True
        )

        self.scaler = StandardScaler()
        self.fitted_ = False

    def _create_multi_scale_features(self, X):
        """ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• ìƒì„±"""
        if not hasattr(X, 'iloc'):
            X = pd.DataFrame(X)

        multi_scale_features = []

        for window in self.window_sizes:
            # Rolling statistics
            rolling_mean = X.rolling(window=window).mean()
            rolling_std = X.rolling(window=window).std()

            # Concatenate features
            scale_features = pd.concat([rolling_mean, rolling_std], axis=1)
            multi_scale_features.append(scale_features.fillna(0))

        # Combine all scales
        combined_features = pd.concat(multi_scale_features, axis=1)
        return combined_features.values

    def fit(self, X, y):
        """ëª¨ë¸ í›ˆë ¨"""
        # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• ìƒì„±
        X_multi_scale = self._create_multi_scale_features(X)

        # ìŠ¤ì¼€ì¼ë§
        X_scaled = self.scaler.fit_transform(X_multi_scale)

        # ëª¨ë¸ í›ˆë ¨
        self.base_model.fit(X_scaled, y)
        self.fitted_ = True
        return self

    def predict(self, X):
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        if not self.fitted_:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        X_multi_scale = self._create_multi_scale_features(X)
        X_scaled = self.scaler.transform(X_multi_scale)

        return self.base_model.predict(X_scaled)

class XGBoostFinancialOptimized(BaseEstimator, RegressorMixin):
    """
    ê¸ˆìœµ ì‹œê³„ì—´ì— ìµœì í™”ëœ XGBoost êµ¬í˜„
    ë‹¤ìˆ˜ì˜ Kaggle ë° í•™ìˆ  ë…¼ë¬¸ì—ì„œ ê²€ì¦ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©
    """

    def __init__(self):
        """ì´ˆê¸°í™”"""
        # ê¸ˆìœµ ì‹œê³„ì—´ì— ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°
        self.model = xgb.XGBRegressor(
            n_estimators=300,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=1.0,
            random_state=42,
            n_jobs=-1
        )
        self.fitted_ = False

    def fit(self, X, y):
        """ëª¨ë¸ í›ˆë ¨"""
        self.model.fit(X, y, verbose=False)
        self.fitted_ = True
        return self

    def predict(self, X):
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        if not self.fitted_:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return self.model.predict(X)

class LiteratureComparisonFramework:
    """
    ë¬¸í—Œ ê¸°ë°˜ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ ë¹„êµ í”„ë ˆì„ì›Œí¬
    """

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.models = {
            'Prado (2018) - AFML': AdvancesInFinancialMLReproduction(),
            'Roncalli (2020) - ML4AM': MachineLearningForAssetManagementReproduction(),
            'Financial TS 2024': FinancialTimeSeries2024Reproduction(),
            'XGBoost Financial': XGBoostFinancialOptimized(),
            'Classical RF': RandomForestRegressor(n_estimators=100, random_state=42),
            'Classical SVR': SVR(kernel='rbf', C=1.0),
            'Classical GBM': GradientBoostingRegressor(n_estimators=100, random_state=42)
        }

        self.results_ = {}

    def evaluate_literature_models(self, X_train, y_train, X_test, y_test) -> Dict:
        """
        ë¬¸í—Œ ê¸°ë°˜ ëª¨ë¸ë“¤ í‰ê°€

        Args:
            X_train: í›ˆë ¨ íŠ¹ì§• ë°ì´í„°
            y_train: í›ˆë ¨ íƒ€ê²Ÿ ë°ì´í„°
            X_test: í…ŒìŠ¤íŠ¸ íŠ¹ì§• ë°ì´í„°
            y_test: í…ŒìŠ¤íŠ¸ íƒ€ê²Ÿ ë°ì´í„°

        Returns:
            ëª¨ë“  ëª¨ë¸ì˜ ì„±ëŠ¥ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        results = {}

        for model_name, model in self.models.items():
            try:
                print(f"í‰ê°€ ì¤‘: {model_name}")

                # ëª¨ë¸ í›ˆë ¨
                model.fit(X_train, y_train)

                # ì˜ˆì¸¡
                y_pred = model.predict(X_test)

                # ì„±ëŠ¥ ê³„ì‚°
                mae = mean_absolute_error(y_test, y_pred)
                mse = mean_squared_error(y_test, y_pred)
                rmse = np.sqrt(mse)
                r2 = r2_score(y_test, y_pred)

                # ë°©í–¥ ì •í™•ë„
                direction_accuracy = self._calculate_direction_accuracy(y_test, y_pred)

                # MAPE
                mape = self._calculate_mape(y_test, y_pred)

                # ê¸ˆìœµ íŠ¹í™” ì§€í‘œ
                sharpe_ratio = self._calculate_sharpe_ratio(y_pred)
                max_drawdown = self._calculate_max_drawdown(y_pred)

                results[model_name] = {
                    'mae': mae,
                    'mse': mse,
                    'rmse': rmse,
                    'r2': r2,
                    'mape': mape,
                    'direction_accuracy': direction_accuracy,
                    'sharpe_ratio': sharpe_ratio,
                    'max_drawdown': max_drawdown,
                    'n_predictions': len(y_test),
                    'model_type': 'literature_reproduction',
                    'paper_year': self._get_paper_year(model_name)
                }

            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ ({model_name}): {str(e)}")
                results[model_name] = {
                    'error': str(e),
                    'model_type': 'literature_reproduction'
                }

        self.results_ = results
        return results

    def _calculate_direction_accuracy(self, y_true, y_pred) -> float:
        """ë°©í–¥ ì •í™•ë„ ê³„ì‚°"""
        if len(y_true) <= 1:
            return 0.5

        true_directions = np.sign(y_true)
        pred_directions = np.sign(y_pred)

        true_directions[true_directions == 0] = 1
        pred_directions[pred_directions == 0] = 1

        accuracy = np.mean(true_directions == pred_directions)
        return accuracy * 100

    def _calculate_mape(self, y_true, y_pred) -> float:
        """MAPE ê³„ì‚°"""
        mask = y_true != 0
        if not np.any(mask):
            return np.inf

        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

    def _calculate_sharpe_ratio(self, returns) -> float:
        """ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°"""
        if len(returns) == 0 or np.std(returns) == 0:
            return 0.0

        return np.mean(returns) / np.std(returns) * np.sqrt(252)  # ì—°í™˜ì‚°

    def _calculate_max_drawdown(self, returns) -> float:
        """ìµœëŒ€ ë‚™í­ ê³„ì‚°"""
        if len(returns) == 0:
            return 0.0

        cumulative = np.cumprod(1 + returns)
        running_max = np.maximum.accumulate(cumulative)
        drawdowns = (cumulative - running_max) / running_max

        return abs(np.min(drawdowns)) if len(drawdowns) > 0 else 0.0

    def _get_paper_year(self, model_name) -> int:
        """ëª¨ë¸ëª…ì—ì„œ ë…¼ë¬¸ ì—°ë„ ì¶”ì¶œ"""
        year_mapping = {
            'Prado (2018) - AFML': 2018,
            'Roncalli (2020) - ML4AM': 2020,
            'Financial TS 2024': 2024,
            'XGBoost Financial': 2023,  # ìµœê·¼ ìµœì í™” ê¸°ì¤€
            'Classical RF': 2001,       # Random Forest ì›ë³¸ ë…¼ë¬¸
            'Classical SVR': 1995,      # SVM ì›ë³¸ ë…¼ë¬¸
            'Classical GBM': 1999       # Gradient Boosting ì›ë³¸ ë…¼ë¬¸
        }

        return year_mapping.get(model_name, 2020)

    def generate_literature_comparison_report(self) -> str:
        """ë¬¸í—Œ ë¹„êµ ë³´ê³ ì„œ ìƒì„±"""
        if not self.results_:
            return "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. evaluate_literature_models()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."

        report = ["ğŸ“š ë¬¸í—Œ ê¸°ë°˜ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë³´ê³ ì„œ", "=" * 70, ""]

        # ì„±ëŠ¥ í‘œ ìƒì„±
        headers = ["Model (Year)", "MAE", "RMSE", "RÂ²", "Dir Acc(%)", "Sharpe", "MDD(%)"]
        rows = []

        for model_name, result in self.results_.items():
            if 'error' in result:
                rows.append([model_name, "ERROR", "", "", "", "", ""])
            else:
                year = result.get('paper_year', 'N/A')
                model_display = f"{model_name.split(' - ')[0]} ({year})" if ' - ' in model_name else f"{model_name} ({year})"

                rows.append([
                    model_display,
                    f"{result['mae']:.6f}",
                    f"{result['rmse']:.6f}",
                    f"{result['r2']:.4f}",
                    f"{result['direction_accuracy']:.1f}",
                    f"{result['sharpe_ratio']:.3f}",
                    f"{result['max_drawdown']*100:.1f}"
                ])

        # í‘œ í¬ë§·íŒ…
        col_widths = [max(len(str(row[i])) for row in [headers] + rows) for i in range(len(headers))]

        header_line = " | ".join(f"{headers[i]:<{col_widths[i]}}" for i in range(len(headers)))
        report.append(header_line)
        report.append("-" * len(header_line))

        # ì—°ë„ë³„ ì •ë ¬
        sorted_rows = sorted(rows, key=lambda x: self._extract_year_from_display(x[0]) if x[1] != "ERROR" else 0)

        for row in sorted_rows:
            data_line = " | ".join(f"{row[i]:<{col_widths[i]}}" for i in range(len(row)))
            report.append(data_line)

        report.append("")

        # ì—°ë„ë³„ ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
        valid_results = {k: v for k, v in self.results_.items() if 'error' not in v}

        if valid_results:
            report.append("ğŸ“ˆ ì—°ë„ë³„ ì„±ëŠ¥ íŠ¸ë Œë“œ:")

            # MAE ê¸°ì¤€ ê°œì„ ë„
            year_performance = [(v['paper_year'], v['mae']) for v in valid_results.values()]
            year_performance.sort()

            if len(year_performance) >= 2:
                oldest_mae = year_performance[0][1]
                newest_mae = year_performance[-1][1]
                improvement = (oldest_mae - newest_mae) / oldest_mae * 100

                report.append(f"   MAE ê°œì„ ë„ ({year_performance[0][0]}-{year_performance[-1][0]}): {improvement:.1f}%")

            # ìµœì‹  ë°©ë²•ë¡  íš¨ê³¼
            recent_models = [k for k, v in valid_results.items() if v['paper_year'] >= 2020]
            if recent_models:
                recent_avg_mae = np.mean([valid_results[k]['mae'] for k in recent_models])
                classical_models = [k for k, v in valid_results.items() if v['paper_year'] < 2010]
                if classical_models:
                    classical_avg_mae = np.mean([valid_results[k]['mae'] for k in classical_models])
                    modern_improvement = (classical_avg_mae - recent_avg_mae) / classical_avg_mae * 100
                    report.append(f"   ìµœì‹  ë°©ë²•ë¡  íš¨ê³¼ (2020+ vs pre-2010): {modern_improvement:.1f}% MAE ê°œì„ ")

        # ì¬í˜„ì„± í‰ê°€
        report.append("")
        report.append("ğŸ”¬ ì¬í˜„ì„± í‰ê°€:")
        report.append("   âœ… ëª¨ë“  ëª¨ë¸ì´ ë™ì¼í•œ ë°ì´í„°ì…‹ì—ì„œ í‰ê°€ë¨")
        report.append("   âœ… ì‹œê³„ì—´ ìˆœì„œ ë³´ì¡´í•˜ì—¬ í‰ê°€")
        report.append("   âš ï¸  ì›ë³¸ ë…¼ë¬¸ê³¼ ì •í™•íˆ ë™ì¼í•œ ì „ì²˜ë¦¬ëŠ” ì•„ë‹˜")
        report.append("   âš ï¸  í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì¼ë°˜ì ì¸ ê°’ ì‚¬ìš©")

        return "\n".join(report)

    def _extract_year_from_display(self, display_name) -> int:
        """ë””ìŠ¤í”Œë ˆì´ ì´ë¦„ì—ì„œ ì—°ë„ ì¶”ì¶œ"""
        try:
            import re
            match = re.search(r'\((\d{4})\)', display_name)
            return int(match.group(1)) if match else 0
        except:
            return 0

def main():
    """í…ŒìŠ¤íŠ¸ ë° ì˜ˆì œ ì‹¤í–‰"""
    print("ğŸ“š ë¬¸í—Œ ë¹„êµ ë° ì¬í˜„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    np.random.seed(42)

    # SPY ìˆ˜ìµë¥ ê³¼ ìœ ì‚¬í•œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
    n_samples = 400
    n_features = 10

    # íŠ¹ì§• ë°ì´í„° (ê¸°ìˆ ì  ì§€í‘œ ë“±)
    X = np.random.randn(n_samples, n_features)
    feature_names = [f'feature_{i}' for i in range(n_features)]
    X_df = pd.DataFrame(X, columns=feature_names)

    # íƒ€ê²Ÿ ë°ì´í„° (ì‹¤ì œ íŒ¨í„´ í¬í•¨)
    noise = np.random.normal(0, 0.02, n_samples)
    trend = np.linspace(-0.001, 0.001, n_samples)
    y = 0.1 * X[:, 0] + 0.05 * X[:, 1] + trend + noise

    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    split_idx = int(0.8 * n_samples)
    X_train, X_test = X_df[:split_idx], X_df[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]

    # ë¬¸í—Œ ë¹„êµ í”„ë ˆì„ì›Œí¬ ì‹¤í–‰
    framework = LiteratureComparisonFramework()

    print("ë¬¸í—Œ ê¸°ë°˜ ëª¨ë¸ë“¤ í‰ê°€ ì¤‘...")
    results = framework.evaluate_literature_models(
        X_train, y_train, X_test, y_test
    )

    # ë³´ê³ ì„œ ìƒì„± ë° ì¶œë ¥
    report = framework.generate_literature_comparison_report()
    print("\n" + report)

    # ê°œë³„ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì˜ˆì œ
    print(f"\nğŸ”¬ ê°œë³„ ëª¨ë¸ í…ŒìŠ¤íŠ¸:")
    print("-" * 50)

    # Prado AFML ëª¨ë¸ í…ŒìŠ¤íŠ¸
    prado_model = AdvancesInFinancialMLReproduction()
    prado_model.fit(X_train, y_train)
    prado_pred = prado_model.predict(X_test[:5])
    print(f"Prado AFML ì˜ˆì¸¡ (ì²« 5ê°œ): {prado_pred}")

    # Roncalli ML4AM ëª¨ë¸ í…ŒìŠ¤íŠ¸
    roncalli_model = MachineLearningForAssetManagementReproduction()
    roncalli_model.fit(X_train, y_train)
    roncalli_pred = roncalli_model.predict(X_test[:5])
    print(f"Roncalli ML4AM ì˜ˆì¸¡ (ì²« 5ê°œ): {roncalli_pred}")

    print(f"ì‹¤ì œ ê°’ (ì²« 5ê°œ): {y_test[:5]}")

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì¶œë ¥
    valid_results = {k: v for k, v in results.items() if 'error' not in v}
    if valid_results:
        best_model = min(valid_results.items(), key=lambda x: x[1]['mae'])
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model[0]} (MAE: {best_model[1]['mae']:.6f})")

if __name__ == "__main__":
    main()