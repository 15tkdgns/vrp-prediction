#!/usr/bin/env python3
"""
ğŸ“Š Classical ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ
í•™ìˆ  ë…¼ë¬¸ì„ ìœ„í•œ ì „í†µì ì¸ ML ëª¨ë¸ êµ¬í˜„

ì£¼ìš” ëª¨ë¸:
- Linear Regression
- Ridge Regression
- LASSO Regression
- Elastic Net
- Support Vector Regression
- Decision Tree
- Random Forest
- ARIMA
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import GridSearchCV, TimeSeriesSplit
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller
import warnings
warnings.filterwarnings('ignore')

class ClassicalModelBenchmark:
    """
    ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ

    ë‹¤ì–‘í•œ classical ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ê³  í‰ê°€
    """

    def __init__(self, random_state=42, scale_features=True):
        """
        ì´ˆê¸°í™”

        Args:
            random_state: ëœë¤ ì‹œë“œ
            scale_features: íŠ¹ì§• ìŠ¤ì¼€ì¼ë§ ì—¬ë¶€
        """
        self.random_state = random_state
        self.scale_features = scale_features
        self.scaler = StandardScaler() if scale_features else None
        self.results_ = {}

        # ëª¨ë¸ ì •ì˜
        self.models = {
            'Linear Regression': LinearRegression(),
            'Ridge Regression': Ridge(alpha=1.0, random_state=random_state),
            'LASSO Regression': Lasso(alpha=0.1, random_state=random_state, max_iter=2000),
            'Elastic Net': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=random_state, max_iter=2000),
            'SVR (RBF)': SVR(kernel='rbf', C=1.0, gamma='scale'),
            'SVR (Linear)': SVR(kernel='linear', C=1.0),
            'Decision Tree': DecisionTreeRegressor(random_state=random_state, max_depth=10),
            'Random Forest': RandomForestRegressor(
                n_estimators=100,
                random_state=random_state,
                max_depth=10,
                n_jobs=-1
            )
        }

        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
        self.param_grids = {
            'Ridge Regression': {
                'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]
            },
            'LASSO Regression': {
                'alpha': [0.001, 0.01, 0.1, 1.0, 10.0]
            },
            'Elastic Net': {
                'alpha': [0.01, 0.1, 1.0],
                'l1_ratio': [0.1, 0.5, 0.9]
            },
            'SVR (RBF)': {
                'C': [0.1, 1.0, 10.0],
                'gamma': ['scale', 'auto', 0.001, 0.01]
            },
            'SVR (Linear)': {
                'C': [0.1, 1.0, 10.0, 100.0]
            },
            'Decision Tree': {
                'max_depth': [5, 10, 15, 20],
                'min_samples_split': [2, 5, 10]
            },
            'Random Forest': {
                'n_estimators': [50, 100, 200],
                'max_depth': [5, 10, 15],
                'min_samples_split': [2, 5]
            }
        }

    def evaluate_all_models(self, X_train, y_train, X_test, y_test,
                           tune_hyperparameters=False, cv_folds=3) -> Dict:
        """
        ëª¨ë“  classical ëª¨ë¸ í‰ê°€

        Args:
            X_train: í›ˆë ¨ íŠ¹ì§• ë°ì´í„°
            y_train: í›ˆë ¨ íƒ€ê²Ÿ ë°ì´í„°
            X_test: í…ŒìŠ¤íŠ¸ íŠ¹ì§• ë°ì´í„°
            y_test: í…ŒìŠ¤íŠ¸ íƒ€ê²Ÿ ë°ì´í„°
            tune_hyperparameters: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì—¬ë¶€
            cv_folds: êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜

        Returns:
            ëª¨ë“  ëª¨ë¸ì˜ ì„±ëŠ¥ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        results = {}

        # íŠ¹ì§• ìŠ¤ì¼€ì¼ë§
        if self.scale_features:
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
        else:
            X_train_scaled = X_train
            X_test_scaled = X_test

        for model_name, model in self.models.items():
            try:
                print(f"í‰ê°€ ì¤‘: {model_name}")

                if tune_hyperparameters and model_name in self.param_grids:
                    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
                    tscv = TimeSeriesSplit(n_splits=cv_folds)
                    grid_search = GridSearchCV(
                        model,
                        self.param_grids[model_name],
                        cv=tscv,
                        scoring='neg_mean_absolute_error',
                        n_jobs=-1 if model_name != 'SVR (RBF)' else 1  # SVRì€ ë³‘ë ¬ ì²˜ë¦¬ ì œí•œ
                    )
                    grid_search.fit(X_train_scaled, y_train)
                    best_model = grid_search.best_estimator_
                    best_params = grid_search.best_params_
                    cv_score = -grid_search.best_score_
                else:
                    # ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©
                    model.fit(X_train_scaled, y_train)
                    best_model = model
                    best_params = {}
                    cv_score = None

                # ì˜ˆì¸¡ ë° ì„±ëŠ¥ ê³„ì‚°
                y_pred = best_model.predict(X_test_scaled)

                mae = mean_absolute_error(y_test, y_pred)
                mse = mean_squared_error(y_test, y_pred)
                rmse = np.sqrt(mse)
                r2 = r2_score(y_test, y_pred)

                # ë°©í–¥ ì •í™•ë„ ê³„ì‚°
                direction_accuracy = self._calculate_direction_accuracy(y_test, y_pred)

                # MAPE ê³„ì‚°
                mape = self._calculate_mape(y_test, y_pred)

                # íŠ¹ì§• ì¤‘ìš”ë„ (ê°€ëŠ¥í•œ ê²½ìš°)
                feature_importance = self._get_feature_importance(best_model, X_train.columns if hasattr(X_train, 'columns') else None)

                results[model_name] = {
                    'mae': mae,
                    'mse': mse,
                    'rmse': rmse,
                    'r2': r2,
                    'mape': mape,
                    'direction_accuracy': direction_accuracy,
                    'cv_score': cv_score,
                    'best_params': best_params,
                    'feature_importance': feature_importance,
                    'n_predictions': len(y_test),
                    'model_type': 'classical_ml',
                    'hyperparameter_tuned': tune_hyperparameters and model_name in self.param_grids
                }

            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ ({model_name}): {str(e)}")
                results[model_name] = {
                    'error': str(e),
                    'model_type': 'classical_ml'
                }

        self.results_ = results
        return results

    def evaluate_arima_models(self, y_train, y_test, max_p=3, max_d=2, max_q=3) -> Dict:
        """
        ARIMA ëª¨ë¸ í‰ê°€

        Args:
            y_train: í›ˆë ¨ ì‹œê³„ì—´ ë°ì´í„°
            y_test: í…ŒìŠ¤íŠ¸ ì‹œê³„ì—´ ë°ì´í„°
            max_p: ìµœëŒ€ AR ì°¨ìˆ˜
            max_d: ìµœëŒ€ ì°¨ë¶„ ì°¨ìˆ˜
            max_q: ìµœëŒ€ MA ì°¨ìˆ˜

        Returns:
            ARIMA ëª¨ë¸ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        results = {}

        try:
            # ì •ìƒì„± ê²€ì •
            adf_result = adfuller(y_train)
            is_stationary = adf_result[1] < 0.05

            print(f"ADF ê²€ì • p-value: {adf_result[1]:.6f}")
            print(f"ì‹œê³„ì—´ ì •ìƒì„±: {'ì •ìƒ' if is_stationary else 'ë¹„ì •ìƒ'}")

            # ìµœì  ARIMA ì°¨ìˆ˜ ì°¾ê¸°
            best_aic = np.inf
            best_order = None
            best_model = None

            for p in range(max_p + 1):
                for d in range(max_d + 1):
                    for q in range(max_q + 1):
                        try:
                            model = ARIMA(y_train, order=(p, d, q))
                            fitted_model = model.fit()

                            if fitted_model.aic < best_aic:
                                best_aic = fitted_model.aic
                                best_order = (p, d, q)
                                best_model = fitted_model

                        except Exception:
                            continue

            if best_model is not None:
                # ì˜ˆì¸¡ ìˆ˜í–‰
                forecast = best_model.forecast(steps=len(y_test))

                # ì„±ëŠ¥ ê³„ì‚°
                mae = mean_absolute_error(y_test, forecast)
                mse = mean_squared_error(y_test, forecast)
                rmse = np.sqrt(mse)
                r2 = r2_score(y_test, forecast)

                direction_accuracy = self._calculate_direction_accuracy(y_test, forecast)
                mape = self._calculate_mape(y_test, forecast)

                results['ARIMA'] = {
                    'mae': mae,
                    'mse': mse,
                    'rmse': rmse,
                    'r2': r2,
                    'mape': mape,
                    'direction_accuracy': direction_accuracy,
                    'best_order': best_order,
                    'aic': best_aic,
                    'bic': best_model.bic,
                    'is_stationary': is_stationary,
                    'adf_pvalue': adf_result[1],
                    'n_predictions': len(y_test),
                    'model_type': 'time_series'
                }

            else:
                results['ARIMA'] = {
                    'error': 'ARIMA ëª¨ë¸ ìµœì í™” ì‹¤íŒ¨',
                    'model_type': 'time_series'
                }

        except Exception as e:
            results['ARIMA'] = {
                'error': str(e),
                'model_type': 'time_series'
            }

        return results

    def _calculate_direction_accuracy(self, y_true, y_pred) -> float:
        """ë°©í–¥ ì •í™•ë„ ê³„ì‚°"""
        if len(y_true) <= 1:
            return 0.5

        true_directions = np.sign(y_true)
        pred_directions = np.sign(y_pred)

        # 0ì¸ ê²½ìš° ì²˜ë¦¬
        true_directions[true_directions == 0] = 1
        pred_directions[pred_directions == 0] = 1

        accuracy = np.mean(true_directions == pred_directions)
        return accuracy * 100

    def _calculate_mape(self, y_true, y_pred) -> float:
        """MAPE ê³„ì‚°"""
        mask = y_true != 0
        if not np.any(mask):
            return np.inf

        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

    def _get_feature_importance(self, model, feature_names=None):
        """íŠ¹ì§• ì¤‘ìš”ë„ ì¶”ì¶œ"""
        try:
            if hasattr(model, 'feature_importances_'):
                # Tree-based ëª¨ë¸
                importance = model.feature_importances_
            elif hasattr(model, 'coef_'):
                # Linear ëª¨ë¸
                importance = np.abs(model.coef_)
            else:
                return None

            if feature_names is not None:
                return dict(zip(feature_names, importance))
            else:
                return importance.tolist()

        except Exception:
            return None

    def get_best_classical_model(self, metric='mae') -> Tuple[str, Dict]:
        """
        ì§€ì •ëœ ì§€í‘œ ê¸°ì¤€ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥ classical ëª¨ë¸ ë°˜í™˜

        Args:
            metric: í‰ê°€ ì§€í‘œ

        Returns:
            (ëª¨ë¸ëª…, ì„±ëŠ¥ ê²°ê³¼) íŠœí”Œ
        """
        if not self.results_:
            raise ValueError("evaluate_all_models()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

        valid_results = {k: v for k, v in self.results_.items() if 'error' not in v}

        if not valid_results:
            raise ValueError("ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        if metric == 'r2' or metric == 'direction_accuracy':
            best_model = max(valid_results.items(), key=lambda x: x[1][metric])
        else:
            best_model = min(valid_results.items(), key=lambda x: x[1][metric])

        return best_model

    def generate_classical_report(self) -> str:
        """Classical ëª¨ë¸ ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""
        if not self.results_:
            return "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. evaluate_all_models()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."

        report = ["ğŸ“Š Classical ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì„±ëŠ¥ ë³´ê³ ì„œ", "=" * 60, ""]

        # ì„±ëŠ¥ í‘œ ìƒì„±
        headers = ["Model", "MAE", "RMSE", "RÂ²", "Dir Acc(%)", "MAPE(%)", "Tuned"]
        rows = []

        for model_name, result in self.results_.items():
            if 'error' in result:
                rows.append([model_name, "ERROR", "", "", "", "", ""])
            else:
                tuned = "Yes" if result.get('hyperparameter_tuned', False) else "No"
                rows.append([
                    model_name,
                    f"{result['mae']:.6f}",
                    f"{result['rmse']:.6f}",
                    f"{result['r2']:.4f}",
                    f"{result['direction_accuracy']:.1f}",
                    f"{result['mape']:.1f}" if not np.isinf(result['mape']) else "âˆ",
                    tuned
                ])

        # í‘œ í¬ë§·íŒ…
        col_widths = [max(len(str(row[i])) for row in [headers] + rows) for i in range(len(headers))]

        header_line = " | ".join(f"{headers[i]:<{col_widths[i]}}" for i in range(len(headers)))
        report.append(header_line)
        report.append("-" * len(header_line))

        for row in rows:
            data_line = " | ".join(f"{row[i]:<{col_widths[i]}}" for i in range(len(row)))
            report.append(data_line)

        report.append("")

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤
        try:
            best_mae = self.get_best_classical_model('mae')
            best_r2 = self.get_best_classical_model('r2')
            best_direction = self.get_best_classical_model('direction_accuracy')

            report.append("ğŸ† ìµœê³  ì„±ëŠ¥ Classical ëª¨ë¸:")
            report.append(f"   MAE ê¸°ì¤€: {best_mae[0]} (MAE: {best_mae[1]['mae']:.6f})")
            report.append(f"   RÂ² ê¸°ì¤€: {best_r2[0]} (RÂ²: {best_r2[1]['r2']:.4f})")
            report.append(f"   ë°©í–¥ ì •í™•ë„ ê¸°ì¤€: {best_direction[0]} ({best_direction[1]['direction_accuracy']:.1f}%)")

        except Exception as e:
            report.append(f"ìµœê³  ì„±ëŠ¥ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")

        # íŠ¹ì§• ì¤‘ìš”ë„ ì •ë³´ (Random Forest ê¸°ì¤€)
        rf_result = self.results_.get('Random Forest')
        if rf_result and 'feature_importance' in rf_result and rf_result['feature_importance']:
            report.append("")
            report.append("ğŸ” íŠ¹ì§• ì¤‘ìš”ë„ (Random Forest):")

            if isinstance(rf_result['feature_importance'], dict):
                # ì¤‘ìš”ë„ë³„ ì •ë ¬
                sorted_features = sorted(rf_result['feature_importance'].items(),
                                       key=lambda x: x[1], reverse=True)
                for i, (feature, importance) in enumerate(sorted_features[:10]):  # ìƒìœ„ 10ê°œ
                    report.append(f"   {i+1}. {feature}: {importance:.4f}")

        return "\n".join(report)

def main():
    """í…ŒìŠ¤íŠ¸ ë° ì˜ˆì œ ì‹¤í–‰"""
    print("ğŸ“Š Classical ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    np.random.seed(42)

    # SPY ìˆ˜ìµë¥ ê³¼ ìœ ì‚¬í•œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
    n_samples = 300
    n_features = 8

    # íŠ¹ì§• ë°ì´í„° ìƒì„± (ê¸°ìˆ ì  ì§€í‘œ ì‹œë®¬ë ˆì´ì…˜)
    X = np.random.randn(n_samples, n_features)
    feature_names = ['MA_5', 'MA_20', 'RSI', 'BB_position', 'Volume_ratio',
                    'Returns_lag_1', 'Returns_lag_2', 'Volatility_20']

    X_df = pd.DataFrame(X, columns=feature_names)

    # íƒ€ê²Ÿ ë°ì´í„° ìƒì„± (ì•½ê°„ì˜ íŒ¨í„´ í¬í•¨)
    y = 0.0005 + 0.1 * X[:, 0] + 0.05 * X[:, 1] + np.random.normal(0, 0.015, n_samples)

    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  (ì‹œê³„ì—´ì´ë¯€ë¡œ ì‹œê°„ìˆœ)
    split_idx = int(0.8 * n_samples)
    X_train, X_test = X_df[:split_idx], X_df[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]

    # Classical ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    benchmark = ClassicalModelBenchmark(random_state=42, scale_features=True)

    print("ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ í‰ê°€ ì¤‘...")
    results = benchmark.evaluate_all_models(
        X_train, y_train, X_test, y_test,
        tune_hyperparameters=False
    )

    # ARIMA ëª¨ë¸ í‰ê°€
    print("\nARIMA ëª¨ë¸ í‰ê°€ ì¤‘...")
    arima_results = benchmark.evaluate_arima_models(y_train, y_test)
    results.update(arima_results)

    # ë³´ê³ ì„œ ìƒì„±
    benchmark.results_.update(arima_results)
    report = benchmark.generate_classical_report()
    print("\n" + report)

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜ˆì œ (ì†Œê·œëª¨)
    print(f"\nğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜ˆì œ (Ridge Regression):")
    print("-" * 50)

    tuned_benchmark = ClassicalModelBenchmark(random_state=42)
    tuned_benchmark.models = {'Ridge Regression': tuned_benchmark.models['Ridge Regression']}

    tuned_results = tuned_benchmark.evaluate_all_models(
        X_train, y_train, X_test, y_test,
        tune_hyperparameters=True, cv_folds=3
    )

    ridge_result = tuned_results['Ridge Regression']
    print(f"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {ridge_result['best_params']}")
    print(f"CV MAE: {ridge_result['cv_score']:.6f}")
    print(f"Test MAE: {ridge_result['mae']:.6f}")

if __name__ == "__main__":
    main()