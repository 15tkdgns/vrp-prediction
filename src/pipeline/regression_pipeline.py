#!/usr/bin/env python3
"""
íšŒê·€ ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸
MAPE, RÂ², MSE ìµœì í™” í†µí•© ì‹œìŠ¤í…œ
"""

import sys
import os
sys.path.append('/root/workspace/src')

import numpy as np
import pandas as pd
import json
import logging
from pathlib import Path
from datetime import datetime

from core.data_processor import DataProcessor
from training.regression_metric_trainer import RegressionMetricTrainer
from evaluation.performance_evaluator import PerformanceEvaluator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RegressionPipeline:
    """íšŒê·€ ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸"""

    def __init__(self, config=None):
        self.config = config or self._get_default_config()
        self.data_processor = DataProcessor()
        self.model_trainer = RegressionMetricTrainer(gpu_enabled=self.config['gpu_enabled'])
        self.evaluator = PerformanceEvaluator()

        logger.info("íšŒê·€ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")

    def _get_default_config(self):
        """ê¸°ë³¸ ì„¤ì •"""
        return {
            'data_path': '/root/workspace/data/training/sp500_2020_2024_enhanced.csv',
            'target_type': 'return',  # íšŒê·€: 'return', ë¶„ë¥˜: 'direction'
            'sequence_length': 20,
            'cv_splits': 3,
            'gpu_enabled': True,
            'save_models': True,
            'save_results': True,
            'output_dir': '/root/workspace/data/results/regression'
        }

    def load_and_prepare_data(self):
        """ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"""
        logger.info("=== íšŒê·€ ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„ ===")

        # ë°ì´í„° ë¡œë”©
        df = self.data_processor.load_and_validate_data(self.config['data_path'])
        if df is None:
            raise ValueError("ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")

        # MLìš© ë°ì´í„° ì¤€ë¹„ (íšŒê·€)
        X, y, feature_cols = self.data_processor.prepare_ml_data(df, self.config['target_type'])

        # ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„
        X_seq, y_seq, scaler = self.data_processor.prepare_sequence_data(
            df, self.config['sequence_length'], self.config['target_type']
        )

        # ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
        integrity_check = self.data_processor.validate_data_integrity(X.values, y.values)
        logger.info(f"ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬: {integrity_check}")

        # í•™ìŠµ/ê²€ì¦ ë¶„í• 
        splits = self.data_processor.create_train_val_split(X.values, y.values, self.config['cv_splits'])

        # íƒ€ê²Ÿ ë¶„í¬ ë¶„ì„
        logger.info(f"íšŒê·€ íƒ€ê²Ÿ í†µê³„:")
        logger.info(f"  í‰ê· : {np.mean(y.values):.6f}")
        logger.info(f"  í‘œì¤€í¸ì°¨: {np.std(y.values):.6f}")
        logger.info(f"  ìµœì†Œê°’: {np.min(y.values):.6f}")
        logger.info(f"  ìµœëŒ€ê°’: {np.max(y.values):.6f}")

        return {
            'flat_data': (X.values, y.values),
            'sequence_data': (X_seq, y_seq),
            'feature_names': feature_cols,
            'splits': splits,
            'scaler': scaler,
            'integrity_check': integrity_check
        }

    def train_regression_models(self, data_dict):
        """íšŒê·€ ëª¨ë¸ í›ˆë ¨"""
        logger.info("=== íšŒê·€ ëª¨ë¸ í›ˆë ¨ ë‹¨ê³„ ===")

        X, y = data_dict['flat_data']
        X_seq, y_seq = data_dict['sequence_data']
        splits = data_dict['splits']

        all_results = {}

        # ê° í´ë“œë³„ë¡œ í›ˆë ¨ ë° í‰ê°€
        for fold, (train_idx, val_idx) in enumerate(splits):
            logger.info(f"Fold {fold + 1}/{len(splits)} íšŒê·€ í›ˆë ¨ ì‹œì‘")

            # ë°ì´í„° ë¶„í• 
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]

            # ì‹œí€€ìŠ¤ ë°ì´í„° ë¶„í•  (ì¸ë±ìŠ¤ ì¡°ì •)
            seq_train_idx = train_idx[train_idx < len(X_seq)]
            seq_val_idx = val_idx[val_idx < len(X_seq)]

            if len(seq_train_idx) > 0 and len(seq_val_idx) > 0:
                X_seq_train, X_seq_val = X_seq[seq_train_idx], X_seq[seq_val_idx]
                sequence_data = (X_seq_train, X_seq_val)
            else:
                sequence_data = None

            # íšŒê·€ ëª¨ë¸ í›ˆë ¨
            fold_results = self.model_trainer.train_all_regression_models(
                X_train, X_val, y_train, y_val, sequence_data=sequence_data
            )

            # ê²°ê³¼ ëˆ„ì 
            for model_name, result in fold_results.items():
                if model_name not in all_results:
                    all_results[model_name] = {
                        'fold_mse': [],
                        'fold_mae': [],
                        'fold_rmse': [],
                        'fold_mape': [],
                        'fold_r2': [],
                        'fold_direction_accuracy': [],
                        'type': result['type']
                    }

                all_results[model_name]['fold_mse'].append(result['mse'])
                all_results[model_name]['fold_mae'].append(result['mae'])
                all_results[model_name]['fold_rmse'].append(result['rmse'])
                all_results[model_name]['fold_mape'].append(result['mape'])
                all_results[model_name]['fold_r2'].append(result['r2'])
                all_results[model_name]['fold_direction_accuracy'].append(result['direction_accuracy'])

        # í‰ê·  ì„±ëŠ¥ ê³„ì‚°
        final_results = {}
        for model_name, data in all_results.items():
            final_results[model_name] = {
                'mean_mse': np.mean(data['fold_mse']),
                'std_mse': np.std(data['fold_mse']),
                'mean_mae': np.mean(data['fold_mae']),
                'std_mae': np.std(data['fold_mae']),
                'mean_rmse': np.mean(data['fold_rmse']),
                'std_rmse': np.std(data['fold_rmse']),
                'mean_mape': np.mean(data['fold_mape']),
                'std_mape': np.std(data['fold_mape']),
                'mean_r2': np.mean(data['fold_r2']),
                'std_r2': np.std(data['fold_r2']),
                'mean_direction_accuracy': np.mean(data['fold_direction_accuracy']),
                'std_direction_accuracy': np.std(data['fold_direction_accuracy']),
                'fold_results': data,
                'type': data['type']
            }

        return final_results

    def analyze_regression_performance(self, results):
        """íšŒê·€ ì„±ëŠ¥ ë¶„ì„"""
        logger.info("=== íšŒê·€ ì„±ëŠ¥ ë¶„ì„ ===")

        analysis = {
            'best_by_mse': None,
            'best_by_mae': None,
            'best_by_mape': None,
            'best_by_r2': None,
            'best_by_direction': None,
            'metric_rankings': {},
            'regression_analysis': {}
        }

        # ê° ì§€í‘œë³„ ìµœê³  ëª¨ë¸ ì°¾ê¸°
        best_mse = float('inf')
        best_mae = float('inf')
        best_mape = float('inf')
        best_r2 = float('-inf')
        best_direction = 0

        for model_name, result in results.items():
            # MSE ê¸°ì¤€ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            if result['mean_mse'] < best_mse:
                best_mse = result['mean_mse']
                analysis['best_by_mse'] = {
                    'model': model_name,
                    'score': best_mse,
                    'details': result
                }

            # MAE ê¸°ì¤€ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            if result['mean_mae'] < best_mae:
                best_mae = result['mean_mae']
                analysis['best_by_mae'] = {
                    'model': model_name,
                    'score': best_mae,
                    'details': result
                }

            # MAPE ê¸°ì¤€ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            if result['mean_mape'] < best_mape:
                best_mape = result['mean_mape']
                analysis['best_by_mape'] = {
                    'model': model_name,
                    'score': best_mape,
                    'details': result
                }

            # RÂ² ê¸°ì¤€ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
            if result['mean_r2'] > best_r2:
                best_r2 = result['mean_r2']
                analysis['best_by_r2'] = {
                    'model': model_name,
                    'score': best_r2,
                    'details': result
                }

            # ë°©í–¥ ì •í™•ë„ ê¸°ì¤€ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
            if result['mean_direction_accuracy'] > best_direction:
                best_direction = result['mean_direction_accuracy']
                analysis['best_by_direction'] = {
                    'model': model_name,
                    'score': best_direction,
                    'details': result
                }

        # ì§€í‘œë³„ ìˆœìœ„ ë§¤ê¸°ê¸°
        for metric in ['mean_mse', 'mean_mae', 'mean_mape']:  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            ranking = sorted(results.items(),
                           key=lambda x: x[1][metric],
                           reverse=False)
            analysis['metric_rankings'][metric] = ranking

        for metric in ['mean_r2', 'mean_direction_accuracy']:  # ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
            ranking = sorted(results.items(),
                           key=lambda x: x[1][metric],
                           reverse=True)
            analysis['metric_rankings'][metric] = ranking

        return analysis

    def run_regression_pipeline(self):
        """ì „ì²´ íšŒê·€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("=" * 80)
        logger.info("ğŸš€ íšŒê·€ ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        logger.info("=" * 80)

        start_time = datetime.now()

        try:
            # 1. ë°ì´í„° ì¤€ë¹„
            data_dict = self.load_and_prepare_data()

            # 2. íšŒê·€ ëª¨ë¸ í›ˆë ¨
            model_results = self.train_regression_models(data_dict)

            # 3. íšŒê·€ ì„±ëŠ¥ ë¶„ì„
            regression_analysis = self.analyze_regression_performance(model_results)

            # 4. ì¢…í•© ê²°ê³¼
            pipeline_results = {
                'pipeline_config': self.config,
                'execution_time': str(datetime.now() - start_time),
                'data_info': {
                    'feature_count': len(data_dict['feature_names']),
                    'sample_count': len(data_dict['flat_data'][1]),
                    'sequence_length': self.config['sequence_length'],
                    'target_type': self.config['target_type']
                },
                'model_results': model_results,
                'regression_analysis': regression_analysis,
                'data_integrity': data_dict['integrity_check']
            }

            # 5. ëª¨ë¸ ì €ì¥
            if self.config['save_models']:
                self.model_trainer.save_regression_models()

            # 6. ê²°ê³¼ ì €ì¥
            if self.config['save_results']:
                self._save_results(pipeline_results)

            # 7. ê²°ê³¼ ì¶œë ¥
            self._print_regression_summary(pipeline_results)

            logger.info("âœ… íšŒê·€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ")
            return pipeline_results

        except Exception as e:
            logger.error(f"âŒ íšŒê·€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise

    def _save_results(self, results):
        """ê²°ê³¼ ì €ì¥"""
        output_dir = Path(self.config['output_dir'])
        output_dir.mkdir(parents=True, exist_ok=True)

        # JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ ë³€í™˜
        def convert_numpy(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.bool_):
                return bool(obj)
            return obj

        def clean_for_json(data):
            if isinstance(data, dict):
                return {k: clean_for_json(v) for k, v in data.items()}
            elif isinstance(data, list):
                return [clean_for_json(item) for item in data]
            else:
                return convert_numpy(data)

        cleaned_results = clean_for_json(results)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = output_dir / f"regression_results_{timestamp}.json"

        with open(results_file, 'w') as f:
            json.dump(cleaned_results, f, indent=2)

        logger.info(f"íšŒê·€ ê²°ê³¼ ì €ì¥: {results_file}")

    def _print_regression_summary(self, results):
        """íšŒê·€ íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ“Š íšŒê·€ ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ ê²°ê³¼")
        print("=" * 80)

        # ê¸°ë³¸ ì •ë³´
        print(f"\nğŸ“‹ ì‹¤í–‰ ì •ë³´:")
        print(f"   ì‹¤í–‰ ì‹œê°„: {results['execution_time']}")
        print(f"   íŠ¹ì§• ìˆ˜: {results['data_info']['feature_count']}")
        print(f"   ìƒ˜í”Œ ìˆ˜: {results['data_info']['sample_count']}")

        # ì§€í‘œë³„ ìµœê³  ì„±ëŠ¥
        analysis = results['regression_analysis']

        print(f"\nğŸ† ì§€í‘œë³„ ìµœê³  ì„±ëŠ¥:")
        print("-" * 80)

        if analysis['best_by_mse']:
            mse_best = analysis['best_by_mse']
            print(f"MSE ìµœì €:        {mse_best['model']:30s} {mse_best['score']:.8f}")

        if analysis['best_by_mae']:
            mae_best = analysis['best_by_mae']
            print(f"MAE ìµœì €:        {mae_best['model']:30s} {mae_best['score']:.6f}")

        if analysis['best_by_mape']:
            mape_best = analysis['best_by_mape']
            print(f"MAPE ìµœì €:       {mape_best['model']:30s} {mape_best['score']:.2f}%")

        if analysis['best_by_r2']:
            r2_best = analysis['best_by_r2']
            print(f"RÂ² ìµœê³ :         {r2_best['model']:30s} {r2_best['score']:.4f}")

        if analysis['best_by_direction']:
            dir_best = analysis['best_by_direction']
            print(f"ë°©í–¥ ì •í™•ë„ ìµœê³ : {dir_best['model']:30s} {dir_best['score']:.2f}%")

        # ì¢…í•© ìˆœìœ„ (MAPE ê¸°ì¤€)
        print(f"\nğŸ“ˆ ì¢…í•© ì„±ëŠ¥ ìˆœìœ„ (MAPE ê¸°ì¤€):")
        print("-" * 80)

        if 'mean_mape' in analysis['metric_rankings']:
            for i, (model_name, result) in enumerate(analysis['metric_rankings']['mean_mape'][:5], 1):
                mape = result['mean_mape']
                r2 = result['mean_r2']
                direction = result['mean_direction_accuracy']
                print(f"{i:2d}. {model_name:30s} | MAPE: {mape:6.2f}% | RÂ²: {r2:7.4f} | ë°©í–¥: {direction:5.1f}%")

        print("\n" + "=" * 80)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    config = {
        'data_path': '/root/workspace/data/training/sp500_2020_2024_enhanced.csv',
        'target_type': 'return',  # íšŒê·€ ëª¨ë“œ
        'sequence_length': 20,
        'cv_splits': 3,
        'gpu_enabled': True,
        'save_models': True,
        'save_results': True,
        'output_dir': '/root/workspace/data/results/regression'
    }

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = RegressionPipeline(config)
    results = pipeline.run_regression_pipeline()

    return results

if __name__ == "__main__":
    results = main()