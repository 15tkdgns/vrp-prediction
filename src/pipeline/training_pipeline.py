#!/usr/bin/env python3
"""
í†µí•© í•™ìŠµ íŒŒì´í”„ë¼ì¸
ë°ì´í„° ì²˜ë¦¬ë¶€í„° ëª¨ë¸ í›ˆë ¨, í‰ê°€ê¹Œì§€ ì „ì²´ ê³¼ì • ê´€ë¦¬
"""

import sys
import os
sys.path.append('/root/workspace/src')

import numpy as np
import pandas as pd
import json
import logging
from pathlib import Path
from datetime import datetime

from core.data_processor import DataProcessor
from training.model_trainer import ModelTrainer
from evaluation.performance_evaluator import PerformanceEvaluator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TrainingPipeline:
    """í†µí•© í•™ìŠµ íŒŒì´í”„ë¼ì¸"""

    def __init__(self, config=None):
        self.config = config or self._get_default_config()
        self.data_processor = DataProcessor()
        self.model_trainer = ModelTrainer(gpu_enabled=self.config['gpu_enabled'])
        self.evaluator = PerformanceEvaluator()

        logger.info("í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")

    def _get_default_config(self):
        """ê¸°ë³¸ ì„¤ì •"""
        return {
            'data_path': '/root/workspace/data/training/sp500_2020_2024_enhanced.csv',
            'target_type': 'direction',  # 'direction' or 'return'
            'sequence_length': 20,
            'cv_splits': 3,
            'gpu_enabled': True,
            'save_models': True,
            'save_results': True,
            'output_dir': '/root/workspace/data/results'
        }

    def load_and_prepare_data(self):
        """ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"""
        logger.info("=== ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„ ===")

        # ë°ì´í„° ë¡œë”©
        df = self.data_processor.load_and_validate_data(self.config['data_path'])
        if df is None:
            raise ValueError("ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")

        # MLìš© ë°ì´í„° ì¤€ë¹„
        X, y, feature_cols = self.data_processor.prepare_ml_data(df, self.config['target_type'])

        # ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„ (ë”¥ëŸ¬ë‹ìš©)
        X_seq, y_seq, scaler = self.data_processor.prepare_sequence_data(
            df, self.config['sequence_length'], self.config['target_type']
        )

        # ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
        integrity_check = self.data_processor.validate_data_integrity(X.values, y.values)
        logger.info(f"ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬: {integrity_check}")

        # í•™ìŠµ/ê²€ì¦ ë¶„í• 
        splits = self.data_processor.create_train_val_split(X.values, y.values, self.config['cv_splits'])

        return {
            'flat_data': (X.values, y.values),
            'sequence_data': (X_seq, y_seq),
            'feature_names': feature_cols,
            'splits': splits,
            'scaler': scaler,
            'integrity_check': integrity_check
        }

    def train_models(self, data_dict):
        """ëª¨ë¸ í›ˆë ¨"""
        logger.info("=== ëª¨ë¸ í›ˆë ¨ ë‹¨ê³„ ===")

        X, y = data_dict['flat_data']
        X_seq, y_seq = data_dict['sequence_data']
        splits = data_dict['splits']

        all_results = {}

        # ê° í´ë“œë³„ë¡œ í›ˆë ¨ ë° í‰ê°€
        for fold, (train_idx, val_idx) in enumerate(splits):
            logger.info(f"Fold {fold + 1}/{len(splits)} í›ˆë ¨ ì‹œì‘")

            # ë°ì´í„° ë¶„í• 
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]

            # ì‹œí€€ìŠ¤ ë°ì´í„° ë¶„í•  (ì¸ë±ìŠ¤ ì¡°ì •)
            seq_train_idx = train_idx[train_idx < len(X_seq)]
            seq_val_idx = val_idx[val_idx < len(X_seq)]

            if len(seq_train_idx) > 0 and len(seq_val_idx) > 0:
                X_seq_train, X_seq_val = X_seq[seq_train_idx], X_seq[seq_val_idx]
                y_seq_train, y_seq_val = y_seq[seq_train_idx], y_seq[seq_val_idx]
            else:
                X_seq_train = X_seq_val = None
                y_seq_train = y_seq_val = None

            # ëª¨ë¸ í›ˆë ¨
            if X_seq_train is not None:
                fold_results = self.model_trainer.train_all_models(
                    X_train, X_val, y_train, y_val,
                    sequence_data=(X_seq_train, X_seq_val)
                )
            else:
                fold_results = self.model_trainer.train_all_models(
                    X_train, X_val, y_train, y_val,
                    sequence_data=None
                )

            # ê°œë³„ ëª¨ë¸ í‰ê°€
            for model_name, result in fold_results.items():
                if model_name not in all_results:
                    all_results[model_name] = {
                        'fold_scores': [],
                        'type': result['type']
                    }
                all_results[model_name]['fold_scores'].append(result['accuracy'])

        # í‰ê·  ì„±ëŠ¥ ê³„ì‚°
        final_results = {}
        for model_name, result in all_results.items():
            scores = result['fold_scores']
            final_results[model_name] = {
                'accuracy': np.mean(scores),
                'accuracy_std': np.std(scores),
                'fold_scores': scores,
                'direction_accuracy': np.mean(scores) * 100,  # ë°©í–¥ ì •í™•ë„
                'type': result['type']
            }

        return final_results

    def evaluate_ensemble_performance(self, data_dict):
        """ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€"""
        logger.info("=== ì•™ìƒë¸” í‰ê°€ ë‹¨ê³„ ===")

        X, y = data_dict['flat_data']
        X_seq, y_seq = data_dict['sequence_data']
        splits = data_dict['splits']

        ensemble_results = []

        for fold, (train_idx, val_idx) in enumerate(splits):
            X_val = X[val_idx]
            y_val = y[val_idx]

            # ì•™ìƒë¸” ì˜ˆì¸¡
            ensemble_pred_proba = self.model_trainer.create_ensemble_prediction(X_val)

            if ensemble_pred_proba is not None:
                ensemble_pred = (ensemble_pred_proba > 0.5).astype(int)

                # ì„±ëŠ¥ í‰ê°€
                performance = self.evaluator.evaluate_classification_performance(
                    y_val, ensemble_pred, ensemble_pred_proba, f"Ensemble_Fold_{fold+1}"
                )

                ensemble_results.append(performance['accuracy'])

        if ensemble_results:
            return {
                'ensemble_accuracy': np.mean(ensemble_results),
                'ensemble_accuracy_std': np.std(ensemble_results),
                'ensemble_direction_accuracy': np.mean(ensemble_results) * 100,
                'fold_results': ensemble_results
            }
        else:
            return None

    def run_full_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("=" * 80)
        logger.info("ğŸš€ í†µí•© í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        logger.info("=" * 80)

        start_time = datetime.now()

        try:
            # 1. ë°ì´í„° ì¤€ë¹„
            data_dict = self.load_and_prepare_data()

            # 2. ëª¨ë¸ í›ˆë ¨
            model_results = self.train_models(data_dict)

            # 3. ì•™ìƒë¸” í‰ê°€
            ensemble_results = self.evaluate_ensemble_performance(data_dict)

            # 4. ì„±ëŠ¥ ë¹„êµ
            model_ranking = self.evaluator.compare_models(model_results)

            # 5. ì¢…í•© ê²°ê³¼
            pipeline_results = {
                'pipeline_config': self.config,
                'execution_time': str(datetime.now() - start_time),
                'data_info': {
                    'feature_count': len(data_dict['feature_names']),
                    'sample_count': len(data_dict['flat_data'][1]),
                    'sequence_length': self.config['sequence_length'],
                    'target_type': self.config['target_type']
                },
                'individual_models': model_results,
                'ensemble_performance': ensemble_results,
                'model_ranking': model_ranking,
                'data_integrity': data_dict['integrity_check']
            }

            # 6. ëª¨ë¸ ì €ì¥
            if self.config['save_models']:
                self.model_trainer.save_models()

            # 7. ê²°ê³¼ ì €ì¥
            if self.config['save_results']:
                self._save_results(pipeline_results)

            # 8. ê²°ê³¼ ì¶œë ¥
            self._print_pipeline_summary(pipeline_results)

            logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ")
            return pipeline_results

        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise

    def _save_results(self, results):
        """ê²°ê³¼ ì €ì¥"""
        output_dir = Path(self.config['output_dir'])
        output_dir.mkdir(parents=True, exist_ok=True)

        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = output_dir / f"pipeline_results_{timestamp}.json"

        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2)

        logger.info(f"ê²°ê³¼ ì €ì¥: {results_file}")

    def _print_pipeline_summary(self, results):
        """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ“Š í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼")
        print("=" * 80)

        # ê¸°ë³¸ ì •ë³´
        print(f"\nğŸ“‹ ì‹¤í–‰ ì •ë³´:")
        print(f"   ì‹¤í–‰ ì‹œê°„: {results['execution_time']}")
        print(f"   íŠ¹ì§• ìˆ˜: {results['data_info']['feature_count']}")
        print(f"   ìƒ˜í”Œ ìˆ˜: {results['data_info']['sample_count']}")
        print(f"   íƒ€ê²Ÿ íƒ€ì…: {results['data_info']['target_type']}")

        # ë°ì´í„° ë¬´ê²°ì„±
        integrity = results['data_integrity']
        print(f"\nğŸ›¡ï¸ ë°ì´í„° ì•ˆì „ì„±:")
        print(f"   íŠ¹ì§•-íƒ€ê²Ÿ ìƒê´€ê´€ê³„ ì•ˆì „: {'âœ…' if integrity['feature_target_correlation_safe'] else 'âš ï¸'}")
        print(f"   ìµœëŒ€ ìƒê´€ê´€ê³„: {integrity['max_correlation']:.3f}")

        # ê°œë³„ ëª¨ë¸ ì„±ëŠ¥
        print(f"\nğŸ† ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„:")
        for i, model in enumerate(results['model_ranking'][:5], 1):
            accuracy = model['full_results']['direction_accuracy']
            print(f"   {i}. {model['model_name']}: {accuracy:.2f}%")

        # ì•™ìƒë¸” ì„±ëŠ¥
        if results['ensemble_performance']:
            ensemble_acc = results['ensemble_performance']['ensemble_direction_accuracy']
            print(f"\nğŸ¯ ì•™ìƒë¸” ì„±ëŠ¥:")
            print(f"   ë°©í–¥ ì •í™•ë„: {ensemble_acc:.2f}%")

        # ìµœê³  ì„±ëŠ¥
        if results['model_ranking']:
            best_model = results['model_ranking'][0]
            best_accuracy = best_model['full_results']['direction_accuracy']
            print(f"\nğŸ¥‡ ìµœê³  ì„±ëŠ¥:")
            print(f"   ëª¨ë¸: {best_model['model_name']}")
            print(f"   ë°©í–¥ ì •í™•ë„: {best_accuracy:.2f}%")

        print("\n" + "=" * 80)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì •
    config = {
        'data_path': '/root/workspace/data/training/sp500_2020_2024_enhanced.csv',
        'target_type': 'direction',  # ë°©í–¥ ì˜ˆì¸¡ì— ì§‘ì¤‘
        'sequence_length': 20,
        'cv_splits': 3,  # ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•´ 3ê°œ í´ë“œ
        'gpu_enabled': True,
        'save_models': True,
        'save_results': True,
        'output_dir': '/root/workspace/data/results'
    }

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = TrainingPipeline(config)
    results = pipeline.run_full_pipeline()

    return results

if __name__ == "__main__":
    results = main()