#!/usr/bin/env python3
"""
ğŸ”’ Purged and Embargoed Cross-Validation for Financial Time Series
ê¸ˆìœµ ì‹œê³„ì—´ì„ ìœ„í•œ ì •ì œ ë° ê¸ˆì§€ êµì°¨ ê²€ì¦

Reference: "Advances in Financial Machine Learning" by Marcos LÃ³pez de Prado
"""

import numpy as np
import pandas as pd
from typing import List, Tuple, Generator, Optional
import warnings
warnings.filterwarnings('ignore')

class PurgedKFold:
    """
    ì •ì œëœ K-Fold êµì°¨ ê²€ì¦
    - í›ˆë ¨/ê²€ì¦ ì‚¬ì´ì— ì‹œê°„ì  gap ì ìš©
    - ê²¹ì¹˜ëŠ” ìƒ˜í”Œ ì œê±° (purging)
    - ê¸ˆì§€ ê¸°ê°„ ì ìš© (embargo)
    """

    def __init__(self, n_splits: int = 5, pct_embargo: float = 0.01):
        """
        Args:
            n_splits: ë¶„í•  ê°œìˆ˜
            pct_embargo: ê¸ˆì§€ ê¸°ê°„ ë¹„ìœ¨ (ì „ì²´ ë°ì´í„°ì˜ %)
        """
        self.n_splits = n_splits
        self.pct_embargo = pct_embargo

    def split(self, X: pd.DataFrame, y: pd.Series = None,
              groups: Optional[pd.Series] = None) -> Generator[Tuple[np.ndarray, np.ndarray], None, None]:
        """
        ì‹œê°„ì  ìˆœì„œë¥¼ ê³ ë ¤í•œ ë¶„í•  ìƒì„±

        Args:
            X: íŠ¹ì§• ë°ì´í„°
            y: íƒ€ê²Ÿ ë°ì´í„° (ì‚¬ìš©ë˜ì§€ ì•ŠìŒ, sklearn í˜¸í™˜ì„±ì„ ìœ„í•´)
            groups: ê·¸ë£¹ ì •ë³´ (ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)

        Yields:
            (train_indices, test_indices)
        """
        if isinstance(X, pd.DataFrame):
            indices = X.index.values
        else:
            indices = np.arange(len(X))

        n_samples = len(indices)
        embargo_size = int(self.pct_embargo * n_samples)

        # ê° foldì˜ í¬ê¸° ê³„ì‚°
        test_size = n_samples // self.n_splits

        for i in range(self.n_splits):
            # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì¸ë±ìŠ¤ ê³„ì‚°
            test_start = i * test_size
            test_end = test_start + test_size

            # ë§ˆì§€ë§‰ foldëŠ” ë‚¨ì€ ëª¨ë“  ë°ì´í„° ì‚¬ìš©
            if i == self.n_splits - 1:
                test_end = n_samples

            test_indices = indices[test_start:test_end]

            # í›ˆë ¨ ì„¸íŠ¸: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì´ì „ì˜ ëª¨ë“  ë°ì´í„°
            # ë‹¨, embargo ê¸°ê°„ ì œì™¸
            train_end = max(0, test_start - embargo_size)
            train_indices = indices[:train_end]

            # ìœ íš¨í•œ ë¶„í• ì¸ì§€ í™•ì¸
            if len(train_indices) > 0 and len(test_indices) > 0:
                yield train_indices, test_indices

    def get_n_splits(self, X=None, y=None, groups=None) -> int:
        """ë¶„í•  ê°œìˆ˜ ë°˜í™˜"""
        return self.n_splits


class CombinatorialPurgedCV:
    """
    ì¡°í•© ì •ì œ êµì°¨ ê²€ì¦ (Combinatorial Purged Cross-Validation)
    - ìˆ˜ë°± ê°œì˜ ê°€ìƒ ë°±í…ŒìŠ¤íŠ¸ ê²½ë¡œ ìƒì„±
    - ì„±ëŠ¥ì˜ ë¶„í¬ í™•ì¸
    - ê³¼ì í•© ìœ„í—˜ ìµœì†Œí™”
    """

    def __init__(self, n_splits: int = 10, n_test_groups: int = 4,
                 pct_embargo: float = 0.01, n_paths: int = 100):
        """
        Args:
            n_splits: ì „ì²´ ë¶„í•  ê°œìˆ˜
            n_test_groups: ê° ê²½ë¡œì—ì„œ ì‚¬ìš©í•  í…ŒìŠ¤íŠ¸ ê·¸ë£¹ ìˆ˜
            pct_embargo: ê¸ˆì§€ ê¸°ê°„ ë¹„ìœ¨
            n_paths: ìƒì„±í•  ë°±í…ŒìŠ¤íŠ¸ ê²½ë¡œ ìˆ˜
        """
        self.n_splits = n_splits
        self.n_test_groups = n_test_groups
        self.pct_embargo = pct_embargo
        self.n_paths = n_paths

    def _generate_test_combinations(self) -> List[List[int]]:
        """í…ŒìŠ¤íŠ¸ ê·¸ë£¹ ì¡°í•© ìƒì„±"""
        from itertools import combinations

        # ê°€ëŠ¥í•œ ëª¨ë“  ì¡°í•© ìƒì„±
        all_combinations = list(combinations(range(self.n_splits), self.n_test_groups))

        # n_pathsê°œë§Œí¼ ëœë¤ ì„ íƒ
        if len(all_combinations) > self.n_paths:
            np.random.seed(42)  # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ
            selected_indices = np.random.choice(len(all_combinations),
                                              self.n_paths, replace=False)
            selected_combinations = [all_combinations[i] for i in selected_indices]
        else:
            selected_combinations = all_combinations

        return selected_combinations

    def split(self, X: pd.DataFrame, y: pd.Series = None) -> Generator[Tuple[np.ndarray, np.ndarray], None, None]:
        """
        ì¡°í•© êµì°¨ ê²€ì¦ ë¶„í•  ìƒì„±

        Args:
            X: íŠ¹ì§• ë°ì´í„°
            y: íƒ€ê²Ÿ ë°ì´í„°

        Yields:
            (train_indices, test_indices) for each path
        """
        if isinstance(X, pd.DataFrame):
            indices = X.index.values
        else:
            indices = np.arange(len(X))

        n_samples = len(indices)
        embargo_size = int(self.pct_embargo * n_samples)

        # ì „ì²´ ë°ì´í„°ë¥¼ n_splitsê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ë¶„í• 
        group_size = n_samples // self.n_splits
        groups = []

        for i in range(self.n_splits):
            start_idx = i * group_size
            end_idx = start_idx + group_size

            # ë§ˆì§€ë§‰ ê·¸ë£¹ì€ ë‚¨ì€ ëª¨ë“  ë°ì´í„° í¬í•¨
            if i == self.n_splits - 1:
                end_idx = n_samples

            groups.append(indices[start_idx:end_idx])

        # í…ŒìŠ¤íŠ¸ ê·¸ë£¹ ì¡°í•© ìƒì„±
        test_combinations = self._generate_test_combinations()

        for test_group_indices in test_combinations:
            # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ êµ¬ì„±
            test_indices = np.concatenate([groups[i] for i in test_group_indices])

            # í›ˆë ¨ ì„¸íŠ¸ êµ¬ì„±: í…ŒìŠ¤íŠ¸ ê·¸ë£¹ ì´ì „ì˜ ëª¨ë“  ë°ì´í„°
            # embargo ê¸°ê°„ ê³ ë ¤
            min_test_start = min([groups[i][0] for i in test_group_indices])
            train_end = max(0, min_test_start - embargo_size)

            train_indices = indices[:train_end]

            # ìœ íš¨í•œ ë¶„í• ì¸ì§€ í™•ì¸
            if len(train_indices) > 0 and len(test_indices) > 0:
                yield train_indices, test_indices


class PurgedTimeSeriesSplit:
    """
    ì •ì œëœ ì‹œê³„ì—´ ë¶„í• 
    - ê° foldì—ì„œ ì ì ˆí•œ purgingê³¼ embargo ì ìš©
    - ì‹œê°„ì  ìˆœì„œ ì—„ê²©íˆ ì¤€ìˆ˜
    """

    def __init__(self, n_splits: int = 5, max_train_size: Optional[int] = None,
                 test_size: Optional[int] = None, gap: int = 0):
        """
        Args:
            n_splits: ë¶„í•  ê°œìˆ˜
            max_train_size: ìµœëŒ€ í›ˆë ¨ í¬ê¸°
            test_size: í…ŒìŠ¤íŠ¸ í¬ê¸°
            gap: í›ˆë ¨ê³¼ í…ŒìŠ¤íŠ¸ ì‚¬ì´ì˜ ê°„ê²© (purging gap)
        """
        self.n_splits = n_splits
        self.max_train_size = max_train_size
        self.test_size = test_size
        self.gap = gap

    def split(self, X, y=None, groups=None):
        """ì‹œê³„ì—´ ë¶„í•  ìƒì„±"""
        n_samples = len(X)

        # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
        if self.test_size is None:
            test_size = n_samples // (self.n_splits + 1)
        else:
            test_size = self.test_size

        for i in range(self.n_splits):
            # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë²”ìœ„
            test_start = (i + 1) * test_size
            test_end = test_start + test_size

            if test_end > n_samples:
                break

            # í›ˆë ¨ ì„¸íŠ¸ ë²”ìœ„ (gap ê³ ë ¤)
            train_end = test_start - self.gap

            if self.max_train_size is not None:
                train_start = max(0, train_end - self.max_train_size)
            else:
                train_start = 0

            # ìœ íš¨í•œ ë¶„í• ì¸ì§€ í™•ì¸
            if train_start < train_end and test_start < test_end:
                train_indices = np.arange(train_start, train_end)
                test_indices = np.arange(test_start, test_end)

                yield train_indices, test_indices

    def get_n_splits(self, X=None, y=None, groups=None):
        """ë¶„í•  ê°œìˆ˜ ë°˜í™˜"""
        return self.n_splits


def validate_purged_cv_integrity(train_indices: np.ndarray, test_indices: np.ndarray,
                                gap: int = 0) -> bool:
    """
    ì •ì œëœ êµì°¨ ê²€ì¦ì˜ ë¬´ê²°ì„± ê²€ì¦

    Args:
        train_indices: í›ˆë ¨ ì¸ë±ìŠ¤
        test_indices: í…ŒìŠ¤íŠ¸ ì¸ë±ìŠ¤
        gap: ìš”êµ¬ë˜ëŠ” ìµœì†Œ ê°„ê²©

    Returns:
        bool: ë¬´ê²°ì„± í†µê³¼ ì—¬ë¶€
    """
    # 1. ì¤‘ë³µ í™•ì¸
    if len(np.intersect1d(train_indices, test_indices)) > 0:
        print("âŒ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì¤‘ë³µ ë°œê²¬")
        return False

    # 2. ì‹œê°„ì  ìˆœì„œ í™•ì¸
    max_train_idx = np.max(train_indices) if len(train_indices) > 0 else -1
    min_test_idx = np.min(test_indices) if len(test_indices) > 0 else float('inf')

    actual_gap = min_test_idx - max_train_idx - 1

    if actual_gap < gap:
        print(f"âŒ ê°„ê²© ë¶€ì¡±: ìš”êµ¬={gap}, ì‹¤ì œ={actual_gap}")
        return False

    # 3. ì—°ì†ì„± í™•ì¸
    if len(train_indices) > 1:
        train_sorted = np.sort(train_indices)
        if not np.array_equal(train_sorted, np.arange(train_sorted[0], train_sorted[-1] + 1)):
            print("âš ï¸ í›ˆë ¨ ì¸ë±ìŠ¤ê°€ ì—°ì†ì ì´ì§€ ì•ŠìŒ")

    print(f"âœ… ë¬´ê²°ì„± ê²€ì¦ í†µê³¼: gap={actual_gap}, í›ˆë ¨={len(train_indices)}, í…ŒìŠ¤íŠ¸={len(test_indices)}")
    return True


def demonstrate_purged_cv():
    """Purged CV ì‹œì—°"""
    print("ğŸ”’ Purged Cross-Validation ì‹œì—°")

    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    n_samples = 1000
    X = pd.DataFrame(np.random.randn(n_samples, 5),
                     columns=[f'feature_{i}' for i in range(5)])
    y = pd.Series(np.random.randn(n_samples))

    print(f"ğŸ“Š ìƒ˜í”Œ ë°ì´í„°: {X.shape}")

    # 1. ê¸°ë³¸ PurgedKFold
    print("\\nğŸ”„ PurgedKFold í…ŒìŠ¤íŠ¸:")
    pkf = PurgedKFold(n_splits=5, pct_embargo=0.02)

    for fold, (train_idx, test_idx) in enumerate(pkf.split(X), 1):
        print(f"Fold {fold}: í›ˆë ¨={len(train_idx)}, í…ŒìŠ¤íŠ¸={len(test_idx)}")
        validate_purged_cv_integrity(train_idx, test_idx, gap=int(0.02 * n_samples))

    # 2. PurgedTimeSeriesSplit
    print("\\nğŸ”„ PurgedTimeSeriesSplit í…ŒìŠ¤íŠ¸:")
    ptss = PurgedTimeSeriesSplit(n_splits=5, gap=20)

    for fold, (train_idx, test_idx) in enumerate(ptss.split(X), 1):
        print(f"Fold {fold}: í›ˆë ¨={len(train_idx)}, í…ŒìŠ¤íŠ¸={len(test_idx)}")
        validate_purged_cv_integrity(train_idx, test_idx, gap=20)

    # 3. CombinatorialPurgedCV
    print("\\nğŸ”„ CombinatorialPurgedCV í…ŒìŠ¤íŠ¸:")
    cpcv = CombinatorialPurgedCV(n_splits=8, n_test_groups=2, n_paths=5)

    for path, (train_idx, test_idx) in enumerate(cpcv.split(X), 1):
        print(f"Path {path}: í›ˆë ¨={len(train_idx)}, í…ŒìŠ¤íŠ¸={len(test_idx)}")
        validate_purged_cv_integrity(train_idx, test_idx, gap=int(0.01 * n_samples))
        if path >= 5:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            break

    print("\\nâœ… Purged CV ì‹œì—° ì™„ë£Œ!")


if __name__ == "__main__":
    demonstrate_purged_cv()