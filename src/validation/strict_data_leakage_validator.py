#!/usr/bin/env python3
"""
ì—„ê²©í•œ ë°ì´í„° ëˆ„ì¶œ ê²€ì¦ ì‹œìŠ¤í…œ
RÂ² 93%ëŠ” ë°ì´í„° ëˆ„ì¶œ ì˜ì‹¬ - ì² ì €í•œ ì¬ê²€ì¦ í•„ìš”
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
import logging
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class StrictDataLeakageValidator:
    """ì—„ê²©í•œ ë°ì´í„° ëˆ„ì¶œ ê²€ì¦"""

    def __init__(self):
        self.suspicious_r2_threshold = 0.7  # 70% ì´ìƒ ì˜ì‹¬
        self.data_issues = []

    def load_and_inspect_data(self, data_path):
        """ë°ì´í„° ë¡œë”© ë° ì„¸ë¶€ ê²€ì‚¬"""
        logger.info("=== ì—„ê²©í•œ ë°ì´í„° ëˆ„ì¶œ ê²€ì¦ ì‹œì‘ ===")

        df = pd.read_csv(data_path)
        logger.info(f"ì›ë³¸ ë°ì´í„°: {df.shape}")

        # ì»¬ëŸ¼ ìƒì„¸ ë¶„ì„
        logger.info(f"ì „ì²´ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")

        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª… ê²€ì‚¬
        suspicious_cols = []
        for col in df.columns:
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in ['future', 'next', 'tomorrow', 'ahead']):
                suspicious_cols.append(col)
                self.data_issues.append(f"ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª…: {col}")

        if suspicious_cols:
            logger.warning(f"ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª… ë°œê²¬: {suspicious_cols}")

        return df

    def check_target_construction(self, df):
        """íƒ€ê²Ÿ ë³€ìˆ˜ êµ¬ì„± ë°©ì‹ ê²€ì¦"""
        logger.info("1. íƒ€ê²Ÿ ë³€ìˆ˜ êµ¬ì„± ê²€ì¦")

        if 'Close' in df.columns:
            # ìˆ˜ìµë¥  ê³„ì‚° ê²€ì¦
            manual_returns = df['Close'].pct_change().dropna()

            # ê¸°ì¡´ ìˆ˜ìµë¥  ì»¬ëŸ¼ê³¼ ë¹„êµ
            if 'Returns' in df.columns:
                existing_returns = df['Returns'].dropna()

                # ê¸¸ì´ ë§ì¶”ê¸°
                min_len = min(len(manual_returns), len(existing_returns))
                corr = np.corrcoef(
                    manual_returns.iloc[:min_len],
                    existing_returns.iloc[:min_len]
                )[0, 1]

                logger.info(f"   ìˆ˜ìµë¥  ê³„ì‚° ì¼ì¹˜ë„: {corr:.6f}")

                if abs(corr - 1.0) > 0.001:  # 99.9% ì´ìƒ ì¼ì¹˜í•´ì•¼ í•¨
                    self.data_issues.append(f"ìˆ˜ìµë¥  ê³„ì‚° ë¶ˆì¼ì¹˜: ìƒê´€ê´€ê³„ {corr:.6f}")
                    logger.warning(f"   âš ï¸ ìˆ˜ìµë¥  ê³„ì‚° ë¶ˆì¼ì¹˜: {corr:.6f}")

            # ê·¹ë‹¨ê°’ ê²€ì‚¬
            extreme_threshold = 0.1  # 10% ì´ìƒ ë³€ë™
            extreme_count = (abs(manual_returns) > extreme_threshold).sum()
            extreme_pct = extreme_count / len(manual_returns) * 100

            logger.info(f"   ê·¹ë‹¨ì  ìˆ˜ìµë¥  (>10%): {extreme_count}ê°œ ({extreme_pct:.1f}%)")

            # ì—°ì† ê·¹ë‹¨ê°’ ê²€ì‚¬ (ì¡°ì‘ ì˜ì‹¬)
            extreme_mask = abs(manual_returns) > extreme_threshold
            consecutive_extremes = 0
            max_consecutive = 0

            for is_extreme in extreme_mask:
                if is_extreme:
                    consecutive_extremes += 1
                    max_consecutive = max(max_consecutive, consecutive_extremes)
                else:
                    consecutive_extremes = 0

            if max_consecutive > 3:
                self.data_issues.append(f"ì—°ì† ê·¹ë‹¨ê°’ {max_consecutive}ê°œ ê°ì§€")
                logger.warning(f"   âš ï¸ ì—°ì† ê·¹ë‹¨ê°’: {max_consecutive}ê°œ")

    def check_feature_timing(self, df):
        """íŠ¹ì§• ë³€ìˆ˜ ì‹œê°„ ì •ë³´ ëˆ„ì¶œ ê²€ì‚¬"""
        logger.info("2. íŠ¹ì§• ë³€ìˆ˜ ì‹œê°„ ëˆ„ì¶œ ê²€ì‚¬")

        # ë‚ ì§œ ì¸ë±ìŠ¤ í™•ì¸
        if 'Date' in df.columns:
            df['Date'] = pd.to_datetime(df['Date'])
            date_diffs = df['Date'].diff().dropna()

            # ë‚ ì§œ ê°„ê²© ì¼ê´€ì„± í™•ì¸
            common_diff = date_diffs.mode()[0] if len(date_diffs.mode()) > 0 else None
            irregular_dates = (date_diffs != common_diff).sum()

            logger.info(f"   ì¼ë°˜ì  ë‚ ì§œ ê°„ê²©: {common_diff}")
            logger.info(f"   ë¶ˆê·œì¹™ ë‚ ì§œ: {irregular_dates}ê°œ")

            if irregular_dates > len(date_diffs) * 0.1:  # 10% ì´ìƒ ë¶ˆê·œì¹™
                self.data_issues.append(f"ë¶ˆê·œì¹™ ë‚ ì§œ ê°„ê²©: {irregular_dates}ê°œ")

        # ë¯¸ë˜ ì •ë³´ê°€ í¬í•¨ëœ íŠ¹ì§• ê²€ì‚¬
        feature_cols = [col for col in df.columns
                       if col not in ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]

        logger.info(f"   ë¶„ì„í•  íŠ¹ì§• ë³€ìˆ˜: {len(feature_cols)}ê°œ")

        # ê° íŠ¹ì§•ì´ í˜„ì¬/ê³¼ê±° ì •ë³´ë§Œ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸
        if 'Close' in df.columns:
            current_close = df['Close']

            suspicious_features = []
            for col in feature_cols:
                if col in df.columns and df[col].dtype in ['float64', 'int64']:
                    # ë¯¸ë˜ ê°€ê²©ê³¼ì˜ ìƒê´€ê´€ê³„ í™•ì¸
                    future_close = df['Close'].shift(-1)  # ë‹¤ìŒë‚  ì¢…ê°€

                    # NaN ì œê±° í›„ ìƒê´€ê´€ê³„ ê³„ì‚°
                    valid_idx = ~(df[col].isna() | future_close.isna())
                    if valid_idx.sum() > 10:
                        corr_future = np.corrcoef(
                            df[col][valid_idx],
                            future_close[valid_idx]
                        )[0, 1]

                        if abs(corr_future) > 0.5:  # ë¯¸ë˜ ì •ë³´ì™€ ë†’ì€ ìƒê´€ê´€ê³„
                            suspicious_features.append((col, corr_future))
                            self.data_issues.append(f"ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œ ì˜ì‹¬: {col} (ìƒê´€ê´€ê³„: {corr_future:.4f})")

            if suspicious_features:
                logger.warning(f"   âš ï¸ ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œ ì˜ì‹¬: {len(suspicious_features)}ê°œ")
                for col, corr in suspicious_features[:5]:
                    logger.warning(f"      {col}: {corr:.4f}")

    def validate_model_performance(self, X, y):
        """ëª¨ë¸ ì„±ëŠ¥ í˜„ì‹¤ì„± ê²€ì¦"""
        logger.info("3. ëª¨ë¸ ì„±ëŠ¥ í˜„ì‹¤ì„± ê²€ì¦")

        # TimeSeriesSplitìœ¼ë¡œ ì—„ê²©í•œ ì‹œê°„ ë¶„í• 
        tscv = TimeSeriesSplit(n_splits=5, test_size=100)  # ì‘ì€ í…ŒìŠ¤íŠ¸ ì…‹

        r2_scores = []
        mse_scores = []

        scaler = StandardScaler()

        for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
            # ì—„ê²©í•œ ì‹œê°„ ìˆœì„œ í™•ì¸
            if train_idx.max() >= test_idx.min():
                self.data_issues.append(f"Fold {fold}: ì‹œê°„ ìˆœì„œ ìœ„ë°˜")
                logger.error(f"   âŒ Fold {fold}: ì‹œê°„ ìˆœì„œ ìœ„ë°˜")
                continue

            X_train, X_test = X[train_idx], X[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]

            # ë°ì´í„° í‘œì¤€í™” (í›ˆë ¨ ë°ì´í„°ë§Œ ì‚¬ìš©)
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            # ë‹¨ìˆœ ì„ í˜• íšŒê·€ë¡œ ê¸°ì¤€ ì„±ëŠ¥ ì¸¡ì •
            from sklearn.linear_model import LinearRegression
            model = LinearRegression()
            model.fit(X_train_scaled, y_train)

            y_pred = model.predict(X_test_scaled)
            r2 = r2_score(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)

            r2_scores.append(r2)
            mse_scores.append(mse)

            logger.info(f"   Fold {fold}: RÂ² = {r2:.4f}, MSE = {mse:.8f}")

            # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê³ ì„±ëŠ¥ ê²€ì‚¬
            if r2 > self.suspicious_r2_threshold:
                self.data_issues.append(f"Fold {fold}: ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê³ ì„±ëŠ¥ RÂ² {r2:.4f}")
                logger.error(f"   âŒ Fold {fold}: ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê³ ì„±ëŠ¥ RÂ² {r2:.4f}")

        avg_r2 = np.mean(r2_scores) if r2_scores else 0
        avg_mse = np.mean(mse_scores) if mse_scores else 0
        std_r2 = np.std(r2_scores) if r2_scores else 0

        logger.info(f"   í‰ê·  RÂ²: {avg_r2:.4f} Â± {std_r2:.4f}")
        logger.info(f"   í‰ê·  MSE: {avg_mse:.8f}")

        # ê¸°ì¤€ì„ ê³¼ ë¹„êµ
        baseline_r2 = 0.0  # ì˜ˆìƒ ê¸°ì¤€ì„ 

        if avg_r2 > self.suspicious_r2_threshold:
            self.data_issues.append(f"ì „ì²´ í‰ê·  RÂ² {avg_r2:.4f} > {self.suspicious_r2_threshold} (ë°ì´í„° ëˆ„ì¶œ ì˜ì‹¬)")
            logger.error(f"   âŒ ì „ì²´ í‰ê·  RÂ² {avg_r2:.4f} - ë°ì´í„° ëˆ„ì¶œ ì˜ì‹¬")

        return avg_r2, std_r2, avg_mse

    def check_information_coefficient(self, X, y):
        """ì •ë³´ ê³„ìˆ˜ (IC) ê²€ì¦"""
        logger.info("4. ì •ë³´ ê³„ìˆ˜ ê²€ì¦")

        # ê° íŠ¹ì§•ì˜ ì •ë³´ ê³„ìˆ˜ ê³„ì‚°
        ic_values = []

        for i in range(X.shape[1]):
            feature = X[:, i]

            # ìˆœìœ„ ìƒê´€ê´€ê³„ (Spearman) ê³„ì‚°
            from scipy.stats import spearmanr

            valid_idx = ~(np.isnan(feature) | np.isnan(y))
            if valid_idx.sum() > 10:
                ic, p_value = spearmanr(feature[valid_idx], y[valid_idx])
                ic_values.append(abs(ic))

                # ê³¼ë„í•œ ì •ë³´ ê³„ìˆ˜ ê²€ì‚¬
                if abs(ic) > 0.1:  # 10% ì´ìƒì˜ ì •ë³´ ê³„ìˆ˜ëŠ” ì˜ì‹¬ìŠ¤ëŸ¬ì›€
                    logger.warning(f"   íŠ¹ì§• {i}: IC = {ic:.4f} (ë†’ì€ ì˜ˆì¸¡ë ¥)")

        max_ic = max(ic_values) if ic_values else 0
        avg_ic = np.mean(ic_values) if ic_values else 0

        logger.info(f"   ìµœëŒ€ ì •ë³´ ê³„ìˆ˜: {max_ic:.4f}")
        logger.info(f"   í‰ê·  ì •ë³´ ê³„ìˆ˜: {avg_ic:.4f}")

        if max_ic > 0.15:  # 15% ì´ìƒì€ ë§¤ìš° ì˜ì‹¬ìŠ¤ëŸ¬ì›€
            self.data_issues.append(f"ê³¼ë„í•œ ì •ë³´ ê³„ìˆ˜: {max_ic:.4f}")
            logger.error(f"   âŒ ê³¼ë„í•œ ì •ë³´ ê³„ìˆ˜: {max_ic:.4f}")

        return max_ic, avg_ic

    def generate_synthetic_comparison(self, X_shape, y_shape):
        """í•©ì„± ë°ì´í„°ì™€ì˜ ë¹„êµ"""
        logger.info("5. í•©ì„± ë°ì´í„° ë¹„êµ")

        # ì™„ì „ ëœë¤ ë°ì´í„° ìƒì„±
        np.random.seed(42)
        X_random = np.random.randn(*X_shape)
        y_random = np.random.randn(*y_shape)

        # ëœë¤ ë°ì´í„°ë¡œ ì„±ëŠ¥ ì¸¡ì •
        random_r2, _, _ = self.validate_model_performance(X_random, y_random)

        logger.info(f"   ëœë¤ ë°ì´í„° RÂ²: {random_r2:.4f}")

        # ì‹¤ì œ ë°ì´í„°ê°€ ëœë¤ë³´ë‹¤ ë„ˆë¬´ ì¢‹ìœ¼ë©´ ì˜ì‹¬
        return random_r2

    def run_comprehensive_validation(self, data_path):
        """ì¢…í•© ê²€ì¦ ì‹¤í–‰"""
        logger.info("=" * 80)
        logger.info("ğŸ” ì—„ê²©í•œ ë°ì´í„° ëˆ„ì¶œ ê²€ì¦")
        logger.info("=" * 80)

        # 1. ë°ì´í„° ë¡œë”© ë° ê²€ì‚¬
        df = self.load_and_inspect_data(data_path)

        # 2. íƒ€ê²Ÿ ë³€ìˆ˜ ê²€ì¦
        self.check_target_construction(df)

        # 3. íŠ¹ì§• ë³€ìˆ˜ ì‹œê°„ ëˆ„ì¶œ ê²€ì‚¬
        self.check_feature_timing(df)

        # 4. ê°„ë‹¨í•œ íŠ¹ì§• ìƒì„± (ê²€ì¦ìš©)
        df = df.dropna()
        if len(df) < 100:
            logger.error("ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŒ")
            return None

        # ì•ˆì „í•œ íŠ¹ì§•ë§Œ ì‚¬ìš©
        df['returns'] = df['Close'].pct_change()
        df['returns_lag1'] = df['returns'].shift(1)
        df['returns_lag2'] = df['returns'].shift(2)
        df['vol_5'] = df['returns'].rolling(5).std()

        df = df.dropna()

        feature_cols = ['returns_lag1', 'returns_lag2', 'vol_5']
        X = df[feature_cols].values
        y = df['returns'].values

        logger.info(f"ê²€ì¦ ë°ì´í„°: X{X.shape}, y{y.shape}")

        # 5. ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦
        actual_r2, r2_std, actual_mse = self.validate_model_performance(X, y)

        # 6. ì •ë³´ ê³„ìˆ˜ ê²€ì¦
        max_ic, avg_ic = self.check_information_coefficient(X, y)

        # 7. í•©ì„± ë°ì´í„° ë¹„êµ
        random_r2 = self.generate_synthetic_comparison(X.shape, y.shape)

        # 8. ìµœì¢… í‰ê°€
        self._print_validation_results(actual_r2, r2_std, max_ic, random_r2)

        return self._get_final_assessment(actual_r2)

    def _print_validation_results(self, actual_r2, r2_std, max_ic, random_r2):
        """ê²€ì¦ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ“‹ ì—„ê²©í•œ ë°ì´í„° ëˆ„ì¶œ ê²€ì¦ ê²°ê³¼")
        print("=" * 80)

        print(f"\nğŸ“Š í•µì‹¬ ì§€í‘œ:")
        print(f"   ì‹¤ì œ ë°ì´í„° RÂ²: {actual_r2:.4f} Â± {r2_std:.4f}")
        print(f"   ëœë¤ ë°ì´í„° RÂ²: {random_r2:.4f}")
        print(f"   ìµœëŒ€ ì •ë³´ ê³„ìˆ˜: {max_ic:.4f}")
        print(f"   ì˜ì‹¬ ì„ê³„ê°’: RÂ² > {self.suspicious_r2_threshold}")

        print(f"\nâš ï¸ ë°œê²¬ëœ ë¬¸ì œì :")
        if self.data_issues:
            for i, issue in enumerate(self.data_issues, 1):
                print(f"   {i}. {issue}")
        else:
            print("   ë¬¸ì œì  ì—†ìŒ")

        # ìµœì¢… íŒì •
        is_suspicious = (actual_r2 > self.suspicious_r2_threshold or
                        len(self.data_issues) > 3 or
                        max_ic > 0.15)

        if is_suspicious:
            print(f"\nâŒ ê²°ë¡ : ë°ì´í„° ëˆ„ì¶œ ì˜ì‹¬ë¨")
            print(f"   - RÂ² {actual_r2:.4f}ëŠ” ê¸ˆìœµ ë°ì´í„°ë¡œëŠ” ë¹„í˜„ì‹¤ì ")
            print(f"   - ì¶”ê°€ ê²€ì¦ ë° ëª¨ë¸ ì¬êµ¬ì„± í•„ìš”")
        else:
            print(f"\nâœ… ê²°ë¡ : ë°ì´í„° ëˆ„ì¶œ ì—†ìŒ")
            print(f"   - RÂ² {actual_r2:.4f}ëŠ” í•©ë¦¬ì  ë²”ìœ„")

        print("=" * 80)

    def _get_final_assessment(self, actual_r2):
        """ìµœì¢… í‰ê°€"""
        is_suspicious = (actual_r2 > self.suspicious_r2_threshold or
                        len(self.data_issues) > 3)

        return {
            'is_suspicious': is_suspicious,
            'actual_r2': actual_r2,
            'issues_count': len(self.data_issues),
            'issues': self.data_issues,
            'recommendation': 'REJECT' if is_suspicious else 'ACCEPT'
        }

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    validator = StrictDataLeakageValidator()
    data_path = '/root/workspace/data/training/sp500_2020_2024_enhanced.csv'

    result = validator.run_comprehensive_validation(data_path)

    if result:
        print(f"\nğŸ¯ ìµœì¢… ê¶Œê³ ì‚¬í•­: {result['recommendation']}")
        if result['is_suspicious']:
            print("ğŸš¨ ê²½ê³ : 93% RÂ² ì„±ëŠ¥ì€ ë°ì´í„° ëˆ„ì¶œ ì˜ì‹¬ - ëª¨ë¸ ì¬ê²€í†  í•„ìš”")

    return result

if __name__ == "__main__":
    result = main()