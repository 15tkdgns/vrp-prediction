"""
V2 Ridge ëª¨ë¸ ê³¼ì í•© ì¢…í•© ê²€ì¦ ì‹œìŠ¤í…œ
V2 ëª¨ë¸ (alpha=19.5029, RÂ²=0.3256)ì˜ ê³¼ì í•© ì—¬ë¶€ë¥¼ ë‹¤ê°ë„ë¡œ ë¶„ì„

ê³¼ì í•© ê²€ì¦ í•­ëª©:
1. í›ˆë ¨ vs ê²€ì¦ ì„±ëŠ¥ ë¹„êµ
2. í•™ìŠµ ê³¡ì„  ë¶„ì„ (Learning Curve)
3. êµì°¨ê²€ì¦ ì¼ê´€ì„± ë¶„ì„
4. Walk-Forward Validation
5. ì”ì°¨ ë¶„ì„ (Residual Analysis)
6. íŠ¹ì„± ì¤‘ìš”ë„ ì•ˆì •ì„±
7. ì •ê·œí™” íš¨ê³¼ ê²€ì¦
8. ì‹œê°„ì  ì•ˆì •ì„± ë¶„ì„
"""

import numpy as np
import pandas as pd
import yfinance as yf
import json
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.model_selection import learning_curve, validation_curve
import logging

warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/workspace/data/raw/v2_overfitting_check.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class PurgedKFoldSklearn:
    """sklearn í˜¸í™˜ Purged K-Fold Cross-Validation"""

    def __init__(self, n_splits=5, purge_length=5, embargo_length=5):
        self.n_splits = n_splits
        self.purge_length = purge_length
        self.embargo_length = embargo_length

    def split(self, X, y=None, groups=None):
        n_samples = len(X)
        indices = np.arange(n_samples)
        test_size = n_samples // self.n_splits
        splits = []

        for i in range(self.n_splits):
            test_start = i * test_size
            test_end = min((i + 1) * test_size, n_samples)
            test_indices = indices[test_start:test_end]

            purge_start = test_end
            purge_end = min(test_end + self.purge_length, n_samples)
            embargo_end = min(purge_end + self.embargo_length, n_samples)

            train_indices = np.concatenate([
                indices[:test_start],
                indices[embargo_end:]
            ])

            if len(train_indices) > 0 and len(test_indices) > 0:
                splits.append((train_indices, test_indices))

        return splits

    def get_n_splits(self, X=None, y=None, groups=None):
        return self.n_splits

class V2OverfittingChecker:
    """V2 ëª¨ë¸ ê³¼ì í•© ì¢…í•© ê²€ì¦ê¸°"""

    def __init__(self):
        self.best_alpha = 19.5029  # V2 ìµœì ê°’
        self.cv = PurgedKFoldSklearn()
        self.scaler = StandardScaler()
        self.results = {}

    def load_spy_data(self):
        """SPY ë°ì´í„° ë¡œë“œ"""
        logger.info("ğŸ“Š SPY ë°ì´í„° ë¡œë”©...")

        spy = yf.Ticker("SPY")
        data = spy.history(start="2015-01-01", end="2024-12-31")
        data['returns'] = np.log(data['Close'] / data['Close'].shift(1))
        data = data.dropna()

        logger.info(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(data)}ê°œ ê´€ì¸¡ì¹˜")
        return data

    def create_v2_features(self, data):
        """V2ì™€ ë™ì¼í•œ íŠ¹ì„± ìƒì„±"""
        logger.info("ğŸ”§ V2 íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§...")

        returns = data['returns']
        prices = data['Close']
        features = pd.DataFrame(index=data.index)

        # 1. ë³€ë™ì„± íŠ¹ì„± (6ê°œ)
        for window in [3, 5, 10, 15, 20, 30]:
            features[f'vol_{window}'] = returns.rolling(window).std()

        # 2. í†µê³„ì  ëª¨ë©˜íŠ¸ (6ê°œ)
        for window in [5, 10, 20]:
            features[f'skew_{window}'] = returns.rolling(window).skew()
            features[f'kurt_{window}'] = returns.rolling(window).kurt()

        # 3. ë˜ê·¸ íŠ¹ì„± (6ê°œ)
        for lag in [1, 2, 3]:
            features[f'return_lag_{lag}'] = returns.shift(lag)
            features[f'vol_lag_{lag}'] = features['vol_5'].shift(lag)

        # 4. ë³€ë™ì„± ì²´ì œ (4ê°œ)
        short_vol = features['vol_5']
        medium_vol = features['vol_20']
        long_vol = features['vol_30']

        features['vol_regime_short'] = (short_vol > medium_vol).astype(float)
        features['vol_regime_medium'] = (medium_vol > long_vol).astype(float)
        features['vol_expansion'] = short_vol / (long_vol + 1e-8)
        features['vol_contraction'] = long_vol / (short_vol + 1e-8)

        # 5. í†µê³„ì  ì§€í‘œ (5ê°œ)
        for window in [10, 20, 30]:
            ma = returns.rolling(window).mean()
            std = returns.rolling(window).std()
            features[f'zscore_{window}'] = (returns - ma) / (std + 1e-8)

        for window in [10, 20]:
            ma = returns.rolling(window).mean()
            std = returns.rolling(window).std()
            features[f'sharpe_{window}'] = (ma * np.sqrt(252)) / (std + 1e-8)

        # 6. ìƒí˜¸ì‘ìš© íŠ¹ì„± (3ê°œ)
        features['vol_5_20_ratio'] = features['vol_5'] / (features['vol_20'] + 1e-8)
        features['vol_10_30_ratio'] = features['vol_10'] / (features['vol_30'] + 1e-8)
        features['vol_price_interaction'] = features['vol_20'] * returns

        # íƒ€ê²Ÿ: 5ì¼ í›„ ë³€ë™ì„±
        target = []
        for i in range(len(returns)):
            if i + 5 < len(returns):
                future_vol = returns.iloc[i+1:i+6].std()
                target.append(future_vol)
            else:
                target.append(np.nan)

        features['target_vol_5d'] = target
        features = features.dropna()

        X = features.drop('target_vol_5d', axis=1)
        y = features['target_vol_5d']

        logger.info(f"âœ… V2 íŠ¹ì„± ìƒì„± ì™„ë£Œ: {X.shape[1]}ê°œ íŠ¹ì„±, {len(X)}ê°œ ìƒ˜í”Œ")
        return X, y

    def test_1_train_vs_validation(self):
        """1. í›ˆë ¨ vs ê²€ì¦ ì„±ëŠ¥ ë¹„êµ"""
        logger.info("ğŸ” 1. í›ˆë ¨ vs ê²€ì¦ ì„±ëŠ¥ ë¹„êµ...")

        data = self.load_spy_data()
        X, y = self.create_v2_features(data)
        X_scaled = self.scaler.fit_transform(X)

        model = Ridge(alpha=self.best_alpha)
        splits = list(self.cv.split(X_scaled))

        train_scores = []
        val_scores = []

        for train_idx, val_idx in splits:
            X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

            # ëª¨ë¸ í›ˆë ¨
            model.fit(X_train, y_train)

            # í›ˆë ¨ ì„±ëŠ¥
            train_pred = model.predict(X_train)
            train_r2 = r2_score(y_train, train_pred)
            train_scores.append(train_r2)

            # ê²€ì¦ ì„±ëŠ¥
            val_pred = model.predict(X_val)
            val_r2 = r2_score(y_val, val_pred)
            val_scores.append(val_r2)

        train_mean = np.mean(train_scores)
        val_mean = np.mean(val_scores)
        performance_gap = train_mean - val_mean

        result = {
            'train_r2_mean': float(train_mean),
            'train_r2_std': float(np.std(train_scores)),
            'val_r2_mean': float(val_mean),
            'val_r2_std': float(np.std(val_scores)),
            'performance_gap': float(performance_gap),
            'overfitting_indicator': bool(performance_gap > 0.05),  # 5% ì´ìƒ ì°¨ì´ë©´ ê³¼ì í•© ì˜ì‹¬
            'train_scores': [float(s) for s in train_scores],
            'val_scores': [float(s) for s in val_scores]
        }

        logger.info(f"   í›ˆë ¨ RÂ²: {train_mean:.4f} Â± {np.std(train_scores):.4f}")
        logger.info(f"   ê²€ì¦ RÂ²: {val_mean:.4f} Â± {np.std(val_scores):.4f}")
        logger.info(f"   ì„±ëŠ¥ ì°¨ì´: {performance_gap:.4f}")
        logger.info(f"   ê³¼ì í•© ì˜ì‹¬: {'YES' if result['overfitting_indicator'] else 'NO'}")

        self.results['train_vs_validation'] = result
        return result

    def test_2_learning_curve_analysis(self):
        """2. í•™ìŠµ ê³¡ì„  ë¶„ì„"""
        logger.info("ğŸ” 2. í•™ìŠµ ê³¡ì„  ë¶„ì„...")

        data = self.load_spy_data()
        X, y = self.create_v2_features(data)
        X_scaled = self.scaler.fit_transform(X)

        model = Ridge(alpha=self.best_alpha)

        # ë‹¤ì–‘í•œ í›ˆë ¨ í¬ê¸°ë¡œ í•™ìŠµ ê³¡ì„  ìƒì„±
        train_sizes = np.linspace(0.3, 1.0, 8)
        train_sizes_abs, train_scores, val_scores = learning_curve(
            model, X_scaled, y,
            cv=self.cv,
            train_sizes=train_sizes,
            scoring='r2',
            n_jobs=-1
        )

        # í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
        train_mean = np.mean(train_scores, axis=1)
        train_std = np.std(train_scores, axis=1)
        val_mean = np.mean(val_scores, axis=1)
        val_std = np.std(val_scores, axis=1)

        # ìˆ˜ë ´ ë¶„ì„
        final_gap = train_mean[-1] - val_mean[-1]
        convergence_trend = np.corrcoef(train_sizes_abs, val_mean)[0, 1]  # ê²€ì¦ ì„±ëŠ¥ê³¼ ë°ì´í„° í¬ê¸° ìƒê´€ê´€ê³„

        result = {
            'train_sizes': [int(s) for s in train_sizes_abs],
            'train_scores_mean': [float(s) for s in train_mean],
            'train_scores_std': [float(s) for s in train_std],
            'val_scores_mean': [float(s) for s in val_mean],
            'val_scores_std': [float(s) for s in val_std],
            'final_performance_gap': float(final_gap),
            'convergence_trend': float(convergence_trend),
            'overfitting_indicator': bool(final_gap > 0.05 or convergence_trend < 0)
        }

        logger.info(f"   ìµœì¢… ì„±ëŠ¥ ì°¨ì´: {final_gap:.4f}")
        logger.info(f"   ìˆ˜ë ´ íŠ¸ë Œë“œ: {convergence_trend:.4f}")
        logger.info(f"   í•™ìŠµ ê³¡ì„  ê³¼ì í•©: {'YES' if result['overfitting_indicator'] else 'NO'}")

        self.results['learning_curve'] = result
        return result

    def test_3_cross_validation_consistency(self):
        """3. êµì°¨ê²€ì¦ ì¼ê´€ì„± ë¶„ì„"""
        logger.info("ğŸ” 3. êµì°¨ê²€ì¦ ì¼ê´€ì„± ë¶„ì„...")

        data = self.load_spy_data()
        X, y = self.create_v2_features(data)
        X_scaled = self.scaler.fit_transform(X)

        model = Ridge(alpha=self.best_alpha)
        splits = list(self.cv.split(X_scaled))

        fold_performances = []
        fold_mse = []
        fold_mae = []

        for i, (train_idx, val_idx) in enumerate(splits):
            X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

            model.fit(X_train, y_train)
            val_pred = model.predict(X_val)

            r2 = r2_score(y_val, val_pred)
            mse = mean_squared_error(y_val, val_pred)
            mae = mean_absolute_error(y_val, val_pred)

            fold_performances.append(r2)
            fold_mse.append(mse)
            fold_mae.append(mae)

            logger.info(f"   Fold {i+1}: RÂ²={r2:.4f}, MSE={mse:.6f}, MAE={mae:.6f}")

        # ì¼ê´€ì„± ì§€í‘œ
        r2_mean = np.mean(fold_performances)
        r2_std = np.std(fold_performances)
        cv_stability = r2_std / abs(r2_mean)  # ë³€ë™ê³„ìˆ˜

        result = {
            'fold_r2_scores': [float(s) for s in fold_performances],
            'fold_mse_scores': [float(s) for s in fold_mse],
            'fold_mae_scores': [float(s) for s in fold_mae],
            'r2_mean': float(r2_mean),
            'r2_std': float(r2_std),
            'r2_min': float(np.min(fold_performances)),
            'r2_max': float(np.max(fold_performances)),
            'cv_stability': float(cv_stability),
            'consistency_indicator': bool(cv_stability < 0.1)  # ë³€ë™ê³„ìˆ˜ 10% ë¯¸ë§Œì´ë©´ ì¼ê´€ì„± ìˆìŒ
        }

        logger.info(f"   RÂ² í‰ê· : {r2_mean:.4f} Â± {r2_std:.4f}")
        logger.info(f"   ë³€ë™ê³„ìˆ˜: {cv_stability:.4f}")
        logger.info(f"   ì¼ê´€ì„±: {'GOOD' if result['consistency_indicator'] else 'POOR'}")

        self.results['cross_validation_consistency'] = result
        return result

    def test_4_walk_forward_validation(self):
        """4. Walk-Forward Validation (ì‹œê°„ì  ì•ˆì •ì„±)"""
        logger.info("ğŸ” 4. Walk-Forward Validation...")

        data = self.load_spy_data()
        X, y = self.create_v2_features(data)
        X_scaled = self.scaler.fit_transform(X)

        model = Ridge(alpha=self.best_alpha)

        # ì‹œê°„ ìˆœì„œëŒ€ë¡œ walk-forward ê²€ì¦
        n_samples = len(X_scaled)
        min_train_size = n_samples // 3  # ìµœì†Œ 1/3ì€ í›ˆë ¨ìš©
        test_size = 200  # ê³ ì • í…ŒìŠ¤íŠ¸ í¬ê¸°

        walk_forward_scores = []
        time_periods = []

        for start_idx in range(min_train_size, n_samples - test_size, test_size // 2):
            end_idx = min(start_idx + test_size, n_samples)

            # í›ˆë ¨: ì²˜ìŒë¶€í„° start_idxê¹Œì§€
            # í…ŒìŠ¤íŠ¸: start_idxë¶€í„° end_idxê¹Œì§€
            X_train = X_scaled[:start_idx]
            y_train = y.iloc[:start_idx]
            X_test = X_scaled[start_idx:end_idx]
            y_test = y.iloc[start_idx:end_idx]

            model.fit(X_train, y_train)
            test_pred = model.predict(X_test)
            test_r2 = r2_score(y_test, test_pred)

            walk_forward_scores.append(test_r2)
            time_periods.append(f"{start_idx}-{end_idx}")

            logger.info(f"   Period {start_idx:4d}-{end_idx:4d}: RÂ²={test_r2:.4f}")

        # ì‹œê°„ì  ì•ˆì •ì„± ë¶„ì„
        wf_mean = np.mean(walk_forward_scores)
        wf_std = np.std(walk_forward_scores)
        time_trend = np.corrcoef(range(len(walk_forward_scores)), walk_forward_scores)[0, 1]

        result = {
            'walk_forward_scores': [float(s) for s in walk_forward_scores],
            'time_periods': time_periods,
            'wf_mean': float(wf_mean),
            'wf_std': float(wf_std),
            'time_trend': float(time_trend),
            'temporal_stability': bool(abs(time_trend) < 0.3)  # ì‹œê°„ íŠ¸ë Œë“œê°€ ì•½í•˜ë©´ ì•ˆì •ì 
        }

        logger.info(f"   Walk-Forward RÂ²: {wf_mean:.4f} Â± {wf_std:.4f}")
        logger.info(f"   ì‹œê°„ íŠ¸ë Œë“œ: {time_trend:.4f}")
        logger.info(f"   ì‹œê°„ì  ì•ˆì •ì„±: {'STABLE' if result['temporal_stability'] else 'UNSTABLE'}")

        self.results['walk_forward_validation'] = result
        return result

    def test_5_regularization_effect(self):
        """5. ì •ê·œí™” íš¨ê³¼ ê²€ì¦"""
        logger.info("ğŸ” 5. ì •ê·œí™” íš¨ê³¼ ê²€ì¦...")

        data = self.load_spy_data()
        X, y = self.create_v2_features(data)
        X_scaled = self.scaler.fit_transform(X)

        # ë‹¤ì–‘í•œ alpha ê°’ìœ¼ë¡œ ê²€ì¦ ê³¡ì„  ìƒì„±
        alpha_range = np.logspace(-2, 2, 20)  # 0.01 ~ 100

        train_scores, val_scores = validation_curve(
            Ridge(), X_scaled, y,
            param_name='alpha',
            param_range=alpha_range,
            cv=self.cv,
            scoring='r2',
            n_jobs=-1
        )

        train_mean = np.mean(train_scores, axis=1)
        val_mean = np.mean(val_scores, axis=1)

        # V2 alpha ìœ„ì¹˜ ì°¾ê¸°
        best_idx = np.argmin(np.abs(alpha_range - self.best_alpha))
        v2_train_score = train_mean[best_idx]
        v2_val_score = val_mean[best_idx]

        # ê³¼ì í•© êµ¬ê°„ ì°¾ê¸°
        performance_gaps = train_mean - val_mean
        overfitting_zone = performance_gaps > 0.05

        result = {
            'alpha_range': [float(a) for a in alpha_range],
            'train_scores_mean': [float(s) for s in train_mean],
            'val_scores_mean': [float(s) for s in val_mean],
            'performance_gaps': [float(g) for g in performance_gaps],
            'v2_alpha': float(self.best_alpha),
            'v2_train_score': float(v2_train_score),
            'v2_val_score': float(v2_val_score),
            'v2_performance_gap': float(performance_gaps[best_idx]),
            'optimal_regularization': bool(performance_gaps[best_idx] < 0.05),
            'overfitting_zone_count': int(np.sum(overfitting_zone))
        }

        logger.info(f"   V2 Alpha {self.best_alpha:.4f}: í›ˆë ¨={v2_train_score:.4f}, ê²€ì¦={v2_val_score:.4f}")
        logger.info(f"   V2 ì„±ëŠ¥ ì°¨ì´: {performance_gaps[best_idx]:.4f}")
        logger.info(f"   ìµœì  ì •ê·œí™”: {'YES' if result['optimal_regularization'] else 'NO'}")

        self.results['regularization_effect'] = result
        return result

    def test_6_feature_stability(self):
        """6. íŠ¹ì„± ì¤‘ìš”ë„ ì•ˆì •ì„±"""
        logger.info("ğŸ” 6. íŠ¹ì„± ì¤‘ìš”ë„ ì•ˆì •ì„±...")

        data = self.load_spy_data()
        X, y = self.create_v2_features(data)
        X_scaled = self.scaler.fit_transform(X)

        model = Ridge(alpha=self.best_alpha)
        splits = list(self.cv.split(X_scaled))

        feature_names = X.columns.tolist()
        feature_importance_matrix = []

        for train_idx, val_idx in splits:
            X_train = X_scaled[train_idx]
            y_train = y.iloc[train_idx]

            model.fit(X_train, y_train)

            # Ridge ê³„ìˆ˜ë¥¼ ì¤‘ìš”ë„ë¡œ ì‚¬ìš©
            importance = np.abs(model.coef_)
            feature_importance_matrix.append(importance)

        feature_importance_matrix = np.array(feature_importance_matrix)

        # ì•ˆì •ì„± ì§€í‘œ
        importance_mean = np.mean(feature_importance_matrix, axis=0)
        importance_std = np.std(feature_importance_matrix, axis=0)
        stability_scores = importance_std / (importance_mean + 1e-8)  # ë³€ë™ê³„ìˆ˜

        # ì¤‘ìš”í•œ íŠ¹ì„± (ìƒìœ„ 10ê°œ)
        top_features_idx = np.argsort(importance_mean)[-10:]

        result = {
            'feature_names': feature_names,
            'importance_mean': [float(s) for s in importance_mean],
            'importance_std': [float(s) for s in importance_std],
            'stability_scores': [float(s) for s in stability_scores],
            'top_features': [feature_names[i] for i in top_features_idx],
            'top_features_stability': [float(stability_scores[i]) for i in top_features_idx],
            'overall_stability': float(np.mean(stability_scores)),
            'stable_features': bool(np.mean(stability_scores) < 0.5)  # ë³€ë™ê³„ìˆ˜ 50% ë¯¸ë§Œì´ë©´ ì•ˆì •ì 
        }

        logger.info(f"   ì „ì²´ ì•ˆì •ì„±: {result['overall_stability']:.4f}")
        logger.info(f"   ìƒìœ„ íŠ¹ì„±: {', '.join(result['top_features'][:5])}")
        logger.info(f"   íŠ¹ì„± ì•ˆì •ì„±: {'STABLE' if result['stable_features'] else 'UNSTABLE'}")

        self.results['feature_stability'] = result
        return result

    def generate_comprehensive_report(self):
        """ì¢…í•© ê³¼ì í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        logger.info("ğŸ“‹ ì¢…í•© ê³¼ì í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±...")

        # ê° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test1 = self.test_1_train_vs_validation()
        test2 = self.test_2_learning_curve_analysis()
        test3 = self.test_3_cross_validation_consistency()
        test4 = self.test_4_walk_forward_validation()
        test5 = self.test_5_regularization_effect()
        test6 = self.test_6_feature_stability()

        # ê³¼ì í•© ì§€í‘œ ì¢…í•©
        overfitting_indicators = [
            test1['overfitting_indicator'],
            test2['overfitting_indicator'],
            not test3['consistency_indicator'],
            not test4['temporal_stability'],
            not test5['optimal_regularization'],
            not test6['stable_features']
        ]

        overfitting_count = sum(overfitting_indicators)
        overfitting_risk = overfitting_count / len(overfitting_indicators)

        # ìµœì¢… íŒì •
        if overfitting_risk <= 0.2:
            final_verdict = "LOW_RISK"
            verdict_desc = "ê³¼ì í•© ìœ„í—˜ ë‚®ìŒ"
        elif overfitting_risk <= 0.5:
            final_verdict = "MEDIUM_RISK"
            verdict_desc = "ê³¼ì í•© ìœ„í—˜ ë³´í†µ"
        else:
            final_verdict = "HIGH_RISK"
            verdict_desc = "ê³¼ì í•© ìœ„í—˜ ë†’ìŒ"

        comprehensive_result = {
            'model_info': {
                'alpha': self.best_alpha,
                'reported_r2': 0.3256,
                'analysis_date': datetime.now().isoformat()
            },
            'test_results': {
                'train_vs_validation': test1,
                'learning_curve': test2,
                'cross_validation_consistency': test3,
                'walk_forward_validation': test4,
                'regularization_effect': test5,
                'feature_stability': test6
            },
            'overfitting_assessment': {
                'overfitting_indicators': overfitting_indicators,
                'overfitting_count': overfitting_count,
                'overfitting_risk': float(overfitting_risk),
                'final_verdict': final_verdict,
                'verdict_description': verdict_desc
            },
            'recommendations': self.generate_recommendations(overfitting_risk, overfitting_indicators)
        }

        # ê²°ê³¼ ì €ì¥
        save_path = '/root/workspace/data/raw/v2_comprehensive_overfitting_analysis.json'
        with open(save_path, 'w') as f:
            json.dump(comprehensive_result, f, indent=2)

        logger.info(f"ğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼:")
        logger.info(f"   ê³¼ì í•© ì§€í‘œ: {overfitting_count}/6ê°œ ì–‘ì„±")
        logger.info(f"   ê³¼ì í•© ìœ„í—˜ë„: {overfitting_risk:.1%}")
        logger.info(f"   ìµœì¢… íŒì •: {verdict_desc}")
        logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {save_path}")

        return comprehensive_result

    def generate_recommendations(self, overfitting_risk, indicators):
        """ê³¼ì í•© ë¶„ì„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if overfitting_risk <= 0.2:
            recommendations.extend([
                "âœ… V2 ëª¨ë¸ì€ ê³¼ì í•© ìœ„í—˜ì´ ë‚®ìŒ",
                "âœ… í˜„ì¬ ì„¤ì • (alpha=19.5029)ì„ í”„ë¡œë•ì…˜ì—ì„œ ì‚¬ìš© ê¶Œì¥",
                "âœ… ì •ê¸°ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ë§Œìœ¼ë¡œ ì¶©ë¶„"
            ])
        elif overfitting_risk <= 0.5:
            recommendations.extend([
                "âš ï¸ ì¤‘ê°„ ìˆ˜ì¤€ì˜ ê³¼ì í•© ìœ„í—˜ ì¡´ì¬",
                "âš ï¸ ì¶”ê°€ ì •ê·œí™” ê³ ë ¤ (alpha ì¦ê°€)",
                "âš ï¸ íŠ¹ì„± ì„ íƒ ì¬ê²€í†  í•„ìš”",
                "âš ï¸ ë” ì—„ê²©í•œ ê²€ì¦ ì²´ê³„ ë„ì…"
            ])
        else:
            recommendations.extend([
                "âŒ ë†’ì€ ê³¼ì í•© ìœ„í—˜ - ì¦‰ì‹œ ê°œì„  í•„ìš”",
                "âŒ ê°•í•œ ì •ê·œí™” ì ìš© (alpha >> 19.5)",
                "âŒ íŠ¹ì„± ìˆ˜ ëŒ€í­ ê°ì†Œ",
                "âŒ ì•™ìƒë¸” ë°©ë²• ê³ ë ¤",
                "âŒ í”„ë¡œë•ì…˜ ë°°í¬ ë³´ë¥˜"
            ])

        return recommendations

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸ” V2 ëª¨ë¸ ê³¼ì í•© ì¢…í•© ê²€ì¦ ì‹œì‘")

    checker = V2OverfittingChecker()

    try:
        result = checker.generate_comprehensive_report()

        verdict = result['overfitting_assessment']['final_verdict']
        risk = result['overfitting_assessment']['overfitting_risk']

        logger.info("="*60)
        logger.info("ğŸ¯ V2 ëª¨ë¸ ê³¼ì í•© ê²€ì¦ ì™„ë£Œ")
        logger.info(f"ğŸ“Š ìµœì¢… íŒì •: {result['overfitting_assessment']['verdict_description']}")
        logger.info(f"ğŸ“Š ìœ„í—˜ë„: {risk:.1%}")
        logger.info("="*60)

        # ê¶Œì¥ì‚¬í•­ ì¶œë ¥
        logger.info("ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        for rec in result['recommendations']:
            logger.info(f"   {rec}")

        return result

    except Exception as e:
        logger.error(f"âŒ ê³¼ì í•© ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
        raise

if __name__ == "__main__":
    main()