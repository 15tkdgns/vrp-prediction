#!/usr/bin/env python3
"""
ğŸš¨ Emergency Data Leakage Audit System
Critical Issue: MDD = 0.0000 indicates severe data leakage
"""

import numpy as np
import pandas as pd
from pathlib import Path
import json
import warnings
warnings.filterwarnings('ignore')

class DataLeakageEmergencyAudit:
    def __init__(self):
        self.data_path = Path("/root/workspace/data")
        self.audit_results = {}
        self.critical_issues = []
        self.warnings = []

    def audit_raw_data_integrity(self):
        """1. ì›ì‹œ ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬"""
        print("ğŸ” 1. ì›ì‹œ ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬...")

        try:
            # SPY í›ˆë ¨ ë°ì´í„° ë¡œë“œ
            data_file = self.data_path / "training" / "sp500_2020_2024_enhanced.csv"
            df = pd.read_csv(data_file)

            print(f"   ğŸ“Š ë°ì´í„° í¬ê¸°: {df.shape}")
            print(f"   ğŸ“… ë‚ ì§œ ë²”ìœ„: {df['Date'].min()} ~ {df['Date'].max()}")

            # ë‚ ì§œ ìˆœì„œ í™•ì¸
            df['Date'] = pd.to_datetime(df['Date'])
            is_sorted = df['Date'].is_monotonic_increasing

            if not is_sorted:
                self.critical_issues.append("âŒ CRITICAL: ë‚ ì§œê°€ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì •ë ¬ë˜ì§€ ì•ŠìŒ")
                print("   âŒ CRITICAL: ë‚ ì§œ ìˆœì„œ ì˜¤ë¥˜ ë°œê²¬!")
            else:
                print("   âœ… ë‚ ì§œ ìˆœì„œ: ì •ìƒ")

            # Returns ê³„ì‚° ê²€ì¦
            calculated_returns = df['Close'].pct_change()
            if 'Returns' in df.columns:
                returns_diff = abs(df['Returns'] - calculated_returns).mean()
                if returns_diff > 1e-6:
                    self.critical_issues.append("âŒ CRITICAL: Returns ê³„ì‚°ì— ë¯¸ë˜ ì •ë³´ í¬í•¨ ì˜ì‹¬")
                    print(f"   âŒ CRITICAL: Returns ê³„ì‚° ì˜¤ë¥˜ (ì°¨ì´: {returns_diff:.8f})")
                else:
                    print("   âœ… Returns ê³„ì‚°: ì •ìƒ")

            # ê²°ì¸¡ê°’ ê²€ì‚¬
            missing_counts = df.isnull().sum()
            critical_missing = missing_counts[missing_counts > len(df) * 0.1]
            if len(critical_missing) > 0:
                self.warnings.append(f"âš ï¸ ë†’ì€ ê²°ì¸¡ë¥  ì»¬ëŸ¼: {critical_missing.to_dict()}")

            self.audit_results['raw_data'] = {
                'shape': df.shape,
                'date_sorted': is_sorted,
                'date_range': [str(df['Date'].min()), str(df['Date'].max())],
                'missing_critical': critical_missing.to_dict()
            }

            return df

        except Exception as e:
            self.critical_issues.append(f"âŒ CRITICAL: ì›ì‹œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ - {e}")
            return None

    def audit_feature_engineering_leakage(self, df):
        """2. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë°ì´í„° ìœ ì¶œ ê²€ì‚¬"""
        print("\nğŸ” 2. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë°ì´í„° ìœ ì¶œ ê²€ì‚¬...")

        leakage_suspects = []

        # ì´ë™í‰ê·  ê²€ì‚¬
        ma_columns = [col for col in df.columns if 'MA_' in col or 'SMA' in col or 'EMA' in col]
        for col in ma_columns:
            if col in df.columns:
                # ì²« ë²ˆì§¸ ê³„ì‚° ê°€ëŠ¥í•œ ì§€ì  í™•ì¸
                window = int(col.split('_')[-1]) if col.split('_')[-1].isdigit() else 20
                first_valid = df[col].first_valid_index()
                expected_first = window - 1

                if first_valid < expected_first:
                    leakage_suspects.append(f"{col}: ì˜ˆìƒë³´ë‹¤ ì´ë¥¸ ì‹œì ë¶€í„° ê°’ ì¡´ì¬")
                    print(f"   âŒ SUSPECT: {col} - ì²« ìœ íš¨ê°’ ìœ„ì¹˜ {first_valid}, ì˜ˆìƒ {expected_first}")

        # RSI ê²€ì‚¬
        if 'RSI' in df.columns:
            first_rsi = df['RSI'].first_valid_index()
            if first_rsi < 14:  # RSIëŠ” ë³´í†µ 14ì¼ í•„ìš”
                leakage_suspects.append("RSI: ê³„ì‚° ìœˆë„ìš°ë³´ë‹¤ ì´ë¥¸ ì‹œì ë¶€í„° ê°’ ì¡´ì¬")
                print(f"   âŒ SUSPECT: RSI ì²« ìœ íš¨ê°’ ìœ„ì¹˜ {first_rsi}, ì˜ˆìƒ >= 14")

        # Lag íŠ¹ì§• ê²€ì‚¬
        lag_features = [col for col in df.columns if 'lag' in col.lower()]
        for col in lag_features:
            lag_num = 1  # ê¸°ë³¸ê°’
            try:
                lag_num = int(col.split('_')[-1])
            except:
                pass

            # Lag íŠ¹ì§•ì˜ ì²« ë²ˆì§¸ ê°’ì´ ë„ˆë¬´ ì´ë¥¸ì§€ í™•ì¸
            first_valid = df[col].first_valid_index()
            if first_valid < lag_num:
                leakage_suspects.append(f"{col}: Lagë³´ë‹¤ ì´ë¥¸ ì‹œì ë¶€í„° ê°’ ì¡´ì¬")
                print(f"   âŒ SUSPECT: {col} - ì²« ìœ íš¨ê°’ ìœ„ì¹˜ {first_valid}, ì˜ˆìƒ >= {lag_num}")

        # ë³¼ë¦°ì € ë°´ë“œ ê²€ì‚¬
        bb_columns = [col for col in df.columns if 'BB_' in col]
        for col in bb_columns:
            first_valid = df[col].first_valid_index()
            if first_valid < 20:  # BBëŠ” ë³´í†µ 20ì¼ í•„ìš”
                leakage_suspects.append(f"{col}: ê³„ì‚° ìœˆë„ìš°ë³´ë‹¤ ì´ë¥¸ ì‹œì ë¶€í„° ê°’ ì¡´ì¬")
                print(f"   âŒ SUSPECT: {col} - ì²« ìœ íš¨ê°’ ìœ„ì¹˜ {first_valid}, ì˜ˆìƒ >= 20")

        if len(leakage_suspects) == 0:
            print("   âœ… í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§: ëª…ë°±í•œ ìœ ì¶œ ì—†ìŒ")
        else:
            self.critical_issues.extend(leakage_suspects)

        self.audit_results['feature_engineering'] = {
            'leakage_suspects': leakage_suspects,
            'total_features': len(df.columns),
            'lag_features': len(lag_features),
            'ma_features': len(ma_columns)
        }

    def audit_preprocessing_leakage(self):
        """3. ì „ì²˜ë¦¬ ê³¼ì • ë°ì´í„° ìœ ì¶œ ê²€ì‚¬"""
        print("\nğŸ” 3. ì „ì²˜ë¦¬ ê³¼ì • ë°ì´í„° ìœ ì¶œ ê²€ì‚¬...")

        # ìŠ¤ì¼€ì¼ë§ ìˆœì„œ ê²€ì‚¬ - ì½”ë“œ íŒŒì¼ë“¤ í™•ì¸
        model_files = list(Path("/root/workspace/src").rglob("*.py"))
        scaling_issues = []

        for file_path in model_files:
            if 'model' in str(file_path) or 'test' in str(file_path):
                try:
                    with open(file_path, 'r') as f:
                        content = f.read()

                    # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ ê²€ì‚¬
                    if 'fit_transform(X)' in content and 'train_test_split' in content:
                        # fit_transformì´ ë¶„í•  ì´ì „ì— ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        fit_pos = content.find('fit_transform(X)')
                        split_pos = content.find('train_test_split')

                        if fit_pos < split_pos and fit_pos != -1 and split_pos != -1:
                            scaling_issues.append(f"{file_path.name}: fit_transformì´ ë°ì´í„° ë¶„í•  ì´ì „ì— ì‹¤í–‰")
                            print(f"   âŒ CRITICAL: {file_path.name} - ìŠ¤ì¼€ì¼ë§ ìˆœì„œ ì˜¤ë¥˜!")

                except Exception as e:
                    continue

        if len(scaling_issues) == 0:
            print("   âœ… ì „ì²˜ë¦¬ ìˆœì„œ: ëª…ë°±í•œ ì˜¤ë¥˜ ì—†ìŒ")
        else:
            self.critical_issues.extend(scaling_issues)

        self.audit_results['preprocessing'] = {
            'scaling_issues': scaling_issues,
            'files_checked': len(model_files)
        }

    def audit_cross_validation_leakage(self):
        """4. êµì°¨ ê²€ì¦ ë°ì´í„° ìœ ì¶œ ê²€ì‚¬"""
        print("\nğŸ” 4. êµì°¨ ê²€ì¦ ë°ì´í„° ìœ ì¶œ ê²€ì‚¬...")

        cv_issues = []

        # ëª¨ë¸ íŒŒì¼ì—ì„œ êµì°¨ ê²€ì¦ ë°©ë²• í™•ì¸
        model_files = list(Path("/root/workspace/src").rglob("*test*.py"))

        for file_path in model_files:
            try:
                with open(file_path, 'r') as f:
                    content = f.read()

                # ì˜ëª»ëœ CV ë°©ë²• ê²€ì‚¬
                if 'KFold' in content and 'TimeSeriesSplit' not in content:
                    cv_issues.append(f"{file_path.name}: ì‹œê³„ì—´ ë°ì´í„°ì— ì¼ë°˜ KFold ì‚¬ìš©")
                    print(f"   âŒ CRITICAL: {file_path.name} - ì˜ëª»ëœ CV ë°©ë²•!")

                if 'StratifiedKFold' in content:
                    cv_issues.append(f"{file_path.name}: ì‹œê³„ì—´ ë°ì´í„°ì— StratifiedKFold ì‚¬ìš©")
                    print(f"   âŒ CRITICAL: {file_path.name} - ì‹œê³„ì—´ì— ë¶€ì ì ˆí•œ CV!")

                if 'shuffle=True' in content and 'TimeSeriesSplit' not in content:
                    cv_issues.append(f"{file_path.name}: ì‹œê³„ì—´ ë°ì´í„° ì…”í”Œë§")
                    print(f"   âŒ CRITICAL: {file_path.name} - ì‹œê³„ì—´ ìˆœì„œ íŒŒê´´!")

            except Exception as e:
                continue

        if len(cv_issues) == 0:
            print("   âœ… êµì°¨ ê²€ì¦: ëª…ë°±í•œ ì˜¤ë¥˜ ì—†ìŒ")
        else:
            self.critical_issues.extend(cv_issues)

        self.audit_results['cross_validation'] = {
            'cv_issues': cv_issues,
            'files_checked': len(model_files)
        }

    def audit_mdd_calculation(self):
        """5. MDD ê³„ì‚° ì˜¤ë¥˜ ê²€ì‚¬ (í•µì‹¬ ì´ìŠˆ)"""
        print("\nğŸ” 5. MDD ê³„ì‚° ì˜¤ë¥˜ ê²€ì‚¬ (í•µì‹¬ ì´ìŠˆ)...")

        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ MDD ê³„ì‚° ê²€ì¦
        test_returns = np.array([0.02, -0.01, 0.015, -0.03, 0.01, -0.02, 0.025, -0.015])

        # ì˜¬ë°”ë¥¸ MDD ê³„ì‚°
        cumulative = np.cumprod(1 + test_returns)
        running_max = np.maximum.accumulate(cumulative)
        drawdown = (cumulative - running_max) / running_max
        correct_mdd = abs(np.min(drawdown))

        print(f"   ğŸ“Š í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥ : {test_returns}")
        print(f"   ğŸ“Š ëˆ„ì  ìˆ˜ìµë¥ : {cumulative}")
        print(f"   ğŸ“Š ì˜¬ë°”ë¥¸ MDD: {correct_mdd:.4f}")

        if correct_mdd == 0.0:
            self.critical_issues.append("âŒ CRITICAL: MDD ê³„ì‚° ë¡œì§ ìì²´ì— ì˜¤ë¥˜")
            print("   âŒ CRITICAL: MDD ê³„ì‚° í•¨ìˆ˜ ì˜¤ë¥˜!")
        else:
            print("   âœ… MDD ê³„ì‚° ë¡œì§: ì •ìƒ")

        # ëª¨ë¸ì—ì„œ MDD 0ì´ ë‚˜ì˜¤ëŠ” ì›ì¸ ë¶„ì„
        zero_mdd_causes = [
            "ì˜ˆì¸¡ ìˆ˜ìµë¥ ì´ ëª¨ë‘ 0ì— ê°€ê¹Œì›€ (ê·¹ë„ë¡œ ë³´ìˆ˜ì  ì˜ˆì¸¡)",
            "ìˆ˜ìµë¥  ê³„ì‚°ì—ì„œ ì‹¤ì œ ì†ì‹¤ì´ ì—†ìŒ (ë°ì´í„° ìœ ì¶œ)",
            "MDD ê³„ì‚° êµ¬ê°„ì´ ë„ˆë¬´ ì§§ìŒ",
            "ì˜ˆì¸¡ê°’ì´ ì‹¤ì œ ë³€ë™ì„±ì„ ë°˜ì˜í•˜ì§€ ëª»í•¨"
        ]

        print(f"   ğŸ” MDD=0 ê°€ëŠ¥í•œ ì›ì¸ë“¤:")
        for i, cause in enumerate(zero_mdd_causes, 1):
            print(f"     {i}. {cause}")

        self.audit_results['mdd_calculation'] = {
            'test_mdd': correct_mdd,
            'zero_mdd_causes': zero_mdd_causes,
            'calculation_logic_ok': correct_mdd > 0
        }

    def audit_target_leakage(self, df):
        """6. íƒ€ê²Ÿ ë³€ìˆ˜ ë°ì´í„° ìœ ì¶œ ê²€ì‚¬"""
        print("\nğŸ” 6. íƒ€ê²Ÿ ë³€ìˆ˜ ë°ì´í„° ìœ ì¶œ ê²€ì‚¬...")

        target_issues = []

        if 'Returns' in df.columns:
            # íƒ€ê²Ÿì´ ë¯¸ë˜ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
            returns = df['Returns'].values

            # íƒ€ê²Ÿì˜ ìê¸°ìƒê´€ ê²€ì‚¬ (ê³¼ë„í•œ ìƒê´€ì€ ìœ ì¶œ ì˜ì‹¬)
            if len(returns) > 1:
                autocorr = np.corrcoef(returns[:-1], returns[1:])[0, 1]
                if abs(autocorr) > 0.3:
                    target_issues.append(f"íƒ€ê²Ÿ ìê¸°ìƒê´€ì´ ê³¼ë„í•¨: {autocorr:.4f}")
                    print(f"   âŒ SUSPECT: íƒ€ê²Ÿ ìê¸°ìƒê´€ {autocorr:.4f} (>0.3)")
                else:
                    print(f"   âœ… íƒ€ê²Ÿ ìê¸°ìƒê´€: {autocorr:.4f} (ì •ìƒ)")

            # íƒ€ê²Ÿì˜ ë¶„ì‚° ê²€ì‚¬
            target_std = np.std(returns)
            if target_std < 0.001:  # ë„ˆë¬´ ë‚®ì€ ë³€ë™ì„±
                target_issues.append(f"íƒ€ê²Ÿ ë³€ë™ì„±ì´ ë¹„í˜„ì‹¤ì ìœ¼ë¡œ ë‚®ìŒ: {target_std:.6f}")
                print(f"   âŒ SUSPECT: íƒ€ê²Ÿ ë³€ë™ì„± {target_std:.6f} (ë„ˆë¬´ ë‚®ìŒ)")
            else:
                print(f"   âœ… íƒ€ê²Ÿ ë³€ë™ì„±: {target_std:.6f} (ì •ìƒ)")

        if len(target_issues) == 0:
            print("   âœ… íƒ€ê²Ÿ ë³€ìˆ˜: ëª…ë°±í•œ ìœ ì¶œ ì—†ìŒ")
        else:
            self.warnings.extend(target_issues)

        self.audit_results['target_leakage'] = {
            'target_issues': target_issues,
            'target_available': 'Returns' in df.columns
        }

    def generate_emergency_report(self):
        """ê¸´ê¸‰ ê°ì‚¬ ë³´ê³ ì„œ ìƒì„±"""
        print("\n" + "="*80)
        print("ğŸš¨ ê¸´ê¸‰ ë°ì´í„° ìœ ì¶œ ê°ì‚¬ ë³´ê³ ì„œ")
        print("="*80)

        print(f"\nğŸ“Š ì „ì²´ ê°ì‚¬ ê²°ê³¼:")
        print(f"   ğŸ”´ ì¤‘ëŒ€ ì´ìŠˆ: {len(self.critical_issues)}ê°œ")
        print(f"   ğŸŸ¡ ê²½ê³  ì‚¬í•­: {len(self.warnings)}ê°œ")

        if len(self.critical_issues) > 0:
            print(f"\nğŸ”´ ì¤‘ëŒ€ ì´ìŠˆë“¤:")
            for i, issue in enumerate(self.critical_issues, 1):
                print(f"   {i}. {issue}")

        if len(self.warnings) > 0:
            print(f"\nğŸŸ¡ ê²½ê³  ì‚¬í•­ë“¤:")
            for i, warning in enumerate(self.warnings, 1):
                print(f"   {i}. {warning}")

        # ìš°ì„ ìˆœìœ„ ìˆ˜ì • ê¶Œê³ 
        print(f"\nğŸ¯ ìš°ì„ ìˆœìœ„ ìˆ˜ì • ê¶Œê³ :")

        if len(self.critical_issues) > 0:
            print("   1. ğŸš¨ ì¦‰ì‹œ ìˆ˜ì • í•„ìš” (CRITICAL)")
            print("      - ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œëŠ” í˜„ì¬ ì‹ ë¢°í•  ìˆ˜ ì—†ìŒ")
            print("      - ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì „ë©´ ì¬êµ¬ì¶• í•„ìš”")
            print("      - MDD=0 ë¬¸ì œ í•´ê²° ìµœìš°ì„ ")
        else:
            print("   1. âœ… ì¤‘ëŒ€ ì´ìŠˆ ì—†ìŒ - ì„¸ë¶€ ê²€í†  ì§„í–‰")

        print("   2. ğŸ“Š ê°•ê±´í•œ ë°±í…ŒìŠ¤íŒ… ì‹œìŠ¤í…œ êµ¬ì¶•")
        print("   3. ğŸ” ì¡°í•© êµì°¨ ê²€ì¦(CPCV) ë„ì…")
        print("   4. ğŸ“ˆ í˜„ì‹¤ì  ì„±ëŠ¥ ì§€í‘œ ì¬ê³„ì‚°")

        # ê²°ê³¼ ì €ì¥
        audit_file = Path("/root/workspace/emergency_data_leakage_audit.json")
        with open(audit_file, 'w', encoding='utf-8') as f:
            json.dump({
                'audit_timestamp': pd.Timestamp.now().isoformat(),
                'critical_issues': self.critical_issues,
                'warnings': self.warnings,
                'audit_results': self.audit_results,
                'total_critical': len(self.critical_issues),
                'total_warnings': len(self.warnings)
            }, f, indent=2, default=str)

        print(f"\nğŸ“ ê°ì‚¬ ë³´ê³ ì„œ ì €ì¥: {audit_file}")

        # ìµœì¢… íŒì •
        if len(self.critical_issues) > 0:
            print(f"\nğŸš¨ ìµœì¢… íŒì •: ë°ì´í„° ìœ ì¶œ ì˜ì‹¬ - ì¦‰ì‹œ ìˆ˜ì • í•„ìš”")
            return False
        else:
            print(f"\nâœ… ìµœì¢… íŒì •: ëª…ë°±í•œ ë°ì´í„° ìœ ì¶œ ì—†ìŒ - ì¶”ê°€ ì •ë°€ ê²€ì‚¬ í•„ìš”")
            return True

    def run_emergency_audit(self):
        """ê¸´ê¸‰ ê°ì‚¬ ì‹¤í–‰"""
        print("ğŸš¨ ê¸´ê¸‰ ë°ì´í„° ìœ ì¶œ ê°ì‚¬ ì‹œì‘")
        print("ë¬¸ì œ: MDD = 0.0000ì€ ì‹¬ê°í•œ ë°ì´í„° ìœ ì¶œì„ ì‹œì‚¬í•©ë‹ˆë‹¤.\n")

        # 1. ì›ì‹œ ë°ì´í„° ê²€ì‚¬
        df = self.audit_raw_data_integrity()

        if df is not None:
            # 2. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê²€ì‚¬
            self.audit_feature_engineering_leakage(df)

            # 6. íƒ€ê²Ÿ ë³€ìˆ˜ ê²€ì‚¬
            self.audit_target_leakage(df)

        # 3. ì „ì²˜ë¦¬ ê³¼ì • ê²€ì‚¬
        self.audit_preprocessing_leakage()

        # 4. êµì°¨ ê²€ì¦ ê²€ì‚¬
        self.audit_cross_validation_leakage()

        # 5. MDD ê³„ì‚° ê²€ì‚¬
        self.audit_mdd_calculation()

        # ìµœì¢… ë³´ê³ ì„œ
        is_clean = self.generate_emergency_report()

        return is_clean, self.audit_results

if __name__ == "__main__":
    auditor = DataLeakageEmergencyAudit()
    is_clean, results = auditor.run_emergency_audit()