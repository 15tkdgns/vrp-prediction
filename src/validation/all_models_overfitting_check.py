"""
ì „ì²´ ëª¨ë¸ (V1-V5) ê³¼ì í•© ì¢…í•© ê²€ì¦ ì‹œìŠ¤í…œ
V2ì—ì„œ ê³¼ì í•©ì´ ë°œê²¬ë˜ì—ˆìœ¼ë¯€ë¡œ, ëª¨ë“  ëª¨ë¸ì˜ ì•ˆì „ì„±ì„ ê²€ì¦

ê²€ì¦ ëŒ€ìƒ:
- V1: alpha=1.8523, 14ê°œ íŠ¹ì„±, RÂ²=0.2775
- V2: alpha=19.5029, 30ê°œ íŠ¹ì„±, RÂ²=0.3256 (ê³¼ì í•© í™•ì¸ë¨)
- V3: sklearn, alpha=1.0, 31ê°œ íŠ¹ì„±, RÂ²=0.2750
- V4: alpha=5.0, 66ê°œ íŠ¹ì„±, RÂ²=0.3222
- V5: ì•™ìƒë¸”, RÂ²=0.2289

ëª©í‘œ: ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œ ì•ˆì „í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ ì°¾ê¸°
"""

import numpy as np
import pandas as pd
import yfinance as yf
import json
import logging
from datetime import datetime
import warnings
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.ensemble import VotingRegressor

warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/root/workspace/data/raw/all_models_overfitting_check.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class PurgedKFoldSklearn:
    """sklearn í˜¸í™˜ Purged K-Fold Cross-Validation"""

    def __init__(self, n_splits=5, purge_length=5, embargo_length=5):
        self.n_splits = n_splits
        self.purge_length = purge_length
        self.embargo_length = embargo_length

    def split(self, X, y=None, groups=None):
        n_samples = len(X)
        indices = np.arange(n_samples)
        test_size = n_samples // self.n_splits
        splits = []

        for i in range(self.n_splits):
            test_start = i * test_size
            test_end = min((i + 1) * test_size, n_samples)
            test_indices = indices[test_start:test_end]

            purge_start = test_end
            purge_end = min(test_end + self.purge_length, n_samples)
            embargo_end = min(purge_end + self.embargo_length, n_samples)

            train_indices = np.concatenate([
                indices[:test_start],
                indices[embargo_end:]
            ])

            if len(train_indices) > 0 and len(test_indices) > 0:
                splits.append((train_indices, test_indices))

        return splits

    def get_n_splits(self, X=None, y=None, groups=None):
        return self.n_splits

class AllModelsOverfittingChecker:
    """ì „ì²´ ëª¨ë¸ ê³¼ì í•© ê²€ì¦ê¸°"""

    def __init__(self):
        self.cv = PurgedKFoldSklearn()
        self.scaler = StandardScaler()
        self.results = {}

        # ëª¨ë¸ ì„¤ì •ë“¤
        self.model_configs = {
            'V1': {
                'alpha': 1.8523,
                'features': 'v1_features',  # 14ê°œ
                'reported_r2': 0.2775,
                'description': 'ê¸°ë³¸ ê²½ì‚¬í•˜ê°•ë²•'
            },
            'V2': {
                'alpha': 19.5029,
                'features': 'v2_features',  # 30ê°œ
                'reported_r2': 0.3256,
                'description': 'ì™„ì „ íŠ¹ì„± + ìµœì í™” (ê³¼ì í•© í™•ì¸ë¨)'
            },
            'V3': {
                'alpha': 1.0,
                'features': 'v3_features',  # 31ê°œ
                'reported_r2': 0.2750,
                'description': 'sklearn í˜¸í™˜ ìµœì í™”'
            },
            'V4': {
                'alpha': 5.0,
                'features': 'v4_features',  # 66ê°œ
                'reported_r2': 0.3222,
                'description': 'í™•ì¥ íŠ¹ì„± ìµœì í™”'
            },
            'V5': {
                'alpha': [31.7068, 17.4421, 161.7161],  # ì•™ìƒë¸”
                'features': 'v5_features',  # 115ê°œ â†’ ê°„ì†Œí™”
                'reported_r2': 0.2289,
                'description': 'ì•™ìƒë¸” ìµœì í™”'
            }
        }

    def load_spy_data(self):
        """SPY ë°ì´í„° ë¡œë“œ"""
        logger.info("ğŸ“Š SPY ë°ì´í„° ë¡œë”©...")

        spy = yf.Ticker("SPY")
        data = spy.history(start="2015-01-01", end="2024-12-31")
        data['returns'] = np.log(data['Close'] / data['Close'].shift(1))
        data = data.dropna()

        logger.info(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(data)}ê°œ ê´€ì¸¡ì¹˜")
        return data

    def create_v1_features(self, data):
        """V1 íŠ¹ì„± (14ê°œ) - ê¸°ë³¸ì ì¸ ê²ƒë§Œ"""
        returns = data['returns']
        features = pd.DataFrame(index=data.index)

        # ê¸°ë³¸ ë³€ë™ì„±
        for window in [5, 10, 20]:
            features[f'vol_{window}'] = returns.rolling(window).std()

        # ê¸°ë³¸ ë˜ê·¸
        for lag in [1, 2, 3]:
            features[f'return_lag_{lag}'] = returns.shift(lag)

        # ê¸°ë³¸ í†µê³„
        for window in [10, 20]:
            ma = returns.rolling(window).mean()
            std = returns.rolling(window).std()
            features[f'zscore_{window}'] = (returns - ma) / (std + 1e-8)
            features[f'momentum_{window}'] = returns.rolling(window).sum()

        # ê¸°ë³¸ ë¹„ìœ¨
        features['vol_5_20_ratio'] = features['vol_5'] / (features['vol_20'] + 1e-8)
        features['vol_regime'] = (features['vol_5'] > features['vol_10']).astype(float)

        return self.finalize_features(features, returns)

    def create_v2_features(self, data):
        """V2 íŠ¹ì„± (30ê°œ) - V2ì™€ ë™ì¼"""
        returns = data['returns']
        features = pd.DataFrame(index=data.index)

        # ë³€ë™ì„± (6ê°œ)
        for window in [3, 5, 10, 15, 20, 30]:
            features[f'vol_{window}'] = returns.rolling(window).std()

        # í†µê³„ì  ëª¨ë©˜íŠ¸ (6ê°œ)
        for window in [5, 10, 20]:
            features[f'skew_{window}'] = returns.rolling(window).skew()
            features[f'kurt_{window}'] = returns.rolling(window).kurt()

        # ë˜ê·¸ (6ê°œ)
        for lag in [1, 2, 3]:
            features[f'return_lag_{lag}'] = returns.shift(lag)
            features[f'vol_lag_{lag}'] = features['vol_5'].shift(lag)

        # ë³€ë™ì„± ì²´ì œ (4ê°œ)
        short_vol = features['vol_5']
        medium_vol = features['vol_20']
        long_vol = features['vol_30']

        features['vol_regime_short'] = (short_vol > medium_vol).astype(float)
        features['vol_regime_medium'] = (medium_vol > long_vol).astype(float)
        features['vol_expansion'] = short_vol / (long_vol + 1e-8)
        features['vol_contraction'] = long_vol / (short_vol + 1e-8)

        # í†µê³„ ì§€í‘œ (5ê°œ)
        for window in [10, 20, 30]:
            ma = returns.rolling(window).mean()
            std = returns.rolling(window).std()
            features[f'zscore_{window}'] = (returns - ma) / (std + 1e-8)

        for window in [10, 20]:
            ma = returns.rolling(window).mean()
            std = returns.rolling(window).std()
            features[f'sharpe_{window}'] = (ma * np.sqrt(252)) / (std + 1e-8)

        # ìƒí˜¸ì‘ìš© (3ê°œ)
        features['vol_5_20_ratio'] = features['vol_5'] / (features['vol_20'] + 1e-8)
        features['vol_10_30_ratio'] = features['vol_10'] / (features['vol_30'] + 1e-8)
        features['vol_price_interaction'] = features['vol_20'] * returns

        return self.finalize_features(features, returns)

    def create_v3_features(self, data):
        """V3 íŠ¹ì„± (31ê°œ) - V2 + 1ê°œ ì¶”ê°€"""
        returns = data['returns']
        features = pd.DataFrame(index=data.index)

        # V2 ê¸°ë°˜ìœ¼ë¡œ ì‹œì‘
        v2_data = self.create_v2_features(data)
        features = v2_data[0].copy()

        # ì¶”ê°€ íŠ¹ì„± 1ê°œ
        features['momentum_15'] = returns.rolling(15).sum()

        return self.finalize_features(features, returns)

    def create_v4_features(self, data):
        """V4 íŠ¹ì„± (66ê°œ) - í™•ì¥ëœ íŠ¹ì„±"""
        returns = data['returns']
        prices = data['Close']
        volume = data['Volume']
        features = pd.DataFrame(index=data.index)

        # V2 ê¸°ë³¸ íŠ¹ì„±ë“¤
        v2_data = self.create_v2_features(data)
        base_features = v2_data[0].copy()

        for col in base_features.columns:
            if col != 'target_vol_5d':
                features[col] = base_features[col]

        # ì¶”ê°€ ë³€ë™ì„±
        for window in [7, 12, 25, 40, 50, 60, 100]:
            features[f'vol_{window}'] = returns.rolling(window).std()

        # ê³ ì°¨ ëª¨ë©˜íŠ¸ í™•ì¥
        for window in [15, 25, 30]:
            features[f'skew_{window}'] = returns.rolling(window).skew()
            features[f'kurt_{window}'] = returns.rolling(window).kurt()

        # ê°€ê²© íŠ¹ì„±
        for window in [5, 10, 20, 30, 50]:
            sma = prices.rolling(window).mean()
            features[f'price_sma_dev_{window}'] = (prices - sma) / sma

        # ê±°ë˜ëŸ‰ íŠ¹ì„± (ê°„ì†Œí™”)
        for window in [10, 20]:
            vol_sma = volume.rolling(window).mean()
            features[f'volume_ratio_{window}'] = volume / (vol_sma + 1)

        # ì¶”ê°€ ë˜ê·¸
        for lag in [5, 7, 10]:
            features[f'return_lag_{lag}'] = returns.shift(lag)

        # ë” ë§ì€ ë¹„ìœ¨
        features['vol_7_30_ratio'] = features['vol_7'] / (features['vol_30'] + 1e-8)
        features['vol_12_50_ratio'] = features['vol_12'] / (features['vol_50'] + 1e-8)

        return self.finalize_features(features, returns)

    def create_v5_features(self, data):
        """V5 íŠ¹ì„± (115ê°œ â†’ 50ê°œë¡œ ê°„ì†Œí™”)"""
        returns = data['returns']
        features = pd.DataFrame(index=data.index)

        # V4 ê¸°ë°˜ìœ¼ë¡œ ì‹œì‘í•˜ë˜ ê°„ì†Œí™”
        v4_data = self.create_v4_features(data)
        v4_features = v4_data[0].copy()

        # í•µì‹¬ íŠ¹ì„±ë§Œ ì„ ë³„ (50ê°œë¡œ ì œí•œ)
        important_features = []
        for col in v4_features.columns:
            if col != 'target_vol_5d':
                important_features.append(col)

        # ìƒìœ„ 50ê°œë§Œ ì„ íƒ (ì„ì˜ë¡œ)
        selected_features = important_features[:50]

        for col in selected_features:
            features[col] = v4_features[col]

        return self.finalize_features(features, returns)

    def finalize_features(self, features, returns):
        """íŠ¹ì„± ë§ˆë¬´ë¦¬ ì²˜ë¦¬"""
        # íƒ€ê²Ÿ ì¶”ê°€
        target = []
        for i in range(len(returns)):
            if i + 5 < len(returns):
                future_vol = returns.iloc[i+1:i+6].std()
                target.append(future_vol)
            else:
                target.append(np.nan)

        features['target_vol_5d'] = target
        features = features.dropna()

        X = features.drop('target_vol_5d', axis=1)
        y = features['target_vol_5d']

        return X, y

    def test_model_overfitting(self, model_name, config):
        """ê°œë³„ ëª¨ë¸ ê³¼ì í•© í…ŒìŠ¤íŠ¸"""
        logger.info(f"ğŸ” {model_name} ê³¼ì í•© ê²€ì¦ ì‹œì‘...")
        logger.info(f"   ì„¤ì •: alpha={config['alpha']}, RÂ²={config['reported_r2']:.4f}")

        # ë°ì´í„° ì¤€ë¹„
        data = self.load_spy_data()

        if config['features'] == 'v1_features':
            X, y = self.create_v1_features(data)
        elif config['features'] == 'v2_features':
            X, y = self.create_v2_features(data)
        elif config['features'] == 'v3_features':
            X, y = self.create_v3_features(data)
        elif config['features'] == 'v4_features':
            X, y = self.create_v4_features(data)
        elif config['features'] == 'v5_features':
            X, y = self.create_v5_features(data)

        X_scaled = self.scaler.fit_transform(X)

        logger.info(f"   íŠ¹ì„±: {X.shape[1]}ê°œ, ìƒ˜í”Œ: {len(X)}ê°œ")

        # ëª¨ë¸ ìƒì„±
        if model_name == 'V5':  # ì•™ìƒë¸”
            models = [
                ('ridge1', Ridge(alpha=config['alpha'][0], random_state=42)),
                ('ridge2', Ridge(alpha=config['alpha'][1], random_state=43)),
                ('ridge3', Ridge(alpha=config['alpha'][2], random_state=44))
            ]
            model = VotingRegressor(estimators=models)
        else:  # ë‹¨ì¼ Ridge
            model = Ridge(alpha=config['alpha'])

        # ê³¼ì í•© í…ŒìŠ¤íŠ¸: í›ˆë ¨ vs ê²€ì¦
        splits = list(self.cv.split(X_scaled))
        train_scores = []
        val_scores = []

        for train_idx, val_idx in splits:
            X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

            model.fit(X_train, y_train)

            # í›ˆë ¨ ì„±ëŠ¥
            train_pred = model.predict(X_train)
            train_r2 = r2_score(y_train, train_pred)
            train_scores.append(train_r2)

            # ê²€ì¦ ì„±ëŠ¥
            val_pred = model.predict(X_val)
            val_r2 = r2_score(y_val, val_pred)
            val_scores.append(val_r2)

        # ê²°ê³¼ ê³„ì‚°
        train_mean = np.mean(train_scores)
        val_mean = np.mean(val_scores)
        performance_gap = train_mean - val_mean

        # ê³¼ì í•© íŒì • ê¸°ì¤€
        overfitting_risk = 'LOW'
        if performance_gap > 0.15:
            overfitting_risk = 'HIGH'
        elif performance_gap > 0.08:
            overfitting_risk = 'MEDIUM'

        result = {
            'model': model_name,
            'config': config,
            'features_count': X.shape[1],
            'samples_count': len(X),
            'train_r2_mean': float(train_mean),
            'train_r2_std': float(np.std(train_scores)),
            'val_r2_mean': float(val_mean),
            'val_r2_std': float(np.std(val_scores)),
            'performance_gap': float(performance_gap),
            'overfitting_risk': overfitting_risk,
            'reported_vs_actual': {
                'reported_r2': config['reported_r2'],
                'actual_r2': float(val_mean),
                'difference': float(val_mean - config['reported_r2'])
            }
        }

        logger.info(f"   í›ˆë ¨ RÂ²: {train_mean:.4f} Â± {np.std(train_scores):.4f}")
        logger.info(f"   ê²€ì¦ RÂ²: {val_mean:.4f} Â± {np.std(val_scores):.4f}")
        logger.info(f"   ì„±ëŠ¥ ê²©ì°¨: {performance_gap:.4f}")
        logger.info(f"   ë³´ê³ ê°’ vs ì‹¤ì œ: {config['reported_r2']:.4f} â†’ {val_mean:.4f}")
        logger.info(f"   ê³¼ì í•© ìœ„í—˜: {overfitting_risk}")

        return result

    def check_all_models(self):
        """ëª¨ë“  ëª¨ë¸ ê³¼ì í•© ê²€ì¦"""
        logger.info("ğŸš€ ì „ì²´ ëª¨ë¸ (V1-V5) ê³¼ì í•© ì¢…í•© ê²€ì¦ ì‹œì‘")

        all_results = {}
        safe_models = []
        risky_models = []

        for model_name, config in self.model_configs.items():
            try:
                result = self.test_model_overfitting(model_name, config)
                all_results[model_name] = result

                if result['overfitting_risk'] == 'LOW':
                    safe_models.append(model_name)
                else:
                    risky_models.append(model_name)

            except Exception as e:
                logger.error(f"âŒ {model_name} ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
                all_results[model_name] = {'error': str(e)}

        # ì¢…í•© ê²°ê³¼
        summary = {
            'analysis_date': datetime.now().isoformat(),
            'total_models_tested': len(self.model_configs),
            'safe_models': safe_models,
            'risky_models': risky_models,
            'detailed_results': all_results,
            'recommendations': self.generate_recommendations(safe_models, risky_models, all_results)
        }

        # ê²°ê³¼ ì €ì¥
        save_path = '/root/workspace/data/raw/all_models_overfitting_analysis.json'
        with open(save_path, 'w') as f:
            json.dump(summary, f, indent=2)

        logger.info("="*70)
        logger.info("ğŸ“Š ì „ì²´ ëª¨ë¸ ê³¼ì í•© ê²€ì¦ ì™„ë£Œ")
        logger.info(f"âœ… ì•ˆì „í•œ ëª¨ë¸: {len(safe_models)}ê°œ - {safe_models}")
        logger.info(f"âš ï¸ ìœ„í—˜í•œ ëª¨ë¸: {len(risky_models)}ê°œ - {risky_models}")
        logger.info(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼: {save_path}")
        logger.info("="*70)

        return summary

    def generate_recommendations(self, safe_models, risky_models, all_results):
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if len(safe_models) > 0:
            best_safe_model = None
            best_safe_r2 = -1

            for model in safe_models:
                if model in all_results and 'val_r2_mean' in all_results[model]:
                    r2 = all_results[model]['val_r2_mean']
                    if r2 > best_safe_r2:
                        best_safe_r2 = r2
                        best_safe_model = model

            recommendations.extend([
                f"âœ… í”„ë¡œë•ì…˜ ê¶Œì¥: {best_safe_model} (RÂ²={best_safe_r2:.4f})",
                "âœ… ê³¼ì í•© ìœ„í—˜ ë‚®ì€ ëª¨ë¸ë“¤ ìš°ì„  ì‚¬ìš©",
                "âœ… ì •ê¸°ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•"
            ])
        else:
            recommendations.extend([
                "âŒ ì•ˆì „í•œ ëª¨ë¸ ì—†ìŒ - ëª¨ë“  ëª¨ë¸ì´ ê³¼ì í•© ìœ„í—˜",
                "âŒ ìƒˆë¡œìš´ ëª¨ë¸ ê°œë°œ í•„ìš”",
                "âŒ ë” ê°•í•œ ì •ê·œí™” ë° íŠ¹ì„± ì„ íƒ í•„ìš”"
            ])

        if len(risky_models) > 0:
            recommendations.append(f"âš ï¸ ìœ„í—˜ ëª¨ë¸ ì‚¬ìš© ê¸ˆì§€: {risky_models}")

        return recommendations

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    logger.info("ğŸ¯ ì „ì²´ ëª¨ë¸ ê³¼ì í•© ê²€ì¦ ì‹œì‘")

    checker = AllModelsOverfittingChecker()

    try:
        results = checker.check_all_models()

        logger.info("ğŸ’¡ ìµœì¢… ê¶Œì¥ì‚¬í•­:")
        for rec in results['recommendations']:
            logger.info(f"   {rec}")

        return results

    except Exception as e:
        logger.error(f"âŒ ì „ì²´ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
        raise

if __name__ == "__main__":
    main()