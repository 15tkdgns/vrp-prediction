#!/usr/bin/env python3
"""
ğŸ” ìë™ í• ë£¨ì‹œë„¤ì´ì…˜ íƒì§€ ì‹œìŠ¤í…œ

ì‹¤í—˜ ê²°ê³¼ì˜ ì§„ìœ„ë¥¼ ìë™ìœ¼ë¡œ ê²€ì¦í•˜ê³  í• ë£¨ì‹œë„¤ì´ì…˜ì„ íƒì§€í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime

warnings.filterwarnings('ignore')

@dataclass
class ValidationResult:
    """ê²€ì¦ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    is_valid: bool
    confidence: float
    issues: List[str]
    recommendations: List[str]
    risk_level: str

class HallucinationDetector:
    """í• ë£¨ì‹œë„¤ì´ì…˜ ìë™ íƒì§€ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.red_flags = []
        self.performance_thresholds = {
            'volatility_r2_max': 0.20,
            'direction_accuracy_max': 0.70,
            'classification_accuracy_max': 0.95,
            'minimum_sample_size': 500
        }

    def detect_file_hallucination(self, file_path: str) -> ValidationResult:
        """íŒŒì¼ ê¸°ë°˜ í• ë£¨ì‹œë„¤ì´ì…˜ íƒì§€"""
        issues = []
        recommendations = []
        confidence = 1.0

        file_path = Path(file_path)

        # 1. íŒŒì¼ëª… ê²€ì‚¬
        if 'simulated' in file_path.name.lower():
            issues.append(f"ğŸš¨ íŒŒì¼ëª…ì— 'simulated' í¬í•¨: {file_path.name}")
            confidence -= 0.5

        if 'fake' in file_path.name.lower():
            issues.append(f"ğŸš¨ íŒŒì¼ëª…ì— 'fake' í¬í•¨: {file_path.name}")
            confidence -= 0.5

        # 2. íŒŒì¼ ë‚´ìš© ê²€ì‚¬
        try:
            if file_path.suffix == '.json':
                validation = self._validate_json_file(file_path)
            elif file_path.suffix == '.txt':
                validation = self._validate_text_file(file_path)
            else:
                validation = ValidationResult(
                    is_valid=True, confidence=0.5,
                    issues=["ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹"],
                    recommendations=["ìˆ˜ë™ ê²€ì¦ í•„ìš”"],
                    risk_level="MEDIUM"
                )

            # ê²°ê³¼ í†µí•©
            issues.extend(validation.issues)
            recommendations.extend(validation.recommendations)
            confidence = min(confidence, validation.confidence)

        except Exception as e:
            issues.append(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            confidence = 0.0

        # 3. ìœ„í—˜ë„ í‰ê°€
        if confidence < 0.3:
            risk_level = "HIGH"
        elif confidence < 0.7:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"

        is_valid = len(issues) == 0 and confidence > 0.7

        return ValidationResult(
            is_valid=is_valid,
            confidence=confidence,
            issues=issues,
            recommendations=recommendations,
            risk_level=risk_level
        )

    def _validate_json_file(self, file_path: Path) -> ValidationResult:
        """JSON íŒŒì¼ ë‚´ìš© ê²€ì¦"""
        issues = []
        recommendations = []
        confidence = 1.0

        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # í• ë£¨ì‹œë„¤ì´ì…˜ ê²½ê³  í—¤ë” í™•ì¸
        if "HALLUCINATION WARNING" in str(data):
            issues.append("ğŸš¨ íŒŒì¼ì— í• ë£¨ì‹œë„¤ì´ì…˜ ê²½ê³  ì¡´ì¬")
            confidence = 0.0
            recommendations.append("ì´ íŒŒì¼ì€ ì‚¬ìš© ê¸ˆì§€ë¨")

        # ì„±ëŠ¥ ì§€í‘œ ê²€ì‚¬
        for key, value in data.items():
            if isinstance(value, (int, float)):
                if 'r2' in key.lower() and value > self.performance_thresholds['volatility_r2_max']:
                    issues.append(f"ğŸš¨ ë¹„í˜„ì‹¤ì  RÂ²: {key} = {value:.4f} (ìµœëŒ€ {self.performance_thresholds['volatility_r2_max']})")
                    confidence -= 0.3

                if 'accuracy' in key.lower() and value > self.performance_thresholds['direction_accuracy_max']:
                    issues.append(f"ğŸš¨ ë¹„í˜„ì‹¤ì  ì •í™•ë„: {key} = {value:.4f}")
                    confidence -= 0.3

        # ìƒ˜í”Œ ìˆ˜ ê²€ì‚¬
        if 'sample_count' in data:
            if data['sample_count'] < self.performance_thresholds['minimum_sample_size']:
                issues.append(f"âš ï¸ ìƒ˜í”Œ ìˆ˜ ë¶€ì¡±: {data['sample_count']} < {self.performance_thresholds['minimum_sample_size']}")
                confidence -= 0.2

        # ëª¨ë“  ê°’ì´ ì–‘ìˆ˜ì¸ì§€ í™•ì¸ (ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´)
        if self._check_all_positive_pattern(data):
            issues.append("ğŸš¨ ëª¨ë“  ê²°ê³¼ê°€ ì–‘ìˆ˜ (ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´)")
            confidence -= 0.4

        return ValidationResult(
            is_valid=len(issues) == 0,
            confidence=max(0, confidence),
            issues=issues,
            recommendations=recommendations,
            risk_level="HIGH" if confidence < 0.3 else "MEDIUM" if confidence < 0.7 else "LOW"
        )

    def _validate_text_file(self, file_path: Path) -> ValidationResult:
        """í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš© ê²€ì¦"""
        issues = []
        recommendations = []
        confidence = 1.0

        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # í• ë£¨ì‹œë„¤ì´ì…˜ ê²½ê³  í™•ì¸
        if "HALLUCINATION WARNING" in content:
            issues.append("ğŸš¨ íŒŒì¼ì— í• ë£¨ì‹œë„¤ì´ì…˜ ê²½ê³  ì¡´ì¬")
            confidence = 0.0

        # ê³¼ì¥ëœ ì„±ê³¼ í‘œí˜„ íƒì§€
        exaggerated_terms = [
            "ì™„ë²½", "í˜ì‹ ì ", "íšê¸°ì ", "ìµœê³ ", "ìµœì ",
            "ì™„ì „", "ì ˆëŒ€", "100%", "ì™„ì„±",
            "breakthrough", "perfect", "optimal"
        ]

        for term in exaggerated_terms:
            if term in content.lower():
                issues.append(f"âš ï¸ ê³¼ì¥ëœ í‘œí˜„ ë°œê²¬: '{term}'")
                confidence -= 0.1

        # RÂ² ê°’ ì¶”ì¶œ ë° ê²€ì‚¬
        import re
        r2_pattern = r'RÂ²[=\s]*([0-9.]+)'
        r2_matches = re.findall(r2_pattern, content)

        for r2_str in r2_matches:
            try:
                r2_value = float(r2_str)
                if r2_value > self.performance_thresholds['volatility_r2_max']:
                    issues.append(f"ğŸš¨ ë¹„í˜„ì‹¤ì  RÂ²: {r2_value:.4f}")
                    confidence -= 0.3
            except ValueError:
                continue

        return ValidationResult(
            is_valid=len(issues) == 0,
            confidence=max(0, confidence),
            issues=issues,
            recommendations=recommendations,
            risk_level="HIGH" if confidence < 0.3 else "MEDIUM" if confidence < 0.7 else "LOW"
        )

    def _check_all_positive_pattern(self, data: dict) -> bool:
        """ëª¨ë“  ê°’ì´ ì–‘ìˆ˜ì¸ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ í™•ì¸"""
        numeric_values = []

        def extract_numbers(obj):
            if isinstance(obj, (int, float)):
                numeric_values.append(obj)
            elif isinstance(obj, dict):
                for value in obj.values():
                    extract_numbers(value)
            elif isinstance(obj, list):
                for item in obj:
                    extract_numbers(item)

        extract_numbers(data)

        # RÂ² ê°’ë“¤ë§Œ í™•ì¸
        r2_values = []
        for key, value in data.items():
            if 'r2' in key.lower() and isinstance(value, (int, float)):
                r2_values.append(value)
            elif isinstance(value, list) and 'r2' in key.lower():
                r2_values.extend([v for v in value if isinstance(v, (int, float))])

        # RÂ² ê°’ì´ 10ê°œ ì´ìƒì´ê³  ëª¨ë‘ ì–‘ìˆ˜ë©´ ì˜ì‹¬
        if len(r2_values) >= 10 and all(v > 0 for v in r2_values):
            return True

        return False

    def validate_experiment_consistency(self, experiment_files: List[str]) -> ValidationResult:
        """ì—¬ëŸ¬ ì‹¤í—˜ íŒŒì¼ ê°„ ì¼ê´€ì„± ê²€ì¦"""
        issues = []
        recommendations = []
        confidence = 1.0

        sample_counts = {}
        r2_values = {}

        # ê° íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        for file_path in experiment_files:
            try:
                if not Path(file_path).exists():
                    continue

                if file_path.endswith('.json'):
                    with open(file_path, 'r') as f:
                        data = json.load(f)

                    # ìƒ˜í”Œ ìˆ˜ ì¶”ì¶œ
                    for key, value in data.items():
                        if 'sample' in key.lower() and isinstance(value, int):
                            sample_counts[file_path] = value
                            break

                    # RÂ² ê°’ ì¶”ì¶œ
                    for key, value in data.items():
                        if 'r2' in key.lower() and isinstance(value, (int, float)):
                            if file_path not in r2_values:
                                r2_values[file_path] = []
                            r2_values[file_path].append(value)

            except Exception as e:
                issues.append(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ {file_path}: {str(e)}")
                confidence -= 0.1

        # ìƒ˜í”Œ ìˆ˜ ì¼ê´€ì„± í™•ì¸
        if len(set(sample_counts.values())) > 1:
            issues.append(f"âš ï¸ ìƒ˜í”Œ ìˆ˜ ë¶ˆì¼ì¹˜: {sample_counts}")
            confidence -= 0.2

        # RÂ² ê°’ ì¼ê´€ì„± í™•ì¸ (ë™ì¼í•œ ì‹¤í—˜ì—ì„œ ë„ˆë¬´ ë‹¤ë¥¸ ê²°ê³¼)
        all_r2 = []
        for values in r2_values.values():
            all_r2.extend(values)

        if len(all_r2) > 1:
            r2_std = np.std(all_r2)
            r2_mean = np.mean(all_r2)

            if r2_std > 0.1 and abs(r2_mean) > 0.01:  # í‘œì¤€í¸ì°¨ê°€ í¬ê³  í‰ê· ì´ 0ì´ ì•„ë‹˜
                issues.append(f"âš ï¸ RÂ² ê°’ í¸ì°¨ í¼: í‰ê·  {r2_mean:.4f}, í‘œì¤€í¸ì°¨ {r2_std:.4f}")
                confidence -= 0.1

        return ValidationResult(
            is_valid=len(issues) == 0,
            confidence=max(0, confidence),
            issues=issues,
            recommendations=recommendations,
            risk_level="HIGH" if confidence < 0.3 else "MEDIUM" if confidence < 0.7 else "LOW"
        )

    def generate_validation_report(self, target_dir: str = "/root/workspace") -> Dict:
        """ì „ì²´ í”„ë¡œì íŠ¸ ê²€ì¦ ë³´ê³ ì„œ ìƒì„±"""
        results = {
            'validation_timestamp': datetime.now().isoformat(),
            'target_directory': target_dir,
            'files_validated': 0,
            'hallucination_files': [],
            'suspicious_files': [],
            'validated_files': [],
            'summary': {}
        }

        # ê²€ì¦ ëŒ€ìƒ íŒŒì¼ ì°¾ê¸°
        target_path = Path(target_dir)
        json_files = list(target_path.rglob("*.json"))
        txt_files = list(target_path.rglob("*.txt"))

        all_files = json_files + txt_files

        for file_path in all_files:
            # íŠ¹ì • ë””ë ‰í† ë¦¬ ì œì™¸
            if any(exclude in str(file_path) for exclude in ['node_modules', '.git', '__pycache__']):
                continue

            validation = self.detect_file_hallucination(str(file_path))
            results['files_validated'] += 1

            file_info = {
                'path': str(file_path),
                'confidence': validation.confidence,
                'risk_level': validation.risk_level,
                'issues': validation.issues,
                'recommendations': validation.recommendations
            }

            if validation.risk_level == "HIGH":
                results['hallucination_files'].append(file_info)
            elif validation.risk_level == "MEDIUM":
                results['suspicious_files'].append(file_info)
            else:
                results['validated_files'].append(file_info)

        # ìš”ì•½ í†µê³„
        results['summary'] = {
            'total_files': results['files_validated'],
            'hallucination_count': len(results['hallucination_files']),
            'suspicious_count': len(results['suspicious_files']),
            'validated_count': len(results['validated_files']),
            'integrity_percentage': (len(results['validated_files']) / max(1, results['files_validated'])) * 100
        }

        return results

def main():
    """ë©”ì¸ ê²€ì¦ ì‹¤í–‰"""
    print("ğŸ” ìë™ í• ë£¨ì‹œë„¤ì´ì…˜ íƒì§€ ì‹œìŠ¤í…œ ì‹œì‘")
    print("="*60)

    detector = HallucinationDetector()

    # ì „ì²´ í”„ë¡œì íŠ¸ ê²€ì¦
    report = detector.generate_validation_report()

    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½:")
    print(f"   ì „ì²´ íŒŒì¼: {report['summary']['total_files']}ê°œ")
    print(f"   í• ë£¨ì‹œë„¤ì´ì…˜: {report['summary']['hallucination_count']}ê°œ")
    print(f"   ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒŒì¼: {report['summary']['suspicious_count']}ê°œ")
    print(f"   ê²€ì¦ëœ íŒŒì¼: {report['summary']['validated_count']}ê°œ")
    print(f"   ë¬´ê²°ì„±: {report['summary']['integrity_percentage']:.1f}%")

    # í• ë£¨ì‹œë„¤ì´ì…˜ íŒŒì¼ ìƒì„¸
    if report['hallucination_files']:
        print(f"\nğŸš¨ í• ë£¨ì‹œë„¤ì´ì…˜ íŒŒì¼:")
        for file_info in report['hallucination_files']:
            print(f"   âŒ {file_info['path']}")
            print(f"      ì‹ ë¢°ë„: {file_info['confidence']:.2f}")
            for issue in file_info['issues'][:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                print(f"      - {issue}")

    # ë³´ê³ ì„œ ì €ì¥
    report_path = "/root/workspace/data/validation_report_auto.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ ìƒì„¸ ë³´ê³ ì„œ ì €ì¥: {report_path}")

    return report

if __name__ == "__main__":
    main()