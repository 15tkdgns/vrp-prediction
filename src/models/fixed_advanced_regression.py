#!/usr/bin/env python3
"""
ğŸ”§ ìˆ˜ì •ëœ ê³ ê¸‰ íšŒê·€ ìµœì í™” ì‹œìŠ¤í…œ

NaN ì²˜ë¦¬ ë¬¸ì œ í•´ê²° ë° ì•ˆì •ì ì¸ íšŒê·€ ëª¨ë¸ í•™ìŠµ
"""

import sys
sys.path.append('/root/workspace/src')

import pandas as pd
import numpy as np
from datetime import datetime
import json
import time
import warnings
warnings.filterwarnings('ignore')

# Core imports
from core.data_processor import DataProcessor

# ML imports
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import ElasticNet, Ridge
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_absolute_error, r2_score
import torch
import torch.nn as nn
import torch.optim as optim

class FixedAdvancedRegressionOptimizer:
    """ìˆ˜ì •ëœ ê³ ê¸‰ íšŒê·€ ìµœì í™” ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.data_processor = DataProcessor()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        print(f"ğŸ”§ ìˆ˜ì •ëœ ê³ ê¸‰ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")

    def prepare_safe_data(self, df, target='returns'):
        """ì•ˆì „í•œ ë°ì´í„° ì¤€ë¹„ (NaN ì™„ì „ ì œê±°)"""
        print(f"ğŸ›¡ï¸ ì•ˆì „í•œ ë°ì´í„° ì¤€ë¹„ ì¤‘... (target: {target})")

        # ê¸°ë³¸ íŠ¹ì„± ìƒì„±
        if target == 'returns':
            df['target'] = df['Close'].pct_change()
        elif target == 'volatility':
            df['target'] = df['Close'].pct_change().rolling(20).std()
        else:
            df['target'] = df[target]

        # ìˆ«ìí˜• íŠ¹ì„±ë§Œ ì„ íƒ
        numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()
        exclude_columns = ['Date', 'target', 'Open', 'High', 'Low', 'Close', 'Volume']
        feature_columns = [col for col in numeric_features if col not in exclude_columns]

        # ë°ì´í„° ì¶”ì¶œ
        X = df[feature_columns].values
        y = df['target'].values

        # 1ë‹¨ê³„: ë¬´í•œê°’ ì²˜ë¦¬
        X = np.where(np.isinf(X), 0, X)
        y = np.where(np.isinf(y), 0, y)

        # 2ë‹¨ê³„: NaNì„ 0ìœ¼ë¡œ ëŒ€ì²´ (ë” ì•ˆì „í•œ ë°©ë²•)
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)

        # 3ë‹¨ê³„: ìœ íš¨í•œ íƒ€ê²Ÿ ì¸ë±ìŠ¤ë§Œ ì„ íƒ
        valid_idx = ~np.isnan(y) & ~np.isinf(y) & (np.abs(y) < 1.0)  # ê·¹ê°’ ì œê±°
        X = X[valid_idx]
        y = y[valid_idx]

        # 4ë‹¨ê³„: ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
        sequence_length = 15
        if len(X) > sequence_length:
            X_seq = []
            y_seq = []

            for i in range(sequence_length, len(X)):
                X_seq.append(X[i-sequence_length:i])
                y_seq.append(y[i])

            X_seq = np.array(X_seq)
            y_seq = np.array(y_seq)

            print(f"   âœ… ì•ˆì „í•œ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: X={X_seq.shape}, y={y_seq.shape}")
            return X_seq, y_seq, feature_columns
        else:
            print(f"   âš ï¸ ë°ì´í„° ë¶€ì¡±: {len(X)} < {sequence_length}")
            return None, None, None

    class SafeLSTM(nn.Module):
        """ì•ˆì „í•œ LSTM ëª¨ë¸"""

        def __init__(self, input_size, hidden_size=32, num_layers=2):
            super().__init__()
            self.lstm = nn.LSTM(input_size, hidden_size, num_layers,
                              batch_first=True, dropout=0.2)
            self.fc = nn.Linear(hidden_size, 1)
            self.dropout = nn.Dropout(0.3)

        def forward(self, x):
            lstm_out, _ = self.lstm(x)
            last_output = lstm_out[:, -1, :]
            dropped = self.dropout(last_output)
            return self.fc(dropped)

    def train_safe_lstm(self, X_train, y_train, X_val, y_val):
        """ì•ˆì „í•œ LSTM í›ˆë ¨"""
        model = self.SafeLSTM(X_train.shape[-1]).to(self.device)
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)

        # í…ì„œ ë³€í™˜
        X_train_tensor = torch.FloatTensor(X_train).to(self.device)
        y_train_tensor = torch.FloatTensor(y_train).to(self.device)
        X_val_tensor = torch.FloatTensor(X_val).to(self.device)

        model.train()
        for epoch in range(50):
            optimizer.zero_grad()
            outputs = model(X_train_tensor)
            loss = criterion(outputs.squeeze(), y_train_tensor)
            loss.backward()
            optimizer.step()

        # ì˜ˆì¸¡
        model.eval()
        with torch.no_grad():
            val_pred = model(X_val_tensor).cpu().numpy().squeeze()

        return val_pred

    def train_safe_traditional_ml(self, X_train, y_train, X_val, y_val):
        """ì•ˆì „í•œ ì „í†µì  ML ëª¨ë¸ë“¤"""
        results = {}

        # 2Dë¡œ ë³€í™˜ (ML ëª¨ë¸ìš©)
        X_train_2d = X_train.reshape(X_train.shape[0], -1)
        X_val_2d = X_val.reshape(X_val.shape[0], -1)

        # ì¶”ê°€ ì•ˆì „ ì²˜ë¦¬
        imputer = SimpleImputer(strategy='mean')
        X_train_2d = imputer.fit_transform(X_train_2d)
        X_val_2d = imputer.transform(X_val_2d)

        # ìŠ¤ì¼€ì¼ë§
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train_2d)
        X_val_scaled = scaler.transform(X_val_2d)

        # Random Forest
        try:
            rf = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)
            rf.fit(X_train_scaled, y_train)
            rf_pred = rf.predict(X_val_scaled)
            results['RandomForest'] = rf_pred
        except Exception as e:
            print(f"      RandomForest ì˜¤ë¥˜: {e}")
            results['RandomForest'] = np.zeros(len(y_val))

        # ElasticNet (ê°•í™”ëœ ì•ˆì „ ì²˜ë¦¬)
        try:
            # ì¶”ê°€ ì•ˆì „ ê²€ì‚¬
            if np.any(np.isnan(X_train_scaled)) or np.any(np.isnan(y_train)):
                print("      ElasticNet: NaN ë°œê²¬, ì œë¡œ íŒ¨ë”© ì ìš©")
                X_train_scaled = np.nan_to_num(X_train_scaled, nan=0.0)
                X_val_scaled = np.nan_to_num(X_val_scaled, nan=0.0)
                y_train_clean = np.nan_to_num(y_train, nan=0.0)
            else:
                y_train_clean = y_train

            elastic = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)
            elastic.fit(X_train_scaled, y_train_clean)
            elastic_pred = elastic.predict(X_val_scaled)
            results['ElasticNet'] = elastic_pred
        except Exception as e:
            print(f"      ElasticNet ì˜¤ë¥˜: {e}")
            results['ElasticNet'] = np.zeros(len(y_val))

        # Ridge
        try:
            ridge = Ridge(alpha=1.0, random_state=42)
            ridge.fit(X_train_scaled, y_train)
            ridge_pred = ridge.predict(X_val_scaled)
            results['Ridge'] = ridge_pred
        except Exception as e:
            print(f"      Ridge ì˜¤ë¥˜: {e}")
            results['Ridge'] = np.zeros(len(y_val))

        return results

    def run_fixed_experiments(self, data_path='/root/workspace/data/training/sp500_2020_2024_enhanced.csv'):
        """ìˆ˜ì •ëœ ì‹¤í—˜ ì‹¤í–‰"""
        print("ğŸ”§ ìˆ˜ì •ëœ ê³ ê¸‰ íšŒê·€ ìµœì í™” ì‹œìŠ¤í…œ ì‹œì‘")
        print("="*70)

        start_time = time.time()
        all_results = {}

        try:
            # ë°ì´í„° ë¡œë”©
            df = self.data_processor.load_and_validate_data(data_path)

            # ì‹¤í—˜ 1: ìˆ˜ìµë¥  ì˜ˆì¸¡
            print("\nğŸ¯ ì‹¤í—˜ 1: ìˆ˜ìµë¥  ì˜ˆì¸¡ (Returns)")
            X, y, features = self.prepare_safe_data(df, target='returns')

            if X is not None:
                returns_results = self._run_cross_validation(X, y, 'returns')
                all_results['returns'] = returns_results

            # ì‹¤í—˜ 2: ë³€ë™ì„± ì˜ˆì¸¡
            print("\nğŸ¯ ì‹¤í—˜ 2: ë³€ë™ì„± ì˜ˆì¸¡ (Volatility)")
            X_vol, y_vol, _ = self.prepare_safe_data(df, target='volatility')

            if X_vol is not None:
                volatility_results = self._run_cross_validation(X_vol, y_vol, 'volatility')
                all_results['volatility'] = volatility_results

            # ê²°ê³¼ ì •ë¦¬
            total_time = time.time() - start_time
            self._summarize_results(all_results, total_time)

            return all_results

        except Exception as e:
            print(f"âŒ ìˆ˜ì •ëœ ì‹¤í—˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def _run_cross_validation(self, X, y, target_type):
        """êµì°¨ ê²€ì¦ ì‹¤í–‰"""
        tscv = TimeSeriesSplit(n_splits=3)
        fold_results = []

        for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
            print(f"\nğŸ“Š Fold {fold+1}/3")

            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]

            fold_result = {}

            # LSTM í›ˆë ¨
            print("   ğŸ§  LSTM í›ˆë ¨...")
            try:
                lstm_pred = self.train_safe_lstm(X_train, y_train, X_val, y_val)
                lstm_mae = mean_absolute_error(y_val, lstm_pred)
                lstm_r2 = r2_score(y_val, lstm_pred)
                fold_result['LSTM'] = {'mae': lstm_mae, 'r2': lstm_r2, 'pred': lstm_pred}
                print(f"      LSTM: MAE={lstm_mae:.6f}, RÂ²={lstm_r2:.4f}")
            except Exception as e:
                print(f"      LSTM ì˜¤ë¥˜: {e}")
                fold_result['LSTM'] = {'mae': np.inf, 'r2': -np.inf, 'pred': np.zeros(len(y_val))}

            # ì „í†µì  ML ëª¨ë¸ë“¤
            print("   ğŸ“Š ì „í†µì  ML ëª¨ë¸ë“¤...")
            try:
                ml_results = self.train_safe_traditional_ml(X_train, y_train, X_val, y_val)

                for model_name, pred in ml_results.items():
                    mae = mean_absolute_error(y_val, pred)
                    r2 = r2_score(y_val, pred)
                    fold_result[model_name] = {'mae': mae, 'r2': r2, 'pred': pred}
                    print(f"      {model_name}: MAE={mae:.6f}, RÂ²={r2:.4f}")

            except Exception as e:
                print(f"      ML ëª¨ë¸ ì˜¤ë¥˜: {e}")

            # ì•™ìƒë¸”
            print("   ğŸ¯ ì•™ìƒë¸”...")
            try:
                ensemble_pred = self._create_ensemble(fold_result, y_val)
                ensemble_mae = mean_absolute_error(y_val, ensemble_pred)
                ensemble_r2 = r2_score(y_val, ensemble_pred)
                fold_result['Ensemble'] = {'mae': ensemble_mae, 'r2': ensemble_r2, 'pred': ensemble_pred}
                print(f"      Ensemble: MAE={ensemble_mae:.6f}, RÂ²={ensemble_r2:.4f}")
            except Exception as e:
                print(f"      ì•™ìƒë¸” ì˜¤ë¥˜: {e}")

            fold_results.append(fold_result)
            print(f"   âœ… Fold {fold+1} ì™„ë£Œ")

        return fold_results

    def _create_ensemble(self, fold_result, y_true):
        """ì•ˆì „í•œ ì•™ìƒë¸” ìƒì„±"""
        predictions = []
        weights = []

        for model_name, result in fold_result.items():
            if 'pred' in result and len(result['pred']) == len(y_true):
                predictions.append(result['pred'])
                # RÂ²ê°€ ë†’ì„ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜
                weight = max(0.1, result.get('r2', 0) + 1)  # ìµœì†Œ 0.1 ê°€ì¤‘ì¹˜
                weights.append(weight)

        if predictions:
            predictions = np.array(predictions)
            weights = np.array(weights)
            weights = weights / weights.sum()  # ì •ê·œí™”

            ensemble_pred = np.average(predictions, axis=0, weights=weights)
            return ensemble_pred
        else:
            return np.zeros(len(y_true))

    def _summarize_results(self, all_results, total_time):
        """ê²°ê³¼ ìš”ì•½"""
        print(f"\nğŸ“Š ìˆ˜ì •ëœ ê³ ê¸‰ íšŒê·€ ìµœì í™” ê²°ê³¼ ìš”ì•½:")
        print(f"   ì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ì´ˆ")

        for target_type, results in all_results.items():
            print(f"\nğŸ¯ {target_type.upper()} ì˜ˆì¸¡ ê²°ê³¼:")

            # ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥ ê³„ì‚°
            model_performance = {}

            for fold_result in results:
                for model_name, metrics in fold_result.items():
                    if model_name not in model_performance:
                        model_performance[model_name] = {'mae': [], 'r2': []}

                    model_performance[model_name]['mae'].append(metrics['mae'])
                    model_performance[model_name]['r2'].append(metrics['r2'])

            # í‰ê·  ì¶œë ¥
            print("   ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥:")
            for model_name, metrics in model_performance.items():
                avg_mae = np.mean(metrics['mae'])
                avg_r2 = np.mean(metrics['r2'])
                print(f"      {model_name:12s}: MAE={avg_mae:.6f}, RÂ²={avg_r2:.4f}")

        # ê²°ê³¼ ì €ì¥
        output_path = f"/root/workspace/data/results/fixed_advanced_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        try:
            # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            serializable_results = {}
            for target_type, results in all_results.items():
                serializable_results[target_type] = []
                for fold_result in results:
                    fold_data = {}
                    for model_name, metrics in fold_result.items():
                        fold_data[model_name] = {
                            'mae': float(metrics['mae']),
                            'r2': float(metrics['r2'])
                        }
                    serializable_results[target_type].append(fold_data)

            with open(output_path, 'w') as f:
                json.dump({
                    'timestamp': datetime.now().isoformat(),
                    'total_time': total_time,
                    'results': serializable_results
                }, f, indent=2)

            print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    optimizer = FixedAdvancedRegressionOptimizer()
    results = optimizer.run_fixed_experiments()

    print("\nğŸ‰ ìˆ˜ì •ëœ ê³ ê¸‰ íšŒê·€ ìµœì í™” ì™„ë£Œ!")
    return results

if __name__ == "__main__":
    main()