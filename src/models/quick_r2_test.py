"""
ë¹ ë¥¸ RÂ² ê°œì„  í…ŒìŠ¤íŠ¸

ê³„ì‚°ëŸ‰ì„ ì¤„ì´ê³  í•µì‹¬ì ì¸ ê°œì„  ë°©ë²•ë“¤ë§Œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸
"""

import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

try:
    from sklearn.preprocessing import StandardScaler, QuantileTransformer
    from sklearn.feature_selection import SelectKBest, f_regression
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.linear_model import ElasticNet, Ridge
    from sklearn.metrics import r2_score
    from sklearn.model_selection import TimeSeriesSplit
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("âš ï¸ sklearn not available")


def create_realistic_financial_data(n_samples=500):
    """í˜„ì‹¤ì ì¸ ê¸ˆìœµ ë°ì´í„° ìƒì„±"""
    np.random.seed(42)
    dates = pd.date_range('2022-01-01', periods=n_samples, freq='D')

    # ìê¸°ìƒê´€ì´ ìˆëŠ” ìˆ˜ìµë¥  ìƒì„±
    returns = np.zeros(n_samples)
    volatility = 0.02

    for i in range(1, n_samples):
        # AR(1) + GARCH ìŠ¤íƒ€ì¼
        returns[i] = 0.1 * returns[i-1] + np.random.normal(0, volatility)
        volatility = 0.95 * volatility + 0.05 * abs(returns[i])

    prices = 100 * np.exp(np.cumsum(returns))

    return pd.DataFrame({
        'price': prices,
        'log_returns': returns
    }, index=dates)


def add_smart_features(data):
    """íš¨ê³¼ì ì¸ íŠ¹ì„± ì¶”ê°€"""
    enhanced = data.copy()
    returns = data['log_returns']
    prices = data['price']

    # 1. ë˜ê·¸ íŠ¹ì„± (ê³¼ê±° ì •ë³´)
    for lag in [1, 2, 3, 5]:
        enhanced[f'returns_lag_{lag}'] = returns.shift(lag)

    # 2. ì´ë™ í†µê³„ëŸ‰
    for window in [5, 10, 20]:
        enhanced[f'ma_{window}'] = returns.rolling(window).mean()
        enhanced[f'std_{window}'] = returns.rolling(window).std()
        enhanced[f'skew_{window}'] = returns.rolling(window).skew()

    # 3. ê°€ê²© ëª¨ë©˜í…€
    for days in [3, 5, 10]:
        enhanced[f'momentum_{days}d'] = prices.pct_change(days)

    # 4. ë³€ë™ì„± íŠ¹ì„±
    enhanced['realized_vol'] = returns.rolling(10).std() * np.sqrt(252)
    enhanced['vol_ratio'] = enhanced['std_5'] / (enhanced['std_20'] + 1e-8)

    # 5. íŠ¸ë Œë“œ íŠ¹ì„±
    enhanced['price_trend'] = prices / prices.rolling(20).mean() - 1
    enhanced['returns_zscore'] = (returns - returns.rolling(20).mean()) / (returns.rolling(20).std() + 1e-8)

    return enhanced.dropna()


def create_better_targets(data):
    """í–¥ìƒëœ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±"""
    enhanced = data.copy()
    returns = data['log_returns']

    # 1. ìŠ¤ë¬´ë”©ëœ íƒ€ê²Ÿ (ë…¸ì´ì¦ˆ ê°ì†Œ)
    enhanced['target_smoothed_3d'] = returns.rolling(3).mean().shift(-3)
    enhanced['target_smoothed_5d'] = returns.rolling(5).mean().shift(-5)

    # 2. ëˆ„ì  ìˆ˜ìµë¥ 
    enhanced['target_cumsum_3d'] = returns.rolling(3).sum().shift(-3)
    enhanced['target_cumsum_5d'] = returns.rolling(5).sum().shift(-5)

    # 3. ë³€ë™ì„± ì¡°ì • ìˆ˜ìµë¥ 
    vol = returns.rolling(10).std()
    enhanced['target_vol_adj'] = (returns / (vol + 1e-8)).shift(-1)

    # 4. ë°©í–¥ ì˜ˆì¸¡ (í™•ë¥ ì  íƒ€ê²Ÿ)
    enhanced['target_direction_3d'] = (returns.rolling(3).sum().shift(-3) > 0).astype(float)

    return enhanced


def test_r2_improvements():
    """RÂ² ê°œì„  í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ë¹ ë¥¸ RÂ² ê°œì„  í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # 1. ë°ì´í„° ìƒì„±
    print("\nğŸ“Š 1. í˜„ì‹¤ì  ê¸ˆìœµ ë°ì´í„° ìƒì„±")
    data = create_realistic_financial_data(n_samples=500)
    print(f"   ê¸°ë³¸ ë°ì´í„°: {len(data)}ê°œ ê´€ì¸¡ì¹˜")

    # 2. íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
    print("\nğŸ”§ 2. ìŠ¤ë§ˆíŠ¸ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§")
    enhanced_data = add_smart_features(data)
    print(f"   íŠ¹ì„± ìˆ˜: {len(enhanced_data.columns)}ê°œ")

    # 3. íƒ€ê²Ÿ ì—”ì§€ë‹ˆì–´ë§
    print("\nğŸ¯ 3. í–¥ìƒëœ íƒ€ê²Ÿ ìƒì„±")
    enhanced_data = create_better_targets(enhanced_data)
    enhanced_data = enhanced_data.dropna()
    print(f"   ìµœì¢… ë°ì´í„°: {len(enhanced_data)}ê°œ ê´€ì¸¡ì¹˜")

    # 4. íŠ¹ì„± ì„ íƒ
    target_columns = [col for col in enhanced_data.columns if 'target_' in col]
    feature_columns = [col for col in enhanced_data.columns if 'target_' not in col and col != 'price']

    X = enhanced_data[feature_columns]

    results = {}

    # 5. ê° íƒ€ê²Ÿë³„ ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("\nğŸ¤– 4. ëª¨ë¸ í…ŒìŠ¤íŠ¸")

    for target_col in target_columns[:3]:  # ìƒìœ„ 3ê°œë§Œ í…ŒìŠ¤íŠ¸
        print(f"\n   {target_col} íƒ€ê²Ÿ:")

        y = enhanced_data[target_col].dropna()
        X_target = X.loc[y.index]

        # íŠ¹ì„± ì„ íƒ (ìƒìœ„ 15ê°œ)
        selector = SelectKBest(score_func=f_regression, k=min(15, len(X_target.columns)))
        X_selected = selector.fit_transform(X_target, y)
        selected_features = X_target.columns[selector.get_support()]

        # ì‹œê³„ì—´ êµì°¨ê²€ì¦
        tscv = TimeSeriesSplit(n_splits=3)

        models = {
            'RandomForest': RandomForestRegressor(n_estimators=50, random_state=42),
            'GradientBoosting': GradientBoostingRegressor(n_estimators=50, random_state=42),
            'ElasticNet': ElasticNet(random_state=42),
            'Ridge': Ridge(random_state=42)
        }

        target_results = {}

        for model_name, model in models.items():
            cv_scores = []

            for train_idx, val_idx in tscv.split(X_selected):
                X_train, X_val = X_selected[train_idx], X_selected[val_idx]
                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

                model.fit(X_train, y_train)
                y_pred = model.predict(X_val)
                score = r2_score(y_val, y_pred)
                cv_scores.append(score)

            avg_score = np.mean(cv_scores)
            target_results[model_name] = avg_score
            print(f"     {model_name:<15} RÂ² = {avg_score:.4f}")

        # ì•™ìƒë¸” í…ŒìŠ¤íŠ¸
        ensemble_pred = np.zeros(len(y))
        ensemble_weights = {}

        # ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
        total_positive_score = sum(max(0, score) for score in target_results.values())

        if total_positive_score > 0:
            for model_name, score in target_results.items():
                weight = max(0, score) / total_positive_score
                ensemble_weights[model_name] = weight
        else:
            # ëª¨ë“  ëª¨ë¸ì´ ìŒìˆ˜ ì„±ëŠ¥ì¸ ê²½ìš° ê· ë“± ê°€ì¤‘ì¹˜
            for model_name in target_results:
                ensemble_weights[model_name] = 1 / len(target_results)

        # ì•™ìƒë¸” ì˜ˆì¸¡ ê³„ì‚°
        cv_ensemble_scores = []
        for train_idx, val_idx in tscv.split(X_selected):
            X_train, X_val = X_selected[train_idx], X_selected[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

            ensemble_pred_fold = np.zeros(len(y_val))

            for model_name, model in models.items():
                model.fit(X_train, y_train)
                y_pred = model.predict(X_val)
                ensemble_pred_fold += ensemble_weights[model_name] * y_pred

            ensemble_score = r2_score(y_val, ensemble_pred_fold)
            cv_ensemble_scores.append(ensemble_score)

        ensemble_avg_score = np.mean(cv_ensemble_scores)
        target_results['Ensemble'] = ensemble_avg_score

        print(f"     {'Ensemble':<15} RÂ² = {ensemble_avg_score:.4f}")
        print(f"     ì„ íƒëœ íŠ¹ì„±: {len(selected_features)}ê°œ")

        results[target_col] = {
            'scores': target_results,
            'selected_features': selected_features.tolist(),
            'ensemble_weights': ensemble_weights
        }

    # 6. ê²°ê³¼ ìš”ì•½
    print("\nğŸ“ˆ 5. ê²°ê³¼ ìš”ì•½")
    print("=" * 50)

    best_overall_score = -np.inf
    best_target = None
    best_model = None

    print("\nğŸ† íƒ€ê²Ÿë³„ ìµœê³  ì„±ëŠ¥:")
    for target_col, result in results.items():
        scores = result['scores']
        best_score = max(scores.values())
        best_model_name = max(scores.keys(), key=lambda k: scores[k])

        print(f"   {target_col:<25} {best_model_name:<15} RÂ² = {best_score:.4f}")

        if best_score > best_overall_score:
            best_overall_score = best_score
            best_target = target_col
            best_model = best_model_name

    print(f"\nğŸ¥‡ ì „ì²´ ìµœê³  ì„±ëŠ¥:")
    print(f"   íƒ€ê²Ÿ: {best_target}")
    print(f"   ëª¨ë¸: {best_model}")
    print(f"   RÂ² ì ìˆ˜: {best_overall_score:.4f}")

    # ê°œì„  ë¶„ì„
    baseline_r2 = -0.01  # ê¸°ì¡´ ì‹œìŠ¤í…œ í‰ê· 
    if best_overall_score > baseline_r2:
        if best_overall_score > 0:
            improvement = ((best_overall_score - baseline_r2) / abs(baseline_r2)) * 100
            print(f"\nğŸ“Š ì„±ëŠ¥ ê°œì„ : {improvement:.1f}% í–¥ìƒ")

            if best_overall_score > 0.2:
                print("ğŸ‰ ìš°ìˆ˜í•œ ì„±ëŠ¥ ë‹¬ì„±!")
            elif best_overall_score > 0.1:
                print("âœ… ìƒë‹¹í•œ ì„±ëŠ¥ ê°œì„ !")
            elif best_overall_score > 0.05:
                print("ğŸ“ˆ ì˜ë¯¸ìˆëŠ” ê°œì„ !")
            else:
                print("ğŸ“Š ì ì§„ì  ê°œì„ ")
        else:
            print("ğŸ“ˆ ê¸°ì¤€ì„  ëŒ€ë¹„ ê°œì„ ë˜ì—ˆìœ¼ë‚˜ ì—¬ì „íˆ ìŒìˆ˜")
    else:
        print("âš ï¸ ì¶”ê°€ ìµœì í™” í•„ìš”")

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì˜ íŠ¹ì„± ë¶„ì„
    if best_target in results:
        best_result = results[best_target]
        print(f"\nğŸ” ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¶„ì„:")
        print(f"   ì„ íƒëœ íŠ¹ì„± ìˆ˜: {len(best_result['selected_features'])}")
        print(f"   ì£¼ìš” íŠ¹ì„±: {best_result['selected_features'][:5]}")

        if 'ensemble_weights' in best_result:
            print(f"   ì•™ìƒë¸” ê°€ì¤‘ì¹˜:")
            for model, weight in best_result['ensemble_weights'].items():
                if weight > 0.01:  # ìœ ì˜ë¯¸í•œ ê°€ì¤‘ì¹˜ë§Œ í‘œì‹œ
                    print(f"     {model}: {weight:.3f}")

    print("\nâœ… ë¹ ë¥¸ RÂ² ê°œì„  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    return results, best_overall_score


if __name__ == "__main__":
    results, best_score = test_r2_improvements()