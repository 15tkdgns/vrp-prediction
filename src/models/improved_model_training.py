import pandas as pd
import numpy as np
import json
import os
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.regularizers import l2
import joblib
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')


class ImprovedSP500EventDetectionModel:
    """
    ê°œì„ ëœ S&P500 ì£¼ì‹ ë°ì´í„° ê¸°ë°˜ ì´ë²¤íŠ¸ íƒì§€ ëª¨ë¸
    - ê³¼ì í•© ë°©ì§€
    - êµì°¨ ê²€ì¦
    - ì •ê·œí™” ì ìš©
    - í˜„ì‹¤ì ì¸ ì‹ ë¢°ë„ ì ìˆ˜
    """

    def __init__(self, data_dir="data", models_dir="data/models"):
        self.data_dir = data_dir
        self.models_dir = models_dir
        self.scaler = StandardScaler()
        self.models = {}

        if not os.path.exists(self.models_dir):
            os.makedirs(self.models_dir)
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        if not os.path.exists("results/analysis"):
            os.makedirs("results/analysis", exist_ok=True)

    def load_training_data(self):
        """í›ˆë ¨ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("[1/6] í›ˆë ¨ ë°ì´í„° ë¡œë“œ...")
        
        # ê¸°ë³¸ íŠ¹ì„± ë° ë¼ë²¨ ë°ì´í„°
        try:
            features_df = pd.read_csv(f"{self.data_dir}/raw/training_features.csv")
            labels_df = pd.read_csv(f"{self.data_dir}/raw/event_labels.csv")
        except FileNotFoundError as e:
            print(f"âŒ í•„ìˆ˜ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return None

        # LLM íŠ¹ì„± ë°ì´í„° (ì„ íƒì )
        try:
            llm_features_df = pd.read_csv(f"{self.data_dir}/processed/llm_enhanced_features.csv")
            # date ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš° ì²˜ë¦¬
            if 'date' not in llm_features_df.columns:
                print("âš ï¸ LLM íŠ¹ì„±ì— date ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. LLM íŠ¹ì„± ì œì™¸í•˜ê³  ì§„í–‰í•©ë‹ˆë‹¤.")
                llm_features_df = pd.DataFrame()
            else:
                llm_features_df = llm_features_df.dropna(subset=["date"])
                llm_features_df["date"] = pd.to_datetime(llm_features_df["date"])
        except FileNotFoundError:
            print("âš ï¸ LLM ê°•í™” íŠ¹ì„± íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ íŠ¹ì„±ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            llm_features_df = pd.DataFrame()

        # ë‚ ì§œ í˜•ì‹ í†µì¼
        if 'Date' in features_df.columns:
            features_df["Date"] = pd.to_datetime(features_df["Date"])
        if 'Date' in labels_df.columns:
            labels_df["Date"] = pd.to_datetime(labels_df["Date"])

        # tickerì™€ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
        if 'ticker' in features_df.columns and 'ticker' in labels_df.columns:
            merged_df = pd.merge(
                features_df, labels_df,
                on=["ticker", "Date"] if 'Date' in features_df.columns else ["ticker"],
                how="inner"
            )
        else:
            # ticker ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ë‚ ì§œë§Œìœ¼ë¡œ ë³‘í•©
            if 'Date' in features_df.columns and 'Date' in labels_df.columns:
                merged_df = pd.merge(features_df, labels_df, on="Date", how="inner")
            else:
                merged_df = pd.concat([features_df, labels_df], axis=1)

        print(f"âœ… ë³‘í•©ëœ ë°ì´í„° í¬ê¸°: {merged_df.shape}")
        return merged_df

    def prepare_features(self, df):
        """íŠ¹ì„± ì¤€ë¹„ ë° ì „ì²˜ë¦¬"""
        print("[2/6] íŠ¹ì„± ì „ì²˜ë¦¬...")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (ìˆ«ìí˜• ì»¬ëŸ¼)
        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ë“¤ ì œì™¸
        target_columns = ['major_event', 'price_spike', 'unusual_volume']
        feature_columns = [col for col in numeric_columns if col not in target_columns]
        
        if not feature_columns:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ«ìí˜• íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None, None, None

        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        X = df[feature_columns].fillna(0)  # NaN ê°’ì„ 0ìœ¼ë¡œ ì²˜ë¦¬
        
        # major_eventê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì„ì‹œ íƒ€ê²Ÿ ìƒì„±
        if 'major_event' in df.columns:
            y = df['major_event']
        else:
            # ì„ì‹œë¡œ íƒ€ê²Ÿ ìƒì„± (Close ê°€ê²© ë³€í™”ìœ¨ ê¸°ì¤€)
            if 'Close' in df.columns:
                price_change = df['Close'].pct_change().fillna(0)
                y = (price_change.abs() > 0.02).astype(int)  # 2% ì´ìƒ ë³€ë™ì„ ì´ë²¤íŠ¸ë¡œ ì •ì˜
                print("âš ï¸ major_event ì»¬ëŸ¼ì´ ì—†ì–´ ê°€ê²© ë³€ë™ë¥ ë¡œ íƒ€ê²Ÿì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            else:
                # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ëœë¤ íƒ€ê²Ÿ
                y = np.random.choice([0, 1], size=len(df), p=[0.8, 0.2])
                print("âš ï¸ íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì„ì‹œ íƒ€ê²Ÿì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

        print(f"âœ… íŠ¹ì„± ìˆ˜: {len(feature_columns)}")
        print(f"âœ… ìƒ˜í”Œ ìˆ˜: {len(X)}")
        print(f"âœ… ì´ë²¤íŠ¸ ë¹„ìœ¨: {y.mean():.3f}")
        
        return X, y, feature_columns

    def train_improved_models(self, X, y):
        """ê°œì„ ëœ ëª¨ë¸ë“¤ í›ˆë ¨"""
        print("[3/6] ê°œì„ ëœ ëª¨ë¸ í›ˆë ¨...")
        
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # 1. ê°œì„ ëœ Random Forest (ê³¼ì í•© ë°©ì§€)
        print("ğŸŒ³ Random Forest í›ˆë ¨...")
        rf_model = RandomForestClassifier(
            n_estimators=100,  # íŠ¸ë¦¬ ìˆ˜ ê°ì†Œ
            max_depth=10,      # ê¹Šì´ ì œí•œ
            min_samples_split=20,  # ë¶„í•  ìµœì†Œ ìƒ˜í”Œ ì¦ê°€
            min_samples_leaf=10,   # ë¦¬í”„ ìµœì†Œ ìƒ˜í”Œ ì¦ê°€
            max_features='sqrt',   # íŠ¹ì„± ìˆ˜ ì œí•œ
            random_state=42,
            n_jobs=-1
        )
        rf_model.fit(X_train_scaled, y_train)
        
        # êµì°¨ ê²€ì¦
        cv_scores_rf = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, scoring='roc_auc')
        
        # ì˜ˆì¸¡ ë° í‰ê°€
        rf_train_pred = rf_model.predict_proba(X_train_scaled)[:, 1]
        rf_test_pred = rf_model.predict_proba(X_test_scaled)[:, 1]
        
        self.models["random_forest"] = {
            "model": rf_model,
            "train_auc": roc_auc_score(y_train, rf_train_pred),
            "test_auc": roc_auc_score(y_test, rf_test_pred),
            "cv_auc_mean": cv_scores_rf.mean(),
            "cv_auc_std": cv_scores_rf.std(),
            "feature_importance": rf_model.feature_importances_
        }
        
        print(f"RF - Train AUC: {self.models['random_forest']['train_auc']:.4f}")
        print(f"RF - Test AUC: {self.models['random_forest']['test_auc']:.4f}")
        print(f"RF - CV AUC: {cv_scores_rf.mean():.4f} Â± {cv_scores_rf.std():.4f}")

        # 2. ê°œì„ ëœ Gradient Boosting
        print("ğŸ“ˆ Gradient Boosting í›ˆë ¨...")
        gb_model = GradientBoostingClassifier(
            n_estimators=100,
            max_depth=6,       # ê¹Šì´ ì œí•œ
            learning_rate=0.1, # í•™ìŠµë¥  ê°ì†Œ
            subsample=0.8,     # ì„œë¸Œìƒ˜í”Œë§
            random_state=42
        )
        gb_model.fit(X_train_scaled, y_train)
        
        # êµì°¨ ê²€ì¦
        cv_scores_gb = cross_val_score(gb_model, X_train_scaled, y_train, cv=5, scoring='roc_auc')
        
        # ì˜ˆì¸¡ ë° í‰ê°€
        gb_train_pred = gb_model.predict_proba(X_train_scaled)[:, 1]
        gb_test_pred = gb_model.predict_proba(X_test_scaled)[:, 1]
        
        self.models["gradient_boosting"] = {
            "model": gb_model,
            "train_auc": roc_auc_score(y_train, gb_train_pred),
            "test_auc": roc_auc_score(y_test, gb_test_pred),
            "cv_auc_mean": cv_scores_gb.mean(),
            "cv_auc_std": cv_scores_gb.std(),
            "feature_importance": gb_model.feature_importances_
        }
        
        print(f"GB - Train AUC: {self.models['gradient_boosting']['train_auc']:.4f}")
        print(f"GB - Test AUC: {self.models['gradient_boosting']['test_auc']:.4f}")
        print(f"GB - CV AUC: {cv_scores_gb.mean():.4f} Â± {cv_scores_gb.std():.4f}")

        # 3. ê°œì„ ëœ LSTM (ì •ê·œí™” ì ìš©)
        print("ğŸ§  LSTM í›ˆë ¨...")
        
        # LSTMìš© ë°ì´í„° ì¤€ë¹„ (ì‹œê³„ì—´ í˜•íƒœë¡œ reshape)
        X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
        X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))
        
        lstm_model = Sequential([
            LSTM(50, return_sequences=True, input_shape=(1, X_train_scaled.shape[1]),
                 kernel_regularizer=l2(0.01)),  # L2 ì •ê·œí™”
            Dropout(0.3),  # ë“œë¡­ì•„ì›ƒ
            LSTM(25, kernel_regularizer=l2(0.01)),
            Dropout(0.3),
            Dense(25, activation='relu', kernel_regularizer=l2(0.01)),
            Dropout(0.2),
            Dense(1, activation='sigmoid')
        ])
        
        lstm_model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        # Early Stopping
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=10,
            restore_best_weights=True
        )
        
        # í›ˆë ¨
        history = lstm_model.fit(
            X_train_lstm, y_train,
            epochs=100,
            batch_size=32,
            validation_data=(X_test_lstm, y_test),
            callbacks=[early_stopping],
            verbose=0
        )
        
        # ì˜ˆì¸¡ ë° í‰ê°€
        lstm_train_pred = lstm_model.predict(X_train_lstm, verbose=0).flatten()
        lstm_test_pred = lstm_model.predict(X_test_lstm, verbose=0).flatten()
        
        self.models["lstm"] = {
            "model": lstm_model,
            "train_auc": roc_auc_score(y_train, lstm_train_pred),
            "test_auc": roc_auc_score(y_test, lstm_test_pred),
            "history": history.history
        }
        
        print(f"LSTM - Train AUC: {self.models['lstm']['train_auc']:.4f}")
        print(f"LSTM - Test AUC: {self.models['lstm']['test_auc']:.4f}")

        return X_train_scaled, X_test_scaled, y_train, y_test

    def evaluate_models(self, X_test, y_test):
        """ëª¨ë¸ í‰ê°€ ë° ë¦¬í¬íŠ¸ ìƒì„±"""
        print("[4/6] ëª¨ë¸ í‰ê°€...")
        
        evaluation_results = {}
        
        for name, model_info in self.models.items():
            if name == "lstm":
                # LSTMì€ ë³„ë„ ì²˜ë¦¬
                X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))
                y_pred_proba = model_info["model"].predict(X_test_lstm, verbose=0).flatten()
            else:
                y_pred_proba = model_info["model"].predict_proba(X_test)[:, 1]
            
            y_pred = (y_pred_proba > 0.5).astype(int)
            
            # ë¶„ë¥˜ ë¦¬í¬íŠ¸
            report = classification_report(y_test, y_pred, output_dict=True)
            
            evaluation_results[name] = {
                "auc": model_info.get("test_auc", roc_auc_score(y_test, y_pred_proba)),
                "accuracy": report["accuracy"],
                "precision": report["1"]["precision"],
                "recall": report["1"]["recall"],
                "f1_score": report["1"]["f1-score"],
                "avg_confidence": np.mean(y_pred_proba),
                "confidence_std": np.std(y_pred_proba)
            }
            
            print(f"\n{name.upper()} í‰ê°€ ê²°ê³¼:")
            print(f"  AUC: {evaluation_results[name]['auc']:.4f}")
            print(f"  ì •í™•ë„: {evaluation_results[name]['accuracy']:.4f}")
            print(f"  F1 ì ìˆ˜: {evaluation_results[name]['f1_score']:.4f}")
            print(f"  í‰ê·  ì‹ ë¢°ë„: {evaluation_results[name]['avg_confidence']:.4f}")
            print(f"  ì‹ ë¢°ë„ í‘œì¤€í¸ì°¨: {evaluation_results[name]['confidence_std']:.4f}")
        
        return evaluation_results

    def save_models(self):
        """ëª¨ë¸ ì €ì¥"""
        print("[5/6] ëª¨ë¸ ì €ì¥...")
        
        # ëª¨ë¸ë³„ ì €ì¥
        for name, model_info in self.models.items():
            if name == "lstm":
                model_info["model"].save(f"{self.models_dir}/lstm_improved_model.h5")
            else:
                joblib.dump(model_info["model"], f"{self.models_dir}/{name}_improved_model.pkl")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        joblib.dump(self.scaler, f"{self.models_dir}/scaler_improved.pkl")
        
        # ì„±ëŠ¥ ê²°ê³¼ ì €ì¥
        performance_results = {}
        for name, model_info in self.models.items():
            performance_results[name] = {
                k: v for k, v in model_info.items() 
                if k != "model" and k != "history"
            }
        
        with open(f"{self.data_dir}/raw/improved_model_performance.json", "w") as f:
            json.dump(performance_results, f, indent=2, default=str)
        
        print("âœ… ëª¨ë“  ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def run_improved_training_pipeline(self):
        """ê°œì„ ëœ ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("=== ê°œì„ ëœ ëª¨ë¸ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ===\n")
        
        # 1. ë°ì´í„° ë¡œë“œ
        df = self.load_training_data()
        if df is None:
            return False
        
        # 2. íŠ¹ì„± ì¤€ë¹„
        X, y, feature_names = self.prepare_features(df)
        if X is None:
            return False
        
        # 3. ëª¨ë¸ í›ˆë ¨
        X_train, X_test, y_train, y_test = self.train_improved_models(X, y)
        
        # 4. ëª¨ë¸ í‰ê°€
        evaluation_results = self.evaluate_models(X_test, y_test)
        
        # 5. ëª¨ë¸ ì €ì¥
        self.save_models()
        
        print("\n=== í›ˆë ¨ ì™„ë£Œ ===")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°
        best_model = max(evaluation_results.keys(), 
                        key=lambda x: evaluation_results[x]['auc'])
        
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model}")
        print(f"   AUC: {evaluation_results[best_model]['auc']:.4f}")
        print(f"   í‰ê·  ì‹ ë¢°ë„: {evaluation_results[best_model]['avg_confidence']:.4f} Â± {evaluation_results[best_model]['confidence_std']:.4f}")
        
        return True


if __name__ == "__main__":
    print("ğŸš€ ê°œì„ ëœ AI ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    
    model_trainer = ImprovedSP500EventDetectionModel()
    success = model_trainer.run_improved_training_pipeline()
    
    if success:
        print("\nâœ… í›ˆë ¨ ì„±ê³µ!")
    else:
        print("\nâŒ í›ˆë ¨ ì‹¤íŒ¨!")