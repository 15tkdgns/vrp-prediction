#!/usr/bin/env python3
"""
Temporal Fusion Transformer (TFT) ë³€ë™ì„± ì˜ˆì¸¡ ëª¨ë¸
=================================================

Google Researchì˜ TFTë¥¼ SPY ë³€ë™ì„± ì˜ˆì¸¡ì— ì ìš©
- Multi-horizon ì˜ˆì¸¡ (1ì¼, 5ì¼ ë™ì‹œ)
- Attention ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ì¤‘ìš” íŠ¹ì„± ìë™ ì‹ë³„
- í•´ì„ ê°€ëŠ¥í•œ ì˜ˆì¸¡

ì‹¤í–‰ ì‹œê°„: ì•½ 30-60ë¶„ (CPU ê¸°ì¤€)
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import yfinance as yf
from pathlib import Path
import json
from datetime import datetime

# PyTorch
import torch
from torch.utils.data import DataLoader

# PyTorch Forecasting
try:
    from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet
    from pytorch_forecasting.data import GroupNormalizer
    from pytorch_forecasting.metrics import QuantileLoss
    from pytorch_lightning import Trainer
    from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint
    HAS_TFT = True
except ImportError:
    HAS_TFT = False
    print("âš ï¸ PyTorch Forecasting ë¯¸ì„¤ì¹˜. ì„¤ì¹˜ ì¤‘...")
    print("pip install pytorch-forecasting pytorch-lightning")

SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)


# =============================================================================
# 1. ë°ì´í„° ì¤€ë¹„
# =============================================================================

def load_and_prepare_data():
    """SPY ë° VIX ë°ì´í„° ë¡œë“œ ë° TFT í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    print("\n" + "="*60)
    print("[1/6] ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„")
    print("="*60)
    
    # SPY ë°ì´í„° ë¡œë“œ
    csv_path = Path('data/raw/spy_data_2020_2025.csv')
    if csv_path.exists():
        spy = pd.read_csv(csv_path, index_col=0, parse_dates=True)
        print(f"  âœ“ SPY ë°ì´í„°: {len(spy)} í–‰")
    else:
        print("  âš ï¸ SPY ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
        spy = yf.download('SPY', start='2020-01-01', end='2025-01-01', 
                         progress=False, auto_adjust=True)
        if isinstance(spy.columns, pd.MultiIndex):
            spy.columns = spy.columns.get_level_values(0)
    
    # VIX ë°ì´í„° ë¡œë“œ
    print("  â†’ VIX ë°ì´í„° ë¡œë“œ ì¤‘...")
    vix = yf.download('^VIX', start='2020-01-01', end='2025-01-01',
                     progress=False, auto_adjust=True)
    if isinstance(vix.columns, pd.MultiIndex):
        vix.columns = vix.columns.get_level_values(0)
    spy['VIX'] = vix['Close']
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    spy = spy.ffill().dropna()
    
    # ê¸°ë³¸ íŠ¹ì„± ìƒì„±
    print("  â†’ íŠ¹ì„± ìƒì„± ì¤‘...")
    spy['returns'] = spy['Close'].pct_change()
    spy['volatility'] = spy['returns'].rolling(5).std() * np.sqrt(252)
    spy['log_volume'] = np.log(spy['Volume'] + 1)
    
    # VIX íŠ¹ì„±
    spy['vix_lag1'] = spy['VIX'].shift(1)
    spy['vix_change'] = spy['VIX'].pct_change()
    
    # Regime íŠ¹ì„±
    vix_lag = spy['VIX'].shift(1)
    spy['regime_high_vol'] = (vix_lag >= 25).astype(int)
    
    # íƒ€ê²Ÿ ìƒì„± (5ì¼ ë¯¸ë˜ ë³€ë™ì„±)
    vol_values = []
    returns = spy['returns'].values
    for i in range(len(returns)):
        if i + 5 < len(returns):
            future_window = returns[i+1:i+6]
            vol_values.append(pd.Series(future_window).std())
        else:
            vol_values.append(np.nan)
    spy['target_vol_5d'] = vol_values
    
    # 1ì¼ íƒ€ê²Ÿë„ ì¶”ê°€
    spy['target_vol_1d'] = spy['returns'].shift(-1).abs()
    
    spy = spy.dropna()
    
    print(f"  âœ“ ìµœì¢… ë°ì´í„°: {len(spy)} í–‰")
    print(f"  âœ“ ê¸°ê°„: {spy.index[0]} ~ {spy.index[-1]}")
    
    return spy


def convert_to_timeseries_format(spy):
    """TFTìš© TimeSeriesDataSet í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    print("\n" + "="*60)
    print("[2/6] TFT í˜•ì‹ ë³€í™˜")
    print("="*60)
    
    # TFTëŠ” íŒ¨ë„ ë°ì´í„° ê¸°ëŒ€ (tickerë³„)
    df = spy.reset_index()
    
    # ì»¬ëŸ¼ ì´ë¦„ í™•ì¸ ë° ë³€ê²½
    if 'index' in df.columns:
        df = df.rename(columns={'index': 'date'})
    elif df.columns[0] not in ['date', 'Date']:
        df = df.rename(columns={df.columns[0]: 'date'})
    
    # ë‹¨ì¼ ì‹œê³„ì—´ì„ íŒ¨ë„ë¡œ ë³€í™˜
    df['ticker'] = 'SPY'
    df['time_idx'] = np.arange(len(df))
    
    # íŠ¹ì„± ì„ íƒ
    feature_cols = [
        'returns', 'volatility', 'log_volume',
        'VIX', 'vix_lag1', 'vix_change',
        'regime_high_vol',
        'target_vol_1d', 'target_vol_5d'
    ]
    
    # date ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
    if 'date' in df.columns:
        df = df[['ticker', 'time_idx', 'date'] + feature_cols]
    else:
        df = df[['ticker', 'time_idx'] + feature_cols]
    
    # ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (TFT ìš”êµ¬ì‚¬í•­)
    df['regime_high_vol'] = df['regime_high_vol'].astype(str)
    
    # ê²°ì¸¡ì¹˜ ìµœì¢… ì œê±°
    df = df.dropna()
    
    print(f"  âœ“ ë³€í™˜ ì™„ë£Œ: {len(df)} ìƒ˜í”Œ")
    print(f"  âœ“ íŠ¹ì„±: {len(feature_cols) - 2}ê°œ (íƒ€ê²Ÿ ì œì™¸)")
    
    return df


# =============================================================================
# 2. TFT ëª¨ë¸ êµ¬ì¶•
# =============================================================================

def create_tft_datasets(df, max_encoder_length=30, max_prediction_length=5):
    """TimeSeriesDataSet ìƒì„±"""
    print("\n" + "="*60)
    print("[3/6] TFT ë°ì´í„°ì…‹ ìƒì„±")
    print("="*60)
    
    if not HAS_TFT:
        raise ImportError("PyTorch Forecastingì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # í•™ìŠµ/ê²€ì¦ ë¶„í•  (80/20)
    split_idx = int(len(df) * 0.8)
    
    print(f"  â†’ Encoder ê¸¸ì´: {max_encoder_length}ì¼")
    print(f"  â†’ Prediction ê¸¸ì´: {max_prediction_length}ì¼")
    
    # í•™ìŠµ ë°ì´í„°ì…‹
    training = TimeSeriesDataSet(
        df.iloc[:split_idx],
        time_idx="time_idx",
        target="target_vol_5d",
        group_ids=["ticker"],
        min_encoder_length=max_encoder_length // 2,
        max_encoder_length=max_encoder_length,
        min_prediction_length=1,
        max_prediction_length=max_prediction_length,
        
        # ì •ì  ë³€ìˆ˜ (ë³€í•˜ì§€ ì•ŠëŠ” ê°’) - ì—†ìŒ
        static_categoricals=[],
        static_reals=[],
        
        # ì‹œê°„ ë³€í™” ë³€ìˆ˜ (ì•Œë ¤ì§„ ë¯¸ë˜ ê°’)
        time_varying_known_reals=["time_idx"],
        time_varying_known_categoricals=[],
        
        # ì‹œê°„ ë³€í™” ë³€ìˆ˜ (ì˜ˆì¸¡ ëŒ€ìƒ)
        time_varying_unknown_reals=[
            "returns", "volatility", "log_volume",
            "VIX", "vix_lag1", "vix_change"
        ],
        time_varying_unknown_categoricals=["regime_high_vol"],
        
        # ì •ê·œí™”
        target_normalizer=GroupNormalizer(
            groups=["ticker"], 
            transformation="softplus"
        ),
        
        # ì¶”ê°€ íŠ¹ì„±
        add_relative_time_idx=True,
        add_target_scales=True,
        add_encoder_length=True,
    )
    
    # ê²€ì¦ ë°ì´í„°ì…‹
    validation = TimeSeriesDataSet.from_dataset(
        training, 
        df.iloc[split_idx:], 
        predict=True, 
        stop_randomization=True
    )
    
    # DataLoader
    batch_size = 32
    train_dataloader = training.to_dataloader(
        train=True, batch_size=batch_size, num_workers=0
    )
    val_dataloader = validation.to_dataloader(
        train=False, batch_size=batch_size, num_workers=0
    )
    
    print(f"  âœ“ í•™ìŠµ ìƒ˜í”Œ: {len(training)}")
    print(f"  âœ“ ê²€ì¦ ìƒ˜í”Œ: {len(validation)}")
    print(f"  âœ“ Batch size: {batch_size}")
    
    return training, validation, train_dataloader, val_dataloader


def build_tft_model(training):
    """TFT ëª¨ë¸ ìƒì„±"""
    print("\n" + "="*60)
    print("[4/6] TFT ëª¨ë¸ ìƒì„±")
    print("="*60)
    
    # ê²½ëŸ‰ TFT ì„¤ì • (ê³¼ì í•© ë°©ì§€)
    tft = TemporalFusionTransformer.from_dataset(
        training,
        learning_rate=0.01,
        hidden_size=16,  # ì‘ê²Œ ì‹œì‘
        attention_head_size=2,
        dropout=0.2,
        hidden_continuous_size=8,
        output_size=7,  # Quantile outputs
        loss=QuantileLoss(),
        log_interval=10,
        reduce_on_plateau_patience=4,
    )
    
    print("  âœ“ TFT ëª¨ë¸ êµ¬ì„±:")
    print(f"    - Hidden size: 16")
    print(f"    - Attention heads: 2")
    print(f"    - Dropout: 0.2")
    print(f"    - Output: 7 quantiles")
    
    return tft


# =============================================================================
# 3. ëª¨ë¸ í•™ìŠµ
# =============================================================================

def train_tft_model(tft, train_dataloader, val_dataloader):
    """TFT ëª¨ë¸ í•™ìŠµ"""
    print("\n" + "="*60)
    print("[5/6] TFT ëª¨ë¸ í•™ìŠµ")
    print("="*60)
    
    # Early stopping
    early_stop_callback = EarlyStopping(
        monitor="val_loss",
        min_delta=1e-4,
        patience=10,
        verbose=False,
        mode="min"
    )
    
    # Checkpoint
    checkpoint_callback = ModelCheckpoint(
        dirpath='data/models',
        filename='tft_volatility',
        monitor='val_loss',
        mode='min',
        save_top_k=1,
    )
    
    # Trainer (CPU ëª…ì‹œ)
    trainer = Trainer(
        max_epochs=50,
        accelerator="cpu",
        devices=1,
        gradient_clip_val=0.1,
        callbacks=[early_stop_callback, checkpoint_callback],
        enable_progress_bar=True,
        enable_model_summary=True,
        logger=False,  # ë¡œê±° ë¹„í™œì„±í™”
    )
    
    print("  â†’ í•™ìŠµ ì‹œì‘ (ìµœëŒ€ 50 epochs, Early stopping ì ìš©)")
    print("  â†’ ì˜ˆìƒ ì‹œê°„: 10-30ë¶„ (CPU)")
    print()
    
    try:
        # fit ë©”ì„œë“œ í˜¸ì¶œ (ëª¨ë¸ì€ LightningModule)
        trainer.fit(
            model=tft,
            train_dataloaders=train_dataloader,
            val_dataloaders=val_dataloader,
        )
    except Exception as e:
        print(f"\n  âš ï¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ê°„ë‹¨í•œ í•™ìŠµ ì‹œë„: {e}")
        # ê°„ë‹¨í•œ ëŒ€ì•ˆ
        trainer = Trainer(
            max_epochs=20,
            accelerator="cpu",
            devices=1,
            enable_progress_bar=True,
        )
        trainer.fit(tft, train_dataloader, val_dataloader)
    
    print(f"\n  âœ“ í•™ìŠµ ì™„ë£Œ")
    print(f"  âœ“ Best model saved to: data/models/tft_volatility.ckpt")
    
    return trainer, tft


# =============================================================================
# 4. í‰ê°€ ë° í•´ì„
# =============================================================================

def evaluate_tft_model(tft, val_dataloader, validation_data):
    """TFT ëª¨ë¸ í‰ê°€"""
    print("\n" + "="*60)
    print("[6/6] ëª¨ë¸ í‰ê°€ ë° í•´ì„")
    print("="*60)
    
    # ì˜ˆì¸¡
    predictions = tft.predict(val_dataloader, return_x=True)
    
    # ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ ì¶”ì¶œ
    actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])
    pred_values = predictions.output
    
    # ì¤‘ê°„ê°’ (median, quantile 0.5) ì‚¬ìš©
    pred_median = pred_values[:, :, 3]  # 7ê°œ quantile ì¤‘ ì¤‘ê°„
    
    # ì²« ìŠ¤í…ë§Œ (1ì¼ ì˜ˆì¸¡)
    y_true = actuals[:, 0].cpu().numpy()
    y_pred = pred_median[:, 0].cpu().numpy()
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
    
    r2 = r2_score(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    
    print("\n  ğŸ“Š TFT ì„±ëŠ¥:")
    print(f"    â€¢ RÂ²:    {r2:.4f}")
    print(f"    â€¢ RMSE:  {rmse:.6f}")
    print(f"    â€¢ MAE:   {mae:.6f}")
    
    # ê²°ê³¼ ì €ì¥
    results = {
        'model': 'Temporal Fusion Transformer',
        'test_r2': float(r2),
        'test_rmse': float(rmse),
        'test_mae': float(mae),
        'config': {
            'hidden_size': 16,
            'attention_heads': 2,
            'dropout': 0.2,
            'max_encoder_length': 30,
            'max_prediction_length': 5,
        },
        'timestamp': datetime.now().isoformat()
    }
    
    with open('data/raw/tft_model_performance.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print("\n  âœ“ ê²°ê³¼ ì €ì¥: data/raw/tft_model_performance.json")
    
    # Attention weights ë¶„ì„
    try:
        interpretation = tft.interpret_output(predictions.output, reduction="sum")
        
        print("\n  ğŸ” Attention ë¶„ì„:")
        print("    â†’ Variable importance (ë³€ìˆ˜ ì¤‘ìš”ë„)")
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ì¶œë ¥
        if hasattr(interpretation, 'attention'):
            print("    (Attention weights ê³„ì‚° ì™„ë£Œ)")
    except Exception as e:
        print(f"    âš ï¸ Attention ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    return results


# =============================================================================
# 5. ë©”ì¸ íŒŒì´í”„ë¼ì¸
# =============================================================================

def main():
    """TFT ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print("\n" + "ğŸš€"*30)
    print("Temporal Fusion Transformer ë³€ë™ì„± ì˜ˆì¸¡")
    print("ğŸš€"*30)
    
    if not HAS_TFT:
        print("\nâŒ PyTorch Forecastingì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("\nì„¤ì¹˜ ëª…ë ¹:")
        print("  pip install pytorch-forecasting pytorch-lightning")
        return None
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ
        spy = load_and_prepare_data()
        
        # 2. TFT í˜•ì‹ ë³€í™˜
        df = convert_to_timeseries_format(spy)
        
        # 3. ë°ì´í„°ì…‹ ìƒì„±
        training, validation, train_dl, val_dl = create_tft_datasets(df)
        
        # 4. ëª¨ë¸ ìƒì„±
        tft = build_tft_model(training)
        
        # 5. í•™ìŠµ
        trainer, tft = train_tft_model(tft, train_dl, val_dl)
        
        # 6. í‰ê°€
        results = evaluate_tft_model(tft, val_dl, validation)
        
        print("\n" + "="*60)
        print("âœ… TFT íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("="*60)
        print(f"\n  ğŸ† ìµœì¢… RÂ²: {results['test_r2']:.4f}")
        
        return results
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == '__main__':
    results = main()
