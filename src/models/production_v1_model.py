#!/usr/bin/env python3
"""
Production V1 Model for SPY Volatility Prediction
ìµœê³  ì„±ëŠ¥ Ridge Regression ëª¨ë¸ (RÂ² = 0.314)
"""

import os
import sys
import json
import pickle
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Tuple, List, Optional, Union

import warnings
warnings.filterwarnings('ignore')

from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append('/root/workspace')
from src.core.unified_config import UnifiedConfigManager
from src.core.logger import setup_logger

class ProductionV1Model:
    """
    í”„ë¡œë•ì…˜ìš© V1 ë³€ë™ì„± ì˜ˆì¸¡ ëª¨ë¸

    íŠ¹ì§•:
    - Ridge Regression (alpha=1.8523)
    - 12ê°œ í•µì‹¬ íŠ¹ì„±
    - 5ì¼ í›„ ë³€ë™ì„± ì˜ˆì¸¡
    - RÂ² = 0.314 (ê²€ì¦ ì™„ë£Œ)
    """

    def __init__(self, config_path: Optional[str] = None):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        self.logger = setup_logger(self.__class__.__name__)
        self.config = UnifiedConfigManager()

        # ëª¨ë¸ ì‚¬ì–‘
        self.model_specs = {
            'name': 'V1_Volatility_Predictor',
            'type': 'Ridge Regression',
            'alpha': 1.8523,
            'validation_r2': 0.314,
            'validation_r2_std': 0.181,
            'features_count': 12,
            'target': 'target_vol_5d',
            'prediction_horizon': '5 days',
            'complexity': 'Low',
            'maintainability': 'High',
            'interpretability': 'Excellent'
        }

        # í•µì‹¬ íŠ¹ì„± ì •ì˜
        self.feature_names = [
            'vol_5', 'vol_10', 'vol_20',
            'return_lag_1', 'return_lag_2', 'return_lag_3',
            'zscore_10', 'zscore_20',
            'momentum_10', 'momentum_20',
            'vol_5_20_ratio', 'vol_regime'
        ]

        # ëª¨ë¸ ì»´í¬ë„ŒíŠ¸
        self.model = Ridge(alpha=self.model_specs['alpha'], random_state=42)
        self.scaler = StandardScaler()

        # ìƒíƒœ ë³€ìˆ˜
        self.is_trained = False
        self.last_prediction_time = None
        self.training_stats = {}

        self.logger.info(f"âœ… {self.model_specs['name']} ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"ğŸ“Š ëª¨ë¸ ì‚¬ì–‘: RÂ² = {self.model_specs['validation_r2']}")

    def prepare_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        V1 ëª¨ë¸ìš© íŠ¹ì„± ìƒì„±

        Args:
            data: OHLCV ë°ì´í„°

        Returns:
            íŠ¹ì„± DataFrame
        """
        try:
            features = pd.DataFrame(index=data.index)

            # 1. ë³€ë™ì„± íŠ¹ì„± (vol_5, vol_10, vol_20)
            for window in [5, 10, 20]:
                features[f'vol_{window}'] = (
                    data['close'].rolling(window).std() * np.sqrt(252)
                )

            # 2. ìˆ˜ìµë¥  ì§€ì—° íŠ¹ì„± (return_lag_1, return_lag_2, return_lag_3)
            returns = data['close'].pct_change()
            for lag in [1, 2, 3]:
                features[f'return_lag_{lag}'] = returns.shift(lag)

            # 3. Z-ìŠ¤ì½”ì–´ íŠ¹ì„± (zscore_10, zscore_20)
            for window in [10, 20]:
                mean_ret = returns.rolling(window).mean()
                std_ret = returns.rolling(window).std()
                features[f'zscore_{window}'] = (returns - mean_ret) / std_ret

            # 4. ëª¨ë©˜í…€ íŠ¹ì„± (momentum_10, momentum_20)
            for window in [10, 20]:
                features[f'momentum_{window}'] = (
                    data['close'] / data['close'].shift(window) - 1
                )

            # 5. ë³€ë™ì„± ë¹„ìœ¨ íŠ¹ì„± (vol_5_20_ratio)
            features['vol_5_20_ratio'] = features['vol_5'] / features['vol_20']

            # 6. ë³€ë™ì„± ì²´ì œ íŠ¹ì„± (vol_regime)
            vol_median = features['vol_20'].rolling(252).median()
            features['vol_regime'] = (features['vol_20'] > vol_median).astype(int)

            # ê²°ì¸¡ì¹˜ ì œê±°
            features = features.dropna()

            # íŠ¹ì„± ìˆœì„œ ì •ë ¬
            features = features[self.feature_names]

            self.logger.info(f"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: {features.shape[0]}ê°œ ìƒ˜í”Œ, {features.shape[1]}ê°œ íŠ¹ì„±")

            return features

        except Exception as e:
            self.logger.error(f"âŒ íŠ¹ì„± ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def create_target(self, data: pd.DataFrame) -> pd.Series:
        """
        5ì¼ í›„ ë³€ë™ì„± íƒ€ê²Ÿ ìƒì„±

        Args:
            data: OHLCV ë°ì´í„°

        Returns:
            íƒ€ê²Ÿ ì‹œë¦¬ì¦ˆ
        """
        try:
            returns = data['close'].pct_change()

            # 5ì¼ í›„ ë³€ë™ì„± ê³„ì‚°
            target = returns.rolling(5).std().shift(-5) * np.sqrt(252)
            target.name = 'target_vol_5d'

            self.logger.info(f"âœ… íƒ€ê²Ÿ ìƒì„± ì™„ë£Œ: {target.count()}ê°œ ìœ íš¨ê°’")

            return target

        except Exception as e:
            self.logger.error(f"âŒ íƒ€ê²Ÿ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def train(self, data: pd.DataFrame) -> Dict:
        """
        ëª¨ë¸ í›ˆë ¨

        Args:
            data: í›ˆë ¨ìš© OHLCV ë°ì´í„°

        Returns:
            í›ˆë ¨ í†µê³„
        """
        try:
            self.logger.info("ğŸ”„ V1 ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")

            # íŠ¹ì„± ë° íƒ€ê²Ÿ ìƒì„±
            features = self.prepare_features(data)
            target = self.create_target(data)

            # ë°ì´í„° ì •ë ¬ ë° ê²°ì¸¡ì¹˜ ì œê±°
            aligned_data = pd.concat([features, target], axis=1).dropna()
            X = aligned_data[self.feature_names]
            y = aligned_data['target_vol_5d']

            self.logger.info(f"ğŸ“Š í›ˆë ¨ ë°ì´í„°: {X.shape[0]}ê°œ ìƒ˜í”Œ")

            # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
            X_scaled = self.scaler.fit_transform(X)

            # ëª¨ë¸ í›ˆë ¨
            self.model.fit(X_scaled, y)

            # í›ˆë ¨ ì„±ëŠ¥ ê³„ì‚°
            y_pred_train = self.model.predict(X_scaled)

            self.training_stats = {
                'samples': len(X),
                'features': len(self.feature_names),
                'train_r2': r2_score(y, y_pred_train),
                'train_mse': mean_squared_error(y, y_pred_train),
                'train_rmse': np.sqrt(mean_squared_error(y, y_pred_train)),
                'train_mae': mean_absolute_error(y, y_pred_train),
                'training_date': datetime.now().isoformat(),
                'model_alpha': self.model_specs['alpha']
            }

            self.is_trained = True

            self.logger.info(f"âœ… V1 ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
            self.logger.info(f"ğŸ“Š í›ˆë ¨ RÂ² = {self.training_stats['train_r2']:.4f}")

            return self.training_stats

        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            raise

    def predict_volatility(self, features: Union[pd.DataFrame, np.ndarray]) -> np.ndarray:
        """
        ë³€ë™ì„± ì˜ˆì¸¡

        Args:
            features: ì˜ˆì¸¡ìš© íŠ¹ì„±

        Returns:
            ì˜ˆì¸¡ëœ 5ì¼ í›„ ë³€ë™ì„±
        """
        if not self.is_trained:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train() ë©”ì„œë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

        try:
            if isinstance(features, pd.DataFrame):
                X = features[self.feature_names].values
            else:
                X = features

            # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
            X_scaled = self.scaler.transform(X)

            # ì˜ˆì¸¡
            predictions = self.model.predict(X_scaled)

            self.last_prediction_time = datetime.now()

            self.logger.info(f"âœ… ë³€ë™ì„± ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ ì˜ˆì¸¡ê°’")

            return predictions

        except Exception as e:
            self.logger.error(f"âŒ ë³€ë™ì„± ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            raise

    def get_feature_importance(self) -> Dict:
        """íŠ¹ì„± ì¤‘ìš”ë„ ë°˜í™˜"""
        if not self.is_trained:
            return {}

        coefficients = self.model.coef_

        importance = {
            feature: abs(coef) for feature, coef
            in zip(self.feature_names, coefficients)
        }

        # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        importance = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True))

        return importance

    def get_performance_metrics(self) -> Dict:
        """ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ë°˜í™˜"""
        metrics = {
            **self.model_specs,
            **self.training_stats,
            'is_trained': self.is_trained,
            'last_prediction_time': self.last_prediction_time.isoformat() if self.last_prediction_time else None,
            'feature_importance': self.get_feature_importance()
        }

        return metrics

    def save_model(self, filepath: str = None) -> str:
        """ëª¨ë¸ ì €ì¥"""
        if not self.is_trained:
            raise ValueError("í›ˆë ¨ëœ ëª¨ë¸ë§Œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        if filepath is None:
            filepath = f"/root/workspace/data/models/v1_production_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"

        try:
            model_data = {
                'model': self.model,
                'scaler': self.scaler,
                'feature_names': self.feature_names,
                'model_specs': self.model_specs,
                'training_stats': self.training_stats,
                'save_time': datetime.now().isoformat()
            }

            os.makedirs(os.path.dirname(filepath), exist_ok=True)

            with open(filepath, 'wb') as f:
                pickle.dump(model_data, f)

            self.logger.info(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filepath}")

            return filepath

        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise

    def load_model(self, filepath: str):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            with open(filepath, 'rb') as f:
                model_data = pickle.load(f)

            self.model = model_data['model']
            self.scaler = model_data['scaler']
            self.feature_names = model_data['feature_names']
            self.model_specs = model_data['model_specs']
            self.training_stats = model_data['training_stats']

            self.is_trained = True

            self.logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {filepath}")

        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise


def demo_v1_model():
    """V1 ëª¨ë¸ ë°ëª¨"""
    import yfinance as yf

    print("ğŸš€ V1 í”„ë¡œë•ì…˜ ëª¨ë¸ ë°ëª¨ ì‹œì‘...")

    # ëª¨ë¸ ì´ˆê¸°í™”
    model = ProductionV1Model()

    # SPY ë°ì´í„° ë¡œë“œ
    print("ğŸ“Š SPY ë°ì´í„° ë¡œë“œ ì¤‘...")
    spy_data = yf.download('SPY', start='2020-01-01', end='2024-01-01')
    spy_data.columns = [col.lower() for col in spy_data.columns]

    # ëª¨ë¸ í›ˆë ¨
    print("ğŸ”„ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
    training_stats = model.train(spy_data)

    # ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥
    print("\nğŸ“Š V1 ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ:")
    print(f"  - í›ˆë ¨ RÂ²: {training_stats['train_r2']:.4f}")
    print(f"  - í›ˆë ¨ RMSE: {training_stats['train_rmse']:.4f}")
    print(f"  - í›ˆë ¨ MAE: {training_stats['train_mae']:.4f}")
    print(f"  - ìƒ˜í”Œ ìˆ˜: {training_stats['samples']:,}")
    print(f"  - íŠ¹ì„± ìˆ˜: {training_stats['features']}")

    # íŠ¹ì„± ì¤‘ìš”ë„
    print("\nğŸ¯ íŠ¹ì„± ì¤‘ìš”ë„ (Top 5):")
    importance = model.get_feature_importance()
    for i, (feature, score) in enumerate(list(importance.items())[:5]):
        print(f"  {i+1}. {feature}: {score:.4f}")

    # ëª¨ë¸ ì €ì¥
    model_path = model.save_model()
    print(f"\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

    # ìµœê·¼ ë°ì´í„°ë¡œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    print("\nğŸ”® ìµœê·¼ ë°ì´í„° ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸...")
    recent_data = yf.download('SPY', start='2024-01-01', period='1y')
    recent_data.columns = [col.lower() for col in recent_data.columns]

    features = model.prepare_features(recent_data)
    if len(features) > 0:
        predictions = model.predict_volatility(features.tail(5))
        print(f"  ìµœê·¼ 5ì¼ ë³€ë™ì„± ì˜ˆì¸¡: {predictions}")

    print("\nğŸ‰ V1 í”„ë¡œë•ì…˜ ëª¨ë¸ ë°ëª¨ ì™„ë£Œ!")

    return model


if __name__ == '__main__':
    model = demo_v1_model()