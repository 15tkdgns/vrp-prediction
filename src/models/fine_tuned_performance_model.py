#!/usr/bin/env python3
"""
Fine-Tuned Performance Model - ì •ë°€ ì¡°ì •ëœ ì„±ëŠ¥ ê°œì„ 
ì´ì „ ì‹¤íŒ¨ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ì •ë°€í•˜ê³  ë³´ìˆ˜ì ì¸ ì ‘ê·¼
"""

import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import warnings
import os
import json
from datetime import datetime
import matplotlib.pyplot as plt

warnings.filterwarnings('ignore')

class FineTunedPredictor:
    """ì •ë°€ ì¡°ì •ëœ ì„±ëŠ¥ ê°œì„  ëª¨ë¸"""

    def __init__(self):
        self.results = {}

    def load_optimal_data_period(self):
        """ìµœì  ë°ì´í„° ê¸°ê°„ ì‹¤í—˜"""
        print("ğŸ“Š ìµœì  ë°ì´í„° ê¸°ê°„ íƒìƒ‰ ì¤‘...")

        # ì—¬ëŸ¬ ì‹œì‘ ê¸°ê°„ í…ŒìŠ¤íŠ¸
        periods = {
            '2008_start': '2008-01-01',  # ê¸ˆìœµìœ„ê¸°ë¶€í„° (ë” ì•ˆì •ì ì¼ ìˆ˜ ìˆìŒ)
            '2010_start': '2010-01-01',  # ìœ„ê¸° ì´í›„ë¶€í„°
            '2015_start': '2015-01-01'   # ìµœê·¼ ê¸°ê°„ë§Œ
        }

        best_period = None
        best_samples = 0

        for period_name, start_date in periods.items():
            try:
                spy = yf.download('SPY', start=start_date, end='2024-12-31', progress=False)
                spy['returns'] = spy['Close'].pct_change()

                vix = yf.download('^VIX', start=start_date, end='2024-12-31', progress=False)
                spy['vix'] = vix['Close'].reindex(spy.index, method='ffill')

                spy = spy.dropna()

                print(f"  {period_name}: {len(spy)} ìƒ˜í”Œ ({spy.index[0].strftime('%Y-%m')} ~ {spy.index[-1].strftime('%Y-%m')})")

                # ì¶©ë¶„í•œ ìƒ˜í”Œ ìˆ˜ í™•ì¸
                if len(spy) > 2000:  # ìµœì†Œ 8ë…„ ë°ì´í„°
                    if len(spy) > best_samples:
                        best_samples = len(spy)
                        best_period = (period_name, start_date, spy)

            except Exception as e:
                print(f"  {period_name}: ë¡œë“œ ì‹¤íŒ¨ - {e}")

        if best_period:
            period_name, start_date, data = best_period
            print(f"âœ… ìµœì  ê¸°ê°„ ì„ íƒ: {period_name} ({len(data)} ìƒ˜í”Œ)")
            return data
        else:
            print("âŒ ì ì ˆí•œ ë°ì´í„° ê¸°ê°„ ì—†ìŒ")
            return None

    def create_minimal_robust_features(self, data):
        """ìµœì†Œí•œì˜ ê°•ê±´í•œ íŠ¹ì„±ë§Œ ìƒì„±"""
        print("ğŸ”§ ìµœì†Œ íŠ¹ì„± ìƒì„± ì¤‘...")

        features = pd.DataFrame(index=data.index)
        returns = data['returns']
        prices = data['Close']
        high = data['High']
        low = data['Low']
        vix = data['vix']

        # 1. í•µì‹¬ ë³€ë™ì„±ë§Œ (ì´ì „ì— ê°€ì¥ íš¨ê³¼ì ì´ì—ˆë˜ ê²ƒë“¤)
        features['volatility_5'] = returns.rolling(5).std()
        features['volatility_10'] = returns.rolling(10).std()
        features['volatility_20'] = returns.rolling(20).std()

        # 2. VIX í•µì‹¬ íŠ¹ì„±ë§Œ
        features['vix_level'] = vix / 100
        features['vix_ma_5'] = vix.rolling(5).mean() / 100
        features['vix_ma_10'] = vix.rolling(10).mean() / 100

        # 3. ì¼ì¤‘ ë³€ë™ì„± (ê°€ì¥ ê°•ë ¥í–ˆë˜ íŠ¹ì„±)
        intraday_range = (high - low) / prices
        features['intraday_vol_5'] = intraday_range.rolling(5).mean()
        features['intraday_vol_10'] = intraday_range.rolling(10).mean()

        # 4. ìµœì†Œí•œì˜ ë˜ê·¸
        features['vol_lag_1'] = features['volatility_5'].shift(1)

        # 5. ê°€ì¥ ê°•ë ¥í–ˆë˜ ìƒí˜¸ì‘ìš© í•˜ë‚˜ë§Œ
        features['vix_vol_ratio'] = features['vix_level'] / (features['volatility_10'] + 1e-8)

        print(f"âœ… ìµœì†Œ íŠ¹ì„± ìƒì„± ì™„ë£Œ: {len(features.columns)}ê°œ")
        return features

    def fine_tune_regularization(self, X, y):
        """ì •ë°€í•œ ì •ê·œí™” ê°•ë„ ì¡°ì •"""
        print("ğŸ¯ ì •ë°€ ì •ê·œí™” ì¡°ì • ì¤‘...")

        # ì´ì „ ì„±ê³µ ì‚¬ë¡€ ì£¼ë³€ì—ì„œ ì •ë°€ íƒìƒ‰
        ridge_alphas = [1.0, 2.0, 5.0, 8.0, 10.0, 15.0, 20.0, 30.0, 40.0, 50.0]

        combined_data = pd.concat([X, y], axis=1).dropna()
        X_clean = combined_data[X.columns]
        y_clean = combined_data[y.name]

        print(f"ì¡°ì • ë°ì´í„°: {len(X_clean)} ìƒ˜í”Œ")

        # ë” ì‹ ì¤‘í•œ Walk-Forward (3ê°œ í´ë“œë§Œìœ¼ë¡œ ë¹ ë¥´ê²Œ)
        initial_window = 800   # ì•½ 3ë…„
        step_size = 150        # 6ê°œì›”
        test_window = 60       # 3ê°œì›”

        best_alpha = 10.0
        best_score = -999
        alpha_scores = {}

        for alpha in ridge_alphas:
            fold_scores = []
            current_start = 0
            fold = 0

            while fold < 3 and current_start + initial_window + test_window < len(X_clean):
                train_end = current_start + initial_window
                test_start = train_end
                test_end = min(test_start + test_window, len(X_clean))

                X_train = X_clean.iloc[current_start:train_end]
                y_train = y_clean.iloc[current_start:train_end]
                X_test = X_clean.iloc[test_start:test_end]
                y_test = y_clean.iloc[test_start:test_end]

                try:
                    scaler = RobustScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)

                    model = Ridge(alpha=alpha)
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)

                    r2 = r2_score(y_test, y_pred)
                    fold_scores.append(r2)

                except:
                    fold_scores.append(-999)

                current_start += step_size
                fold += 1

            valid_scores = [s for s in fold_scores if s > -900]
            if valid_scores:
                mean_score = np.mean(valid_scores)
                alpha_scores[alpha] = {
                    'mean_r2': mean_score,
                    'std_r2': np.std(valid_scores),
                    'count': len(valid_scores)
                }

                if mean_score > best_score:
                    best_score = mean_score
                    best_alpha = alpha

                print(f"  Î±={alpha:6.1f}: RÂ²={mean_score:7.4f} Â± {np.std(valid_scores):.4f}")

        print(f"âœ… ìµœì  ì •ê·œí™”: Î±={best_alpha}, RÂ²={best_score:.4f}")
        return best_alpha, alpha_scores

    def create_ensemble_models(self, best_alpha):
        """ì•™ìƒë¸” ëª¨ë¸ ìƒì„±"""
        print("ğŸ¤– ì•™ìƒë¸” ëª¨ë¸ ìƒì„± ì¤‘...")

        models = {
            'Ridge_Optimal': Ridge(alpha=best_alpha),
            'Ridge_Conservative': Ridge(alpha=best_alpha * 1.5),  # ë” ë³´ìˆ˜ì 
            'Ridge_Aggressive': Ridge(alpha=best_alpha * 0.7),   # ëœ ë³´ìˆ˜ì 
        }

        # ê°„ë‹¨í•œ í‰ê·  ì•™ìƒë¸”ë„ ì¤€ë¹„
        models['Ensemble_Simple'] = 'ensemble'

        print(f"âœ… ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„: {len(models)}ê°œ")
        return models

    def comprehensive_walkforward_test(self, X, y, models, best_alpha):
        """ì¢…í•©ì ì¸ Walk-Forward í…ŒìŠ¤íŠ¸"""
        print("ğŸš€ ì¢…í•© Walk-Forward í…ŒìŠ¤íŠ¸...")

        combined_data = pd.concat([X, y], axis=1).dropna()
        X_clean = combined_data[X.columns]
        y_clean = combined_data[y.name]

        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_clean)} ìƒ˜í”Œ")

        # ë³´ìˆ˜ì  ì„¤ì •
        initial_window = 1000  # 4ë…„
        step_size = 100        # 4ê°œì›”
        test_window = 50       # 2ê°œì›”

        results = {}
        for model_name in models.keys():
            results[model_name] = []

        current_start = 0
        fold = 0

        while current_start + initial_window + test_window < len(X_clean):
            fold += 1

            train_end = current_start + initial_window
            test_start = train_end
            test_end = min(test_start + test_window, len(X_clean))

            X_train = X_clean.iloc[current_start:train_end]
            y_train = y_clean.iloc[current_start:train_end]
            X_test = X_clean.iloc[test_start:test_end]
            y_test = y_clean.iloc[test_start:test_end]

            print(f"  Fold {fold}: í›ˆë ¨ {len(X_train)}, í…ŒìŠ¤íŠ¸ {len(X_test)} ({X_test.index[0].strftime('%Y-%m')})")

            # ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ ì €ì¥ (ì•™ìƒë¸”ìš©)
            individual_predictions = {}

            for model_name, model in models.items():
                if model_name == 'Ensemble_Simple':
                    continue  # ë‚˜ì¤‘ì— ì²˜ë¦¬

                try:
                    scaler = RobustScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)

                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)

                    # ê°œë³„ ëª¨ë¸ ì„±ëŠ¥
                    r2 = r2_score(y_test, y_pred)
                    results[model_name].append({
                        'fold': fold,
                        'r2': r2,
                        'rmse': np.sqrt(mean_squared_error(y_test, y_pred))
                    })

                    # ì•™ìƒë¸”ìš© ì˜ˆì¸¡ ì €ì¥
                    individual_predictions[model_name] = y_pred

                    print(f"    {model_name:20}: RÂ²={r2:7.4f}")

                except Exception as e:
                    print(f"    {model_name:20}: ì˜¤ë¥˜ - {e}")
                    results[model_name].append({'fold': fold, 'r2': -999, 'rmse': 999})

            # ì•™ìƒë¸” ì˜ˆì¸¡ (í‰ê· )
            if len(individual_predictions) >= 2:
                try:
                    # ê°œë³„ ëª¨ë¸ë“¤ì˜ í‰ê· 
                    ensemble_pred = np.mean(list(individual_predictions.values()), axis=0)
                    ensemble_r2 = r2_score(y_test, ensemble_pred)

                    results['Ensemble_Simple'].append({
                        'fold': fold,
                        'r2': ensemble_r2,
                        'rmse': np.sqrt(mean_squared_error(y_test, ensemble_pred))
                    })

                    print(f"    {'Ensemble_Simple':20}: RÂ²={ensemble_r2:7.4f}")

                except:
                    results['Ensemble_Simple'].append({'fold': fold, 'r2': -999, 'rmse': 999})

            current_start += step_size

        # ê²°ê³¼ ìš”ì•½
        summary = {}
        print(f"\nğŸ“Š ì¢…í•© í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"{'Model':<20} {'Mean RÂ²':<10} {'Std RÂ²':<10} {'Max RÂ²':<10} {'Valid'}")
        print("-" * 70)

        for model_name, fold_results in results.items():
            valid_r2s = [r['r2'] for r in fold_results if r['r2'] != -999]

            if valid_r2s:
                mean_r2 = np.mean(valid_r2s)
                std_r2 = np.std(valid_r2s)
                max_r2 = np.max(valid_r2s)
                valid_count = len(valid_r2s)

                summary[model_name] = {
                    'mean_r2': mean_r2,
                    'std_r2': std_r2,
                    'max_r2': max_r2,
                    'valid_folds': valid_count,
                    'total_folds': len(fold_results)
                }

                print(f"{model_name:<20} {mean_r2:<10.4f} {std_r2:<10.4f} {max_r2:<10.4f} {valid_count}/{len(fold_results)}")
            else:
                summary[model_name] = {'mean_r2': -999}
                print(f"{model_name:<20} {'FAILED':<10}")

        return summary, results

def main():
    """ë©”ì¸ ì •ë°€ ì¡°ì • í•¨ìˆ˜"""
    print("ğŸ¯ Fine-Tuned Performance Model")
    print("=" * 70)
    print("ì •ë°€í•œ ì¡°ì •ì„ í†µí•œ ì•ˆì „í•œ ì„±ëŠ¥ ê°œì„ ")
    print("=" * 70)

    predictor = FineTunedPredictor()

    # 1. ìµœì  ë°ì´í„° ê¸°ê°„ ì„ íƒ
    data = predictor.load_optimal_data_period()
    if data is None:
        return

    # 2. ìµœì†Œí•œì˜ ê°•ê±´í•œ íŠ¹ì„±
    features = predictor.create_minimal_robust_features(data)

    # 3. íƒ€ê²Ÿ ìƒì„±
    targets = pd.DataFrame(index=data.index)
    returns = data['returns']
    vol_values = []
    for i in range(len(returns)):
        if i + 5 < len(returns):
            future_returns = returns.iloc[i+1:i+6]
            vol_values.append(future_returns.std())
        else:
            vol_values.append(np.nan)
    targets['target_vol_5d'] = vol_values

    # 4. ì •ë°€í•œ ì •ê·œí™” ì¡°ì •
    best_alpha, alpha_scores = predictor.fine_tune_regularization(features, targets['target_vol_5d'])

    # 5. ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
    models = predictor.create_ensemble_models(best_alpha)

    # 6. ì¢…í•© í…ŒìŠ¤íŠ¸
    summary, detailed_results = predictor.comprehensive_walkforward_test(
        features, targets['target_vol_5d'], models, best_alpha
    )

    # 7. ìµœê³  ëª¨ë¸ ì„ íƒ
    best_model = None
    best_score = -999

    for model_name, stats in summary.items():
        if stats.get('mean_r2', -999) > best_score:
            best_score = stats['mean_r2']
            best_model = model_name

    # 8. ê²°ê³¼ ì €ì¥
    os.makedirs('results', exist_ok=True)

    fine_tuned_results = {
        'version': 'Fine_Tuned_Performance',
        'timestamp': datetime.now().isoformat(),
        'approach': 'Minimal features + fine-tuned regularization + ensemble',
        'data_samples': len(pd.concat([features, targets], axis=1).dropna()),
        'features_count': len(features.columns),
        'best_model': {
            'name': best_model,
            'mean_r2': best_score,
            'std_r2': summary.get(best_model, {}).get('std_r2', 0) if best_model else 0
        },
        'optimization_results': {
            'best_alpha': best_alpha,
            'alpha_scores': alpha_scores
        },
        'all_results': summary,
        'feature_names': features.columns.tolist()
    }

    with open('results/fine_tuned_performance_model.json', 'w') as f:
        json.dump(fine_tuned_results, f, indent=2, default=str)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: results/fine_tuned_performance_model.json")

    # 9. ìµœì¢… í‰ê°€
    if best_model and best_score > 0:
        print(f"\nğŸ‰ ì •ë°€ ì¡°ì • ì„±ê³µ!")
        print(f"   ìµœê³  ëª¨ë¸: {best_model}")
        print(f"   Walk-Forward RÂ²: {best_score:.4f}")

        # ì´ì „ ê²°ê³¼ë“¤ê³¼ ë¹„êµ
        robust_r2 = 0.0145
        improvement = (best_score - robust_r2) / robust_r2 * 100 if robust_r2 > 0 else 0

        print(f"   ì´ì „ Robust ëª¨ë¸: {robust_r2:.4f}")
        print(f"   ê°œì„ ë„: {improvement:+.1f}%")

        if improvement > 50:
            print(f"   âœ… ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ ê°œì„ !")
        elif improvement > 0:
            print(f"   âœ… ì†Œí­ ì„±ëŠ¥ ê°œì„ ")
        else:
            print(f"   âš ï¸ ì„±ëŠ¥ ìœ ì§€ ë˜ëŠ” í•˜ë½")

    else:
        print(f"\nâš ï¸ ì •ë°€ ì¡°ì •ì—ë„ ì„±ëŠ¥ ê°œì„  ì‹¤íŒ¨")
        print(f"   ìµœê³  ì„±ëŠ¥: {best_score:.4f}")
        print(f"   ê·¼ë³¸ì ì¸ ì ‘ê·¼ë²• ì¬ê²€í†  í•„ìš”")

    print("=" * 70)

if __name__ == "__main__":
    main()