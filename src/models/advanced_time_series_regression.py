#!/usr/bin/env python3
"""
ðŸš€ ê³ ë„í™”ëœ ì‹œê³„ì—´ íšŒê·€ ëª¨ë¸ ì—°êµ¬

RÂ² ë° MAE ì¤‘ì‹¬ ì„±ëŠ¥ ìµœì í™” with ì™„ì „ ë°ì´í„° ëˆ„ì¶œ ë°©ì§€
ìˆ˜ìµë¥  ì§ì ‘ ì˜ˆì¸¡ì— ì´ˆì 
"""

import sys
sys.path.append('/root/workspace/src')

import pandas as pd
import numpy as np
from datetime import datetime
import json
import warnings
warnings.filterwarnings('ignore')

# Core imports
from core.data_processor import DataProcessor

# Advanced ML imports
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.linear_model import Ridge, ElasticNet, BayesianRidge, LassoCV, RidgeCV
from sklearn.preprocessing import RobustScaler, StandardScaler, PowerTransformer
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.pipeline import Pipeline
from sklearn.compose import TransformedTargetRegressor

# Advanced regressor imports
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

# Time series specific imports
try:
    from sklearn.gaussian_process import GaussianProcessRegressor
    from sklearn.gaussian_process.kernels import RBF, WhiteKernel, RationalQuadratic
    GP_AVAILABLE = True
except ImportError:
    GP_AVAILABLE = False

class AdvancedTimeSeriesRegression:
    """ê³ ë„í™”ëœ ì‹œê³„ì—´ íšŒê·€ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.data_processor = DataProcessor()
        self.max_allowed_correlation = 0.2  # ë§¤ìš° ì—„ê²©í•œ ê¸°ì¤€
        self.target_r2_threshold = 0.1      # RÂ² ëª©í‘œ ìž„ê³„ê°’
        self.target_mae_threshold = 0.01    # MAE ëª©í‘œ ìž„ê³„ê°’

        print(f"ðŸš€ ê³ ë„í™”ëœ ì‹œê³„ì—´ íšŒê·€ ì—°êµ¬ ì‹œìŠ¤í…œ")
        print(f"   ðŸŽ¯ ëª©í‘œ: RÂ²>{self.target_r2_threshold}, MAE<{self.target_mae_threshold}")
        print(f"   ðŸ”’ ìµœëŒ€ í—ˆìš© ìƒê´€ê´€ê³„: {self.max_allowed_correlation}")

    def create_advanced_time_series_features(self, df):
        """ê³ ë„í™”ëœ ì‹œê³„ì—´ íŠ¹ì„± ê³µí•™"""
        print("ðŸ”§ ê³ ë„í™”ëœ ì‹œê³„ì—´ íŠ¹ì„± ê³µí•™...")

        advanced_df = df.copy()

        # 1. ê¸°ë³¸ ìˆ˜ìµë¥  ë° ë¡œê·¸ ìˆ˜ìµë¥ 
        advanced_df['returns'] = advanced_df['Close'].pct_change()
        advanced_df['log_returns'] = np.log(advanced_df['Close'] / advanced_df['Close'].shift(1))

        # 2. ë‹¤ì¤‘ ì‹œì  ëª¨ë©˜í…€ (ê³¼ê±°ë§Œ)
        momentum_periods = [3, 5, 7, 10, 14, 20, 30, 50, 100]
        for period in momentum_periods:
            advanced_df[f'momentum_{period}d'] = (
                advanced_df['Close'] / advanced_df['Close'].shift(period) - 1
            )
            advanced_df[f'log_momentum_{period}d'] = (
                np.log(advanced_df['Close'] / advanced_df['Close'].shift(period))
            )

        # 3. ë‹¤ì¤‘ ë³€ë™ì„± ì¸¡ì • (ê³¼ê±°ë§Œ)
        volatility_windows = [5, 10, 15, 20, 30, 50, 100]
        for window in volatility_windows:
            # ë‹¨ìˆœ ë³€ë™ì„±
            advanced_df[f'volatility_{window}d'] = (
                advanced_df['returns'].rolling(window).std()
            )
            # ë¡œê·¸ ìˆ˜ìµë¥  ë³€ë™ì„±
            advanced_df[f'log_volatility_{window}d'] = (
                advanced_df['log_returns'].rolling(window).std()
            )
            # EWMA ë³€ë™ì„±
            advanced_df[f'ewm_volatility_{window}d'] = (
                advanced_df['returns'].ewm(span=window).std()
            )

        # 4. ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ
        ta_periods = [5, 10, 14, 20, 30, 50]
        for period in ta_periods:
            # ì´ë™í‰ê·  ë° ë¹„ìœ¨
            sma = advanced_df['Close'].rolling(period).mean()
            advanced_df[f'sma_{period}d'] = sma
            advanced_df[f'sma_ratio_{period}d'] = advanced_df['Close'] / sma

            # ì§€ìˆ˜ì´ë™í‰ê· 
            ema = advanced_df['Close'].ewm(span=period).mean()
            advanced_df[f'ema_{period}d'] = ema
            advanced_df[f'ema_ratio_{period}d'] = advanced_df['Close'] / ema

            # ë³¼ë¦°ì € ë°´ë“œ
            rolling_std = advanced_df['Close'].rolling(period).std()
            advanced_df[f'bb_upper_{period}d'] = sma + (rolling_std * 2)
            advanced_df[f'bb_lower_{period}d'] = sma - (rolling_std * 2)
            advanced_df[f'bb_position_{period}d'] = (
                (advanced_df['Close'] - advanced_df[f'bb_lower_{period}d']) /
                (advanced_df[f'bb_upper_{period}d'] - advanced_df[f'bb_lower_{period}d'])
            )

            # RSI
            delta = advanced_df['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
            rs = gain / loss
            advanced_df[f'rsi_{period}d'] = 100 - (100 / (1 + rs))

        # 5. ë³¼ë¥¨ ê¸°ë°˜ ê³ ê¸‰ íŠ¹ì„±
        volume_periods = [5, 10, 20, 30, 50]
        for period in volume_periods:
            # ë³¼ë¥¨ ì´ë™í‰ê· 
            vol_sma = advanced_df['Volume'].rolling(period).mean()
            advanced_df[f'vol_sma_{period}d'] = vol_sma
            advanced_df[f'vol_ratio_{period}d'] = advanced_df['Volume'] / vol_sma

            # ë³¼ë¥¨ ê°€ì¤‘ í‰ê·  ê°€ê²© (VWAP)
            vwap_num = (advanced_df['Close'] * advanced_df['Volume']).rolling(period).sum()
            vwap_den = advanced_df['Volume'].rolling(period).sum()
            advanced_df[f'vwap_{period}d'] = vwap_num / vwap_den
            advanced_df[f'vwap_ratio_{period}d'] = advanced_df['Close'] / advanced_df[f'vwap_{period}d']

            # ì˜¨ë°¸ëŸ°ìŠ¤ ë³¼ë¥¨ (OBV)
            obv = (advanced_df['Volume'] * np.sign(advanced_df['returns'])).cumsum()
            advanced_df[f'obv_sma_{period}d'] = obv.rolling(period).mean()

        # 6. ê°€ê²© ë ˆì¸ì§€ ë° ê°­ íŠ¹ì„±
        advanced_df['hl_range'] = (advanced_df['High'] - advanced_df['Low']) / advanced_df['Close']
        advanced_df['oc_range'] = (advanced_df['Close'] - advanced_df['Open']) / advanced_df['Open']
        advanced_df['ho_gap'] = (advanced_df['High'] - advanced_df['Open']) / advanced_df['Open']
        advanced_df['ol_gap'] = (advanced_df['Open'] - advanced_df['Low']) / advanced_df['Low']

        # 7. í†µê³„ì  íŠ¹ì„± (ê³¼ê±°ë§Œ)
        stat_windows = [10, 20, 50]
        for window in stat_windows:
            # ì™œë„ ë° ì²¨ë„ (scipy.stats ì‚¬ìš©)
            from scipy.stats import skew, kurtosis
            advanced_df[f'skew_{window}d'] = advanced_df['returns'].rolling(window).apply(lambda x: skew(x, nan_policy='omit'))
            advanced_df[f'kurtosis_{window}d'] = advanced_df['returns'].rolling(window).apply(lambda x: kurtosis(x, nan_policy='omit'))

            # ë¶„ìœ„ìˆ˜
            advanced_df[f'q25_{window}d'] = advanced_df['returns'].rolling(window).quantile(0.25)
            advanced_df[f'q75_{window}d'] = advanced_df['returns'].rolling(window).quantile(0.75)
            advanced_df[f'iqr_{window}d'] = (
                advanced_df[f'q75_{window}d'] - advanced_df[f'q25_{window}d']
            )

        # 8. ëž˜ê·¸ íŠ¹ì„± (ê³¼ê±°ë§Œ)
        lag_periods = [1, 2, 3, 5, 10, 20]
        for lag in lag_periods:
            advanced_df[f'returns_lag_{lag}'] = advanced_df['returns'].shift(lag)
            advanced_df[f'volume_lag_{lag}'] = advanced_df['Volume'].shift(lag)
            advanced_df[f'volatility_lag_{lag}'] = advanced_df[f'volatility_20d'].shift(lag)

        # 9. ë‹¤ì¤‘ íƒ€ê²Ÿ ë³€ìˆ˜ (ë¯¸ëž˜ ì •ë³´ - íƒ€ê²Ÿë§Œ)
        # ë‹¤ìŒë‚  ìˆ˜ìµë¥  (ì£¼ íƒ€ê²Ÿ)
        advanced_df['target_return_1d'] = advanced_df['returns'].shift(-1)

        # ë‹¤ì¤‘ ì‹œì  ìˆ˜ìµë¥  (ì¶”ê°€ íƒ€ê²Ÿë“¤)
        advanced_df['target_return_3d'] = advanced_df['Close'].pct_change(3).shift(-3)
        advanced_df['target_return_5d'] = advanced_df['Close'].pct_change(5).shift(-5)

        # ë°©í–¥ ì˜ˆì¸¡ (ë³´ì¡° íƒ€ê²Ÿ)
        advanced_df['target_direction'] = (advanced_df['target_return_1d'] > 0).astype(int)

        # NaN ì²˜ë¦¬
        advanced_df = advanced_df.fillna(method='ffill').fillna(method='bfill').fillna(0)
        advanced_df = advanced_df.replace([np.inf, -np.inf], 0)

        print(f"   âœ… ê³ ê¸‰ íŠ¹ì„± ìƒì„± ì™„ë£Œ: {advanced_df.shape}")
        return advanced_df

    def validate_ultra_strict_leakage(self, df, target_col='target_return_1d'):
        """ì´ˆì—„ê²© ë°ì´í„° ëˆ„ì¶œ ê²€ì¦"""
        print("ðŸ” ì´ˆì—„ê²© ë°ì´í„° ëˆ„ì¶œ ê²€ì¦...")

        # íŠ¹ì„± ì„ íƒ (íƒ€ê²Ÿ ë° ê¸°ë³¸ ì»¬ëŸ¼ ì œì™¸)
        exclude_cols = [
            target_col, 'target_return_3d', 'target_return_5d', 'target_direction',
            'Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'log_returns'
        ]

        feature_cols = [col for col in df.columns if col not in exclude_cols]
        print(f"   ê²€ì¦í•  íŠ¹ì„± ìˆ˜: {len(feature_cols)}")

        # ìƒê´€ê´€ê³„ ê²€ì‚¬
        safe_features = []
        suspicious_features = []

        for feature in feature_cols:
            if feature in df.columns and target_col in df.columns:
                corr = abs(df[feature].corr(df[target_col]))
                if not pd.isna(corr):
                    if corr > self.max_allowed_correlation:
                        suspicious_features.append((feature, corr))
                        print(f"   âš ï¸ ì˜ì‹¬ íŠ¹ì„±: {feature} (ìƒê´€ê´€ê³„: {corr:.4f})")
                    else:
                        safe_features.append(feature)

        if suspicious_features:
            print(f"   ðŸš¨ ì˜ì‹¬ íŠ¹ì„± {len(suspicious_features)}ê°œ ì œê±°!")
        else:
            print("   âœ… ëª¨ë“  íŠ¹ì„±ì´ ì´ˆì—„ê²© ê¸°ì¤€ í†µê³¼")

        return safe_features

    def create_advanced_regression_models(self):
        """ê³ ë„í™”ëœ íšŒê·€ ëª¨ë¸ë“¤ ìƒì„±"""
        print("ðŸŽ¯ ê³ ë„í™”ëœ íšŒê·€ ëª¨ë¸ë“¤ ìƒì„±...")

        models = {}

        # 1. ê³ ê¸‰ ì„ í˜• ëª¨ë¸ë“¤
        models['Ridge_Optimized'] = RidgeCV(
            alphas=np.logspace(-4, 4, 50),
            cv=TimeSeriesSplit(n_splits=3)
        )

        models['ElasticNet_Advanced'] = Pipeline([
            ('scaler', RobustScaler()),
            ('regressor', ElasticNet(
                alpha=0.01, l1_ratio=0.5, max_iter=2000, random_state=42
            ))
        ])

        models['BayesianRidge_Enhanced'] = Pipeline([
            ('scaler', StandardScaler()),
            ('regressor', BayesianRidge(
                alpha_1=1e-6, alpha_2=1e-6, lambda_1=1e-6, lambda_2=1e-6
            ))
        ])

        # 2. ì•™ìƒë¸” ëª¨ë¸ë“¤
        models['RandomForest_Tuned'] = RandomForestRegressor(
            n_estimators=200, max_depth=8, min_samples_split=5,
            min_samples_leaf=2, max_features='sqrt', random_state=42, n_jobs=-1
        )

        models['ExtraTrees_Optimized'] = ExtraTreesRegressor(
            n_estimators=150, max_depth=10, min_samples_split=3,
            min_samples_leaf=1, max_features='sqrt', random_state=42, n_jobs=-1
        )

        models['GradientBoosting_Advanced'] = GradientBoostingRegressor(
            n_estimators=200, learning_rate=0.05, max_depth=6,
            subsample=0.8, max_features='sqrt', random_state=42
        )

        # 3. XGBoost ëª¨ë¸ë“¤ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if XGBOOST_AVAILABLE:
            models['XGBoost_Regression'] = xgb.XGBRegressor(
                n_estimators=200, learning_rate=0.05, max_depth=6,
                subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1,
                reg_lambda=1.0, random_state=42, n_jobs=-1, verbosity=0
            )

            models['XGBoost_Dart'] = xgb.XGBRegressor(
                booster='dart', n_estimators=150, learning_rate=0.1,
                max_depth=5, subsample=0.9, colsample_bytree=0.9,
                random_state=42, n_jobs=-1, verbosity=0
            )

        # 4. LightGBM ëª¨ë¸ë“¤ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if LIGHTGBM_AVAILABLE:
            models['LightGBM_Regression'] = lgb.LGBMRegressor(
                n_estimators=200, learning_rate=0.05, max_depth=8,
                subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1,
                reg_lambda=1.0, random_state=42, n_jobs=-1, verbosity=-1
            )

        # 5. ê°€ìš°ì‹œì•ˆ í”„ë¡œì„¸ìŠ¤ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if GP_AVAILABLE:
            kernel = RBF(length_scale=1.0) + WhiteKernel(noise_level=0.1)
            models['GaussianProcess'] = GaussianProcessRegressor(
                kernel=kernel, alpha=1e-6, random_state=42
            )

        # 6. íƒ€ê²Ÿ ë³€í™˜ ëª¨ë¸ë“¤
        models['Ridge_LogTransformed'] = TransformedTargetRegressor(
            regressor=Ridge(alpha=1.0, random_state=42),
            transformer=PowerTransformer(method='yeo-johnson')
        )

        print(f"   âœ… ìƒì„±ëœ ëª¨ë¸: {len(models)}ê°œ")
        return models

    def evaluate_regression_performance(self, models, X, y, safe_features):
        """íšŒê·€ ì„±ëŠ¥ í‰ê°€ (RÂ² ë° MAE ì¤‘ì‹¬)"""
        print(f"\nðŸ“Š íšŒê·€ ì„±ëŠ¥ í‰ê°€ (íŠ¹ì„± ìˆ˜: {len(safe_features)})")

        # ë°ì´í„° ì¤€ë¹„
        X_features = X[safe_features].values
        y_values = y.values

        # ì•ˆì „ ì²˜ë¦¬
        X_features = np.nan_to_num(X_features, nan=0.0, posinf=0.0, neginf=0.0)
        y_values = np.nan_to_num(y_values, nan=0.0, posinf=0.0, neginf=0.0)

        # ìœ íš¨ ë°ì´í„°ë§Œ ì„ íƒ
        valid_idx = ~(pd.isna(y) | (y == 0))
        X_features = X_features[valid_idx]
        y_values = y_values[valid_idx]

        print(f"   ìµœì¢… ë°ì´í„°: X={X_features.shape}, y={y_values.shape}")
        print(f"   íƒ€ê²Ÿ í†µê³„: í‰ê· ={np.mean(y_values):.6f}, í‘œì¤€íŽ¸ì°¨={np.std(y_values):.6f}")

        # ì‹œê°„ ìˆœì„œ êµì°¨ ê²€ì¦
        tscv = TimeSeriesSplit(n_splits=5)
        results = {}

        for model_name, model in models.items():
            print(f"\n   ðŸ”¬ {model_name} í‰ê°€...")

            fold_r2s = []
            fold_maes = []
            fold_mses = []

            for fold, (train_idx, val_idx) in enumerate(tscv.split(X_features)):
                try:
                    X_train, X_val = X_features[train_idx], X_features[val_idx]
                    y_train, y_val = y_values[train_idx], y_values[val_idx]

                    # ëª¨ë¸ í›ˆë ¨
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_val)

                    # ì„±ëŠ¥ ê³„ì‚°
                    r2 = r2_score(y_val, y_pred)
                    mae = mean_absolute_error(y_val, y_pred)
                    mse = mean_squared_error(y_val, y_pred)

                    fold_r2s.append(r2)
                    fold_maes.append(mae)
                    fold_mses.append(mse)

                    print(f"      Fold {fold+1}: RÂ²={r2:.4f}, MAE={mae:.6f}, MSE={mse:.6f}")

                except Exception as e:
                    print(f"      Fold {fold+1} ì‹¤íŒ¨: {e}")
                    fold_r2s.append(-1.0)
                    fold_maes.append(1.0)
                    fold_mses.append(1.0)

            # í‰ê·  ì„±ëŠ¥
            avg_r2 = np.mean(fold_r2s)
            avg_mae = np.mean(fold_maes)
            avg_mse = np.mean(fold_mses)

            results[model_name] = {
                'r2': avg_r2,
                'mae': avg_mae,
                'mse': avg_mse,
                'rmse': np.sqrt(avg_mse),
                'fold_r2s': fold_r2s,
                'fold_maes': fold_maes,
                'target_achieved': {
                    'r2_target': avg_r2 > self.target_r2_threshold,
                    'mae_target': avg_mae < self.target_mae_threshold
                }
            }

            # ì„±ëŠ¥ í‰ê°€
            status = "ðŸŽ¯ ëª©í‘œ ë‹¬ì„±!" if (avg_r2 > self.target_r2_threshold and avg_mae < self.target_mae_threshold) else "ðŸ“Š ê¸°ì¤€ì¹˜"
            print(f"   âœ… {model_name}: RÂ²={avg_r2:.4f}, MAE={avg_mae:.6f} - {status}")

        return results

    def run_advanced_regression_research(self, data_path='/root/workspace/data/training/sp500_2020_2024_enhanced.csv'):
        """ê³ ë„í™”ëœ íšŒê·€ ì—°êµ¬ ì‹¤í–‰"""
        print("ðŸš€ ê³ ë„í™”ëœ ì‹œê³„ì—´ íšŒê·€ ì—°êµ¬ ì‹œìž‘")
        print("="*80)

        try:
            # 1. ë°ì´í„° ë¡œë”© ë° ê³ ê¸‰ íŠ¹ì„± ìƒì„±
            df = self.data_processor.load_and_validate_data(data_path)
            advanced_df = self.create_advanced_time_series_features(df)

            # 2. ì´ˆì—„ê²© ëˆ„ì¶œ ê²€ì¦
            safe_features = self.validate_ultra_strict_leakage(advanced_df, 'target_return_1d')

            if len(safe_features) < 10:
                print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì•ˆì „ íŠ¹ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤!")
                return None

            print(f"âœ… ì•ˆì „ íŠ¹ì„± {len(safe_features)}ê°œ í™•ë³´")

            # 3. ê³ ë„í™”ëœ ëª¨ë¸ë“¤ ìƒì„±
            models = self.create_advanced_regression_models()

            # 4. ì„±ëŠ¥ í‰ê°€
            X = advanced_df[safe_features]
            y = advanced_df['target_return_1d']

            results = self.evaluate_regression_performance(models, X, y, safe_features)

            # 5. ê²°ê³¼ ë¶„ì„ ë° ì €ìž¥
            self._analyze_and_save_results(results, safe_features)

            return results

        except Exception as e:
            print(f"âŒ ê³ ë„í™”ëœ íšŒê·€ ì—°êµ¬ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def _analyze_and_save_results(self, results, safe_features):
        """ê²°ê³¼ ë¶„ì„ ë° ì €ìž¥"""
        print("\nðŸ“‹ ê³ ë„í™”ëœ íšŒê·€ ì—°êµ¬ ê²°ê³¼ ë¶„ì„")
        print("="*60)

        # ì„±ëŠ¥ ìˆœìœ„ (RÂ² ê¸°ì¤€)
        sorted_by_r2 = sorted(results.items(), key=lambda x: x[1]['r2'], reverse=True)

        print(f"\nðŸ† RÂ² ì„±ëŠ¥ ìˆœìœ„:")
        for rank, (model_name, metrics) in enumerate(sorted_by_r2[:5], 1):
            r2 = metrics['r2']
            mae = metrics['mae']
            target_status = "ðŸŽ¯" if metrics['target_achieved']['r2_target'] and metrics['target_achieved']['mae_target'] else "ðŸ“Š"

            print(f"   {rank}. {model_name}: RÂ²={r2:.4f}, MAE={mae:.6f} {target_status}")

        # MAE ìˆœìœ„
        sorted_by_mae = sorted(results.items(), key=lambda x: x[1]['mae'])

        print(f"\nðŸ“‰ MAE ì„±ëŠ¥ ìˆœìœ„:")
        for rank, (model_name, metrics) in enumerate(sorted_by_mae[:5], 1):
            r2 = metrics['r2']
            mae = metrics['mae']
            target_status = "ðŸŽ¯" if metrics['target_achieved']['r2_target'] and metrics['target_achieved']['mae_target'] else "ðŸ“Š"

            print(f"   {rank}. {model_name}: MAE={mae:.6f}, RÂ²={r2:.4f} {target_status}")

        # ëª©í‘œ ë‹¬ì„± ëª¨ë¸ë“¤
        target_achieved_models = [(name, metrics) for name, metrics in results.items()
                                if metrics['target_achieved']['r2_target'] and metrics['target_achieved']['mae_target']]

        if target_achieved_models:
            print(f"\nðŸŽ‰ ëª©í‘œ ë‹¬ì„± ëª¨ë¸ë“¤ ({len(target_achieved_models)}ê°œ):")
            for name, metrics in target_achieved_models:
                print(f"   âœ… {name}: RÂ²={metrics['r2']:.4f}, MAE={metrics['mae']:.6f}")
        else:
            print(f"\nâš ï¸ ëª©í‘œ ë‹¬ì„± ëª¨ë¸ ì—†ìŒ - ì¶”ê°€ ì—°êµ¬ í•„ìš”")

        # ê²°ê³¼ ì €ìž¥
        output_path = f"/root/workspace/data/results/advanced_time_series_regression_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        try:
            with open(output_path, 'w') as f:
                json.dump({
                    'timestamp': datetime.now().isoformat(),
                    'experiment_type': 'advanced_time_series_regression',
                    'target_thresholds': {
                        'r2_threshold': self.target_r2_threshold,
                        'mae_threshold': self.target_mae_threshold
                    },
                    'safe_features_count': len(safe_features),
                    'max_allowed_correlation': self.max_allowed_correlation,
                    'results': {k: {**v, 'fold_r2s': [float(x) for x in v['fold_r2s']],
                                          'fold_maes': [float(x) for x in v['fold_maes']]}
                              for k, v in results.items()}
                }, f, indent=2)
            print(f"\nðŸ’¾ ê²°ê³¼ ì €ìž¥: {output_path}")
        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ìž¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    research = AdvancedTimeSeriesRegression()
    results = research.run_advanced_regression_research()

    if results:
        print("\nðŸŽ‰ ê³ ë„í™”ëœ ì‹œê³„ì—´ íšŒê·€ ì—°êµ¬ ì™„ë£Œ!")
    else:
        print("\nâŒ ê³ ë„í™”ëœ ì‹œê³„ì—´ íšŒê·€ ì—°êµ¬ ì‹¤íŒ¨!")

    return results

if __name__ == "__main__":
    main()