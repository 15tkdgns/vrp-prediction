#!/usr/bin/env python3
"""
Time Window Optimization - ì‹œê°„ ìœˆë„ìš° ìµœì í™”
ë‹¤ì–‘í•œ ì˜ˆì¸¡ ê¸°ê°„ì„ ë¹„êµí•˜ì—¬ ìµœì  ì‹œê°„ ìœˆë„ìš° ì°¾ê¸°
"""

import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import RobustScaler
from sklearn.linear_model import Ridge
from sklearn.metrics import r2_score, mean_squared_error
import warnings
import os
import json
from datetime import datetime
import matplotlib.pyplot as plt

warnings.filterwarnings('ignore')

class TimeWindowOptimizer:
    """ì‹œê°„ ìœˆë„ìš° ìµœì í™”ê¸°"""

    def __init__(self):
        self.results = {}

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")

        spy = yf.download('SPY', start='2015-01-01', end='2024-12-31', progress=False)  # ë” ìµœê·¼ ë°ì´í„°ë§Œ
        spy['returns'] = spy['Close'].pct_change()

        vix = yf.download('^VIX', start='2015-01-01', end='2024-12-31', progress=False)
        spy['vix'] = vix['Close'].reindex(spy.index, method='ffill')

        spy = spy.dropna()
        print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(spy)} ìƒ˜í”Œ (2015-2024)")
        return spy

    def create_minimal_features(self, data):
        """ìµœì†Œí•œì˜ íŠ¹ì„±"""
        print("ğŸ”§ ìµœì†Œ íŠ¹ì„± ìƒì„±...")

        features = pd.DataFrame(index=data.index)
        returns = data['returns']
        prices = data['Close']
        high = data['High']
        low = data['Low']
        vix = data['vix']

        # ê°€ì¥ í•µì‹¬ì ì¸ íŠ¹ì„±ë“¤ë§Œ
        features['volatility_5'] = returns.rolling(5).std()
        features['vix_level'] = vix / 100
        features['intraday_vol'] = ((high - low) / prices).rolling(5).mean()

        print(f"âœ… ìµœì†Œ íŠ¹ì„±: {len(features.columns)}ê°œ")
        return features

    def create_multiple_targets(self, data):
        """ë‹¤ì–‘í•œ ì˜ˆì¸¡ ê¸°ê°„ì˜ íƒ€ê²Ÿ ìƒì„±"""
        print("ğŸ¯ ë‹¤ì–‘í•œ íƒ€ê²Ÿ ìƒì„±...")

        targets = pd.DataFrame(index=data.index)
        returns = data['returns']

        # 1ì¼, 2ì¼, 3ì¼, 5ì¼, 10ì¼ ì˜ˆì¸¡
        horizons = [1, 2, 3, 5, 10]

        for horizon in horizons:
            vol_values = []
            for i in range(len(returns)):
                if i + horizon < len(returns):
                    if horizon == 1:
                        # 1ì¼ ì˜ˆì¸¡: ë‹¨ìˆœíˆ ë‹¤ìŒ ë‚ ì˜ ì ˆëŒ“ê°’ ìˆ˜ìµë¥ 
                        vol_values.append(abs(returns.iloc[i+1]))
                    else:
                        # ë‹¤ì¼ ì˜ˆì¸¡: í•´ë‹¹ ê¸°ê°„ì˜ í‘œì¤€í¸ì°¨
                        future_returns = returns.iloc[i+1:i+1+horizon]
                        vol_values.append(future_returns.std())
                else:
                    vol_values.append(np.nan)

            targets[f'target_vol_{horizon}d'] = vol_values

        print(f"âœ… íƒ€ê²Ÿ ìƒì„±: {len(horizons)}ê°œ ê¸°ê°„")
        return targets, horizons

    def quick_walkforward_test(self, X, y, horizon):
        """ë¹ ë¥¸ Walk-Forward í…ŒìŠ¤íŠ¸"""
        combined_data = pd.concat([X, y], axis=1).dropna()
        X_clean = combined_data[X.columns]
        y_clean = combined_data[y.name]

        if len(X_clean) < 500:
            return {'mean_r2': -999, 'valid_folds': 0}

        # ë§¤ìš° ë¹ ë¥¸ ì„¤ì •
        initial_window = 400  # 1.5ë…„
        step_size = 50        # 2ê°œì›”
        test_window = 10      # 2ì£¼
        max_folds = 10        # ìµœëŒ€ 10ê°œ í´ë“œë§Œ

        model = Ridge(alpha=20.0)  # ë³´ìˆ˜ì  ì •ê·œí™”
        r2_scores = []

        current_start = 0
        fold = 0

        while fold < max_folds and current_start + initial_window + test_window < len(X_clean):
            fold += 1

            train_end = current_start + initial_window
            test_start = train_end
            test_end = min(test_start + test_window, len(X_clean))

            X_train = X_clean.iloc[current_start:train_end]
            y_train = y_clean.iloc[current_start:train_end]
            X_test = X_clean.iloc[test_start:test_end]
            y_test = y_clean.iloc[test_start:test_end]

            try:
                scaler = RobustScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)

                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)

                r2 = r2_score(y_test, y_pred)
                r2_scores.append(r2)

            except:
                r2_scores.append(-999)

            current_start += step_size

        valid_scores = [s for s in r2_scores if s > -900]

        if valid_scores:
            return {
                'mean_r2': np.mean(valid_scores),
                'std_r2': np.std(valid_scores),
                'max_r2': np.max(valid_scores),
                'valid_folds': len(valid_scores),
                'total_folds': len(r2_scores)
            }
        else:
            return {'mean_r2': -999, 'valid_folds': 0}

    def compare_time_windows(self, features, targets, horizons):
        """ì‹œê°„ ìœˆë„ìš° ë¹„êµ"""
        print("â±ï¸ ì‹œê°„ ìœˆë„ìš° ë¹„êµ ì¤‘...")

        results = {}

        for horizon in horizons:
            print(f"\n  {horizon}ì¼ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì¤‘...")

            target_col = f'target_vol_{horizon}d'
            if target_col not in targets.columns:
                continue

            result = self.quick_walkforward_test(features, targets[target_col], horizon)
            results[horizon] = result

            if result['valid_folds'] > 0:
                print(f"    RÂ² = {result['mean_r2']:7.4f} Â± {result.get('std_r2', 0):.4f} "
                      f"(ìµœê³ : {result.get('max_r2', 0):.4f}, ì„±ê³µ: {result['valid_folds']}/{result.get('total_folds', 0)})")
            else:
                print(f"    ì‹¤íŒ¨")

        return results

    def find_optimal_window(self, results):
        """ìµœì  ì‹œê°„ ìœˆë„ìš° ì°¾ê¸°"""
        print(f"\nğŸ¯ ìµœì  ì‹œê°„ ìœˆë„ìš° ë¶„ì„:")

        valid_results = {h: r for h, r in results.items() if r.get('valid_folds', 0) > 0}

        if not valid_results:
            print("âŒ ëª¨ë“  ì‹œê°„ ìœˆë„ìš°ì—ì„œ ì‹¤íŒ¨")
            return None, None

        # í‰ê·  RÂ² ê¸°ì¤€ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥
        best_horizon = max(valid_results.items(), key=lambda x: x[1]['mean_r2'])

        print(f"\nğŸ“Š ì‹œê°„ ìœˆë„ìš°ë³„ ì„±ëŠ¥:")
        print(f"{'ê¸°ê°„':<8} {'í‰ê·  RÂ²':<12} {'í‘œì¤€í¸ì°¨':<12} {'ìµœê³  RÂ²':<12} {'ì„±ê³µë¥ '}")
        print("-" * 60)

        for horizon, stats in valid_results.items():
            success_rate = stats['valid_folds'] / stats.get('total_folds', 1) * 100
            marker = "ğŸ†" if horizon == best_horizon[0] else "  "

            print(f"{marker} {horizon}ì¼{'':<4} {stats['mean_r2']:<12.4f} "
                  f"{stats.get('std_r2', 0):<12.4f} {stats.get('max_r2', 0):<12.4f} "
                  f"{success_rate:>6.1f}%")

        print(f"\nğŸ† ìµœì  ì‹œê°„ ìœˆë„ìš°: {best_horizon[0]}ì¼")
        print(f"   í‰ê·  RÂ²: {best_horizon[1]['mean_r2']:.4f}")
        print(f"   í‘œì¤€í¸ì°¨: {best_horizon[1].get('std_r2', 0):.4f}")
        print(f"   ìµœê³  ì„±ëŠ¥: {best_horizon[1].get('max_r2', 0):.4f}")

        return best_horizon[0], best_horizon[1]

    def detailed_test_optimal_window(self, features, targets, optimal_horizon):
        """ìµœì  ìœˆë„ìš°ë¡œ ìƒì„¸ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ” {optimal_horizon}ì¼ ì˜ˆì¸¡ ìƒì„¸ í…ŒìŠ¤íŠ¸...")

        target_col = f'target_vol_{optimal_horizon}d'
        combined_data = pd.concat([features, targets[[target_col]]], axis=1).dropna()
        X_clean = combined_data[features.columns]
        y_clean = combined_data[target_col]

        # ë” ì—„ê²©í•œ ì„¤ì •
        initial_window = 600  # 2.5ë…„
        step_size = 30        # 1ê°œì›”
        test_window = 15      # 3ì£¼

        model = Ridge(alpha=20.0)
        results = []

        current_start = 0
        fold = 0

        while current_start + initial_window + test_window < len(X_clean):
            fold += 1

            train_end = current_start + initial_window
            test_start = train_end
            test_end = min(test_start + test_window, len(X_clean))

            X_train = X_clean.iloc[current_start:train_end]
            y_train = y_clean.iloc[current_start:train_end]
            X_test = X_clean.iloc[test_start:test_end]
            y_test = y_clean.iloc[test_start:test_end]

            try:
                scaler = RobustScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)

                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)

                r2 = r2_score(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))

                results.append({
                    'fold': fold,
                    'r2': r2,
                    'rmse': rmse,
                    'test_period': f"{X_test.index[0].strftime('%Y-%m')} ~ {X_test.index[-1].strftime('%Y-%m')}"
                })

                print(f"  Fold {fold:2d}: RÂ²={r2:7.4f}, RMSE={rmse:.5f} ({X_test.index[0].strftime('%Y-%m')})")

            except Exception as e:
                print(f"  Fold {fold:2d}: ì˜¤ë¥˜ - {e}")
                results.append({'fold': fold, 'r2': -999, 'rmse': 999})

            current_start += step_size

        # ìƒì„¸ ë¶„ì„
        valid_r2s = [r['r2'] for r in results if r['r2'] != -999]

        if valid_r2s:
            detailed_stats = {
                'mean_r2': np.mean(valid_r2s),
                'std_r2': np.std(valid_r2s),
                'min_r2': np.min(valid_r2s),
                'max_r2': np.max(valid_r2s),
                'positive_folds': sum(1 for r2 in valid_r2s if r2 > 0),
                'total_valid_folds': len(valid_r2s),
                'success_rate': sum(1 for r2 in valid_r2s if r2 > 0) / len(valid_r2s) * 100
            }

            print(f"\nğŸ“Š {optimal_horizon}ì¼ ì˜ˆì¸¡ ìƒì„¸ ê²°ê³¼:")
            print(f"   í‰ê·  RÂ²: {detailed_stats['mean_r2']:.4f} Â± {detailed_stats['std_r2']:.4f}")
            print(f"   ë²”ìœ„: {detailed_stats['min_r2']:.4f} ~ {detailed_stats['max_r2']:.4f}")
            print(f"   ì–‘ì˜ ì„±ëŠ¥: {detailed_stats['positive_folds']}/{detailed_stats['total_valid_folds']} "
                  f"({detailed_stats['success_rate']:.1f}%)")

            return detailed_stats, results
        else:
            print(f"âŒ {optimal_horizon}ì¼ ì˜ˆì¸¡ ìƒì„¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return None, results

def main():
    """ë©”ì¸ ì‹œê°„ ìœˆë„ìš° ìµœì í™” í•¨ìˆ˜"""
    print("â±ï¸ Time Window Optimization - ì‹œê°„ ìœˆë„ìš° ìµœì í™”")
    print("=" * 70)

    optimizer = TimeWindowOptimizer()

    # 1. ë°ì´í„° ë¡œë“œ
    data = optimizer.load_data()

    # 2. ìµœì†Œ íŠ¹ì„± ìƒì„±
    features = optimizer.create_minimal_features(data)

    # 3. ë‹¤ì–‘í•œ íƒ€ê²Ÿ ìƒì„±
    targets, horizons = optimizer.create_multiple_targets(data)

    # 4. ì‹œê°„ ìœˆë„ìš° ë¹„êµ
    comparison_results = optimizer.compare_time_windows(features, targets, horizons)

    # 5. ìµœì  ìœˆë„ìš° ì°¾ê¸°
    optimal_horizon, optimal_stats = optimizer.find_optimal_window(comparison_results)

    if optimal_horizon is None:
        print("\nâŒ ìµœì  ì‹œê°„ ìœˆë„ìš°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        print("   ëª¨ë“  ì˜ˆì¸¡ ê¸°ê°„ì—ì„œ ìŒì˜ ì„±ëŠ¥")
        return

    # 6. ìµœì  ìœˆë„ìš° ìƒì„¸ í…ŒìŠ¤íŠ¸
    detailed_stats, detailed_results = optimizer.detailed_test_optimal_window(
        features, targets, optimal_horizon
    )

    # 7. ê²°ê³¼ ì €ì¥
    os.makedirs('results', exist_ok=True)

    time_window_results = {
        'version': 'Time_Window_Optimization',
        'timestamp': datetime.now().isoformat(),
        'data_period': '2015-2024',
        'horizons_tested': horizons,
        'comparison_results': comparison_results,
        'optimal_horizon': optimal_horizon,
        'optimal_stats': optimal_stats,
        'detailed_stats': detailed_stats,
        'feature_names': features.columns.tolist()
    }

    with open('results/time_window_optimization.json', 'w') as f:
        json.dump(time_window_results, f, indent=2, default=str)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: results/time_window_optimization.json")

    # 8. ìµœì¢… í‰ê°€
    if detailed_stats and detailed_stats['mean_r2'] > 0:
        print(f"\nğŸ‰ ì‹œê°„ ìœˆë„ìš° ìµœì í™” ì„±ê³µ!")
        print(f"   ìµœì  ì˜ˆì¸¡ ê¸°ê°„: {optimal_horizon}ì¼")
        print(f"   í‰ê·  ì„±ëŠ¥: RÂ² = {detailed_stats['mean_r2']:.4f}")
        print(f"   ì–‘ì˜ ì„±ëŠ¥ ë¹„ìœ¨: {detailed_stats['success_rate']:.1f}%")

        # ì´ì „ ìµœê³  ê²°ê³¼ì™€ ë¹„êµ
        previous_best = 0.0145  # ì´ì „ Robust ëª¨ë¸
        if detailed_stats['mean_r2'] > previous_best:
            improvement = (detailed_stats['mean_r2'] - previous_best) / previous_best * 100
            print(f"   ì´ì „ ìµœê³  ëŒ€ë¹„: +{improvement:.1f}% ê°œì„ ")
        else:
            print(f"   ì´ì „ ìµœê³  (RÂ²={previous_best:.4f})ì—ëŠ” ë¯¸ì¹˜ì§€ ëª»í•¨")

    elif detailed_stats:
        print(f"\nâš ï¸ ìµœì í™” ì™„ë£Œ, í•˜ì§€ë§Œ ì—¬ì „íˆ ìŒì˜ ì„±ëŠ¥")
        print(f"   ìµœì  ì˜ˆì¸¡ ê¸°ê°„: {optimal_horizon}ì¼")
        print(f"   í‰ê·  ì„±ëŠ¥: RÂ² = {detailed_stats['mean_r2']:.4f}")
        print(f"   ì–‘ì˜ ì„±ëŠ¥ í´ë“œ: {detailed_stats['positive_folds']}/{detailed_stats['total_valid_folds']}")

    else:
        print(f"\nâŒ ì‹œê°„ ìœˆë„ìš° ìµœì í™” ì‹¤íŒ¨")
        print(f"   ëª¨ë“  ì˜ˆì¸¡ ê¸°ê°„ì—ì„œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„±ëŠ¥ì„ ì–»ì§€ ëª»í•¨")

    print("=" * 70)

if __name__ == "__main__":
    main()