#!/usr/bin/env python3
"""
ğŸ¯ ë³´ìˆ˜ì  ì„±ëŠ¥ íŠœë‹ ì‹œìŠ¤í…œ

ê¸°ì¤€ì„ : 84.82% (ê²€ì¦ëœ ì›ë³¸ ì„±ê³¼)
ëª©í‘œ: 86-88% (ì•ˆì „í•œ ê°œì„ )

ì›ë³¸ íŒŒì´í”„ë¼ì¸ ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¸ì„¸ì¡°ì •ë§Œ ìˆ˜í–‰
"""

import sys
sys.path.append('/root/workspace/src')

from pipeline.advanced_metric_pipeline import AdvancedMetricPipeline
import json
from datetime import datetime
import numpy as np

class ConservativePerformanceTuner:
    """ë³´ìˆ˜ì  ì„±ëŠ¥ íŠœë‹ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.baseline_config = {
            'data_path': '/root/workspace/data/training/sp500_2020_2024_enhanced.csv',
            'target_type': 'direction',
            'sequence_length': 20,
            'cv_splits': 3,
            'gpu_enabled': True,
            'save_models': False,  # ì†ë„ í–¥ìƒ
            'save_results': False,
            'output_dir': '/tmp'
        }

    def run_tuning_experiment(self, config_name, modified_params=None):
        """íŠœë‹ ì‹¤í—˜ ì‹¤í–‰"""
        print(f"ğŸ”§ {config_name} ì‹¤í—˜ ì¤‘...")

        # ê¸°ë³¸ ì„¤ì •ì— ìˆ˜ì •ì‚¬í•­ ì ìš©
        config = self.baseline_config.copy()
        if modified_params:
            config.update(modified_params)

        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline = AdvancedMetricPipeline(config)
        results = pipeline.run_advanced_pipeline()

        # ìµœê³  ì„±ëŠ¥ ì¶”ì¶œ
        model_results = results.get('model_results', {})
        best_acc = 0
        best_model = None

        for model_name, metrics in model_results.items():
            if 'direction_accuracy' in metrics:
                acc = metrics['direction_accuracy'] / 100.0  # % to decimal
                if acc > best_acc:
                    best_acc = acc
                    best_model = model_name

        print(f"   âœ… {config_name}: {best_acc:.4f} ({best_model})")

        return {
            'config_name': config_name,
            'best_accuracy': best_acc,
            'best_model': best_model,
            'config': config
        }

    def run_conservative_optimization(self):
        """ë³´ìˆ˜ì  ìµœì í™” ì‹¤í–‰"""
        print("ğŸ¯ ë³´ìˆ˜ì  ì„±ëŠ¥ íŠœë‹ ì‹œì‘")
        print("="*60)

        results = []

        # 1. ë² ì´ìŠ¤ë¼ì¸ (ì›ë³¸ ì„¤ì •)
        baseline_result = self.run_tuning_experiment("ë² ì´ìŠ¤ë¼ì¸")
        results.append(baseline_result)

        # 2. CV ë¶„í•  ìˆ˜ ì¦ê°€ (ë” ì•ˆì •ì  ê²€ì¦)
        cv_result = self.run_tuning_experiment(
            "CV ë¶„í•  ì¦ê°€",
            {'cv_splits': 5}
        )
        results.append(cv_result)

        # 3. ì‹œí€€ìŠ¤ ê¸¸ì´ ì¡°ì •
        seq_result = self.run_tuning_experiment(
            "ì‹œí€€ìŠ¤ ê¸¸ì´ ì¡°ì •",
            {'sequence_length': 25}
        )
        results.append(seq_result)

        # 4. CV + ì‹œí€€ìŠ¤ ì¡°í•©
        combo_result = self.run_tuning_experiment(
            "CV + ì‹œí€€ìŠ¤ ì¡°í•©",
            {'cv_splits': 5, 'sequence_length': 25}
        )
        results.append(combo_result)

        # ê²°ê³¼ ë¶„ì„
        print(f"\nğŸ“Š íŠœë‹ ê²°ê³¼ ìš”ì•½:")
        print("-" * 60)

        baseline_acc = results[0]['best_accuracy']
        best_result = max(results, key=lambda x: x['best_accuracy'])

        for result in sorted(results, key=lambda x: x['best_accuracy'], reverse=True):
            improvement = (result['best_accuracy'] - baseline_acc) * 100
            print(f"   {result['config_name']:15s}: {result['best_accuracy']:.4f} ({improvement:+.2f}%p)")

        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best_result['config_name']} = {best_result['best_accuracy']:.4f}")

        # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
        target_min = 0.86
        target_max = 0.88

        if best_result['best_accuracy'] >= target_min:
            if best_result['best_accuracy'] <= target_max:
                print(f"ğŸ¯ ëª©í‘œ ë‹¬ì„±! ({target_min:.2f}-{target_max:.2f} ë²”ìœ„)")
            else:
                print(f"ğŸ¯ ëª©í‘œ ì´ˆê³¼! (ëª©í‘œ: {target_max:.2f} ì´í•˜)")
        else:
            needed = (target_min - best_result['best_accuracy']) * 100
            print(f"ğŸ“Š ëª©í‘œ ë¯¸ë‹¬ (ì¶”ê°€ {needed:.2f}%p í•„ìš”)")

        # ìµœì¢… ê²°ê³¼
        final_result = {
            'baseline_accuracy': baseline_acc,
            'best_accuracy': best_result['best_accuracy'],
            'improvement': (best_result['best_accuracy'] - baseline_acc) * 100,
            'best_config': best_result['config_name'],
            'target_achieved': best_result['best_accuracy'] >= target_min,
            'all_results': results
        }

        return final_result

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    tuner = ConservativePerformanceTuner()

    results = tuner.run_conservative_optimization()

    # ê²°ê³¼ ì €ì¥
    experiment_results = {
        'timestamp': datetime.now().isoformat(),
        'experiment_type': 'conservative_performance_tuning',
        'approach': 'Original pipeline with hyperparameter fine-tuning',
        'baseline_accuracy': results['baseline_accuracy'],
        'achieved_accuracy': results['best_accuracy'],
        'improvement': results['improvement'],
        'best_configuration': results['best_config'],
        'target_range': '86-88%',
        'target_achieved': results['target_achieved'],
        'validation_method': 'Original AdvancedMetricPipeline',
        'status': 'completed'
    }

    output_path = f"/root/workspace/data/results/conservative_tuning_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_path, 'w') as f:
        json.dump(experiment_results, f, indent=2)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

    return results

if __name__ == "__main__":
    main()