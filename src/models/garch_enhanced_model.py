#!/usr/bin/env python3
"""
GARCH Enhanced Volatility Model - Phase 2
ì‹¤ì œ GARCH ëª¨ë¸ë§ì„ í†µí•œ ì¡°ê±´ë¶€ ì´ë¶„ì‚°ì„± íŠ¹ì„± ì¶”ê°€
"""

import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.model_selection import TimeSeriesSplit
import warnings
import os
import json
from datetime import datetime

# GARCH ëª¨ë¸ë§ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from arch import arch_model
    ARCH_AVAILABLE = True
    print("âœ… ARCH ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    ARCH_AVAILABLE = False
    print("âš ï¸ ARCH ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ, ê·¼ì‚¬ GARCH ì‚¬ìš©")

warnings.filterwarnings('ignore')

def load_data_for_garch():
    """GARCH ëª¨ë¸ë§ìš© ë°ì´í„° ë¡œë“œ"""
    print("ğŸ“Š GARCH ëª¨ë¸ë§ìš© ë°ì´í„° ë¡œë“œ ì¤‘...")

    # SPY ë°ì´í„°
    spy = yf.download('SPY', start='2010-01-01', end='2024-12-31', progress=False)
    spy['returns'] = spy['Close'].pct_change()

    # VIX ë°ì´í„°
    vix = yf.download('^VIX', start='2010-01-01', end='2024-12-31', progress=False)
    spy['vix'] = vix['Close'].reindex(spy.index, method='ffill')

    # 10ë…„ êµ­ì±„ ê¸ˆë¦¬
    try:
        treasury = yf.download('^TNX', start='2010-01-01', end='2024-12-31', progress=False)
        spy['treasury_10y'] = treasury['Close'].reindex(spy.index, method='ffill')
    except:
        spy['treasury_10y'] = 2.5

    spy = spy.dropna()
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(spy)} ê´€ì¸¡ì¹˜")
    return spy

def create_garch_features(returns, window_size=252):
    """GARCH ëª¨ë¸ íŠ¹ì„± ìƒì„±"""
    print("ğŸ”§ GARCH íŠ¹ì„± ìƒì„± ì¤‘...")

    garch_features = pd.DataFrame(index=returns.index)

    if ARCH_AVAILABLE:
        # ì‹¤ì œ GARCH ëª¨ë¸ ì‚¬ìš©
        print("  ğŸ“ˆ ì‹¤ì œ GARCH(1,1) ëª¨ë¸ ì ìš© ì¤‘...")

        # ë¡¤ë§ ìœˆë„ìš°ë¡œ GARCH ëª¨ë¸ ì í•©
        garch_vol = []
        garch_residuals = []

        # ë°±ë¶„ìœ¨ ë‹¨ìœ„ë¡œ ë³€í™˜ (GARCH ëª¨ë¸ë§ì„ ìœ„í•´)
        returns_pct = returns * 100

        for i in range(window_size, len(returns)):
            try:
                # ê³¼ê±° 252ì¼ ë°ì´í„°ë¡œ GARCH ì í•©
                window_data = returns_pct.iloc[i-window_size:i]

                # GARCH(1,1) ëª¨ë¸
                model = arch_model(window_data, vol='GARCH', p=1, q=1, rescale=False)
                fitted_model = model.fit(disp='off', show_warning=False)

                # ì¡°ê±´ë¶€ ë¶„ì‚° (ë³€ë™ì„±)
                conditional_vol = fitted_model.conditional_volatility.iloc[-1] / 100  # ë‹¤ì‹œ ì†Œìˆ˜ë¡œ ë³€í™˜
                garch_vol.append(conditional_vol)

                # í‘œì¤€í™” ì”ì°¨
                std_residual = fitted_model.std_resid.iloc[-1]
                garch_residuals.append(std_residual)

            except:
                # ì‹¤íŒ¨ ì‹œ ì´ë™í‰ê·  ë³€ë™ì„± ì‚¬ìš©
                rolling_vol = window_data.std() / 100
                garch_vol.append(rolling_vol)
                garch_residuals.append(0)

        # NaNìœ¼ë¡œ ì´ˆê¸°í™” í›„ ê°’ í• ë‹¹
        garch_features['garch_vol'] = np.nan
        garch_features['garch_residuals'] = np.nan

        garch_features.iloc[window_size:, garch_features.columns.get_loc('garch_vol')] = garch_vol
        garch_features.iloc[window_size:, garch_features.columns.get_loc('garch_residuals')] = garch_residuals

    else:
        # ARCH ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì„ ë•Œ ê·¼ì‚¬ GARCH êµ¬í˜„
        print("  ğŸ“ˆ ê·¼ì‚¬ GARCH ëª¨ë¸ ì ìš© ì¤‘...")

        # ê°„ë‹¨í•œ GARCH(1,1) ê·¼ì‚¬
        returns_squared = returns ** 2

        # ì´ˆê¸°ê°’
        omega = returns_squared.var() * 0.1
        alpha = 0.1
        beta = 0.8

        garch_vol_approx = []
        current_var = returns_squared.iloc[0]

        for i, ret_sq in enumerate(returns_squared):
            if i == 0:
                garch_vol_approx.append(np.sqrt(current_var))
            else:
                # GARCH(1,1): ÏƒÂ²(t) = Ï‰ + Î±*ÎµÂ²(t-1) + Î²*ÏƒÂ²(t-1)
                prev_ret_sq = returns_squared.iloc[i-1]
                current_var = omega + alpha * prev_ret_sq + beta * current_var
                garch_vol_approx.append(np.sqrt(current_var))

        garch_features['garch_vol'] = garch_vol_approx
        garch_features['garch_residuals'] = returns / pd.Series(garch_vol_approx, index=returns.index)

    # GARCH ê¸°ë°˜ ì¶”ê°€ íŠ¹ì„±
    garch_features['garch_vol_ma_5'] = garch_features['garch_vol'].rolling(5).mean()
    garch_features['garch_vol_ma_20'] = garch_features['garch_vol'].rolling(20).mean()
    garch_features['garch_vol_ratio'] = garch_features['garch_vol'] / garch_features['garch_vol_ma_20']

    # GARCH ë³€ë™ì„± vs ì‹¤í˜„ ë³€ë™ì„± ë¹„êµ
    realized_vol = returns.rolling(20).std()
    garch_features['garch_vs_realized'] = garch_features['garch_vol'] / (realized_vol + 1e-8)

    # GARCH ì”ì°¨ ê¸°ë°˜ íŠ¹ì„±
    garch_features['garch_resid_abs'] = garch_features['garch_residuals'].abs()
    garch_features['garch_resid_sq'] = garch_features['garch_residuals'] ** 2

    print(f"âœ… GARCH íŠ¹ì„± ìƒì„± ì™„ë£Œ: {len(garch_features.columns)}ê°œ")
    return garch_features

def create_all_features_with_garch(data):
    """GARCH í¬í•¨ ëª¨ë“  íŠ¹ì„± ìƒì„±"""
    print("ğŸ”§ GARCH í¬í•¨ ì „ì²´ íŠ¹ì„± ìƒì„± ì¤‘...")

    features = pd.DataFrame(index=data.index)
    returns = data['returns']
    prices = data['Close']
    high = data['High']
    low = data['Low']
    volume = data['Volume']

    # 1. ê¸°ì¡´ í•µì‹¬ íŠ¹ì„±ë“¤
    for window in [5, 10, 20, 50]:
        features[f'volatility_{window}'] = returns.rolling(window).std()
        features[f'realized_vol_{window}'] = features[f'volatility_{window}'] * np.sqrt(252)

    # 2. VIX íŠ¹ì„±
    if 'vix' in data.columns:
        vix = data['vix']
        features['vix_level'] = vix
        features['vix_change'] = vix.pct_change()
        for window in [5, 10, 20]:
            features[f'vix_ma_{window}'] = vix.rolling(window).mean()
        features['vix_term_structure'] = vix / features['vix_ma_20']

    # 3. ê²½ì œ ì§€í‘œ
    if 'treasury_10y' in data.columns:
        treasury = data['treasury_10y']
        features['treasury_10y'] = treasury
        features['treasury_change'] = treasury.diff()
        features['vix_treasury_spread'] = features['vix_level'] - treasury

    # 4. GARCH íŠ¹ì„± ì¶”ê°€
    garch_features = create_garch_features(returns)
    features = pd.concat([features, garch_features], axis=1)

    # 5. ê³ ê¸‰ ë³€ë™ì„± ì¸¡ì •
    for window in [5, 10, 20]:
        gk_vol = np.log(high / low) ** 2
        features[f'garman_klass_{window}'] = gk_vol.rolling(window).mean()

        intraday_range = (high - low) / prices
        features[f'intraday_vol_{window}'] = intraday_range.rolling(window).mean()

    # 6. ì§€ìˆ˜ ê°€ì¤‘ ë³€ë™ì„±
    for span in [10, 20]:
        features[f'ewm_vol_{span}'] = returns.ewm(span=span).std()

    # 7. ë˜ê·¸ íŠ¹ì„±
    for lag in [1, 2, 3, 5]:
        features[f'return_lag_{lag}'] = returns.shift(lag)
        features[f'vol_lag_{lag}'] = features['volatility_5'].shift(lag)

    # 8. GARCHì™€ ë‹¤ë¥¸ íŠ¹ì„±ë“¤ì˜ ìƒí˜¸ì‘ìš©
    if 'garch_vol' in features.columns:
        features['garch_vix_ratio'] = features['garch_vol'] / (features['vix_level'] / 100 / np.sqrt(252) + 1e-8)
        features['garch_realized_spread'] = features['garch_vol'] - features['volatility_20']

    print(f"âœ… GARCH í¬í•¨ ì „ì²´ íŠ¹ì„± ìƒì„± ì™„ë£Œ: {len(features.columns)}ê°œ")
    return features

def create_future_volatility_targets(data):
    """ë¯¸ë˜ ë³€ë™ì„± íƒ€ê²Ÿ ìƒì„±"""
    print("ğŸ¯ ë³€ë™ì„± íƒ€ê²Ÿ ìƒì„± ì¤‘...")

    targets = pd.DataFrame(index=data.index)
    returns = data['returns']

    for window in [5]:  # 5ì¼ ì§‘ì¤‘
        vol_values = []
        for i in range(len(returns)):
            if i + window < len(returns):
                future_window = returns.iloc[i+1:i+1+window]
                vol_values.append(future_window.std())
            else:
                vol_values.append(np.nan)
        targets[f'target_vol_{window}d'] = vol_values

    return targets

def test_garch_models(X, y):
    """GARCH í¬í•¨ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ¤– GARCH Enhanced ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    combined_data = pd.concat([X, y], axis=1).dropna()
    print(f"ìœ íš¨ ìƒ˜í”Œ ìˆ˜: {len(combined_data)}")

    if len(combined_data) < 300:
        print("âš ï¸ ìƒ˜í”Œ ìˆ˜ ë¶€ì¡±")
        return {}

    X_clean = combined_data[X.columns]
    y_clean = combined_data[y.name]

    # êµì°¨ ê²€ì¦
    tscv = TimeSeriesSplit(n_splits=3)
    results = {}

    models = {
        'Lasso (Î±=0.0001)': Lasso(alpha=0.0001, max_iter=3000),
        'Lasso (Î±=0.0005)': Lasso(alpha=0.0005, max_iter=3000),
        'ElasticNet (Î±=0.0005)': ElasticNet(alpha=0.0005, l1_ratio=0.7, max_iter=3000),
        'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=6),
        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=8)
    }

    for name, model in models.items():
        scores = []

        for train_idx, test_idx in tscv.split(X_clean):
            X_train, X_test = X_clean.iloc[train_idx], X_clean.iloc[test_idx]
            y_train, y_test = y_clean.iloc[train_idx], y_clean.iloc[test_idx]

            if 'Forest' not in name and 'Boosting' not in name:
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
            else:
                X_train_scaled = X_train.values
                X_test_scaled = X_test.values

            try:
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
                score = r2_score(y_test, y_pred)
                scores.append(score)
            except Exception as e:
                print(f"  ëª¨ë¸ {name} ì˜¤ë¥˜: {e}")
                scores.append(-999)

        avg_score = np.mean(scores)
        std_score = np.std(scores)

        results[name] = {
            'mean_r2': avg_score,
            'std_r2': std_score
        }

        print(f"{name:25}: RÂ² = {avg_score:7.4f} Â± {std_score:.4f}")

    return results

def main():
    """ë©”ì¸ GARCH ëª¨ë¸ í•¨ìˆ˜"""
    print("ğŸš€ GARCH Enhanced Volatility Model")
    print("=" * 60)

    # 1. ë°ì´í„° ë¡œë“œ
    spy_data = load_data_for_garch()

    # 2. GARCH í¬í•¨ íŠ¹ì„± ìƒì„±
    all_features = create_all_features_with_garch(spy_data)

    # 3. íƒ€ê²Ÿ ìƒì„±
    targets = create_future_volatility_targets(spy_data)

    # 4. ìƒê´€ê´€ê³„ ë¶„ì„
    if 'target_vol_5d' in targets.columns:
        combined = pd.concat([all_features, targets[['target_vol_5d']]], axis=1).dropna()

        if len(combined) > 300:
            print(f"\nğŸ“Š GARCH í¬í•¨ ìƒê´€ê´€ê³„ ë¶„ì„ (ìƒ˜í”Œ ìˆ˜: {len(combined)})")

            correlations = combined[all_features.columns].corrwith(
                combined['target_vol_5d']
            ).abs().sort_values(ascending=False)

            print("ìƒìœ„ 15ê°œ íŠ¹ì„±:")
            for i, (feature, corr) in enumerate(correlations.head(15).items()):
                print(f"  {i+1:2d}. {feature:30}: {corr:.4f}")

            # 5. ìƒìœ„ íŠ¹ì„± ì„ ë³„
            top_15_features = correlations.head(15).index
            final_features = all_features[top_15_features]

            print(f"\nğŸ“Š GARCH ìµœì¢… íŠ¹ì„± ìˆ˜: {len(final_features.columns)}")

            # 6. ëª¨ë¸ í…ŒìŠ¤íŠ¸
            results = test_garch_models(final_features, targets['target_vol_5d'])

            if results:
                valid_results = {k: v for k, v in results.items() if v['mean_r2'] > -900}
                if valid_results:
                    best_model = max(valid_results.items(), key=lambda x: x[1]['mean_r2'])
                    print(f"\nğŸ† GARCH ìµœê³  ì„±ëŠ¥: {best_model[0]}")
                    print(f"   RÂ² = {best_model[1]['mean_r2']:.4f} Â± {best_model[1]['std_r2']:.4f}")

                    # V2 Liteì™€ ë¹„êµ
                    v2_lite_r2 = 0.4556  # ì´ì „ ê²°ê³¼
                    improvement = (best_model[1]['mean_r2'] - v2_lite_r2) / v2_lite_r2 * 100
                    print(f"\nğŸ“ˆ V2 Lite ëŒ€ë¹„ ê°œì„ :")
                    print(f"   V2 Lite RÂ²: {v2_lite_r2:.4f}")
                    print(f"   GARCH RÂ²:   {best_model[1]['mean_r2']:.4f}")
                    print(f"   ê°œì„ :       {improvement:+.1f}%")

                    # ê²°ê³¼ ì €ì¥
                    os.makedirs('results', exist_ok=True)

                    garch_results = {
                        'version': 'GARCH_Enhanced',
                        'timestamp': datetime.now().isoformat(),
                        'garch_library': 'arch' if ARCH_AVAILABLE else 'approximation',
                        'samples': len(combined),
                        'features': len(final_features.columns),
                        'best_model': {
                            'name': best_model[0],
                            'r2_mean': best_model[1]['mean_r2'],
                            'r2_std': best_model[1]['std_r2']
                        },
                        'improvement_vs_v2_lite': improvement,
                        'top_features': top_15_features.tolist(),
                        'all_results': results
                    }

                    with open('results/garch_enhanced_model.json', 'w') as f:
                        json.dump(garch_results, f, indent=2, default=str)

                    print(f"\nğŸ’¾ GARCH ê²°ê³¼ ì €ì¥: results/garch_enhanced_model.json")

    print("=" * 60)

if __name__ == "__main__":
    main()