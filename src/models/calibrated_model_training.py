import pandas as pd
import numpy as np
import json
import os
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, brier_score_loss
from sklearn.calibration import CalibratedClassifierCV, calibration_curve
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.regularizers import l2
import joblib
import matplotlib.pyplot as plt
from scipy import stats
import warnings
warnings.filterwarnings('ignore')


class CalibratedSP500Model:
    """
    ì—°êµ¬ ê¸°ë°˜ ì‹ ë¢°ë„ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì ìš©í•œ S&P500 ì´ë²¤íŠ¸ íƒì§€ ëª¨ë¸
    - Platt Scaling (Sigmoid ìº˜ë¦¬ë¸Œë ˆì´ì…˜)
    - Isotonic Regression
    - Bootstrap ì‹ ë¢°êµ¬ê°„
    - ì•™ìƒë¸” ëª¨ë¸
    """

    def __init__(self, data_dir="data", models_dir="data/models"):
        self.data_dir = data_dir
        self.models_dir = models_dir
        self.scaler = StandardScaler()
        self.models = {}
        self.calibrated_models = {}
        self.ensemble_weights = {}

        if not os.path.exists(self.models_dir):
            os.makedirs(self.models_dir)
        
        if not os.path.exists("results/analysis"):
            os.makedirs("results/analysis", exist_ok=True)

    def load_and_enhance_training_data(self):
        """í–¥ìƒëœ í›ˆë ¨ ë°ì´í„° ë¡œë“œ ë° ì´ë²¤íŠ¸ ì •ì˜ ì¬ì¡°ì •"""
        print("[1/8] í–¥ìƒëœ í›ˆë ¨ ë°ì´í„° ë¡œë“œ...")
        
        features_df = pd.read_csv(f"{self.data_dir}/raw/training_features.csv")
        labels_df = pd.read_csv(f"{self.data_dir}/raw/event_labels.csv")
        
        # ë‚ ì§œ í˜•ì‹ í†µì¼
        features_df["Date"] = pd.to_datetime(features_df["Date"])
        labels_df["Date"] = pd.to_datetime(labels_df["Date"])
        
        # ë°ì´í„° ë³‘í•©
        merged_df = pd.merge(features_df, labels_df, on=["ticker", "Date"], how="inner")
        
        # í–¥ìƒëœ ì´ë²¤íŠ¸ ì •ì˜ (ì—°êµ¬ ê¸°ë°˜)
        print("ğŸ”„ ì´ë²¤íŠ¸ ì •ì˜ ì¬ì¡°ì • (ëª©í‘œ: 15-25% ì´ë²¤íŠ¸ ë¹„ìœ¨)...")
        
        # ê¸°ì¡´ íŠ¹ì„±ë“¤
        price_change = merged_df['Price_Change'] if 'Price_Change' in merged_df.columns else merged_df['Returns'].abs()
        volume_spike = merged_df['Volume_Spike'] if 'Volume_Spike' in merged_df.columns else merged_df['Volume'] / merged_df['Volume_MA']
        
        # ìƒˆë¡œìš´ ì´ë²¤íŠ¸ ì •ì˜ (ë” ê´€ëŒ€í•œ ê¸°ì¤€)
        # 1. ê°€ê²© ì´ë²¤íŠ¸: 2.5% ì´ìƒ ë³€ë™ (ê¸°ì¡´ 3%ì—ì„œ ì™„í™”)
        price_event = price_change > 0.025
        
        # 2. ê±°ë˜ëŸ‰ ì´ë²¤íŠ¸: 1.5ë°° ì´ìƒ ì¦ê°€ (ê¸°ì¡´ 2ë°°ì—ì„œ ì™„í™”)
        volume_event = volume_spike > 1.5
        
        # 3. ë³€ë™ì„± ì´ë²¤íŠ¸: 5ì¼ ë³€ë™ì„±ì´ 20ì¼ í‰ê· ì˜ 1.5ë°° ì´ìƒ
        volatility_5d = merged_df['Volatility'] if 'Volatility' in merged_df.columns else merged_df['Returns'].rolling(5).std()
        volatility_20d = merged_df['Returns'].rolling(20).std()
        volatility_event = volatility_5d > (volatility_20d * 1.5)
        
        # 4. ê¸°ìˆ ì  ì§€í‘œ ì´ë²¤íŠ¸
        rsi = merged_df['RSI'] if 'RSI' in merged_df.columns else 50
        rsi_event = (rsi > 70) | (rsi < 30)  # ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„
        
        # ë³µí•© ì´ë²¤íŠ¸ ì •ì˜ (OR ì¡°ê±´ìœ¼ë¡œ ì´ë²¤íŠ¸ ë¹„ìœ¨ ì¦ê°€)
        major_event = (price_event | volume_event | volatility_event | rsi_event).astype(int)
        
        # ê¸°ì¡´ ë¼ë²¨ ì—…ë°ì´íŠ¸
        merged_df['major_event'] = major_event
        merged_df['price_spike'] = price_event.astype(int)
        merged_df['unusual_volume'] = volume_event.astype(int)
        
        event_rate = merged_df['major_event'].mean()
        print(f"âœ… ìƒˆë¡œìš´ ì´ë²¤íŠ¸ ë¹„ìœ¨: {event_rate:.3f} ({event_rate*100:.1f}%)")
        
        if event_rate < 0.15:
            print("âš ï¸ ì´ë²¤íŠ¸ ë¹„ìœ¨ì´ ëª©í‘œì¹˜(15%) ë¯¸ë§Œì…ë‹ˆë‹¤. ì¶”ê°€ ì¡°ì •...")
            # ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì ìš©
            price_event_soft = price_change > 0.02  # 2%ë¡œ ë” ì™„í™”
            volume_event_soft = volume_spike > 1.3   # 1.3ë°°ë¡œ ë” ì™„í™”
            major_event_soft = (price_event_soft | volume_event_soft | volatility_event | rsi_event).astype(int)
            merged_df['major_event'] = major_event_soft
            
            final_event_rate = merged_df['major_event'].mean()
            print(f"ğŸ”„ ì¡°ì •ëœ ì´ë²¤íŠ¸ ë¹„ìœ¨: {final_event_rate:.3f} ({final_event_rate*100:.1f}%)")
        
        print(f"âœ… ìµœì¢… ë°ì´í„° í¬ê¸°: {merged_df.shape}")
        return merged_df

    def prepare_enhanced_features(self, df):
        """í–¥ìƒëœ íŠ¹ì„± ì¤€ë¹„"""
        print("[2/8] í–¥ìƒëœ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§...")
        
        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
        target_columns = ['major_event', 'price_spike', 'unusual_volume']
        feature_columns = [col for col in numeric_columns if col not in target_columns]
        
        X = df[feature_columns].fillna(0)
        y = df['major_event']
        
        # ì‹œì¥ ìƒí™© íŠ¹ì„± ì¶”ê°€ (ì‹œë®¬ë ˆì´ì…˜)
        print("ğŸ”§ ì‹œì¥ ìƒí™© íŠ¹ì„± ì¶”ê°€...")
        
        # VIX ëŒ€ìš© ì§€í‘œ (ë³€ë™ì„± ê¸°ë°˜)
        X['market_fear'] = X['Volatility'] * 100 if 'Volatility' in X.columns else np.random.normal(20, 5, len(X))
        
        # ì‹œì¥ ëª¨ë©˜í…€ (ì´ë™í‰ê·  ê¸°ë°˜)
        if 'Price_MA_5' in X.columns and 'Price_MA_20' in X.columns:
            X['momentum'] = (X['Price_MA_5'] / X['Price_MA_20'] - 1) * 100
        else:
            X['momentum'] = np.random.normal(0, 2, len(X))
        
        # ì‹œê°„ì  íŠ¹ì„± (ìš”ì¼, ì›”)
        if 'Date' in df.columns:
            dates = pd.to_datetime(df['Date'])
            X['day_of_week'] = dates.dt.dayofweek
            X['month'] = dates.dt.month
        
        # ìƒëŒ€ì  ê°•ë„ ì§€ìˆ˜
        if 'RSI' in X.columns:
            X['rsi_normalized'] = (X['RSI'] - 50) / 50  # -1 to 1 ë²”ìœ„ë¡œ ì •ê·œí™”
        
        feature_columns = X.columns.tolist()
        
        print(f"âœ… ì´ íŠ¹ì„± ìˆ˜: {len(feature_columns)}")
        print(f"âœ… ìƒ˜í”Œ ìˆ˜: {len(X)}")
        print(f"âœ… ì´ë²¤íŠ¸ ë¹„ìœ¨: {y.mean():.3f}")
        
        return X, y, feature_columns

    def train_base_models(self, X, y):
        """ê¸°ë³¸ ëª¨ë¸ë“¤ í›ˆë ¨"""
        print("[3/8] ê¸°ë³¸ ëª¨ë¸ í›ˆë ¨...")
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # 1. Random Forest (ì—°êµ¬ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì¡°ì •)
        print("ğŸŒ³ Random Forest í›ˆë ¨...")
        rf_model = RandomForestClassifier(
            n_estimators=150,      # ì¦ê°€
            max_depth=15,          # ì¦ê°€ (ê¸°ì¡´ 10)
            min_samples_split=10,  # ê°ì†Œ (ê¸°ì¡´ 20)
            min_samples_leaf=5,    # ê°ì†Œ (ê¸°ì¡´ 10)
            max_features='sqrt',
            random_state=42,
            n_jobs=-1
        )
        rf_model.fit(X_train_scaled, y_train)
        
        rf_train_pred = rf_model.predict_proba(X_train_scaled)[:, 1]
        rf_test_pred = rf_model.predict_proba(X_test_scaled)[:, 1]
        
        self.models["random_forest"] = {
            "model": rf_model,
            "train_auc": roc_auc_score(y_train, rf_train_pred),
            "test_auc": roc_auc_score(y_test, rf_test_pred),
            "feature_importance": rf_model.feature_importances_
        }
        
        # 2. Gradient Boosting (ì—°êµ¬ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì¡°ì •)
        print("ğŸ“ˆ Gradient Boosting í›ˆë ¨...")
        gb_model = GradientBoostingClassifier(
            n_estimators=120,      # ì¦ê°€
            max_depth=8,           # ì¦ê°€ (ê¸°ì¡´ 6)
            learning_rate=0.15,    # ì¦ê°€ (ê¸°ì¡´ 0.1)
            subsample=0.85,        # ì¦ê°€
            random_state=42
        )
        gb_model.fit(X_train_scaled, y_train)
        
        gb_train_pred = gb_model.predict_proba(X_train_scaled)[:, 1]
        gb_test_pred = gb_model.predict_proba(X_test_scaled)[:, 1]
        
        self.models["gradient_boosting"] = {
            "model": gb_model,
            "train_auc": roc_auc_score(y_train, gb_train_pred),
            "test_auc": roc_auc_score(y_test, gb_test_pred),
            "feature_importance": gb_model.feature_importances_
        }
        
        # 3. LSTM (ì—°êµ¬ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì¡°ì •)
        print("ğŸ§  LSTM í›ˆë ¨...")
        X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
        X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))
        
        lstm_model = Sequential([
            LSTM(64, return_sequences=True, input_shape=(1, X_train_scaled.shape[1]),
                 kernel_regularizer=l2(0.005)),  # ì •ê·œí™” ì™„í™”
            Dropout(0.2),  # ë“œë¡­ì•„ì›ƒ ê°ì†Œ
            LSTM(32, kernel_regularizer=l2(0.005)),
            Dropout(0.2),
            Dense(32, activation='relu', kernel_regularizer=l2(0.005)),
            Dropout(0.15),  # ê°ì†Œ
            Dense(1, activation='sigmoid')
        ])
        
        lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
        
        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
        
        history = lstm_model.fit(
            X_train_lstm, y_train,
            epochs=100,
            batch_size=32,
            validation_data=(X_test_lstm, y_test),
            callbacks=[early_stopping],
            verbose=0
        )
        
        lstm_train_pred = lstm_model.predict(X_train_lstm, verbose=0).flatten()
        lstm_test_pred = lstm_model.predict(X_test_lstm, verbose=0).flatten()
        
        self.models["lstm"] = {
            "model": lstm_model,
            "train_auc": roc_auc_score(y_train, lstm_train_pred),
            "test_auc": roc_auc_score(y_test, lstm_test_pred),
            "history": history.history
        }
        
        # ì„±ëŠ¥ ì¶œë ¥
        for name, model_info in self.models.items():
            print(f"{name.upper()} - Train AUC: {model_info['train_auc']:.4f}, Test AUC: {model_info['test_auc']:.4f}")
        
        return X_train_scaled, X_test_scaled, y_train, y_test

    def apply_calibration(self, X_train, X_test, y_train, y_test):
        """Platt Scalingê³¼ Isotonic Regression ì ìš©"""
        print("[4/8] ì‹ ë¢°ë„ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš©...")
        
        for model_name, model_info in self.models.items():
            if model_name == 'lstm':
                continue  # LSTMì€ ë³„ë„ ì²˜ë¦¬
            
            print(f"ğŸ¯ {model_name.upper()} ìº˜ë¦¬ë¸Œë ˆì´ì…˜...")
            
            # Platt Scaling (Sigmoid)
            platt_calibrated = CalibratedClassifierCV(
                model_info['model'], 
                method='sigmoid', 
                cv=3
            )
            platt_calibrated.fit(X_train, y_train)
            
            # Isotonic Regression
            isotonic_calibrated = CalibratedClassifierCV(
                model_info['model'], 
                method='isotonic', 
                cv=3
            )
            isotonic_calibrated.fit(X_train, y_train)
            
            # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ì˜ˆì¸¡
            platt_pred = platt_calibrated.predict_proba(X_test)[:, 1]
            isotonic_pred = isotonic_calibrated.predict_proba(X_test)[:, 1]
            original_pred = model_info['model'].predict_proba(X_test)[:, 1]
            
            # Brier Scoreë¡œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í’ˆì§ˆ í‰ê°€
            original_brier = brier_score_loss(y_test, original_pred)
            platt_brier = brier_score_loss(y_test, platt_pred)
            isotonic_brier = brier_score_loss(y_test, isotonic_pred)
            
            # ìµœì  ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°©ë²• ì„ íƒ
            if platt_brier <= isotonic_brier:
                best_method = 'platt'
                best_calibrated = platt_calibrated
                best_pred = platt_pred
                best_brier = platt_brier
            else:
                best_method = 'isotonic'
                best_calibrated = isotonic_calibrated
                best_pred = isotonic_pred
                best_brier = isotonic_brier
            
            self.calibrated_models[model_name] = {
                'calibrated_model': best_calibrated,
                'method': best_method,
                'original_brier': original_brier,
                'calibrated_brier': best_brier,
                'improvement': original_brier - best_brier
            }
            
            print(f"  ìµœì  ë°©ë²•: {best_method}")
            print(f"  Brier Score ê°œì„ : {original_brier:.4f} â†’ {best_brier:.4f}")
            print(f"  í‰ê·  ì‹ ë¢°ë„: {np.mean(best_pred):.4f}")
            
        print("âœ… ëª¨ë“  ëª¨ë¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ")

    def create_ensemble_model(self, X_test, y_test):
        """ì•™ìƒë¸” ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ìµœì í™”"""
        print("[5/8] ì•™ìƒë¸” ëª¨ë¸ ìƒì„±...")
        
        # ê° ëª¨ë¸ì˜ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ì˜ˆì¸¡
        predictions = {}
        
        for model_name in self.calibrated_models:
            calibrated_model = self.calibrated_models[model_name]['calibrated_model']
            pred = calibrated_model.predict_proba(X_test)[:, 1]
            predictions[model_name] = pred
        
        # LSTM ì˜ˆì¸¡ (ë³„ë„ ì²˜ë¦¬)
        if 'lstm' in self.models:
            X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))
            lstm_pred = self.models['lstm']['model'].predict(X_test_lstm, verbose=0).flatten()
            predictions['lstm'] = lstm_pred
        
        # ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
        weights = {}
        total_weight = 0
        
        for model_name in predictions:
            if model_name == 'lstm':
                auc_score = self.models[model_name]['test_auc']
            else:
                auc_score = self.models[model_name]['test_auc']
            
            # AUC ì ìˆ˜ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš© (ì •ê·œí™”)
            weight = max(0, auc_score - 0.5) ** 2  # 0.5 ì´ìƒë§Œ ìœ ì˜ë¯¸
            weights[model_name] = weight
            total_weight += weight
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        for model_name in weights:
            weights[model_name] = weights[model_name] / total_weight if total_weight > 0 else 1/len(weights)
        
        self.ensemble_weights = weights
        
        # ì•™ìƒë¸” ì˜ˆì¸¡ ê³„ì‚°
        ensemble_pred = np.zeros(len(y_test))
        for model_name, pred in predictions.items():
            ensemble_pred += weights[model_name] * pred
        
        ensemble_auc = roc_auc_score(y_test, ensemble_pred)
        ensemble_avg_confidence = np.mean(ensemble_pred)
        ensemble_std_confidence = np.std(ensemble_pred)
        
        print(f"âœ… ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥:")
        print(f"  AUC: {ensemble_auc:.4f}")
        print(f"  í‰ê·  ì‹ ë¢°ë„: {ensemble_avg_confidence:.4f} Â± {ensemble_std_confidence:.4f}")
        print(f"  ëª¨ë¸ ê°€ì¤‘ì¹˜:")
        for name, weight in weights.items():
            print(f"    {name}: {weight:.3f}")
        
        return ensemble_pred

    def bootstrap_confidence_intervals(self, X_test, y_test, n_bootstrap=500):
        """Bootstrapì„ ì´ìš©í•œ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°"""
        print("[6/8] Bootstrap ì‹ ë¢°êµ¬ê°„ ê³„ì‚°...")
        
        bootstrap_predictions = []
        
        for i in range(n_bootstrap):
            if i % 100 == 0:
                print(f"  ì§„í–‰ë¥ : {i}/{n_bootstrap}")
            
            # Bootstrap ìƒ˜í”Œë§
            indices = np.random.choice(len(X_test), size=len(X_test), replace=True)
            X_boot = X_test[indices]
            
            # ì•™ìƒë¸” ì˜ˆì¸¡
            ensemble_pred_boot = np.zeros(len(indices))
            
            for model_name in self.calibrated_models:
                calibrated_model = self.calibrated_models[model_name]['calibrated_model']
                pred = calibrated_model.predict_proba(X_boot)[:, 1]
                ensemble_pred_boot += self.ensemble_weights[model_name] * pred
            
            if 'lstm' in self.models:
                X_boot_lstm = X_boot.reshape((X_boot.shape[0], 1, X_boot.shape[1]))
                lstm_pred = self.models['lstm']['model'].predict(X_boot_lstm, verbose=0).flatten()
                ensemble_pred_boot += self.ensemble_weights['lstm'] * lstm_pred
            
            bootstrap_predictions.append(ensemble_pred_boot)
        
        bootstrap_predictions = np.array(bootstrap_predictions)
        
        # ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
        confidence_intervals = {
            'mean': np.mean(bootstrap_predictions, axis=0),
            'lower_95': np.percentile(bootstrap_predictions, 2.5, axis=0),
            'upper_95': np.percentile(bootstrap_predictions, 97.5, axis=0),
            'lower_68': np.percentile(bootstrap_predictions, 16, axis=0),
            'upper_68': np.percentile(bootstrap_predictions, 84, axis=0)
        }
        
        avg_interval_width = np.mean(confidence_intervals['upper_95'] - confidence_intervals['lower_95'])
        print(f"âœ… Bootstrap ì™„ë£Œ - í‰ê·  95% ì‹ ë¢°êµ¬ê°„ í­: {avg_interval_width:.4f}")
        
        return confidence_intervals

    def evaluate_calibration_quality(self, X_test, y_test):
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í’ˆì§ˆ í‰ê°€"""
        print("[7/8] ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í’ˆì§ˆ í‰ê°€...")
        
        evaluation_results = {}
        
        for model_name in self.calibrated_models:
            calibrated_model = self.calibrated_models[model_name]['calibrated_model']
            y_pred_proba = calibrated_model.predict_proba(X_test)[:, 1]
            
            # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê³¡ì„ 
            fraction_of_positives, mean_predicted_value = calibration_curve(
                y_test, y_pred_proba, n_bins=10, strategy='uniform'
            )
            
            # Expected Calibration Error (ECE)
            bin_boundaries = np.linspace(0, 1, 11)
            bin_lowers = bin_boundaries[:-1]
            bin_uppers = bin_boundaries[1:]
            
            ece = 0
            for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):
                in_bin = (y_pred_proba > bin_lower) & (y_pred_proba <= bin_upper)
                prop_in_bin = in_bin.mean()
                
                if prop_in_bin > 0:
                    accuracy_in_bin = y_test[in_bin].mean()
                    avg_confidence_in_bin = y_pred_proba[in_bin].mean()
                    ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin
            
            evaluation_results[model_name] = {
                'ece': ece,
                'brier_score': brier_score_loss(y_test, y_pred_proba),
                'avg_confidence': np.mean(y_pred_proba),
                'confidence_std': np.std(y_pred_proba),
                'auc': roc_auc_score(y_test, y_pred_proba)
            }
            
            print(f"{model_name.upper()}:")
            print(f"  ECE: {ece:.4f}")
            print(f"  Brier Score: {evaluation_results[model_name]['brier_score']:.4f}")
            print(f"  í‰ê·  ì‹ ë¢°ë„: {evaluation_results[model_name]['avg_confidence']:.4f}")
        
        return evaluation_results

    def save_calibrated_models(self):
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ëª¨ë¸ë“¤ ì €ì¥"""
        print("[8/8] ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ëª¨ë¸ ì €ì¥...")
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ëª¨ë¸ë“¤ ì €ì¥
        for model_name, calibrated_info in self.calibrated_models.items():
            joblib.dump(
                calibrated_info['calibrated_model'], 
                f"{self.models_dir}/{model_name}_calibrated_model.pkl"
            )
        
        # LSTM ëª¨ë¸ ì €ì¥
        if 'lstm' in self.models:
            self.models['lstm']['model'].save(f"{self.models_dir}/lstm_calibrated_model.h5")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
        joblib.dump(self.scaler, f"{self.models_dir}/scaler_calibrated.pkl")
        
        # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì €ì¥
        with open(f"{self.data_dir}/raw/ensemble_weights.json", "w") as f:
            json.dump(self.ensemble_weights, f, indent=2)
        
        print("âœ… ëª¨ë“  ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ëª¨ë¸ ì €ì¥ ì™„ë£Œ")

    def run_calibrated_training_pipeline(self):
        """ì „ì²´ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ ì—°êµ¬ ê¸°ë°˜ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        print("=" * 60)
        
        # 1. ë°ì´í„° ë¡œë“œ ë° í–¥ìƒ
        df = self.load_and_enhance_training_data()
        
        # 2. íŠ¹ì„± ì¤€ë¹„
        X, y, feature_names = self.prepare_enhanced_features(df)
        
        # 3. ê¸°ë³¸ ëª¨ë¸ í›ˆë ¨
        X_train, X_test, y_train, y_test = self.train_base_models(X, y)
        
        # 4. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš©
        self.apply_calibration(X_train, X_test, y_train, y_test)
        
        # 5. ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
        ensemble_pred = self.create_ensemble_model(X_test, y_test)
        
        # 6. Bootstrap ì‹ ë¢°êµ¬ê°„
        confidence_intervals = self.bootstrap_confidence_intervals(X_test, y_test)
        
        # 7. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í’ˆì§ˆ í‰ê°€
        evaluation_results = self.evaluate_calibration_quality(X_test, y_test)
        
        # 8. ëª¨ë¸ ì €ì¥
        self.save_calibrated_models()
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 60)
        print("ğŸ‰ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í›ˆë ¨ ì™„ë£Œ!")
        print("=" * 60)
        
        ensemble_avg = np.mean(ensemble_pred)
        ensemble_std = np.std(ensemble_pred)
        
        print(f"ğŸ“Š ì•™ìƒë¸” ëª¨ë¸ ìµœì¢… ì„±ê³¼:")
        print(f"   í‰ê·  ì‹ ë¢°ë„: {ensemble_avg:.4f} ({ensemble_avg*100:.1f}%)")
        print(f"   ì‹ ë¢°ë„ í‘œì¤€í¸ì°¨: {ensemble_std:.4f}")
        print(f"   AUC: {roc_auc_score(y_test, ensemble_pred):.4f}")
        
        # ì‹ ë¢°ë„ êµ¬ê°„ë³„ ë¶„í¬
        low_conf = np.sum(ensemble_pred < 0.3) / len(ensemble_pred)
        mid_conf = np.sum((ensemble_pred >= 0.3) & (ensemble_pred <= 0.7)) / len(ensemble_pred)
        high_conf = np.sum(ensemble_pred > 0.7) / len(ensemble_pred)
        
        print(f"   ì‹ ë¢°ë„ ë¶„í¬:")
        print(f"     ë‚®ìŒ (<30%): {low_conf*100:.1f}%")
        print(f"     ì¤‘ê°„ (30-70%): {mid_conf*100:.1f}%")
        print(f"     ë†’ìŒ (>70%): {high_conf*100:.1f}%")
        
        target_achieved = 0.35 <= ensemble_avg <= 0.55
        print(f"\nğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ (35-55% ì‹ ë¢°ë„): {'âœ… ë‹¬ì„±' if target_achieved else 'âŒ ë¯¸ë‹¬ì„±'}")
        
        return True


if __name__ == "__main__":
    print("ğŸ”¬ ì—°êµ¬ ê¸°ë°˜ S&P500 ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë¸ í›ˆë ¨")
    
    model_trainer = CalibratedSP500Model()
    success = model_trainer.run_calibrated_training_pipeline()
    
    if success:
        print("\nâœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë¸ í›ˆë ¨ ì„±ê³µ!")
        print("   ì´ì œ 35-55% ë²”ìœ„ì˜ í˜„ì‹¤ì ì¸ ì‹ ë¢°ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
    else:
        print("\nâŒ í›ˆë ¨ ì‹¤íŒ¨!")