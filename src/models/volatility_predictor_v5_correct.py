#!/usr/bin/env python3
"""
ë³€ë™ì„± ì˜ˆì¸¡ V5: V0 ì˜¬ë°”ë¥¸ íƒ€ê²Ÿ + ë°œê²¬ëœ íŒ¨í„´ íŠ¹ì„±
íƒ€ê²Ÿ: returns[t+1:t+6].std() (V0 ë°©ì‹)
íŠ¹ì„±: íŒ¨í„´ ë¶„ì„ì—ì„œ ë°œê²¬í•œ ê°•ë ¥í•œ íŠ¹ì„±ë“¤

ëª©í‘œ: RÂ² 0.303 â†’ 0.40+
"""

import pandas as pd
import numpy as np
import yfinance as yf
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import r2_score
from xgboost import XGBRegressor
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class VolatilityPredictorV5:
    """V0 íƒ€ê²Ÿ + íŒ¨í„´ íŠ¹ì„±"""

    def __init__(self, ticker="SPY", start_date="2015-01-01", end_date="2024-12-31"):
        self.ticker = ticker
        self.start_date = start_date
        self.end_date = end_date
        self.data = None
        self.results = {}

    def load_and_engineer_features(self):
        """V0 íƒ€ê²Ÿ + íŒ¨í„´ íŠ¹ì„±"""
        print(f"ğŸ“‚ {self.ticker} ë°ì´í„° ë¡œë“œ ì¤‘...")

        spy = yf.Ticker(self.ticker)
        df = spy.history(start=self.start_date, end=self.end_date)
        df.index = pd.to_datetime(df.index).tz_localize(None)

        print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(df)} ìƒ˜í”Œ")

        df['returns'] = np.log(df['Close'] / df['Close'].shift(1))

        print("\nğŸ”§ ì˜¬ë°”ë¥¸ íƒ€ê²Ÿ ìƒì„± (V0 ë°©ì‹: t+1~t+5)...")

        # === íƒ€ê²Ÿ: V0 ë°©ì‹ (5ì¼ ë¯¸ë˜) ===
        targets = []
        for i in range(len(df)):
            if i + 5 < len(df):
                future_returns = df['returns'].iloc[i+1:i+6]  # t+1~t+5
                targets.append(future_returns.std())
            else:
                targets.append(np.nan)
        df['target_vol_5d'] = targets

        print("\nğŸ”§ íŒ¨í„´ ê¸°ë°˜ íŠ¹ì„± (ëª¨ë‘ shift ì ìš©)...")

        # === ê¸°ë³¸ ë³€ë™ì„± (ê³¼ê±°ë§Œ) ===
        df['vol_5d'] = df['returns'].rolling(5).std()
        df['vol_10d'] = df['returns'].rolling(10).std()
        df['vol_20d'] = df['returns'].rolling(20).std()
        df['vol_60d'] = df['returns'].rolling(60).std()

        # === íŒ¨í„´ 1: ATR (ìƒê´€ 0.67) ===
        df['high_low'] = df['High'] - df['Low']
        df['high_close'] = abs(df['High'] - df['Close'].shift(1))
        df['low_close'] = abs(df['Low'] - df['Close'].shift(1))
        df['true_range'] = df[['high_low', 'high_close', 'low_close']].max(axis=1)
        df['atr_14'] = df['true_range'].rolling(14).mean()

        # === íŒ¨í„´ 2: Gap (íš¨ê³¼ 1.98ë°°) ===
        df['gap'] = (df['Open'] - df['Close'].shift(1)) / df['Close'].shift(1)
        df['gap_size'] = df['gap'].abs()
        df['large_gap_freq'] = (df['gap_size'] > df['gap_size'].quantile(0.9)).rolling(20).sum()

        # === íŒ¨í„´ 3: Volume (íš¨ê³¼ 1.66ë°°) ===
        df['volume_ratio'] = df['Volume'] / df['Volume'].rolling(20).mean()
        df['volume_spike_freq'] = (df['volume_ratio'] > 1.5).rolling(20).sum()

        # === íŒ¨í„´ 4: Momentum (íš¨ê³¼ 1.68ë°°) ===
        df['momentum_5'] = df['Close'] / df['Close'].shift(5) - 1
        df['momentum_20'] = df['Close'] / df['Close'].shift(20) - 1
        df['momentum_strength'] = df['momentum_20'].abs()

        # === íŒ¨í„´ 5: Vol-of-Vol (íš¨ê³¼ 1.58ë°°) ===
        df['vol_of_vol'] = df['vol_20d'].rolling(20).std()

        # === íŒ¨í„´ 6: Parkinson Vol ===
        df['parkinson_vol'] = np.sqrt(
            1 / (4 * np.log(2)) * (np.log(df['High'] / df['Low']) ** 2)
        )

        # === íŒ¨í„´ 7: Skew/Kurt ===
        df['rolling_skew'] = df['returns'].rolling(20).skew()
        df['rolling_kurt'] = df['returns'].rolling(20).kurt()

        # === Lag features ===
        for lag in [1, 2, 3, 5, 10, 20]:
            df[f'vol_lag_{lag}'] = df['vol_20d'].shift(lag)

        # === ê·¹ë‹¨ê°’ ===
        df['extreme_return'] = (df['returns'].abs() > df['returns'].rolling(60).std() * 2).astype(int)
        df['extreme_freq'] = df['extreme_return'].rolling(20).sum()

        # === ìƒí˜¸ì‘ìš© ===
        df['atr_x_volume'] = df['atr_14'] * df['volume_ratio']
        df['gap_x_momentum'] = df['gap_size'] * df['momentum_strength']

        df = df.dropna()
        self.data = df

        print(f"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: {df.shape[1]}ê°œ ì»¬ëŸ¼, {len(df)} ìƒ˜í”Œ")
        print(f"âœ… íƒ€ê²Ÿ: V0 ë°©ì‹ returns[t+1:t+6].std()")

        return True

    def method1_baseline_v0(self):
        """ë°©ë²• 1: V0 ê¸°ë³¸ íŠ¹ì„± ì¬í˜„"""
        print("\nğŸ”¹ ë°©ë²• 1: V0 Baseline (ì¬í˜„)...")

        features = [
            'vol_5d', 'vol_10d', 'vol_20d',
            'vol_lag_1', 'vol_lag_2', 'vol_lag_3', 'vol_lag_5', 'vol_lag_10'
        ]

        X = self.data[features]
        y = self.data['target_vol_5d']

        r2 = self._train_and_evaluate(X, y, Ridge(alpha=1.0), "V0 Baseline")

        self.results['method1_v0_baseline'] = {'r2': r2}
        return r2

    def method2_pattern_features(self):
        """ë°©ë²• 2: íŒ¨í„´ íŠ¹ì„± ì¶”ê°€"""
        print("\nğŸ”¹ ë°©ë²• 2: V0 + íŒ¨í„´ íŠ¹ì„±...")

        features = [
            # ê¸°ë³¸
            'vol_20d', 'vol_lag_1', 'vol_lag_2', 'vol_lag_5',
            # íŒ¨í„´
            'atr_14', 'gap_size', 'large_gap_freq',
            'volume_ratio', 'volume_spike_freq',
            'momentum_strength', 'vol_of_vol',
            'parkinson_vol', 'extreme_freq',
            # ìƒí˜¸ì‘ìš©
            'atr_x_volume', 'gap_x_momentum'
        ]

        X = self.data[features]
        y = self.data['target_vol_5d']

        r2 = self._train_and_evaluate(X, y, Ridge(alpha=1.0), "V0 + Pattern")

        self.results['method2_v0_pattern'] = {'r2': r2}
        return r2

    def method3_xgboost_pattern(self):
        """ë°©ë²• 3: XGBoost + íŒ¨í„´"""
        print("\nğŸ”¹ ë°©ë²• 3: XGBoost + íŒ¨í„´...")

        features = [
            'vol_20d', 'vol_lag_1', 'vol_lag_5',
            'atr_14', 'gap_size', 'volume_ratio',
            'momentum_strength', 'vol_of_vol',
            'parkinson_vol', 'extreme_freq',
            'atr_x_volume'
        ]

        X = self.data[features]
        y = self.data['target_vol_5d']

        model = XGBRegressor(
            n_estimators=100,
            max_depth=3,
            learning_rate=0.05,
            subsample=0.8,
            random_state=42,
            verbosity=0
        )

        r2 = self._train_and_evaluate(X, y, model, "XGBoost + Pattern")

        self.results['method3_xgboost_pattern'] = {'r2': r2}
        return r2

    def method4_vix_pattern(self):
        """ë°©ë²• 4: VIX + íŒ¨í„´"""
        print("\nğŸ”¹ ë°©ë²• 4: VIX + íŒ¨í„´...")

        try:
            vix = yf.Ticker("^VIX")
            vix_data = vix.history(start=self.start_date, end=self.end_date)
            vix_data.index = pd.to_datetime(vix_data.index).tz_localize(None)

            df = self.data.copy()
            df['vix'] = vix_data['Close'].reindex(df.index, method='ffill')
            df['vix_change'] = df['vix'].pct_change(5)

            df = df.dropna()

            features = [
                'vix', 'vix_change',
                'vol_20d', 'vol_lag_1', 'vol_lag_5',
                'atr_14', 'gap_size', 'volume_ratio',
                'momentum_strength', 'vol_of_vol',
                'parkinson_vol'
            ]

            X = df[features]
            y = df['target_vol_5d']

            r2 = self._train_and_evaluate(X, y, Ridge(alpha=1.0), "VIX + Pattern")

            self.results['method4_vix_pattern'] = {'r2': r2}
            return r2

        except Exception as e:
            print(f"   âš ï¸  VIX ì‹¤íŒ¨: {e}")
            self.results['method4_vix_pattern'] = {'r2': 0.0}
            return 0.0

    def method5_stacking(self):
        """ë°©ë²• 5: Stacking"""
        print("\nğŸ”¹ ë°©ë²• 5: Stacking (Ridge + XGBoost)...")

        features = [
            'vol_20d', 'vol_lag_1', 'vol_lag_5',
            'atr_14', 'gap_size', 'volume_ratio',
            'momentum_strength', 'vol_of_vol',
            'parkinson_vol', 'atr_x_volume'
        ]

        X = self.data[features]
        y = self.data['target_vol_5d']

        tscv = TimeSeriesSplit(n_splits=5)
        all_preds = []
        all_actuals = []

        for train_idx, test_idx in tscv.split(X):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            ridge = Ridge(alpha=1.0)
            xgb = XGBRegressor(n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42, verbosity=0)

            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            ridge.fit(X_train_scaled, y_train)
            xgb.fit(X_train, y_train)

            ridge_pred = ridge.predict(X_test_scaled)
            xgb_pred = xgb.predict(X_test)

            ensemble_pred = 0.6 * ridge_pred + 0.4 * xgb_pred

            all_preds.extend(ensemble_pred)
            all_actuals.extend(y_test)

        r2 = r2_score(all_actuals, all_preds)
        print(f"   Stacking RÂ²: {r2:.4f}")

        self.results['method5_stacking'] = {'r2': r2}
        return r2

    def _train_and_evaluate(self, X, y, model, method_name):
        """TimeSeriesSplit í‰ê°€"""
        tscv = TimeSeriesSplit(n_splits=5)
        scores = []

        for train_idx, test_idx in tscv.split(X):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            if isinstance(model, Ridge):
                scaler = StandardScaler()
                X_train = scaler.fit_transform(X_train)
                X_test = scaler.transform(X_test)

            model.fit(X_train, y_train)
            pred = model.predict(X_test)

            r2 = r2_score(y_test, pred)
            scores.append(r2)

        mean_r2 = np.mean(scores)
        print(f"   {method_name} RÂ²: {mean_r2:.4f} (Â±{np.std(scores):.4f})")

        return mean_r2

    def run_all_methods(self):
        """ì „ì²´ ì‹¤í–‰"""
        print("="*70)
        print("ğŸš€ ë³€ë™ì„± ì˜ˆì¸¡ V5: V0 íƒ€ê²Ÿ + íŒ¨í„´ íŠ¹ì„±")
        print("="*70)
        print("ê¸°ì¤€: V0 RÂ² = 0.303, V2 RÂ² = 0.328\n")

        self.load_and_engineer_features()

        methods = [
            ("V0 Baseline", self.method1_baseline_v0),
            ("V0 + Pattern", self.method2_pattern_features),
            ("XGBoost + Pattern", self.method3_xgboost_pattern),
            ("VIX + Pattern", self.method4_vix_pattern),
            ("Stacking", self.method5_stacking),
        ]

        scores = []

        for name, method in methods:
            try:
                r2 = method()
                scores.append((name, r2))
            except Exception as e:
                print(f"   âŒ {name} ì‹¤íŒ¨: {e}")
                scores.append((name, 0.0))

        # ìµœì¢… ë¹„êµ
        print("\n" + "="*70)
        print("ğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ")
        print("="*70)

        baseline_v2 = 0.328
        baseline_v0 = 0.303

        print(f"{'ë°©ë²•':<30s} {'RÂ²':>10s} {'vs V2':>12s} {'vs V0':>12s}")
        print("-"*70)
        print(f"{'V0 Baseline (Original)':<30s} {baseline_v0:>10.4f} {'-':>12s} {'-':>12s}")
        print(f"{'V2 Regime':<30s} {baseline_v2:>10.4f} {f'+{baseline_v2-baseline_v0:.4f}':>12s} {'-':>12s}")

        for name, r2 in sorted(scores, key=lambda x: x[1], reverse=True):
            improvement_v2 = r2 - baseline_v2
            improvement_v0 = r2 - baseline_v0
            symbol = "âœ…" if r2 > baseline_v2 else ("âš ï¸" if r2 > baseline_v0 else "âŒ")
            print(f"{name:<30s} {r2:>10.4f} {improvement_v2:>+11.4f} {improvement_v0:>+11.4f} {symbol}")

        best_method, best_r2 = max(scores, key=lambda x: x[1])

        print("\n" + "="*70)
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥: {best_method}")
        print(f"   RÂ² = {best_r2:.4f}")

        if best_r2 > baseline_v2:
            print(f"   âœ… ì„±ê³µ! vs V2 ê°œì„  = {best_r2 - baseline_v2:+.4f}")
            print(f"   âœ… ì„±ê³µ! vs V0 ê°œì„  = {best_r2 - baseline_v0:+.4f}")
        elif best_r2 > baseline_v0:
            print(f"   âš ï¸  V2 ë¯¸ë‹¬, V0 ê°œì„  = {best_r2 - baseline_v0:+.4f}")
        else:
            print(f"   âŒ V0ë„ ë¯¸ë‹¬")

        print("="*70)

        output = {
            'experiment': 'volatility_prediction_v5_correct',
            'baseline_v0_r2': baseline_v0,
            'baseline_v2_r2': baseline_v2,
            'best_method': best_method,
            'best_r2': best_r2,
            'improvement_vs_v2': best_r2 - baseline_v2,
            'improvement_vs_v0': best_r2 - baseline_v0,
            'all_results': self.results,
            'target_design': 'V0 ë°©ì‹ returns[t+1:t+6].std()',
            'features': 'íŒ¨í„´ ë¶„ì„ ê¸°ë°˜ (ATR, Gap, Volume, Momentum, Vol-of-Vol)',
            'timestamp': datetime.now().isoformat()
        }

        with open('data/raw/volatility_v5_final_results.json', 'w') as f:
            json.dump(output, f, indent=2)

        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥: data/raw/volatility_v5_final_results.json")

        return best_r2

if __name__ == "__main__":
    predictor = VolatilityPredictorV5()
    predictor.run_all_methods()
