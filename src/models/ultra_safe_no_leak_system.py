#!/usr/bin/env python3
"""
ğŸ”’ ì™„ì „ ëˆ„ì¶œ ë°©ì§€ ì‹œìŠ¤í…œ

99%+ ì„±ëŠ¥ ëª¨ë¸ë“¤ì„ ì™„ì „íˆ ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ì¬ì‹¤í—˜
ë°ì´í„° ëˆ„ì¶œ ì ˆëŒ€ ë¶ˆê°€ëŠ¥í•œ ì—„ê²©í•œ ì‹œìŠ¤í…œ
"""

import sys
sys.path.append('/root/workspace/src')

import pandas as pd
import numpy as np
from datetime import datetime
import json
import warnings
warnings.filterwarnings('ignore')

# Core imports
from core.data_processor import DataProcessor

# ML imports
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge, BayesianRidge
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_absolute_error, r2_score
import catboost as cb
import xgboost as xgb

class UltraSafeNoLeakSystem:
    """ì™„ì „ ëˆ„ì¶œ ë°©ì§€ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.data_processor = DataProcessor()
        self.max_allowed_correlation = 0.3  # ì—„ê²©í•œ ìƒê´€ê´€ê³„ ì„ê³„ê°’
        self.realistic_performance_max = 0.75  # í˜„ì‹¤ì  ì„±ëŠ¥ ìƒí•œì„ 

        print(f"ğŸ”’ ì™„ì „ ëˆ„ì¶œ ë°©ì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"   ğŸš¨ ìµœëŒ€ í—ˆìš© ìƒê´€ê´€ê³„: {self.max_allowed_correlation}")
        print(f"   ğŸ“Š í˜„ì‹¤ì  ì„±ëŠ¥ ìƒí•œ: {self.realistic_performance_max}")

    def create_ultra_safe_features(self, df):
        """ì™„ì „íˆ ì•ˆì „í•œ íŠ¹ì„± ìƒì„± (ëˆ„ì¶œ ë¶ˆê°€ëŠ¥)"""
        print("ğŸ”’ ì™„ì „íˆ ì•ˆì „í•œ íŠ¹ì„± ìƒì„±...")

        safe_df = df.copy()

        # ğŸš¨ í•µì‹¬ ì›ì¹™: ë¯¸ë˜ ì •ë³´ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
        # ëª¨ë“  íŠ¹ì„±ì€ í˜„ì¬(t) ë˜ëŠ” ê³¼ê±°(t-n)ë§Œ ì‚¬ìš©

        # 1. ê¸°ë³¸ ìˆ˜ìµë¥  (í˜„ì¬ ì‹œì )
        safe_df['returns'] = safe_df['Close'].pct_change()

        # 2. ì•ˆì „í•œ ê³¼ê±° ëª¨ë©˜í…€ (ê³¼ê±°ë§Œ)
        for period in [5, 10, 20]:
            safe_df[f'momentum_past_{period}'] = (
                safe_df['Close'] / safe_df['Close'].shift(period) - 1
            )

        # 3. ì•ˆì „í•œ ê³¼ê±° ë³€ë™ì„± (ê³¼ê±°ë§Œ)
        for window in [10, 20]:
            safe_df[f'volatility_past_{window}'] = (
                safe_df['returns'].rolling(window).std()
            )

        # 4. ì•ˆì „í•œ ê³¼ê±° ê¸°ìˆ ì  ì§€í‘œ (ê³¼ê±°ë§Œ)
        for period in [14, 20]:
            safe_df[f'sma_ratio_past_{period}'] = (
                safe_df['Close'] / safe_df['Close'].rolling(period).mean()
            )

        # 5. ì•ˆì „í•œ ê³¼ê±° ë³¼ë¥¨ íŠ¹ì„± (ê³¼ê±°ë§Œ)
        safe_df['volume_sma_20'] = safe_df['Volume'].rolling(20).mean()
        safe_df['volume_ratio_past'] = (
            safe_df['Volume'] / safe_df['volume_sma_20']
        )

        # 6. ì•ˆì „í•œ ê°€ê²© ë ˆì¸ì§€ íŠ¹ì„± (í˜„ì¬ ì‹œì ë§Œ)
        safe_df['hl_range'] = (safe_df['High'] - safe_df['Low']) / safe_df['Close']

        # ğŸš¨ íƒ€ê²Ÿ ë³€ìˆ˜ë§Œ ë¯¸ë˜ ì •ë³´ ì‚¬ìš© (ìœ ì¼í•œ ì˜ˆì™¸)
        safe_df['future_return'] = safe_df['Close'].pct_change().shift(-1)
        safe_df['direction_target'] = (safe_df['future_return'] > 0).astype(int)

        # NaN ì²˜ë¦¬
        safe_df = safe_df.fillna(method='ffill').fillna(0)
        safe_df = safe_df.replace([np.inf, -np.inf], 0)

        print(f"   âœ… ì™„ì „ ì•ˆì „ íŠ¹ì„± ìƒì„± ì™„ë£Œ: {safe_df.shape}")
        return safe_df

    def validate_no_leakage(self, df):
        """ì‹¤ì‹œê°„ ëˆ„ì¶œ ê²€ì¦ ì‹œìŠ¤í…œ"""
        print("ğŸ” ì‹¤ì‹œê°„ ë°ì´í„° ëˆ„ì¶œ ê²€ì¦...")

        # ì•ˆì „í•œ íŠ¹ì„±ë§Œ ì„ íƒ
        safe_features = []
        for col in df.columns:
            if col not in ['direction_target', 'future_return', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume']:
                safe_features.append(col)

        print(f"   ê²€ì¦í•  íŠ¹ì„± ìˆ˜: {len(safe_features)}")

        # íŠ¹ì„±-íƒ€ê²Ÿ ìƒê´€ê´€ê³„ ê²€ì‚¬
        suspicious_features = []
        for feature in safe_features:
            if feature in df.columns:
                corr = abs(df[feature].corr(df['direction_target']))
                if not pd.isna(corr):
                    if corr > self.max_allowed_correlation:
                        suspicious_features.append((feature, corr))
                        print(f"   âš ï¸ ì˜ì‹¬ íŠ¹ì„±: {feature} (ìƒê´€ê´€ê³„: {corr:.4f})")

        if suspicious_features:
            print(f"   ğŸš¨ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŠ¹ì„± {len(suspicious_features)}ê°œ ë°œê²¬!")
            print("   ì´ íŠ¹ì„±ë“¤ì„ ì œê±°í•˜ê³  ê³„ì†...")

            # ì˜ì‹¬ íŠ¹ì„±ë“¤ ì œê±°
            for feature, _ in suspicious_features:
                if feature in safe_features:
                    safe_features.remove(feature)
        else:
            print("   âœ… ëª¨ë“  íŠ¹ì„±ì´ ì•ˆì „ ê¸°ì¤€ í†µê³¼")

        return safe_features

    def run_ultra_safe_experiments(self, data_path='/root/workspace/data/training/sp500_2020_2024_enhanced.csv'):
        """ì™„ì „ ì•ˆì „ ì‹¤í—˜ ì‹¤í–‰"""
        print("ğŸ”’ ì™„ì „ ëˆ„ì¶œ ë°©ì§€ ì‹œìŠ¤í…œ ì‹¤í—˜ ì‹œì‘")
        print("="*70)

        try:
            # 1. ë°ì´í„° ë¡œë”© ë° ì•ˆì „ ì²˜ë¦¬
            df = self.data_processor.load_and_validate_data(data_path)
            safe_df = self.create_ultra_safe_features(df)

            # 2. ëˆ„ì¶œ ê²€ì¦
            safe_features = self.validate_no_leakage(safe_df)

            if len(safe_features) == 0:
                print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì•ˆì „ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤!")
                return None

            # 3. ì•ˆì „í•œ ëª¨ë¸ë“¤ë¡œ ì‹¤í—˜
            safe_results = self._run_safe_models(safe_df, safe_features)

            # 4. ê²°ê³¼ ê²€ì¦ ë° ê²½ê³ 
            self._validate_results(safe_results)

            return safe_results

        except Exception as e:
            print(f"âŒ ì™„ì „ ì•ˆì „ ì‹¤í—˜ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def _run_safe_models(self, safe_df, safe_features):
        """ì•ˆì „ ê²€ì¦ëœ ëª¨ë¸ë“¤ë§Œ ì‹¤í–‰"""
        print(f"\nğŸ›¡ï¸ ì•ˆì „ ê²€ì¦ëœ ëª¨ë¸ë“¤ ì‹¤í–‰ (íŠ¹ì„± ìˆ˜: {len(safe_features)})")

        # ë°ì´í„° ì¤€ë¹„
        X = safe_df[safe_features].values
        y = safe_df['direction_target'].values

        # ì•ˆì „ ì²˜ë¦¬
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        y = np.nan_to_num(y, nan=0.5, posinf=1.0, neginf=0.0).astype(int)

        # ìœ íš¨ ë°ì´í„°ë§Œ ì„ íƒ
        valid_idx = ~pd.isna(safe_df['direction_target'])
        X = X[valid_idx]
        y = y[valid_idx]

        print(f"   ìµœì¢… ë°ì´í„°: X={X.shape}, y=í´ë˜ìŠ¤ë¶„í¬{np.bincount(y)}")

        # ì•ˆì „í•œ ëª¨ë¸ë“¤ ì •ì˜
        safe_models = {
            'SafeRidge': Ridge(alpha=1.0, random_state=42),
            'SafeBayesianRidge': BayesianRidge(),
            'SafeRandomForest': RandomForestRegressor(
                n_estimators=50, max_depth=8, random_state=42
            ),
            'SafeGradientBoosting': GradientBoostingRegressor(
                n_estimators=50, max_depth=6, random_state=42
            ),
            'SafeXGBoost': xgb.XGBRegressor(
                n_estimators=50, max_depth=6, learning_rate=0.1,
                random_state=42, verbosity=0
            ),
            'SafeCatBoost': cb.CatBoostRegressor(
                iterations=50, depth=6, learning_rate=0.1,
                random_seed=42, verbose=False
            )
        }

        # ì—„ê²©í•œ ì‹œê°„ ìˆœì„œ êµì°¨ ê²€ì¦
        tscv = TimeSeriesSplit(n_splits=3)
        model_results = {}

        for model_name, model in safe_models.items():
            print(f"\n   ğŸ”’ {model_name} ì•ˆì „ ì‹¤í—˜...")

            fold_accuracies = []
            fold_maes = []
            fold_r2s = []

            for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
                X_train, X_val = X[train_idx], X[val_idx]
                y_train, y_val = y[train_idx], y[val_idx]

                # ì•ˆì „í•œ ìŠ¤ì¼€ì¼ë§
                scaler = RobustScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_val_scaled = scaler.transform(X_val)

                try:
                    # ëª¨ë¸ í›ˆë ¨
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_val_scaled)

                    # ì„±ëŠ¥ ê³„ì‚°
                    mae = mean_absolute_error(y_val, y_pred)
                    r2 = r2_score(y_val, y_pred)

                    # ë°©í–¥ ì •í™•ë„ (íšŒê·€â†’ë¶„ë¥˜ ë³€í™˜)
                    y_pred_direction = (y_pred > 0.5).astype(int)
                    direction_acc = np.mean(y_pred_direction == y_val)

                    fold_accuracies.append(direction_acc)
                    fold_maes.append(mae)
                    fold_r2s.append(r2)

                    print(f"      Fold {fold+1}: ë°©í–¥ì •í™•ë„={direction_acc:.4f}, MAE={mae:.6f}, RÂ²={r2:.4f}")

                except Exception as e:
                    print(f"      Fold {fold+1} ì‹¤íŒ¨: {e}")
                    fold_accuracies.append(0.5)
                    fold_maes.append(1.0)
                    fold_r2s.append(-1.0)

            # í‰ê·  ì„±ëŠ¥
            avg_accuracy = np.mean(fold_accuracies)
            avg_mae = np.mean(fold_maes)
            avg_r2 = np.mean(fold_r2s)

            model_results[model_name] = {
                'direction_accuracy': avg_accuracy,
                'mae': avg_mae,
                'r2': avg_r2,
                'fold_accuracies': fold_accuracies
            }

            print(f"   âœ… {model_name} í‰ê· : ë°©í–¥ì •í™•ë„={avg_accuracy:.4f}, MAE={avg_mae:.6f}, RÂ²={avg_r2:.4f}")

        return model_results

    def _validate_results(self, results):
        """ê²°ê³¼ ê²€ì¦ ë° ê²½ê³  ì‹œìŠ¤í…œ"""
        print("\nğŸš¨ ê²°ê³¼ ê²€ì¦ ë° ê²½ê³  ì‹œìŠ¤í…œ")
        print("="*50)

        for model_name, metrics in results.items():
            accuracy = metrics['direction_accuracy']
            r2 = metrics['r2']

            # ì„±ëŠ¥ ê²€ì¦
            if accuracy > 0.9:
                print(f"ğŸš¨ {model_name}: {accuracy:.1%} - ì—¬ì „íˆ ëˆ„ì¶œ ì˜ì‹¬!")
            elif accuracy > 0.75:
                print(f"âš ï¸ {model_name}: {accuracy:.1%} - ë†’ì€ ì„±ëŠ¥, ì¬ê²€ì¦ ê¶Œì¥")
            elif accuracy > 0.6:
                print(f"âœ… {model_name}: {accuracy:.1%} - ì–‘í˜¸í•œ ì„±ëŠ¥")
            else:
                print(f"ğŸ“Š {model_name}: {accuracy:.1%} - í˜„ì‹¤ì  ì„±ëŠ¥")

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
        best_model = max(results.keys(), key=lambda k: results[k]['direction_accuracy'])
        best_acc = results[best_model]['direction_accuracy']

        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best_model} ({best_acc:.1%})")

        if best_acc > 0.85:
            print("ğŸš¨ ê²½ê³ : ì—¬ì „íˆ ë†’ì€ ì„±ëŠ¥, ì¶”ê°€ ëˆ„ì¶œ ê²€ì¦ í•„ìš”!")
        elif best_acc > 0.7:
            print("ğŸ“Š ì–‘í˜¸: í•©ë¦¬ì  ì„±ëŠ¥ ë²”ìœ„")
        else:
            print("âœ… ì•ˆì „: í˜„ì‹¤ì  ì„±ëŠ¥, ëˆ„ì¶œ ì—†ìŒ í™•ì¸")

        # ê²°ê³¼ ì €ì¥
        output_path = f"/root/workspace/data/results/ultra_safe_no_leak_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        try:
            with open(output_path, 'w') as f:
                json.dump({
                    'timestamp': datetime.now().isoformat(),
                    'experiment_type': 'ultra_safe_no_leak_system',
                    'max_allowed_correlation': self.max_allowed_correlation,
                    'realistic_performance_max': self.realistic_performance_max,
                    'results': {k: {**v, 'fold_accuracies': [float(x) for x in v['fold_accuracies']]}
                              for k, v in results.items()}
                }, f, indent=2)
            print(f"\nğŸ’¾ ì•ˆì „í•œ ê²°ê³¼ ì €ì¥: {output_path}")
        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    system = UltraSafeNoLeakSystem()
    results = system.run_ultra_safe_experiments()

    if results:
        print("\nğŸ‰ ì™„ì „ ëˆ„ì¶œ ë°©ì§€ ì‹¤í—˜ ì™„ë£Œ!")
        print("âœ… ëª¨ë“  ê²°ê³¼ê°€ ëˆ„ì¶œ ê²€ì¦ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ì™„ì „ ëˆ„ì¶œ ë°©ì§€ ì‹¤í—˜ ì‹¤íŒ¨!")

    return results

if __name__ == "__main__":
    main()