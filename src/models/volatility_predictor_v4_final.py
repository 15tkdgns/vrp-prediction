#!/usr/bin/env python3
"""
ë³€ë™ì„± ì˜ˆì¸¡ V4 Final: ì™„ì „í•œ ë°ì´í„° ëˆ„ì¶œ ì œê±°
íƒ€ê²Ÿ ì¬ì„¤ê³„: returns[t+1:t+21].std() (100% ë¯¸ë˜ ë°ì´í„°)

ëª©í‘œ: RÂ² 0.33 â†’ 0.40+ (ëˆ„ì¶œ ì™„ì „ ì œê±°)
"""

import pandas as pd
import numpy as np
import yfinance as yf
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import r2_score
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class VolatilityPredictorV4Final:
    """ì™„ì „ ëˆ„ì¶œ ì œê±° V4"""

    def __init__(self, ticker="SPY", start_date="2015-01-01", end_date="2024-12-31"):
        self.ticker = ticker
        self.start_date = start_date
        self.end_date = end_date
        self.data = None
        self.results = {}

    def load_and_engineer_features(self):
        """ì™„ì „í•œ ì‹œê°„ì  ë¶„ë¦¬"""
        print(f"ğŸ“‚ {self.ticker} ë°ì´í„° ë¡œë“œ ì¤‘...")

        spy = yf.Ticker(self.ticker)
        df = spy.history(start=self.start_date, end=self.end_date)
        df.index = pd.to_datetime(df.index).tz_localize(None)

        print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(df)} ìƒ˜í”Œ")

        # ê¸°ë³¸ ê³„ì‚°
        df['returns'] = np.log(df['Close'] / df['Close'].shift(1))

        print("\nğŸ”§ íŠ¹ì„± ìƒì„± (ì™„ì „ ë¶„ë¦¬ ë³´ì¥)...")

        # === íƒ€ê²Ÿ: ë¯¸ë˜ 20ì¼ ë³€ë™ì„± (ì™„ì „ ë¯¸ë˜) ===
        # âœ… returns[t+1:t+21].std() (t+1ë¶€í„° ì‹œì‘ â†’ ê²¹ì¹¨ 0)
        df['target_vol_future'] = df['returns'].iloc[::-1].rolling(20).std().iloc[::-1].shift(-20)

        # === íŠ¹ì„±: t-1ì¼ê¹Œì§€ë§Œ ì‚¬ìš© ===

        # 1. ê³¼ê±° ë³€ë™ì„±
        df['vol_5d'] = df['returns'].rolling(5).std().shift(1)
        df['vol_10d'] = df['returns'].rolling(10).std().shift(1)
        df['vol_20d'] = df['returns'].rolling(20).std().shift(1)
        df['vol_60d'] = df['returns'].rolling(60).std().shift(1)

        # 2. ATR
        df['high_low'] = (df['High'] - df['Low']).shift(1)
        df['true_range'] = df[['High', 'Low', 'Close']].apply(
            lambda x: max(x['High'] - x['Low'],
                         abs(x['High'] - x['Close']),
                         abs(x['Low'] - x['Close'])), axis=1
        ).shift(1)
        df['atr_14'] = df['true_range'].rolling(14).mean().shift(1)

        # 3. Gap
        df['gap_size'] = abs((df['Open'] - df['Close'].shift(1)) / df['Close'].shift(1)).shift(1)
        df['large_gap_freq'] = (df['gap_size'] > df['gap_size'].quantile(0.9)).rolling(20).sum().shift(1)

        # 4. Volume
        df['volume_ratio'] = (df['Volume'] / df['Volume'].rolling(20).mean()).shift(1)
        df['volume_spike_freq'] = (df['volume_ratio'] > 1.5).rolling(20).sum().shift(1)

        # 5. Momentum
        df['momentum_5'] = (df['Close'].shift(1) / df['Close'].shift(6) - 1)
        df['momentum_20'] = (df['Close'].shift(1) / df['Close'].shift(21) - 1)
        df['momentum_strength'] = df['momentum_20'].abs()

        # 6. Vol-of-vol
        df['vol_of_vol'] = df['vol_20d'].rolling(20).std().shift(1)

        # 7. Parkinson vol
        df['parkinson_vol'] = np.sqrt(
            1 / (4 * np.log(2)) * (np.log(df['High'] / df['Low']) ** 2)
        ).shift(1)

        # 8. Lag features
        df['vol_lag_1'] = df['vol_20d'].shift(1)
        df['vol_lag_2'] = df['vol_20d'].shift(2)
        df['vol_lag_5'] = df['vol_20d'].shift(5)
        df['vol_lag_10'] = df['vol_20d'].shift(10)

        # 9. ê·¹ë‹¨ê°’
        df['extreme_return'] = (df['returns'].abs() > df['returns'].rolling(60).std() * 2).astype(int).shift(1)
        df['extreme_freq'] = df['extreme_return'].rolling(20).sum().shift(1)

        # 10. ìƒí˜¸ì‘ìš©
        df['atr_x_volume'] = df['atr_14'] * df['volume_ratio']
        df['gap_x_momentum'] = df['gap_size'] * df['momentum_strength']

        df = df.dropna()
        self.data = df

        print(f"âœ… íŠ¹ì„± ìƒì„± ì™„ë£Œ: {df.shape[1]}ê°œ ì»¬ëŸ¼, {len(df)} ìƒ˜í”Œ")
        print(f"âœ… íƒ€ê²Ÿ: returns[t+1:t+21].std() (ì™„ì „ ë¯¸ë˜)")
        print(f"âœ… íŠ¹ì„±: ëª¨ë‘ t-1ì¼ê¹Œì§€ (ì™„ì „ ë¶„ë¦¬)")

        return True

    def method1_pattern_ridge_v4(self):
        """ë°©ë²• 1: íŒ¨í„´ Ridge (ì™„ì „ ë¶„ë¦¬)"""
        print("\nğŸ”¹ ë°©ë²• 1: Pattern Ridge V4...")

        features = [
            'vol_20d', 'vol_lag_1', 'vol_lag_2', 'vol_lag_5',
            'atr_14', 'gap_size', 'large_gap_freq',
            'volume_ratio', 'volume_spike_freq',
            'momentum_strength', 'vol_of_vol',
            'parkinson_vol', 'extreme_freq',
            'atr_x_volume', 'gap_x_momentum'
        ]

        X = self.data[features].dropna()
        y = self.data.loc[X.index, 'target_vol_future']

        r2 = self._train_and_evaluate(X, y, Ridge(alpha=1.0), "Pattern Ridge V4")

        self.results['method1_ridge_v4'] = {'r2': r2}
        return r2

    def method2_xgboost_v4(self):
        """ë°©ë²• 2: XGBoost V4"""
        print("\nğŸ”¹ ë°©ë²• 2: XGBoost V4...")

        features = [
            'vol_20d', 'vol_lag_1', 'vol_lag_5',
            'atr_14', 'gap_size', 'volume_ratio',
            'momentum_strength', 'vol_of_vol',
            'parkinson_vol', 'atr_x_volume'
        ]

        X = self.data[features].dropna()
        y = self.data.loc[X.index, 'target_vol_future']

        model = XGBRegressor(
            n_estimators=100,
            max_depth=3,
            learning_rate=0.05,
            subsample=0.8,
            random_state=42,
            verbosity=0
        )

        r2 = self._train_and_evaluate(X, y, model, "XGBoost V4")

        self.results['method2_xgboost_v4'] = {'r2': r2}
        return r2

    def method3_vix_v4(self):
        """ë°©ë²• 3: VIX + íŒ¨í„´ V4"""
        print("\nğŸ”¹ ë°©ë²• 3: VIX + Ridge V4...")

        try:
            vix = yf.Ticker("^VIX")
            vix_data = vix.history(start=self.start_date, end=self.end_date)
            vix_data.index = pd.to_datetime(vix_data.index).tz_localize(None)

            df = self.data.copy()
            df['vix'] = vix_data['Close'].reindex(df.index, method='ffill').shift(1)
            df['vix_change'] = df['vix'].pct_change(5)

            df = df.dropna()

            features = [
                'vix', 'vix_change',
                'vol_20d', 'vol_lag_1', 'atr_14',
                'gap_size', 'volume_ratio',
                'momentum_strength', 'vol_of_vol'
            ]

            X = df[features]
            y = df['target_vol_future']

            r2 = self._train_and_evaluate(X, y, Ridge(alpha=1.0), "VIX + Ridge V4")

            self.results['method3_vix_v4'] = {'r2': r2}
            return r2

        except Exception as e:
            print(f"   âš ï¸  VIX ì‹¤íŒ¨: {e}")
            self.results['method3_vix_v4'] = {'r2': 0.0}
            return 0.0

    def method4_stacking_v4(self):
        """ë°©ë²• 4: Stacking V4"""
        print("\nğŸ”¹ ë°©ë²• 4: Stacking V4...")

        features = [
            'vol_20d', 'vol_lag_1', 'vol_lag_5',
            'atr_14', 'gap_size', 'volume_ratio',
            'momentum_strength', 'vol_of_vol',
            'parkinson_vol', 'atr_x_volume'
        ]

        X = self.data[features].dropna()
        y = self.data.loc[X.index, 'target_vol_future']

        tscv = TimeSeriesSplit(n_splits=5)
        all_preds = []
        all_actuals = []

        for train_idx, test_idx in tscv.split(X):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            ridge = Ridge(alpha=1.0)
            xgb = XGBRegressor(n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42, verbosity=0)

            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            ridge.fit(X_train_scaled, y_train)
            xgb.fit(X_train, y_train)

            ridge_pred = ridge.predict(X_test_scaled)
            xgb_pred = xgb.predict(X_test)

            ensemble_pred = 0.6 * ridge_pred + 0.4 * xgb_pred

            all_preds.extend(ensemble_pred)
            all_actuals.extend(y_test)

        r2 = r2_score(all_actuals, all_preds)
        print(f"   Stacking V4 RÂ²: {r2:.4f}")

        self.results['method4_stacking_v4'] = {'r2': r2}
        return r2

    def _train_and_evaluate(self, X, y, model, method_name):
        """TimeSeriesSplit í‰ê°€"""
        tscv = TimeSeriesSplit(n_splits=5)
        scores = []

        for train_idx, test_idx in tscv.split(X):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            if isinstance(model, Ridge):
                scaler = StandardScaler()
                X_train = scaler.fit_transform(X_train)
                X_test = scaler.transform(X_test)

            model.fit(X_train, y_train)
            pred = model.predict(X_test)

            r2 = r2_score(y_test, pred)
            scores.append(r2)

        mean_r2 = np.mean(scores)
        print(f"   {method_name} RÂ²: {mean_r2:.4f} (Â±{np.std(scores):.4f})")

        return mean_r2

    def run_all_methods(self):
        """ì „ì²´ ì‹¤í–‰"""
        print("="*70)
        print("ğŸš€ ë³€ë™ì„± ì˜ˆì¸¡ V4 Final: ì™„ì „í•œ ë°ì´í„° ëˆ„ì¶œ ì œê±°")
        print("="*70)
        print("ê¸°ì¤€ì„ : V2 Regime RÂ² = 0.328\n")

        self.load_and_engineer_features()

        methods = [
            ("Pattern Ridge V4", self.method1_pattern_ridge_v4),
            ("XGBoost V4", self.method2_xgboost_v4),
            ("VIX + Ridge V4", self.method3_vix_v4),
            ("Stacking V4", self.method4_stacking_v4),
        ]

        scores = []

        for name, method in methods:
            try:
                r2 = method()
                scores.append((name, r2))
            except Exception as e:
                print(f"   âŒ {name} ì‹¤íŒ¨: {e}")
                scores.append((name, 0.0))

        # ìµœì¢… ë¹„êµ
        print("\n" + "="*70)
        print("ğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ (ì™„ì „ ëˆ„ì¶œ ì œê±°)")
        print("="*70)

        baseline_v2 = 0.328
        baseline_v0 = 0.303

        print(f"{'ë°©ë²•':<30s} {'RÂ²':>10s} {'vs V2':>12s} {'vs V0':>12s}")
        print("-"*70)
        print(f"{'V0 Ridge':<30s} {baseline_v0:>10.4f} {'-':>12s} {'-':>12s}")
        print(f"{'V2 Regime':<30s} {baseline_v2:>10.4f} {'-':>12s} {f'+{baseline_v2-baseline_v0:.4f}':>12s}")

        for name, r2 in sorted(scores, key=lambda x: x[1], reverse=True):
            improvement_v2 = r2 - baseline_v2
            improvement_v0 = r2 - baseline_v0
            symbol = "âœ…" if r2 > baseline_v2 else ("âš ï¸" if r2 > baseline_v0 else "âŒ")
            print(f"{name:<30s} {r2:>10.4f} {improvement_v2:>+11.4f} {improvement_v0:>+11.4f} {symbol}")

        best_method, best_r2 = max(scores, key=lambda x: x[1])

        print("\n" + "="*70)
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥: {best_method}")
        print(f"   RÂ² = {best_r2:.4f}")

        if best_r2 > 0.7:
            print(f"   âš ï¸  ê²½ê³ : RÂ² > 0.7 (ëˆ„ì¶œ ì¬í™•ì¸ í•„ìš”)")
        elif best_r2 > baseline_v2:
            print(f"   âœ… ì„±ê³µ: vs V2 ê°œì„ í­ = {best_r2 - baseline_v2:+.4f}")
        else:
            print(f"   âš ï¸  V2 ë¯¸ë‹¬: {best_r2 - baseline_v2:+.4f}")

        print("="*70)

        output = {
            'experiment': 'volatility_prediction_v4_final',
            'baseline_v0_r2': baseline_v0,
            'baseline_v2_r2': baseline_v2,
            'best_method': best_method,
            'best_r2': best_r2,
            'improvement_vs_v2': best_r2 - baseline_v2,
            'improvement_vs_v0': best_r2 - baseline_v0,
            'all_results': self.results,
            'target_design': 'returns[t+1:t+21].std() (ì™„ì „ ë¯¸ë˜)',
            'data_leakage': 'ZERO - Complete temporal separation',
            'timestamp': datetime.now().isoformat()
        }

        with open('data/raw/volatility_v4_final_results.json', 'w') as f:
            json.dump(output, f, indent=2)

        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥: data/raw/volatility_v4_final_results.json")

        return best_r2

if __name__ == "__main__":
    predictor = VolatilityPredictorV4Final()
    predictor.run_all_methods()
