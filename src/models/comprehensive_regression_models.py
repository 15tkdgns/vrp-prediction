#!/usr/bin/env python3
"""
ğŸš€ ì¢…í•© íšŒê·€ ëª¨ë¸ í•™ìŠµ ì‹œìŠ¤í…œ

SVR, KNN, Gradient Boosting, XGBoost, LightGBM ë“± ë‹¤ì–‘í•œ íšŒê·€ëª¨ë¸ ë¹„êµ
"""

import sys
sys.path.append('/root/workspace/src')

import pandas as pd
import numpy as np
from datetime import datetime
import json
import time
import warnings
warnings.filterwarnings('ignore')

# Core imports
from core.data_processor import DataProcessor

# ML imports
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import ElasticNet, Ridge, Lasso, BayesianRidge
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_absolute_error, r2_score
import xgboost as xgb
import catboost as cb

# Deep learning
import torch
import torch.nn as nn
import torch.optim as optim

class ComprehensiveRegressionModels:
    """ì¢…í•© íšŒê·€ ëª¨ë¸ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.data_processor = DataProcessor()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        print(f"ğŸš€ ì¢…í•© íšŒê·€ ëª¨ë¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")

    def prepare_regression_data(self, df, target='returns'):
        """íšŒê·€ ë°ì´í„° ì¤€ë¹„"""
        print(f"ğŸ“Š íšŒê·€ ë°ì´í„° ì¤€ë¹„ ì¤‘... (target: {target})")

        # íƒ€ê²Ÿ ìƒì„±
        if target == 'returns':
            df['target'] = df['Close'].pct_change()
        elif target == 'volatility':
            df['target'] = df['Close'].pct_change().rolling(20).std()
        elif target == 'log_returns':
            df['target'] = np.log(df['Close'] / df['Close'].shift(1))
        else:
            df['target'] = df[target]

        # íŠ¹ì„± ì„ íƒ
        numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()
        exclude_columns = ['Date', 'target', 'Open', 'High', 'Low', 'Close', 'Volume']
        feature_columns = [col for col in numeric_features if col not in exclude_columns]

        # ë°ì´í„° ì¶”ì¶œ ë° ì •ì œ
        X = df[feature_columns].values
        y = df['target'].values

        # ì•ˆì „í•œ ì „ì²˜ë¦¬
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)

        # ê·¹ê°’ ì œê±°
        valid_idx = (np.abs(y) < 0.5) & ~np.isnan(y) & ~np.isinf(y)
        X = X[valid_idx]
        y = y[valid_idx]

        print(f"   âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: X={X.shape}, y={y.shape}")
        return X, y, feature_columns

    def get_regression_models(self):
        """íšŒê·€ ëª¨ë¸ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜"""
        models = {
            # ì„ í˜• ëª¨ë¸ë“¤
            'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42),
            'Ridge': Ridge(alpha=1.0, random_state=42),
            'Lasso': Lasso(alpha=0.1, random_state=42),
            'BayesianRidge': BayesianRidge(),

            # íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ë“¤
            'RandomForest': RandomForestRegressor(
                n_estimators=100, max_depth=10, random_state=42
            ),
            'GradientBoosting': GradientBoostingRegressor(
                n_estimators=100, max_depth=6, random_state=42
            ),

            # ê³ ê¸‰ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…
            'XGBoost': xgb.XGBRegressor(
                n_estimators=100, max_depth=6, learning_rate=0.1,
                random_state=42, verbosity=0
            ),
            'CatBoost': cb.CatBoostRegressor(
                iterations=100, depth=6, learning_rate=0.1,
                random_seed=42, verbose=False
            ),

            # ì¸ìŠ¤í„´ìŠ¤ ê¸°ë°˜ ëª¨ë¸ë“¤
            'KNN': KNeighborsRegressor(n_neighbors=5),
            'SVR_linear': SVR(kernel='linear', C=1.0),
            'SVR_rbf': SVR(kernel='rbf', C=1.0, gamma='scale'),
        }

        return models

    class DeepRegressionModel(nn.Module):
        """ë”¥ëŸ¬ë‹ íšŒê·€ ëª¨ë¸"""

        def __init__(self, input_size, hidden_sizes=[128, 64, 32]):
            super().__init__()
            layers = []

            prev_size = input_size
            for hidden_size in hidden_sizes:
                layers.extend([
                    nn.Linear(prev_size, hidden_size),
                    nn.BatchNorm1d(hidden_size),
                    nn.ReLU(),
                    nn.Dropout(0.3)
                ])
                prev_size = hidden_size

            layers.append(nn.Linear(prev_size, 1))
            self.network = nn.Sequential(*layers)

        def forward(self, x):
            return self.network(x)

    def train_deep_model(self, X_train, y_train, X_val, y_val):
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨"""
        model = self.DeepRegressionModel(X_train.shape[1]).to(self.device)
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)

        # í…ì„œ ë³€í™˜
        X_train_tensor = torch.FloatTensor(X_train).to(self.device)
        y_train_tensor = torch.FloatTensor(y_train).to(self.device)
        X_val_tensor = torch.FloatTensor(X_val).to(self.device)

        # í›ˆë ¨
        model.train()
        for epoch in range(100):
            optimizer.zero_grad()
            outputs = model(X_train_tensor)
            loss = criterion(outputs.squeeze(), y_train_tensor)
            loss.backward()
            optimizer.step()

        # ì˜ˆì¸¡
        model.eval()
        with torch.no_grad():
            val_pred = model(X_val_tensor).cpu().numpy().squeeze()

        return val_pred

    def run_comprehensive_comparison(self, data_path='/root/workspace/data/training/sp500_2020_2024_enhanced.csv'):
        """ì¢…í•© íšŒê·€ ëª¨ë¸ ë¹„êµ ì‹¤í—˜"""
        print("ğŸš€ ì¢…í•© íšŒê·€ ëª¨ë¸ ë¹„êµ ì‹¤í—˜ ì‹œì‘")
        print("="*70)

        start_time = time.time()
        all_results = {}

        try:
            # ë°ì´í„° ë¡œë”©
            df = self.data_processor.load_and_validate_data(data_path)

            # ì‹¤í—˜ 1: ìˆ˜ìµë¥  ì˜ˆì¸¡
            print("\nğŸ¯ ì‹¤í—˜ 1: ìˆ˜ìµë¥  ì˜ˆì¸¡")
            X_returns, y_returns, features = self.prepare_regression_data(df, target='returns')
            if X_returns is not None:
                returns_results = self._run_model_comparison(X_returns, y_returns, 'returns')
                all_results['returns'] = returns_results

            # ì‹¤í—˜ 2: ë¡œê·¸ ìˆ˜ìµë¥  ì˜ˆì¸¡
            print("\nğŸ¯ ì‹¤í—˜ 2: ë¡œê·¸ ìˆ˜ìµë¥  ì˜ˆì¸¡")
            X_log, y_log, _ = self.prepare_regression_data(df, target='log_returns')
            if X_log is not None:
                log_results = self._run_model_comparison(X_log, y_log, 'log_returns')
                all_results['log_returns'] = log_results

            # ì‹¤í—˜ 3: ë³€ë™ì„± ì˜ˆì¸¡
            print("\nğŸ¯ ì‹¤í—˜ 3: ë³€ë™ì„± ì˜ˆì¸¡")
            X_vol, y_vol, _ = self.prepare_regression_data(df, target='volatility')
            if X_vol is not None:
                vol_results = self._run_model_comparison(X_vol, y_vol, 'volatility')
                all_results['volatility'] = vol_results

            # ê²°ê³¼ ì •ë¦¬
            total_time = time.time() - start_time
            self._summarize_comprehensive_results(all_results, total_time)

            return all_results

        except Exception as e:
            print(f"âŒ ì¢…í•© ì‹¤í—˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def _run_model_comparison(self, X, y, target_type):
        """ëª¨ë¸ ë¹„êµ ì‹¤í–‰"""
        models = self.get_regression_models()
        tscv = TimeSeriesSplit(n_splits=3)
        model_results = {}

        # ëª¨ë¸ë³„ ê²°ê³¼ ì €ì¥
        for model_name in models.keys():
            model_results[model_name] = {'mae': [], 'r2': [], 'direction_acc': []}

        # ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ê°€
        model_results['DeepNN'] = {'mae': [], 'r2': [], 'direction_acc': []}

        for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
            print(f"\nğŸ“Š Fold {fold+1}/3")

            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]

            # ë°ì´í„° ì „ì²˜ë¦¬
            imputer = SimpleImputer(strategy='mean')
            X_train_clean = imputer.fit_transform(X_train)
            X_val_clean = imputer.transform(X_val)

            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train_clean)
            X_val_scaled = scaler.transform(X_val_clean)

            # ì „í†µì  ML ëª¨ë¸ë“¤
            for model_name, model in models.items():
                try:
                    print(f"   ğŸ¤– {model_name} í›ˆë ¨...")
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_val_scaled)

                    mae = mean_absolute_error(y_val, y_pred)
                    r2 = r2_score(y_val, y_pred)

                    # ë°©í–¥ ì •í™•ë„ ê³„ì‚°
                    direction_acc = self._calculate_direction_accuracy(y_val, y_pred)

                    model_results[model_name]['mae'].append(mae)
                    model_results[model_name]['r2'].append(r2)
                    model_results[model_name]['direction_acc'].append(direction_acc)

                    print(f"      MAE={mae:.6f}, RÂ²={r2:.4f}, ë°©í–¥ì •í™•ë„={direction_acc:.4f}")

                except Exception as e:
                    print(f"      {model_name} ì˜¤ë¥˜: {e}")
                    model_results[model_name]['mae'].append(np.inf)
                    model_results[model_name]['r2'].append(-np.inf)
                    model_results[model_name]['direction_acc'].append(0.5)

            # ë”¥ëŸ¬ë‹ ëª¨ë¸
            try:
                print(f"   ğŸ§  DeepNN í›ˆë ¨...")
                deep_pred = self.train_deep_model(X_train_scaled, y_train, X_val_scaled, y_val)

                deep_mae = mean_absolute_error(y_val, deep_pred)
                deep_r2 = r2_score(y_val, deep_pred)
                deep_direction = self._calculate_direction_accuracy(y_val, deep_pred)

                model_results['DeepNN']['mae'].append(deep_mae)
                model_results['DeepNN']['r2'].append(deep_r2)
                model_results['DeepNN']['direction_acc'].append(deep_direction)

                print(f"      MAE={deep_mae:.6f}, RÂ²={deep_r2:.4f}, ë°©í–¥ì •í™•ë„={deep_direction:.4f}")

            except Exception as e:
                print(f"      DeepNN ì˜¤ë¥˜: {e}")
                model_results['DeepNN']['mae'].append(np.inf)
                model_results['DeepNN']['r2'].append(-np.inf)
                model_results['DeepNN']['direction_acc'].append(0.5)

            print(f"   âœ… Fold {fold+1} ì™„ë£Œ")

        return model_results

    def _calculate_direction_accuracy(self, y_true, y_pred):
        """ë°©í–¥ ì •í™•ë„ ê³„ì‚°"""
        if len(y_true) < 2:
            return 0.5

        true_direction = np.diff(y_true) > 0
        pred_direction = np.diff(y_pred) > 0

        if len(true_direction) == 0:
            return 0.5

        return np.mean(true_direction == pred_direction)

    def _summarize_comprehensive_results(self, all_results, total_time):
        """ì¢…í•© ê²°ê³¼ ìš”ì•½"""
        print(f"\nğŸš€ ì¢…í•© íšŒê·€ ëª¨ë¸ ë¹„êµ ê²°ê³¼ ìš”ì•½:")
        print(f"   ì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ì´ˆ")
        print("="*70)

        for target_type, model_results in all_results.items():
            print(f"\nğŸ¯ {target_type.upper()} ì˜ˆì¸¡ ê²°ê³¼:")
            print("-"*50)

            # ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥ ê³„ì‚° ë° ìˆœìœ„
            model_performance = []

            for model_name, metrics in model_results.items():
                avg_mae = np.mean(metrics['mae'])
                avg_r2 = np.mean(metrics['r2'])
                avg_direction = np.mean(metrics['direction_acc'])

                model_performance.append({
                    'model': model_name,
                    'mae': avg_mae,
                    'r2': avg_r2,
                    'direction_acc': avg_direction
                })

            # MAE ê¸°ì¤€ ì •ë ¬ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            model_performance.sort(key=lambda x: x['mae'])

            print(f"ğŸ† ì„±ëŠ¥ ìˆœìœ„ (MAE ê¸°ì¤€):")
            for i, perf in enumerate(model_performance):
                rank_emoji = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰" if i == 2 else f"{i+1:2d}."
                print(f"   {rank_emoji} {perf['model']:15s}: MAE={perf['mae']:.6f}, RÂ²={perf['r2']:+.4f}, ë°©í–¥={perf['direction_acc']:.4f}")

            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤
            best_mae = min(p['mae'] for p in model_performance if not np.isinf(p['mae']))
            best_r2 = max(p['r2'] for p in model_performance if not np.isinf(p['r2']))
            best_direction = max(p['direction_acc'] for p in model_performance)

            print(f"\nğŸ“Š ìµœê³  ì„±ëŠ¥:")
            print(f"   MAE ìµœê³ : {best_mae:.6f}")
            print(f"   RÂ² ìµœê³ : {best_r2:+.4f}")
            print(f"   ë°©í–¥ì •í™•ë„ ìµœê³ : {best_direction:.4f}")

        # ê²°ê³¼ ì €ì¥
        self._save_comprehensive_results(all_results, total_time)

    def _save_comprehensive_results(self, all_results, total_time):
        """ê²°ê³¼ ì €ì¥"""
        output_path = f"/root/workspace/data/results/comprehensive_regression_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        try:
            # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            serializable_results = {}
            for target_type, model_results in all_results.items():
                serializable_results[target_type] = {}
                for model_name, metrics in model_results.items():
                    serializable_results[target_type][model_name] = {
                        'mae_mean': float(np.mean(metrics['mae'])),
                        'mae_std': float(np.std(metrics['mae'])),
                        'r2_mean': float(np.mean(metrics['r2'])),
                        'r2_std': float(np.std(metrics['r2'])),
                        'direction_acc_mean': float(np.mean(metrics['direction_acc'])),
                        'direction_acc_std': float(np.std(metrics['direction_acc']))
                    }

            with open(output_path, 'w') as f:
                json.dump({
                    'timestamp': datetime.now().isoformat(),
                    'total_time': total_time,
                    'results': serializable_results
                }, f, indent=2)

            print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    system = ComprehensiveRegressionModels()
    results = system.run_comprehensive_comparison()

    print("\nğŸ‰ ì¢…í•© íšŒê·€ ëª¨ë¸ ë¹„êµ ì™„ë£Œ!")
    return results

if __name__ == "__main__":
    main()