#!/usr/bin/env python3
"""
ì‹œê³„ì—´ íŠ¹í™” ì–´í…ì…˜ ëª¨ë¸ ì•„í‚¤í…ì²˜
ìºê¸€ ìš°ìŠ¹ì ê¸°ë²•: Multi-horizon ì˜ˆì¸¡ + Attention ë©”ì»¤ë‹ˆì¦˜
ì•ˆì „í•˜ê³  íš¨ê³¼ì ì¸ ì‹œê³„ì—´ ëª¨ë¸ë§
"""

import sys
sys.path.append('/root/workspace')

import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Tuple, Optional
from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.linear_model import Ridge
import warnings
warnings.filterwarnings('ignore')

from src.features.kaggle_advanced_features import KaggleAdvancedFeatureEngineer
from src.core.ultra_safe_data_processor import UltraSafeDataProcessor
from src.validation.auto_leakage_detector import AutoLeakageDetector

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SafeTemporalAttention:
    """ì•ˆì „í•œ ì‹œê°„ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜"""

    def __init__(self, sequence_length: int = 20, attention_dim: int = 16):
        self.sequence_length = sequence_length
        self.attention_dim = attention_dim
        self.attention_weights_ = None
        self.scaler_ = StandardScaler()

    def _compute_attention_scores(self, X_sequence):
        """ì–´í…ì…˜ ì ìˆ˜ ê³„ì‚° (ê°„ì†Œí™”ëœ ë²„ì „)"""
        batch_size, seq_len, n_features = X_sequence.shape

        # ê° ì‹œì ì˜ ì¤‘ìš”ë„ ê³„ì‚° (ë³€ë™ì„± ê¸°ë°˜)
        attention_scores = np.zeros((batch_size, seq_len))

        for i in range(batch_size):
            for t in range(seq_len):
                # ë³€ë™ì„± ê¸°ë°˜ ì¤‘ìš”ë„ (ìµœê·¼ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
                time_weight = np.exp(-0.1 * (seq_len - t - 1))  # ì§€ìˆ˜ ê°ì†Œ
                feature_variance = np.var(X_sequence[i, t, :])   # íŠ¹ì§• ë¶„ì‚°
                attention_scores[i, t] = time_weight * (1 + feature_variance)

        # Softmax ì •ê·œí™”
        exp_scores = np.exp(attention_scores - np.max(attention_scores, axis=1, keepdims=True))
        attention_weights = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)

        return attention_weights

    def fit(self, X, y=None):
        """ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ í•™ìŠµ"""
        logger.info("ì‹œê°„ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ í•™ìŠµ")

        if len(X.shape) == 2:
            # 2D ì…ë ¥ì„ 3D ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
            X_sequences = self._create_sequences(X)
        else:
            X_sequences = X

        # ì–´í…ì…˜ ê°€ì¤‘ì¹˜ í•™ìŠµ
        self.attention_weights_ = self._compute_attention_scores(X_sequences)

        # ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ
        attended_features = self._apply_attention(X_sequences, self.attention_weights_)
        self.scaler_.fit(attended_features)

        return self

    def transform(self, X):
        """ì–´í…ì…˜ ì ìš©ëœ íŠ¹ì§• ìƒì„±"""
        if len(X.shape) == 2:
            X_sequences = self._create_sequences(X)
        else:
            X_sequences = X

        # ì–´í…ì…˜ ì ìš©
        attention_weights = self._compute_attention_scores(X_sequences)
        attended_features = self._apply_attention(X_sequences, attention_weights)

        # ìŠ¤ì¼€ì¼ë§
        attended_features_scaled = self.scaler_.transform(attended_features)

        return attended_features_scaled

    def _create_sequences(self, X):
        """2D ë°ì´í„°ë¥¼ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜"""
        n_samples, n_features = X.shape
        seq_len = min(self.sequence_length, n_samples)

        X_sequences = np.zeros((n_samples, seq_len, n_features))

        for i in range(n_samples):
            start_idx = max(0, i - seq_len + 1)
            actual_len = min(seq_len, i + 1)

            # ê³¼ê±° ë°ì´í„°ë¡œ ì‹œí€€ìŠ¤ êµ¬ì„±
            for j in range(actual_len):
                X_sequences[i, seq_len - actual_len + j, :] = X[start_idx + j, :]

        return X_sequences

    def _apply_attention(self, X_sequences, attention_weights):
        """ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì ìš©"""
        batch_size, seq_len, n_features = X_sequences.shape

        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        attended_features = np.zeros((batch_size, n_features))

        for i in range(batch_size):
            for f in range(n_features):
                attended_features[i, f] = np.sum(
                    attention_weights[i, :] * X_sequences[i, :, f]
                )

        return attended_features

class MultiHorizonPredictor:
    """ë‹¤ì¤‘ ì‹œì  ì˜ˆì¸¡ ëª¨ë¸"""

    def __init__(self, horizons: List[int] = [1, 3, 5], primary_horizon: int = 1):
        self.horizons = horizons
        self.primary_horizon = primary_horizon
        self.models_ = {}
        self.auxiliary_weight = 0.3  # ë³´ì¡° ì†ì‹¤ ê°€ì¤‘ì¹˜

    def _create_multi_targets(self, y):
        """ë‹¤ì¤‘ ì‹œì  íƒ€ê²Ÿ ìƒì„±"""
        n_samples = len(y)
        targets = {}

        for horizon in self.horizons:
            targets[horizon] = np.zeros(n_samples)
            targets[horizon][:] = np.nan

            # ê° ì‹œì ì— ëŒ€í•œ íƒ€ê²Ÿ ìƒì„±
            for i in range(n_samples - horizon):
                if horizon == 1:
                    targets[horizon][i] = y[i + horizon]
                else:
                    # ì—¬ëŸ¬ ì‹œì ì˜ í‰ê·  ìˆ˜ìµë¥ 
                    targets[horizon][i] = np.mean(y[i+1:i+horizon+1])

        return targets

    def fit(self, X, y):
        """ë‹¤ì¤‘ ì‹œì  ëª¨ë¸ í›ˆë ¨"""
        logger.info("ë‹¤ì¤‘ ì‹œì  ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨")

        # ë‹¤ì¤‘ íƒ€ê²Ÿ ìƒì„±
        multi_targets = self._create_multi_targets(y)

        # ê° ì‹œì ë³„ ëª¨ë¸ í›ˆë ¨
        for horizon in self.horizons:
            logger.info(f"  {horizon}ì¼ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨")

            target = multi_targets[horizon]
            valid_mask = ~np.isnan(target)

            if np.sum(valid_mask) < len(target) * 0.5:
                logger.warning(f"  {horizon}ì¼ íƒ€ê²Ÿì˜ ìœ íš¨ ë°ì´í„° ë¶€ì¡±")
                continue

            # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì‚¬ìš©
            X_valid = X[valid_mask]
            y_valid = target[valid_mask]

            # ë³´ìˆ˜ì ì¸ Ridge ëª¨ë¸ ì‚¬ìš©
            alpha = 50.0 if horizon == self.primary_horizon else 100.0
            model = Ridge(alpha=alpha)
            model.fit(X_valid, y_valid)

            self.models_[horizon] = model

        return self

    def predict(self, X):
        """ë‹¤ì¤‘ ì‹œì  ì˜ˆì¸¡ (ì£¼ìš” ì‹œì  ë°˜í™˜)"""
        if self.primary_horizon not in self.models_:
            raise ValueError(f"ì£¼ìš” ì‹œì  {self.primary_horizon} ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")

        primary_pred = self.models_[self.primary_horizon].predict(X)

        # ë³´ì¡° ì˜ˆì¸¡ë“¤ê³¼ ì•™ìƒë¸”
        if len(self.models_) > 1:
            auxiliary_preds = []
            for horizon, model in self.models_.items():
                if horizon != self.primary_horizon:
                    aux_pred = model.predict(X)
                    auxiliary_preds.append(aux_pred)

            if auxiliary_preds:
                # ë³´ì¡° ì˜ˆì¸¡ë“¤ì˜ í‰ê· 
                aux_ensemble = np.mean(auxiliary_preds, axis=0)
                # ì£¼ìš” ì˜ˆì¸¡ê³¼ ë³´ì¡° ì˜ˆì¸¡ ê²°í•©
                final_pred = (1 - self.auxiliary_weight) * primary_pred + \
                           self.auxiliary_weight * aux_ensemble
            else:
                final_pred = primary_pred
        else:
            final_pred = primary_pred

        return final_pred

    def get_auxiliary_predictions(self, X):
        """ëª¨ë“  ì‹œì ì˜ ì˜ˆì¸¡ê°’ ë°˜í™˜"""
        predictions = {}
        for horizon, model in self.models_.items():
            predictions[horizon] = model.predict(X)
        return predictions

class TimeSeriesAttentionModel(BaseEstimator, RegressorMixin):
    """ì‹œê³„ì—´ ì–´í…ì…˜ ëª¨ë¸ (í†µí•©)"""

    def __init__(self, sequence_length: int = 15, attention_dim: int = 16,
                 horizons: List[int] = [1, 3, 5], use_attention: bool = True):
        self.sequence_length = sequence_length
        self.attention_dim = attention_dim
        self.horizons = horizons
        self.use_attention = use_attention

        # êµ¬ì„±ìš”ì†Œ
        self.attention_module = SafeTemporalAttention(sequence_length, attention_dim) if use_attention else None
        self.multi_horizon_predictor = MultiHorizonPredictor(horizons, primary_horizon=1)

        # ìŠ¤ì¼€ì¼ëŸ¬
        self.feature_scaler_ = StandardScaler()

    def fit(self, X, y):
        """í†µí•© ëª¨ë¸ í›ˆë ¨"""
        logger.info("ì‹œê³„ì—´ ì–´í…ì…˜ ëª¨ë¸ í›ˆë ¨")

        # 1. íŠ¹ì§• ìŠ¤ì¼€ì¼ë§
        X_scaled = self.feature_scaler_.fit_transform(X)

        # 2. ì–´í…ì…˜ ëª¨ë“ˆ í›ˆë ¨ ë° ì ìš©
        if self.use_attention:
            X_attended = self.attention_module.fit_transform(X_scaled)
        else:
            X_attended = X_scaled

        # 3. ë‹¤ì¤‘ ì‹œì  ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨
        self.multi_horizon_predictor.fit(X_attended, y)

        return self

    def predict(self, X):
        """í†µí•© ì˜ˆì¸¡"""
        # 1. íŠ¹ì§• ìŠ¤ì¼€ì¼ë§
        X_scaled = self.feature_scaler_.transform(X)

        # 2. ì–´í…ì…˜ ì ìš©
        if self.use_attention:
            X_attended = self.attention_module.transform(X_scaled)
        else:
            X_attended = X_scaled

        # 3. ë‹¤ì¤‘ ì‹œì  ì˜ˆì¸¡
        predictions = self.multi_horizon_predictor.predict(X_attended)

        return predictions

class SafeTimeSeriesSystem:
    """ì•ˆì „í•œ ì‹œê³„ì—´ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.data_processor = UltraSafeDataProcessor()
        self.feature_engineer = KaggleAdvancedFeatureEngineer(safety_mode=True)
        self.leakage_detector = AutoLeakageDetector()

        # ì—„ê²©í•œ ì•ˆì „ ê¸°ì¤€
        self.MAX_R2 = 0.12
        self.MAX_DIRECTION_ACC = 62.0

        # ì‹œê³„ì—´ ëª¨ë¸ë“¤
        self.models = {
            'attention_multi': TimeSeriesAttentionModel(
                sequence_length=15, use_attention=True, horizons=[1, 3, 5]
            ),
            'simple_multi': TimeSeriesAttentionModel(
                sequence_length=10, use_attention=False, horizons=[1, 3]
            ),
            'baseline_single': TimeSeriesAttentionModel(
                sequence_length=5, use_attention=False, horizons=[1]
            )
        }

        self.fitted_models_ = {}
        self.ensemble_weights_ = None

        logger.info("ì•ˆì „í•œ ì‹œê³„ì—´ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")

    def run_time_series_optimization(self, data_path: str):
        """ì‹œê³„ì—´ ëª¨ë¸ ìµœì í™” ì‹¤í–‰"""
        logger.info("=" * 100)
        logger.info("ğŸ• ì‹œê³„ì—´ íŠ¹í™” ì–´í…ì…˜ ëª¨ë¸ ì‹œìŠ¤í…œ ì‹¤í–‰")
        logger.info("=" * 100)

        # 1. ê³ ê¸‰ íŠ¹ì§• ë°ì´í„° ì¤€ë¹„
        data_dict = self.data_processor.prepare_ultra_safe_data(data_path)
        X_base, y = data_dict['X'], data_dict['y']

        # ìºê¸€ ê³ ê¸‰ íŠ¹ì§• ì ìš©
        X_enhanced = self.feature_engineer.fit_transform(X_base)

        # 2. ë°ì´í„° ë¶„í• 
        split_point = int(len(X_enhanced) * 0.8)
        X_train = X_enhanced[:split_point]
        X_test = X_enhanced[split_point:]
        y_train = y[:split_point]
        y_test = y[split_point:]

        logger.info(f"ë°ì´í„° ì¤€ë¹„: train={X_train.shape}, test={X_test.shape}")

        # 3. ì‹œê³„ì—´ ëª¨ë¸ë³„ í›ˆë ¨ ë° í‰ê°€
        logger.info("\nì‹œê³„ì—´ ëª¨ë¸ ê°œë³„ ì„±ëŠ¥ í‰ê°€")
        model_results = {}

        for model_name, model in self.models.items():
            try:
                logger.info(f"\n{model_name} í›ˆë ¨ ë° í‰ê°€")

                # ëª¨ë¸ í›ˆë ¨
                fitted_model = model.fit(X_train, y_train)
                self.fitted_models_[model_name] = fitted_model

                # ì˜ˆì¸¡ ë° í‰ê°€
                y_pred = fitted_model.predict(X_test)

                # ì„±ëŠ¥ ì§€í‘œ
                mse = mean_squared_error(y_test, y_pred)
                mae = mean_absolute_error(y_test, y_pred)
                r2 = 1 - (mse / np.var(y_test))

                direction_actual = (y_test > 0).astype(int)
                direction_pred = (y_pred > 0).astype(int)
                direction_acc = np.mean(direction_actual == direction_pred) * 100

                model_results[model_name] = {
                    'r2': r2, 'mae': mae, 'direction_acc': direction_acc,
                    'predictions': y_pred
                }

                logger.info(f"  RÂ²: {r2:.4f}")
                logger.info(f"  MAE: {mae:.4f}")
                logger.info(f"  ë°©í–¥ì •í™•ë„: {direction_acc:.1f}%")

                # ì•ˆì „ì„± ê²€ì¦
                metrics = {'r2': r2, 'direction_accuracy': direction_acc}
                is_safe = self.leakage_detector.validate_during_training(0, model_name, metrics)

                if not is_safe:
                    logger.warning(f"  {model_name} ì•ˆì „ ê¸°ì¤€ ìœ„í—˜")

            except Exception as e:
                logger.error(f"  {model_name} ì‹¤íŒ¨: {e}")

        # 4. ì‹œê³„ì—´ ì•™ìƒë¸” êµ¬ì„±
        logger.info(f"\nì‹œê³„ì—´ ëª¨ë¸ ì•™ìƒë¸” êµ¬ì„±")

        # ì•ˆì „í•œ ëª¨ë¸ë“¤ë§Œ ì„ íƒ
        safe_models = []
        safe_predictions = []

        for model_name, result in model_results.items():
            r2 = result['r2']
            direction_acc = result['direction_acc']

            if r2 <= self.MAX_R2 and direction_acc <= self.MAX_DIRECTION_ACC:
                safe_models.append(model_name)
                safe_predictions.append(result['predictions'])
                logger.info(f"  {model_name}: ì•™ìƒë¸”ì— í¬í•¨")

        # 5. ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”
        if len(safe_predictions) > 1:
            safe_predictions = np.array(safe_predictions)

            # ê°„ë‹¨í•œ ê°€ì¤‘ì¹˜ ìµœì í™”
            best_weights = None
            best_score = float('inf')

            for w1 in np.arange(0.2, 0.8, 0.1):
                if len(safe_predictions) == 2:
                    weights = np.array([w1, 1-w1])
                elif len(safe_predictions) == 3:
                    for w2 in np.arange(0.1, 0.8-w1, 0.1):
                        w3 = 1 - w1 - w2
                        if w3 > 0.1:
                            weights = np.array([w1, w2, w3])
                        else:
                            continue
                else:
                    # ê· ë“± ê°€ì¤‘ì¹˜
                    weights = np.ones(len(safe_predictions)) / len(safe_predictions)

                ensemble_pred = np.average(safe_predictions, weights=weights, axis=0)
                score = mean_squared_error(y_test, ensemble_pred)

                if score < best_score:
                    best_score = score
                    best_weights = weights

            if best_weights is None:
                best_weights = np.ones(len(safe_predictions)) / len(safe_predictions)

            # ìµœì¢… ì•™ìƒë¸” ì˜ˆì¸¡
            final_pred = np.average(safe_predictions, weights=best_weights, axis=0)

        elif len(safe_predictions) == 1:
            best_weights = np.array([1.0])
            final_pred = safe_predictions[0]
        else:
            logger.error("ì•ˆì „í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
            return None

        # 6. ìµœì¢… ì„±ëŠ¥ í‰ê°€
        final_mse = mean_squared_error(y_test, final_pred)
        final_mae = mean_absolute_error(y_test, final_pred)
        final_r2 = 1 - (final_mse / np.var(y_test))

        final_direction_actual = (y_test > 0).astype(int)
        final_direction_pred = (final_pred > 0).astype(int)
        final_direction_acc = np.mean(final_direction_actual == final_direction_pred) * 100

        # ìµœì¢… ì•ˆì „ì„± ê²€ì¦
        final_metrics = {'r2': final_r2, 'direction_accuracy': final_direction_acc}
        final_safety = self.leakage_detector.validate_during_training(0, 'ts_ensemble', final_metrics)
        safe_performance = (final_r2 <= self.MAX_R2 and final_direction_acc <= self.MAX_DIRECTION_ACC)

        # 7. ê²°ê³¼ ì¶œë ¥
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ• ì‹œê³„ì—´ ì–´í…ì…˜ ëª¨ë¸ ìµœì¢… ì„±ëŠ¥")
        logger.info(f"{'='*80}")
        logger.info(f"RÂ²: {final_r2:.4f} ({'âœ… ì•ˆì „' if final_r2 <= self.MAX_R2 else 'âŒ ìœ„í—˜'})")
        logger.info(f"MAE: {final_mae:.4f}")
        logger.info(f"ë°©í–¥ì •í™•ë„: {final_direction_acc:.1f}% ({'âœ… ì•ˆì „' if final_direction_acc <= self.MAX_DIRECTION_ACC else 'âŒ ìœ„í—˜'})")

        logger.info(f"\nì•™ìƒë¸” êµ¬ì„±:")
        for i, (model_name, weight) in enumerate(zip(safe_models, best_weights)):
            logger.info(f"  {model_name}: {weight:.3f}")

        success = final_safety and safe_performance
        logger.info(f"\nìµœì¢… ì•ˆì „ì„±: {'âœ… ì„±ê³µ' if success else 'âŒ ì‹¤íŒ¨'}")

        return {
            'final_performance': {
                'r2': final_r2,
                'mae': final_mae,
                'direction_accuracy': final_direction_acc
            },
            'individual_results': model_results,
            'ensemble_models': safe_models,
            'ensemble_weights': dict(zip(safe_models, best_weights)),
            'safety_check': success,
            'fitted_models': self.fitted_models_
        }

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    system = SafeTimeSeriesSystem()

    try:
        results = system.run_time_series_optimization(
            '/root/workspace/data/training/sp500_2020_2024_enhanced.csv'
        )

        if results is None:
            print("âŒ ì‹œê³„ì—´ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨")
            return None

        print(f"\n{'='*100}")
        print(f"ğŸ• ì‹œê³„ì—´ ì–´í…ì…˜ ëª¨ë¸ ì‹œìŠ¤í…œ ì™„ë£Œ")
        print(f"{'='*100}")

        # ìµœì¢… ì„±ëŠ¥
        final_perf = results['final_performance']
        print(f"\nğŸ“Š ìµœì¢… ì•™ìƒë¸” ì„±ëŠ¥:")
        print(f"   RÂ²: {final_perf['r2']:.4f}")
        print(f"   MAE: {final_perf['mae']:.4f}")
        print(f"   ë°©í–¥ì •í™•ë„: {final_perf['direction_accuracy']:.1f}%")

        # ì•™ìƒë¸” êµ¬ì„±
        print(f"\nğŸ—ï¸ ì‹œê³„ì—´ ì•™ìƒë¸” êµ¬ì„±:")
        for model_name, weight in results['ensemble_weights'].items():
            print(f"   {model_name}: {weight:.3f}")

        # ê°œë³„ ëª¨ë¸ ì„±ëŠ¥
        print(f"\nğŸ“ˆ ê°œë³„ ëª¨ë¸ ì„±ëŠ¥:")
        for model_name, perf in results['individual_results'].items():
            print(f"   {model_name}: RÂ²={perf['r2']:.4f}, ë°©í–¥ì •í™•ë„={perf['direction_acc']:.1f}%")

        print(f"\nğŸ›¡ï¸ ì•ˆì „ì„±: {'âœ… í†µê³¼' if results['safety_check'] else 'âŒ ì‹¤íŒ¨'}")

        if results['safety_check']:
            print(f"\nğŸ‰ ì„±ê³µ: ì‹œê³„ì—´ ì–´í…ì…˜ ëª¨ë¸ë¡œ ì•ˆì „í•œ ì„±ëŠ¥ í–¥ìƒ!")
        else:
            print(f"\nâš ï¸ ì£¼ì˜: ì•ˆì „ ê¸°ì¤€ ì´ˆê³¼ - ì¶”ê°€ ë³´ì • í•„ìš”")

        return results

    except Exception as e:
        logger.error(f"ì‹œê³„ì—´ ì‹œìŠ¤í…œ ì‹¤íŒ¨: {e}")
        return None

if __name__ == "__main__":
    result = main()