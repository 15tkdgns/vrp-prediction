#!/usr/bin/env python3
"""
ê³ ê¸‰ ë³€ë™ì„± ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ v3.0
=================================

êµ¬í˜„ ë‚´ìš©:
1. HAR-RV í”¼ì²˜ (1ì¼/5ì¼/22ì¼ ë³€ë™ì„±)
2. GARCH(1,1) í•„í„°ë§ ë° ì”ì°¨ ì¶”ì¶œ
3. GARCH-LSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸
4. í™•ë¥ ì  ì˜ˆì¸¡ (ë¶„í¬ ì¶”ì •)

ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„: 10-15ë¶„
"""

import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.linear_model import ElasticNet, Ridge
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import joblib
import json
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ì„ íƒì  ì„í¬íŠ¸
try:
    from arch import arch_model
    HAS_ARCH = True
except ImportError:
    HAS_ARCH = False
    print("âš ï¸ arch íŒ¨í‚¤ì§€ ì—†ìŒ. GARCH ê¸°ëŠ¥ ë¹„í™œì„±í™”.")

try:
    import torch
    import torch.nn as nn
    from torch.utils.data import DataLoader, TensorDataset
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False
    print("âš ï¸ PyTorch ì—†ìŒ. LSTM ê¸°ëŠ¥ ë¹„í™œì„±í™”.")

SEED = 42
np.random.seed(SEED)
if HAS_TORCH:
    torch.manual_seed(SEED)


# =============================================================================
# 1. HAR-RV í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
# =============================================================================

class HARFeatureEngineer:
    """HAR-RV (Heterogeneous Autoregressive Realized Volatility) í”¼ì²˜"""
    
    def __init__(self):
        self.windows = {
            'daily': 1,      # ì¼ë³„
            'weekly': 5,     # ì£¼ê°„
            'monthly': 22    # ì›”ê°„
        }
    
    def create_har_features(self, df):
        """HAR í”¼ì²˜ ìƒì„±"""
        print("  â†’ HAR í”¼ì²˜ ìƒì„±...")
        
        # Realized Volatility ê³„ì‚° (ì¼ë³„ ìˆ˜ìµë¥  ì œê³±ì˜ í•©)
        df['returns'] = df['Close'].pct_change()
        df['returns_sq'] = df['returns'] ** 2
        
        # ë‹¤ì–‘í•œ ìœˆë„ìš°ì˜ RV
        for name, window in self.windows.items():
            if window == 1:
                df[f'rv_{name}'] = df['returns_sq']
            else:
                df[f'rv_{name}'] = df['returns_sq'].rolling(window).mean()
            
            # ë˜ê·¸ëœ RV (t-1)
            df[f'rv_{name}_lag1'] = df[f'rv_{name}'].shift(1)
        
        # HAR ëª¨ë¸ì˜ í•µì‹¬ í”¼ì²˜: RV_d(t-1), RV_w(t-1), RV_m(t-1)
        df['har_rv_d'] = df['rv_daily'].shift(1)       # ì–´ì œ
        df['har_rv_w'] = df['rv_weekly'].shift(1)      # ì§€ë‚œ ì£¼ í‰ê· 
        df['har_rv_m'] = df['rv_monthly'].shift(1)     # ì§€ë‚œ ë‹¬ í‰ê· 
        
        # HAR ë¹„ìœ¨ (ìƒëŒ€ì  ë³€ë™ì„± ìˆ˜ì¤€)
        df['har_ratio_w_d'] = df['har_rv_w'] / (df['har_rv_d'] + 1e-10)
        df['har_ratio_m_d'] = df['har_rv_m'] / (df['har_rv_d'] + 1e-10)
        df['har_ratio_m_w'] = df['har_rv_m'] / (df['har_rv_w'] + 1e-10)
        
        # ë³€ë™ì„± ë³€í™”
        df['har_rv_d_change'] = df['har_rv_d'].pct_change()
        df['har_rv_w_change'] = df['har_rv_w'].pct_change()
        
        # Jump ì„±ë¶„ (ê¸‰ê²©í•œ ë³€ë™ì„± ë³€í™”)
        df['har_jump'] = np.maximum(df['har_rv_d'] - df['har_rv_w'], 0)
        
        print(f"    - HAR í”¼ì²˜ 10ê°œ ìƒì„± ì™„ë£Œ")
        return df
    
    def create_realized_variance(self, df):
        """ë‹¤ì–‘í•œ Realized Variance ì¶”ì •ê¸°"""
        print("  â†’ Realized Variance ì¶”ì •...")
        
        # Parkinson (High-Low ê¸°ë°˜)
        df['rv_parkinson'] = (1 / (4 * np.log(2))) * (
            np.log(df['High'] / df['Low']) ** 2
        )
        
        # Garman-Klass
        log_hl = np.log(df['High'] / df['Low'])
        log_co = np.log(df['Close'] / df['Open'])
        df['rv_garman_klass'] = 0.5 * log_hl**2 - (2*np.log(2) - 1) * log_co**2
        
        # Rogers-Satchell (drift ê³ ë ¤)
        log_ho = np.log(df['High'] / df['Open'])
        log_lo = np.log(df['Low'] / df['Open'])
        log_co = np.log(df['Close'] / df['Open'])
        df['rv_rogers_satchell'] = log_ho * (log_ho - log_co) + log_lo * (log_lo - log_co)
        
        # ë¡¤ë§ í‰ê· 
        for rv_col in ['rv_parkinson', 'rv_garman_klass', 'rv_rogers_satchell']:
            for w in [5, 10, 20]:
                df[f'{rv_col}_{w}d'] = df[rv_col].rolling(w).mean()
        
        print(f"    - RV ì¶”ì •ê¸° 12ê°œ ìƒì„± ì™„ë£Œ")
        return df


# =============================================================================
# 2. GARCH í•„í„°ë§
# =============================================================================

class GARCHFilter:
    """GARCH(1,1) í•„í„°ë§ ë° ì”ì°¨ ì¶”ì¶œ"""
    
    def __init__(self, p=1, q=1):
        self.p = p
        self.q = q
        self.model = None
        self.result = None
    
    def fit_filter(self, returns):
        """GARCH ëª¨ë¸ í”¼íŒ… ë° ì¡°ê±´ë¶€ ë³€ë™ì„± ì¶”ì¶œ"""
        if not HAS_ARCH:
            return None, None, None
        
        print("  â†’ GARCH(1,1) í•„í„°ë§...")
        
        # ìˆ˜ìµë¥ ì„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
        returns_pct = returns.dropna() * 100
        
        try:
            # GARCH(1,1) ëª¨ë¸
            model = arch_model(returns_pct, vol='Garch', p=self.p, q=self.q,
                              mean='Constant', rescale=False)
            result = model.fit(disp='off', show_warning=False)
            
            # ì¡°ê±´ë¶€ ë³€ë™ì„± (ì—°ê°„í™”)
            cond_vol = result.conditional_volatility / 100
            
            # í‘œì¤€í™” ì”ì°¨ (GARCHë¡œ ì„¤ëª…ë˜ì§€ ì•ŠëŠ” ë¶€ë¶„)
            std_residuals = result.std_resid
            
            # ëª¨ë¸ íŒŒë¼ë¯¸í„°
            params = {
                'omega': result.params['omega'],
                'alpha': result.params['alpha[1]'],
                'beta': result.params['beta[1]']
            }
            
            print(f"    - GARCH íŒŒë¼ë¯¸í„°: Î±={params['alpha']:.4f}, Î²={params['beta']:.4f}")
            print(f"    - ì§€ì†ì„± (Î±+Î²): {params['alpha'] + params['beta']:.4f}")
            
            self.result = result
            return cond_vol, std_residuals, params
            
        except Exception as e:
            print(f"    âš ï¸ GARCH í”¼íŒ… ì˜¤ë¥˜: {e}")
            return None, None, None
    
    def create_garch_features(self, df):
        """GARCH ê¸°ë°˜ í”¼ì²˜ ìƒì„±"""
        if not HAS_ARCH:
            return df
        
        print("  â†’ GARCH í”¼ì²˜ ìƒì„±...")
        
        cond_vol, std_resid, params = self.fit_filter(df['returns'])
        
        if cond_vol is not None:
            # ì¡°ê±´ë¶€ ë³€ë™ì„±
            df['garch_vol'] = np.nan
            df.loc[cond_vol.index, 'garch_vol'] = cond_vol.values
            df['garch_vol'] = df['garch_vol'].ffill()
            
            # GARCH ë³€ë™ì„± ë˜ê·¸
            df['garch_vol_lag1'] = df['garch_vol'].shift(1)
            df['garch_vol_lag5'] = df['garch_vol'].shift(5)
            
            # í‘œì¤€í™” ì”ì°¨ (LSTMì´ í•™ìŠµí•  ë¹„ì„ í˜• íŒ¨í„´)
            if std_resid is not None:
                df['garch_residual'] = np.nan
                df.loc[std_resid.index, 'garch_residual'] = std_resid.values
                df['garch_residual'] = df['garch_residual'].ffill()
                
                # ì”ì°¨ì˜ ì ˆëŒ€ê°’ ë° ì œê³±
                df['garch_resid_abs'] = np.abs(df['garch_residual'])
                df['garch_resid_sq'] = df['garch_residual'] ** 2
            
            # GARCH vs Realized Vol ë¹„ìœ¨
            df['garch_rv_ratio'] = df['garch_vol'] / (df['rv_weekly'] + 1e-10)
            
            print(f"    - GARCH í”¼ì²˜ 7ê°œ ìƒì„± ì™„ë£Œ")
        
        return df


# =============================================================================
# 3. LSTM ëª¨ë¸
# =============================================================================

class LSTMVolatilityModel(nn.Module):
    """LSTM ë³€ë™ì„± ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.2):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        
        self.fc = nn.Sequential(
            nn.Linear(hidden_size, 32),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(32, 1)
        )
    
    def forward(self, x):
        # x: (batch, seq_len, features)
        lstm_out, (h_n, c_n) = self.lstm(x)
        # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ ì¶œë ¥ ì‚¬ìš©
        last_output = lstm_out[:, -1, :]
        return self.fc(last_output)


class GARCHLSTMHybrid:
    """GARCH-LSTM í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸"""
    
    def __init__(self, seq_length=20, hidden_size=64, epochs=50, lr=0.001):
        self.seq_length = seq_length
        self.hidden_size = hidden_size
        self.epochs = epochs
        self.lr = lr
        self.model = None
        self.scaler = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    def prepare_sequences(self, X, y):
        """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±"""
        X_seq, y_seq = [], []
        for i in range(len(X) - self.seq_length):
            X_seq.append(X[i:i+self.seq_length])
            y_seq.append(y[i+self.seq_length])
        return np.array(X_seq), np.array(y_seq)
    
    def fit(self, X_train, y_train, X_val=None, y_val=None):
        """ëª¨ë¸ í•™ìŠµ"""
        if not HAS_TORCH:
            print("  âš ï¸ PyTorch ì—†ìŒ. LSTM í•™ìŠµ ë¶ˆê°€.")
            return
        
        print(f"  â†’ LSTM í•™ìŠµ ì‹œì‘ (epochs={self.epochs})...")
        
        # ìŠ¤ì¼€ì¼ë§
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        # ì‹œí€€ìŠ¤ ìƒì„±
        X_seq, y_seq = self.prepare_sequences(X_train_scaled, y_train.values)
        
        # í…ì„œ ë³€í™˜
        X_tensor = torch.FloatTensor(X_seq).to(self.device)
        y_tensor = torch.FloatTensor(y_seq).unsqueeze(1).to(self.device)
        
        dataset = TensorDataset(X_tensor, y_tensor)
        loader = DataLoader(dataset, batch_size=32, shuffle=False)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        input_size = X_train.shape[1]
        self.model = LSTMVolatilityModel(input_size, self.hidden_size).to(self.device)
        
        criterion = nn.MSELoss()
        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)
        
        # í•™ìŠµ
        best_loss = float('inf')
        for epoch in range(self.epochs):
            self.model.train()
            epoch_loss = 0
            for X_batch, y_batch in loader:
                optimizer.zero_grad()
                pred = self.model(X_batch)
                loss = criterion(pred, y_batch)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
            
            avg_loss = epoch_loss / len(loader)
            scheduler.step(avg_loss)
            
            if (epoch + 1) % 10 == 0:
                print(f"    Epoch {epoch+1}/{self.epochs}, Loss: {avg_loss:.6f}")
            
            if avg_loss < best_loss:
                best_loss = avg_loss
        
        print(f"    - ìµœì¢… Loss: {best_loss:.6f}")
    
    def predict(self, X_test):
        """ì˜ˆì¸¡"""
        if not HAS_TORCH or self.model is None:
            return None
        
        self.model.eval()
        X_test_scaled = self.scaler.transform(X_test)
        X_seq, _ = self.prepare_sequences(X_test_scaled, pd.Series(np.zeros(len(X_test))))
        
        X_tensor = torch.FloatTensor(X_seq).to(self.device)
        
        with torch.no_grad():
            predictions = self.model(X_tensor).cpu().numpy().flatten()
        
        return predictions


# =============================================================================
# 4. í™•ë¥ ì  ì˜ˆì¸¡ (ë¶„í¬ ì¶”ì •)
# =============================================================================

class ProbabilisticVolatility:
    """í™•ë¥ ì  ë³€ë™ì„± ì˜ˆì¸¡ (í‰ê·  + ë¶„ì‚° ì¶”ì •)"""
    
    def __init__(self):
        self.mean_model = None
        self.var_model = None
    
    def fit(self, X_train, y_train):
        """í‰ê· ê³¼ ë¶„ì‚° ëª¨ë¸ í•™ìŠµ"""
        print("  â†’ í™•ë¥ ì  ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ...")
        
        # í‰ê·  ì˜ˆì¸¡ ëª¨ë¸
        self.mean_model = GradientBoostingRegressor(
            n_estimators=100, max_depth=5, learning_rate=0.1,
            random_state=SEED
        )
        self.mean_model.fit(X_train, y_train)
        
        # ì”ì°¨ ê³„ì‚°
        y_pred_mean = self.mean_model.predict(X_train)
        residuals = np.abs(y_train - y_pred_mean)
        
        # ë¶„ì‚° ì˜ˆì¸¡ ëª¨ë¸ (ì”ì°¨ì˜ ì ˆëŒ€ê°’ ì˜ˆì¸¡)
        self.var_model = GradientBoostingRegressor(
            n_estimators=100, max_depth=3, learning_rate=0.1,
            random_state=SEED
        )
        self.var_model.fit(X_train, residuals)
        
        print("    - í‰ê· /ë¶„ì‚° ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    
    def predict(self, X_test, confidence=0.95):
        """í™•ë¥ ì  ì˜ˆì¸¡ (í‰ê· , í•˜í•œ, ìƒí•œ)"""
        from scipy import stats
        
        y_mean = self.mean_model.predict(X_test)
        y_std = self.var_model.predict(X_test)
        
        # ì‹ ë¢° êµ¬ê°„ (ì •ê·œ ë¶„í¬ ê°€ì •)
        z = stats.norm.ppf((1 + confidence) / 2)
        y_lower = y_mean - z * y_std
        y_upper = y_mean + z * y_std
        
        return y_mean, y_lower, y_upper, y_std


# =============================================================================
# 5. í†µí•© íŒŒì´í”„ë¼ì¸
# =============================================================================

class AdvancedVolatilityPipeline:
    """ê³ ê¸‰ ë³€ë™ì„± ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ v3.0"""
    
    def __init__(self, start_date='2015-01-01', end_date='2024-12-31'):
        self.start_date = start_date
        self.end_date = end_date
        self.data = None
        self.feature_cols = []
        self.results = {}
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("\n" + "="*60)
        print("[1/7] ë°ì´í„° ë¡œë“œ...")
        print("="*60)
        
        tickers = {
            'SPY': 'SPY',
            'VIX': '^VIX',
        }
        
        all_data = {}
        for name, ticker in tickers.items():
            df = yf.download(ticker, start=self.start_date, end=self.end_date,
                           progress=False, auto_adjust=True)
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.get_level_values(0)
            all_data[name] = df
            print(f"  âœ“ {name}: {len(df)} í–‰")
        
        self.data = all_data['SPY'].copy()
        self.data['VIX'] = all_data['VIX']['Close']
        self.data = self.data.ffill().dropna()
        
        print(f"\n  âœ“ ìµœì¢…: {len(self.data)} í–‰")
        return self.data
    
    def engineer_features(self):
        """í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"""
        print("\n" + "="*60)
        print("[2/7] í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§...")
        print("="*60)
        
        df = self.data.copy()
        
        # 1. HAR í”¼ì²˜
        har = HARFeatureEngineer()
        df = har.create_har_features(df)
        df = har.create_realized_variance(df)
        
        # 2. GARCH í”¼ì²˜
        garch = GARCHFilter()
        df = garch.create_garch_features(df)
        
        # 3. VIX í”¼ì²˜ (ê¸°ì¡´)
        print("  â†’ VIX í”¼ì²˜ ìƒì„±...")
        df['vix_lag1'] = df['VIX'].shift(1)
        df['vix_lag5'] = df['VIX'].shift(5)
        df['vix_change'] = df['VIX'].pct_change()
        df['vix_zscore'] = (df['VIX'] - df['VIX'].rolling(20).mean()) / (df['VIX'].rolling(20).std() + 1e-10)
        
        # 4. Regime í”¼ì²˜ (ê¸°ì¡´)
        print("  â†’ Regime í”¼ì²˜ ìƒì„±...")
        vix_lag = df['VIX'].shift(1)
        df['regime_high_vol'] = (vix_lag >= 25).astype(int)
        df['regime_crisis'] = (vix_lag >= 35).astype(int)
        df['vol_in_high_regime'] = df['regime_high_vol'] * df['rv_weekly']
        df['vix_excess_25'] = np.maximum(vix_lag - 25, 0)
        
        self.data = df
        print(f"\n  âœ“ ì´ {len(df.columns)} ì»¬ëŸ¼ ìƒì„±")
        return df
    
    def create_target(self, horizon=5):
        """íƒ€ê²Ÿ ìƒì„±"""
        print("\n" + "="*60)
        print(f"[3/7] íƒ€ê²Ÿ ìƒì„± (horizon={horizon})...")
        print("="*60)
        
        df = self.data.copy()
        
        # ë¯¸ë˜ Realized Variance (t+1 ~ t+horizon)
        future_rv = []
        returns_sq = df['returns_sq'].values
        
        for i in range(len(returns_sq)):
            if i + horizon < len(returns_sq):
                future_rv.append(np.mean(returns_sq[i+1:i+1+horizon]))
            else:
                future_rv.append(np.nan)
        
        df['target_rv'] = future_rv
        df['target_vol'] = np.sqrt(df['target_rv'])  # ë³€ë™ì„±ìœ¼ë¡œ ë³€í™˜
        
        self.data = df
        print(f"  âœ“ íƒ€ê²Ÿ ìƒì„± ì™„ë£Œ (í‰ê· : {np.nanmean(df['target_vol']):.6f})")
        return df
    
    def select_features(self):
        """í”¼ì²˜ ì„ íƒ"""
        print("\n" + "="*60)
        print("[4/7] í”¼ì²˜ ì„ íƒ...")
        print("="*60)
        
        exclude = ['Open', 'High', 'Low', 'Close', 'Volume', 'VIX',
                   'returns', 'returns_sq', 'target_rv', 'target_vol']
        
        self.feature_cols = [c for c in self.data.columns 
                            if c not in exclude and not c.startswith('rv_daily')]
        
        # íƒ€ê²Ÿê³¼ì˜ ìƒê´€ê´€ê³„ ë¶„ì„
        df_clean = self.data.dropna()
        correlations = df_clean[self.feature_cols].corrwith(df_clean['target_vol']).abs()
        correlations = correlations.sort_values(ascending=False)
        
        print("\n  ğŸ“Š ìƒìœ„ 15 í”¼ì²˜ (íƒ€ê²Ÿ ìƒê´€ê´€ê³„):")
        for i, (feat, corr) in enumerate(correlations.head(15).items()):
            print(f"    {i+1}. {feat}: {corr:.4f}")
        
        # ìƒìœ„ 40ê°œë§Œ ì„ íƒ (ê³¼ì í•© ë°©ì§€)
        self.feature_cols = correlations.head(40).index.tolist()
        
        print(f"\n  âœ“ {len(self.feature_cols)}ê°œ í”¼ì²˜ ì„ íƒë¨")
        return self.feature_cols
    
    def prepare_data(self, test_ratio=0.2):
        """ë°ì´í„° ë¶„í• """
        print("\n" + "="*60)
        print("[5/7] ë°ì´í„° ë¶„í• ...")
        print("="*60)
        
        df = self.data.dropna().copy()
        
        # ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬
        for col in self.feature_cols:
            if col in df.columns:
                df[col] = df[col].replace([np.inf, -np.inf], np.nan)
                df[col] = df[col].fillna(df[col].median())
        
        # ì´ìƒì¹˜ í´ë¦¬í•‘ (99.9 ë°±ë¶„ìœ„ìˆ˜)
        for col in self.feature_cols:
            if col in df.columns:
                lower = df[col].quantile(0.001)
                upper = df[col].quantile(0.999)
                df[col] = df[col].clip(lower, upper)
        
        df = df.dropna()
        
        split_idx = int(len(df) * (1 - test_ratio))
        train_df = df.iloc[:split_idx]
        test_df = df.iloc[split_idx:]
        
        X_train = train_df[self.feature_cols]
        y_train = train_df['target_vol']
        X_test = test_df[self.feature_cols]
        y_test = test_df['target_vol']
        
        print(f"  âœ“ Train: {len(X_train)}, Test: {len(X_test)}")
        
        self.X_train = X_train
        self.X_test = X_test
        self.y_train = y_train
        self.y_test = y_test
        self.test_df = test_df
        
        return X_train, X_test, y_train, y_test
    
    def train_models(self):
        """ëª¨ë¸ í•™ìŠµ"""
        print("\n" + "="*60)
        print("[6/7] ëª¨ë¸ í•™ìŠµ...")
        print("="*60)
        
        # ìŠ¤ì¼€ì¼ë§
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(self.X_train)
        X_test_scaled = scaler.transform(self.X_test)
        
        results = {}
        
        # 1. ElasticNet (ë² ì´ìŠ¤ë¼ì¸)
        print("\n  [1] ElasticNet (ë² ì´ìŠ¤ë¼ì¸)...")
        en = ElasticNet(alpha=0.0005, l1_ratio=0.5, random_state=SEED, max_iter=10000)
        en.fit(X_train_scaled, self.y_train)
        y_pred_en = en.predict(X_test_scaled)
        results['ElasticNet'] = {
            'r2': r2_score(self.y_test, y_pred_en),
            'rmse': np.sqrt(mean_squared_error(self.y_test, y_pred_en)),
            'predictions': y_pred_en
        }
        print(f"      RÂ²: {results['ElasticNet']['r2']:.4f}")
        
        # 2. GradientBoosting
        print("  [2] GradientBoosting...")
        gb = GradientBoostingRegressor(n_estimators=100, max_depth=5, learning_rate=0.1,
                                       random_state=SEED)
        gb.fit(X_train_scaled, self.y_train)
        y_pred_gb = gb.predict(X_test_scaled)
        results['GradientBoosting'] = {
            'r2': r2_score(self.y_test, y_pred_gb),
            'rmse': np.sqrt(mean_squared_error(self.y_test, y_pred_gb)),
            'predictions': y_pred_gb
        }
        print(f"      RÂ²: {results['GradientBoosting']['r2']:.4f}")
        
        # 3. GARCH-LSTM í•˜ì´ë¸Œë¦¬ë“œ
        if HAS_TORCH:
            print("  [3] GARCH-LSTM í•˜ì´ë¸Œë¦¬ë“œ...")
            lstm = GARCHLSTMHybrid(seq_length=20, hidden_size=64, epochs=30)
            lstm.fit(self.X_train, self.y_train)
            y_pred_lstm = lstm.predict(self.X_test)
            if y_pred_lstm is not None and len(y_pred_lstm) > 0:
                # ì‹œí€€ìŠ¤ë¡œ ì¸í•œ ê¸¸ì´ ì°¨ì´ ì¡°ì •
                y_test_lstm = self.y_test.values[20:]
                y_pred_lstm = y_pred_lstm[:len(y_test_lstm)]
                results['GARCH-LSTM'] = {
                    'r2': r2_score(y_test_lstm, y_pred_lstm),
                    'rmse': np.sqrt(mean_squared_error(y_test_lstm, y_pred_lstm)),
                    'predictions': y_pred_lstm
                }
                print(f"      RÂ²: {results['GARCH-LSTM']['r2']:.4f}")
        
        # 4. í™•ë¥ ì  ì˜ˆì¸¡
        print("  [4] í™•ë¥ ì  ì˜ˆì¸¡...")
        prob = ProbabilisticVolatility()
        prob.fit(X_train_scaled, self.y_train)
        y_mean, y_lower, y_upper, y_std = prob.predict(X_test_scaled)
        results['Probabilistic'] = {
            'r2': r2_score(self.y_test, y_mean),
            'rmse': np.sqrt(mean_squared_error(self.y_test, y_mean)),
            'predictions': y_mean,
            'lower': y_lower,
            'upper': y_upper,
            'std': y_std
        }
        print(f"      RÂ²: {results['Probabilistic']['r2']:.4f}")
        
        # ê²°ê³¼ ì €ì¥
        self.results = results
        self.scaler = scaler
        
        return results
    
    def evaluate(self):
        """ê²°ê³¼ í‰ê°€"""
        print("\n" + "="*60)
        print("[7/7] ê²°ê³¼ í‰ê°€...")
        print("="*60)
        
        print("\n" + "-"*60)
        print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ:")
        print("-"*60)
        print(f"{'ëª¨ë¸':<20} {'RÂ²':>12} {'RMSE':>12}")
        print("-"*60)
        
        for name, res in sorted(self.results.items(), 
                                key=lambda x: x[1]['r2'], reverse=True):
            print(f"{name:<20} {res['r2']:>12.4f} {res['rmse']:>12.6f}")
        
        # ìµœê³  ëª¨ë¸
        best_name = max(self.results, key=lambda x: self.results[x]['r2'])
        best_r2 = self.results[best_name]['r2']
        
        print(f"\n  ğŸ† ìµœê³  ëª¨ë¸: {best_name} (RÂ² = {best_r2:.4f})")
        
        return best_name, best_r2
    
    def save_results(self, best_name):
        """ê²°ê³¼ ì €ì¥"""
        print("\n" + "="*60)
        print("ê²°ê³¼ ì €ì¥...")
        print("="*60)
        
        model_dir = Path('data/models')
        model_dir.mkdir(parents=True, exist_ok=True)
        
        # ë©”íŠ¸ë¦­ ì €ì¥
        metrics = {
            'model_name': f'Advanced {best_name}',
            'test_r2': float(self.results[best_name]['r2']),
            'test_rmse': float(self.results[best_name]['rmse']),
            'n_features': len(self.feature_cols),
            'methods_used': ['HAR-RV', 'GARCH', 'LSTM', 'Probabilistic'],
            'all_results': {k: {'r2': float(v['r2'])} for k, v in self.results.items()},
            'timestamp': datetime.now().isoformat()
        }
        
        with open('data/raw/advanced_model_performance.json', 'w') as f:
            json.dump(metrics, f, indent=2)
        
        print(f"  âœ“ ë©”íŠ¸ë¦­ ì €ì¥ë¨")
        return metrics
    
    def run(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        start = datetime.now()
        print("\n" + "ğŸš€"*30)
        print("ê³ ê¸‰ ë³€ë™ì„± ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ v3.0")
        print("ğŸš€"*30)
        
        self.load_data()
        self.engineer_features()
        self.create_target()
        self.select_features()
        self.prepare_data()
        self.train_models()
        best_name, best_r2 = self.evaluate()
        metrics = self.save_results(best_name)
        
        elapsed = datetime.now() - start
        print("\n" + "="*60)
        print("âœ… ì™„ë£Œ!")
        print("="*60)
        print(f"  â±ï¸ ì†Œìš” ì‹œê°„: {elapsed}")
        print(f"  ğŸ† ìµœê³  ëª¨ë¸: {best_name}")
        print(f"  ğŸ“Š Test RÂ²: {best_r2:.4f}")
        
        return metrics


def main():
    pipeline = AdvancedVolatilityPipeline(
        start_date='2015-01-01',
        end_date='2024-12-31'
    )
    metrics = pipeline.run()
    return metrics


if __name__ == '__main__':
    metrics = main()
