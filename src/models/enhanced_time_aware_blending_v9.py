#!/usr/bin/env python3
"""
Enhanced Time Aware Blending V9.0
ëª©í‘œ: MDD ìµœì†Œí™” (<0.6) + Log Loss ê°ì†Œ (<0.7)
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import log_loss, mean_absolute_error
from sklearn.preprocessing import RobustScaler
from sklearn.calibration import CalibratedClassifierCV
import warnings
warnings.filterwarnings('ignore')

class EnhancedTimeAwareBlendingV9:
    def __init__(self, max_drawdown_threshold=0.15, confidence_threshold=0.6):
        """
        Enhanced Time Aware Blending with MDD control and log loss optimization

        Args:
            max_drawdown_threshold: ìµœëŒ€ í—ˆìš© ë‚™í­ (ê¸°ë³¸: 15%)
            confidence_threshold: ì˜ˆì¸¡ ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸: 60%)
        """
        self.max_dd_threshold = max_drawdown_threshold
        self.confidence_threshold = confidence_threshold

        # ê¸°ë³¸ ëª¨ë¸ë“¤ (ë³´ìˆ˜ì  ì„¤ì •)
        self.base_models = {
            'ridge_ultra_conservative': Ridge(alpha=50.0, random_state=42),
            'lasso_ultra_conservative': Lasso(alpha=0.05, random_state=42),
            'rf_ultra_conservative': RandomForestRegressor(
                n_estimators=20, max_depth=3, random_state=42,
                min_samples_split=20, min_samples_leaf=10
            ),
            'gb_ultra_conservative': GradientBoostingRegressor(
                n_estimators=30, max_depth=2, learning_rate=0.05,
                random_state=42, subsample=0.8
            )
        }

        # ëª¨ë¸ ê°€ì¤‘ì¹˜ (ì´ˆê¸°ê°’)
        self.model_weights = np.array([0.3, 0.25, 0.25, 0.2])
        self.weight_decay = 0.98  # ê°€ì¤‘ì¹˜ ê°ì‡ ìœ¨
        self.min_weight = 0.05   # ìµœì†Œ ê°€ì¤‘ì¹˜

        # ë¦¬ìŠ¤í¬ ê´€ë¦¬ íŒŒë¼ë¯¸í„°
        self.volatility_window = 20
        self.position_sizing_factor = 0.5  # ë³´ìˆ˜ì  í¬ì§€ì…˜ í¬ê¸°
        self.rebalance_threshold = 0.1     # ë¦¬ë°¸ëŸ°ì‹± ì„ê³„ê°’

        # ì˜ˆì¸¡ ë³´ì • ê´€ë ¨
        self.prediction_smoothing = 0.3    # ì˜ˆì¸¡ ìŠ¤ë¬´ë”© íŒ©í„°
        self.calibration_window = 50       # ë³´ì • ìœˆë„ìš°

        # ì„±ëŠ¥ ì¶”ì 
        self.performance_history = []
        self.drawdown_history = []
        self.prediction_history = []

    def calculate_volatility_adjusted_weights(self, returns_history):
        """ë³€ë™ì„± ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •"""
        if len(returns_history) < self.volatility_window:
            return self.model_weights

        recent_volatility = np.std(returns_history[-self.volatility_window:])

        # ë³€ë™ì„±ì´ ë†’ì„ìˆ˜ë¡ ë³´ìˆ˜ì ìœ¼ë¡œ ì¡°ì •
        volatility_adjustment = 1.0 / (1.0 + recent_volatility * 10)

        # ê°€ì¤‘ì¹˜ ì¬ì¡°ì •
        adjusted_weights = self.model_weights * volatility_adjustment

        # ì •ê·œí™”
        adjusted_weights = adjusted_weights / np.sum(adjusted_weights)

        return adjusted_weights

    def calculate_current_drawdown(self, returns_history):
        """í˜„ì¬ ë“œë¡œë‹¤ìš´ ê³„ì‚°"""
        if len(returns_history) == 0:
            return 0.0

        cumulative_returns = np.cumprod(1 + np.array(returns_history))
        running_max = np.maximum.accumulate(cumulative_returns)
        drawdown = (cumulative_returns - running_max) / running_max

        return abs(np.min(drawdown)) if len(drawdown) > 0 else 0.0

    def apply_drawdown_control(self, prediction, current_drawdown):
        """ë“œë¡œë‹¤ìš´ ê¸°ë°˜ ì˜ˆì¸¡ ì¡°ì •"""
        if current_drawdown > self.max_dd_threshold:
            # ë“œë¡œë‹¤ìš´ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ë©´ ë§¤ìš° ë³´ìˆ˜ì ìœ¼ë¡œ ì¡°ì •
            conservative_factor = 0.1  # 90% ê°ì†Œ
            return prediction * conservative_factor
        elif current_drawdown > self.max_dd_threshold * 0.7:
            # ë“œë¡œë‹¤ìš´ì´ ì„ê³„ê°’ì˜ 70%ë¥¼ ì´ˆê³¼í•˜ë©´ ë³´ìˆ˜ì  ì¡°ì •
            conservative_factor = 0.5  # 50% ê°ì†Œ
            return prediction * conservative_factor
        else:
            return prediction

    def calibrate_prediction_probabilities(self, predictions, targets):
        """ì˜ˆì¸¡ í™•ë¥  ë³´ì •ìœ¼ë¡œ Log Loss ê°œì„ """
        try:
            # ì˜ˆì¸¡ê°’ì„ í™•ë¥ ë¡œ ë³€í™˜
            pred_probs = 1 / (1 + np.exp(-predictions))  # ì‹œê·¸ëª¨ì´ë“œ ë³€í™˜

            # ê·¹ê°’ ë°©ì§€ (Log Loss ì•ˆì •í™”)
            pred_probs = np.clip(pred_probs, 0.001, 0.999)

            # íƒ€ê²Ÿì„ ì´ì§„ ë¶„ë¥˜ë¡œ ë³€í™˜
            binary_targets = (targets > 0).astype(int)

            # ë³´ì • ì ìš© (ë‹¨ìˆœ ìŠ¤ì¼€ì¼ë§)
            if len(np.unique(binary_targets)) > 1:
                # ì‹¤ì œ ì–‘ì„± ë¹„ìœ¨ ê³„ì‚°
                actual_positive_rate = np.mean(binary_targets)
                predicted_positive_rate = np.mean(pred_probs > 0.5)

                if predicted_positive_rate > 0:
                    calibration_factor = actual_positive_rate / predicted_positive_rate
                    pred_probs = pred_probs * calibration_factor
                    pred_probs = np.clip(pred_probs, 0.001, 0.999)

            return pred_probs
        except Exception as e:
            print(f"Calibration error: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return np.full(len(predictions), 0.5)

    def dynamic_weight_update(self, model_performances, current_period):
        """ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜ ë™ì  ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸"""
        if len(model_performances) == 0:
            return self.model_weights

        # ìµœê·¼ ì„±ëŠ¥ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
        recent_window = min(10, len(model_performances))
        recent_performances = model_performances[-recent_window:]

        # ê° ëª¨ë¸ì˜ í‰ê·  ì„±ëŠ¥ ê³„ì‚° (MAE ê¸°ì¤€, ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        model_maes = []
        for i in range(len(self.base_models)):
            model_mae = np.mean([perf[i] for perf in recent_performances])
            model_maes.append(model_mae)

        # ì„±ëŠ¥ì´ ì¢‹ì„ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜ (MAEì˜ ì—­ìˆ˜ ì‚¬ìš©)
        inverse_maes = [1.0 / (mae + 1e-6) for mae in model_maes]
        new_weights = np.array(inverse_maes)

        # ì •ê·œí™”
        new_weights = new_weights / np.sum(new_weights)

        # ê¸‰ê²©í•œ ë³€í™” ë°©ì§€ (ìŠ¤ë¬´ë”©)
        smoothing_factor = 0.1
        self.model_weights = (1 - smoothing_factor) * self.model_weights + smoothing_factor * new_weights

        # ìµœì†Œ ê°€ì¤‘ì¹˜ ë³´ì¥
        self.model_weights = np.maximum(self.model_weights, self.min_weight)
        self.model_weights = self.model_weights / np.sum(self.model_weights)

        return self.model_weights

    def enhanced_ensemble_prediction(self, X, y_history=None, return_history=None):
        """í–¥ìƒëœ ì•™ìƒë¸” ì˜ˆì¸¡"""
        predictions = []
        model_maes = []

        # ê° ëª¨ë¸ë¡œ ì˜ˆì¸¡
        for model_name, model in self.base_models.items():
            try:
                pred = model.predict(X)
                predictions.append(pred)

                # ëª¨ë¸ ì„±ëŠ¥ ì¶”ì  (ê°€ëŠ¥í•œ ê²½ìš°)
                if y_history is not None and len(y_history) > 0:
                    mae = mean_absolute_error(y_history[-len(pred):], pred)
                    model_maes.append(mae)
                else:
                    model_maes.append(0.01)  # ê¸°ë³¸ê°’

            except Exception as e:
                print(f"Model {model_name} prediction error: {e}")
                predictions.append(np.zeros(len(X)))
                model_maes.append(1.0)  # ë†’ì€ ì˜¤ë¥˜ê°’

        # ì„±ëŠ¥ ê¸°ë¡ ì—…ë°ì´íŠ¸
        if len(model_maes) == len(self.base_models):
            self.performance_history.append(model_maes)

        # ë™ì  ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        if len(self.performance_history) > 5:  # ì¶©ë¶„í•œ ì´ë ¥ì´ ìˆì„ ë•Œë§Œ
            self.dynamic_weight_update(self.performance_history, len(self.performance_history))

        # ë³€ë™ì„± ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
        if return_history is not None and len(return_history) > 0:
            vol_adjusted_weights = self.calculate_volatility_adjusted_weights(return_history)
        else:
            vol_adjusted_weights = self.model_weights

        # ê°€ì¤‘ í‰ê·  ì˜ˆì¸¡
        predictions_array = np.array(predictions)
        ensemble_pred = np.average(predictions_array, axis=0, weights=vol_adjusted_weights)

        # ì˜ˆì¸¡ ìŠ¤ë¬´ë”© ì ìš©
        if len(self.prediction_history) > 0:
            previous_pred = self.prediction_history[-1]
            ensemble_pred = (1 - self.prediction_smoothing) * ensemble_pred + \
                          self.prediction_smoothing * previous_pred

        # ì˜ˆì¸¡ ì´ë ¥ ì—…ë°ì´íŠ¸
        self.prediction_history.append(ensemble_pred)

        # ë“œë¡œë‹¤ìš´ ì œì–´ ì ìš©
        if return_history is not None and len(return_history) > 0:
            current_dd = self.calculate_current_drawdown(return_history)
            self.drawdown_history.append(current_dd)
            ensemble_pred = self.apply_drawdown_control(ensemble_pred, current_dd)

        return ensemble_pred

    def fit(self, X, y):
        """ëª¨ë¸ í›ˆë ¨"""
        print("ğŸ”§ Enhanced Time Aware Blending V9 í›ˆë ¨ ì‹œì‘...")

        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        self.scaler = RobustScaler()
        X_scaled = self.scaler.fit_transform(X)

        # ê° ëª¨ë¸ í›ˆë ¨
        for model_name, model in self.base_models.items():
            print(f"  ğŸ“ˆ {model_name} í›ˆë ¨ ì¤‘...")
            model.fit(X_scaled, y)

        print("âœ… ëª¨ë“  ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        return self

    def predict(self, X, y_history=None, return_history=None):
        """ì˜ˆì¸¡ ì‹¤í–‰"""
        X_scaled = self.scaler.transform(X)
        return self.enhanced_ensemble_prediction(X_scaled, y_history, return_history)

    def predict_proba(self, X, y_history=None, return_history=None):
        """í™•ë¥  ì˜ˆì¸¡ (Log Loss ê³„ì‚°ìš©)"""
        predictions = self.predict(X, y_history, return_history)

        # ì‹¤ì œ íƒ€ê²Ÿì´ ìˆë‹¤ë©´ ë³´ì • ì ìš©
        if y_history is not None and len(y_history) > 0:
            calibrated_probs = self.calibrate_prediction_probabilities(predictions, y_history)
        else:
            # ê¸°ë³¸ ì‹œê·¸ëª¨ì´ë“œ ë³€í™˜
            calibrated_probs = 1 / (1 + np.exp(-predictions))
            calibrated_probs = np.clip(calibrated_probs, 0.001, 0.999)

        return calibrated_probs

    def get_performance_summary(self):
        """ì„±ëŠ¥ ìš”ì•½ ë°˜í™˜"""
        if len(self.drawdown_history) == 0:
            return {
                'max_drawdown': 0.0,
                'current_drawdown': 0.0,
                'avg_drawdown': 0.0,
                'drawdown_control_active': False,
                'model_weights': self.model_weights.tolist()
            }

        return {
            'max_drawdown': max(self.drawdown_history),
            'current_drawdown': self.drawdown_history[-1],
            'avg_drawdown': np.mean(self.drawdown_history),
            'drawdown_control_active': self.drawdown_history[-1] > self.max_dd_threshold,
            'model_weights': self.model_weights.tolist(),
            'weight_evolution': len(self.performance_history),
            'prediction_smoothing_factor': self.prediction_smoothing
        }

def create_enhanced_time_aware_blending_v9():
    """Enhanced Time Aware Blending V9 ëª¨ë¸ ìƒì„±"""
    return EnhancedTimeAwareBlendingV9(
        max_drawdown_threshold=0.12,  # 12% MDD ì œí•œ
        confidence_threshold=0.65      # 65% ì‹ ë¢°ë„ ì„ê³„ê°’
    )

if __name__ == "__main__":
    print("ğŸš€ Enhanced Time Aware Blending V9 - MDD ìµœì†Œí™” & Log Loss ìµœì í™”")

    # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±
    np.random.seed(42)
    n_samples = 200
    n_features = 10

    X = np.random.randn(n_samples, n_features)
    y = np.random.randn(n_samples) * 0.02  # 2% ë³€ë™ì„±

    # ëª¨ë¸ í…ŒìŠ¤íŠ¸
    model = create_enhanced_time_aware_blending_v9()
    model.fit(X[:150], y[:150])

    # ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    predictions = model.predict(X[150:], y_history=y[:150])
    proba_predictions = model.predict_proba(X[150:], y_history=y[:150])

    # ì„±ëŠ¥ í‰ê°€
    test_y = y[150:]
    mae = mean_absolute_error(test_y, predictions)

    # Log Loss ê³„ì‚°
    binary_targets = (test_y > 0).astype(int)
    log_loss_val = log_loss(binary_targets, proba_predictions)

    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"  MAE: {mae:.4f}")
    print(f"  Log Loss: {log_loss_val:.4f}")

    # ì„±ëŠ¥ ìš”ì•½
    summary = model.get_performance_summary()
    print(f"\nğŸ” ëª¨ë¸ ìƒíƒœ:")
    for key, value in summary.items():
        print(f"  {key}: {value}")