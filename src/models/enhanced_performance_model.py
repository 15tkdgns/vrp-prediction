#!/usr/bin/env python3
"""
Enhanced Performance Model - ì•ˆì „í•œ ì„±ëŠ¥ ê°œì„ 
Walk-Forward ê²€ì¦ì„ ê¸°ë³¸ìœ¼ë¡œ í•˜ì—¬ ì‹ ì¤‘í•˜ê²Œ ì„±ëŠ¥ í–¥ìƒ ì‹œë„
"""

import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import warnings
import os
import json
from datetime import datetime
import matplotlib.pyplot as plt

warnings.filterwarnings('ignore')

class EnhancedPerformancePredictor:
    """Walk-Forward ê²€ì¦ ê¸°ë°˜ ì•ˆì „í•œ ì„±ëŠ¥ ê°œì„ """

    def __init__(self):
        self.models = {}
        self.validation_results = {}

    def load_extended_data(self):
        """ë” ê¸´ ê¸°ê°„ì˜ ë°ì´í„° ë¡œë“œ (2000ë…„ë¶€í„°)"""
        print("ğŸ“Š í™•ì¥ëœ ë°ì´í„° ë¡œë”© ì¤‘ (2000-2024)...")

        try:
            # SPY ë°ì´í„° (ë” ê¸´ ê¸°ê°„)
            spy = yf.download('SPY', start='2000-01-01', end='2024-12-31', progress=False)
            spy['returns'] = spy['Close'].pct_change()

            # VIX ë°ì´í„°
            vix = yf.download('^VIX', start='2000-01-01', end='2024-12-31', progress=False)
            spy['vix'] = vix['Close'].reindex(spy.index, method='ffill')

            # ì¶”ê°€ ê²½ì œ ì§€í‘œë“¤
            try:
                # 10ë…„ êµ­ì±„ ê¸ˆë¦¬
                treasury = yf.download('^TNX', start='2000-01-01', end='2024-12-31', progress=False)
                spy['treasury_10y'] = treasury['Close'].reindex(spy.index, method='ffill')
            except:
                spy['treasury_10y'] = 2.5

            try:
                # 2ë…„ êµ­ì±„ ê¸ˆë¦¬ (ìˆ˜ìµë¥  ê³¡ì„ ì„ ìœ„í•´)
                treasury_2y = yf.download('^TNX', start='2000-01-01', end='2024-12-31', progress=False)
                spy['treasury_2y'] = treasury_2y['Close'].reindex(spy.index, method='ffill') * 0.8  # ê·¼ì‚¬ì¹˜
            except:
                spy['treasury_2y'] = 2.0

            spy = spy.dropna()
            print(f"âœ… í™•ì¥ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(spy)} ê´€ì¸¡ì¹˜ (2000-2024)")

            # ë°ì´í„° í’ˆì§ˆ í™•ì¸
            print(f"   ê¸°ê°„: {spy.index[0].strftime('%Y-%m-%d')} ~ {spy.index[-1].strftime('%Y-%m-%d')}")
            print(f"   ì£¼ìš” ê²½ì œ ì´ë²¤íŠ¸ í¬í•¨:")
            print(f"     - ë‹·ì»´ ë²„ë¸” (2000-2002)")
            print(f"     - ê¸ˆìœµìœ„ê¸° (2008-2009)")
            print(f"     - ì½”ë¡œë‚˜ ìœ„ê¸° (2020)")

            return spy

        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def create_enhanced_features(self, data):
        """í–¥ìƒëœ íŠ¹ì„± ìƒì„± (ì•ˆì „í•œ ë²”ìœ„ ë‚´ì—ì„œ)"""
        print("ğŸ”§ í–¥ìƒëœ íŠ¹ì„± ìƒì„± ì¤‘...")

        features = pd.DataFrame(index=data.index)
        returns = data['returns']
        prices = data['Close']
        high = data['High']
        low = data['Low']
        volume = data['Volume']
        vix = data['vix']

        # 1. í•µì‹¬ ë³€ë™ì„± íŠ¹ì„± (ë‹¤ì–‘í•œ ìœˆë„ìš°)
        for window in [5, 10, 20, 60]:  # 60ì¼ ì¶”ê°€ë¡œ ë” ê¸´ ê¸°ê°„ ë³€ë™ì„±
            features[f'volatility_{window}'] = returns.rolling(window).std()
            # ì—°ìœ¨í™”ëœ ë³€ë™ì„±
            features[f'vol_annualized_{window}'] = features[f'volatility_{window}'] * np.sqrt(252)

        # 2. VIX íŠ¹ì„± ê°•í™”
        features['vix_level'] = vix / 100  # ì •ê·œí™”
        for window in [5, 10, 20, 60]:
            features[f'vix_ma_{window}'] = vix.rolling(window).mean() / 100

        # VIX ê¸°ê°„êµ¬ì¡°
        features['vix_term_structure'] = features['vix_level'] / features['vix_ma_20']
        features['vix_change'] = vix.pct_change()
        features['vix_momentum'] = features['vix_change'].rolling(5).mean()

        # 3. ê²½ì œ ì§€í‘œ íŠ¹ì„±
        if 'treasury_10y' in data.columns:
            treasury_10y = data['treasury_10y']
            treasury_2y = data['treasury_2y']

            features['treasury_10y'] = treasury_10y / 100
            features['treasury_2y'] = treasury_2y / 100

            # ìˆ˜ìµë¥  ê³¡ì„  ê¸°ìš¸ê¸°
            features['yield_curve_slope'] = (treasury_10y - treasury_2y) / 100

            # VIX-ê¸ˆë¦¬ ìŠ¤í”„ë ˆë“œ (ì´ì „ì— íš¨ê³¼ì ì´ì—ˆë˜ íŠ¹ì„±)
            features['vix_treasury_spread'] = features['vix_level'] - features['treasury_10y']

            # ê¸ˆë¦¬ ë³€í™”
            features['treasury_change'] = treasury_10y.diff() / 100

        # 4. ê°€ê²© ê¸°ë°˜ íŠ¹ì„±
        for window in [5, 10, 20]:
            # ê°€ê²© ëª¨ë©˜í…€
            features[f'price_momentum_{window}'] = prices.pct_change(window)

            # ì¼ì¤‘ ë³€ë™ì„±
            intraday_range = (high - low) / prices
            features[f'intraday_vol_{window}'] = intraday_range.rolling(window).mean()

            # Garman-Klass ì¶”ì •ëŸ‰
            gk = np.log(high / low) ** 2
            features[f'garman_klass_{window}'] = gk.rolling(window).mean()

        # 5. ì§€ìˆ˜ ê°€ì¤‘ íŠ¹ì„±
        for span in [10, 30]:
            features[f'ewm_vol_{span}'] = returns.ewm(span=span).std()
            features[f'ewm_vix_{span}'] = vix.ewm(span=span).mean() / 100

        # 6. ë˜ê·¸ íŠ¹ì„± (ì œí•œì )
        for lag in [1, 2, 5]:
            features[f'vol_lag_{lag}'] = features['volatility_5'].shift(lag)
            features[f'vix_lag_{lag}'] = features['vix_level'].shift(lag)

        # 7. ì•ˆì „í•œ ìƒí˜¸ì‘ìš© íŠ¹ì„±
        features['vix_vol_ratio'] = features['vix_level'] / (features['volatility_20'] + 1e-8)
        if 'yield_curve_slope' in features.columns:
            features['vix_yield_interaction'] = features['vix_level'] * features['yield_curve_slope']

        # 8. ì‹œì¥ ì²´ì œ ì§€í‘œ
        # ë³€ë™ì„± ë ˆì§
        vol_percentile = features['volatility_20'].rolling(252).rank(pct=True)
        features['vol_regime_high'] = (vol_percentile > 0.8).astype(int)
        features['vol_regime_low'] = (vol_percentile < 0.2).astype(int)

        print(f"âœ… í–¥ìƒëœ íŠ¹ì„± ìƒì„± ì™„ë£Œ: {len(features.columns)}ê°œ")
        return features

    def create_robust_targets(self, data):
        """ì•ˆì •ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±"""
        print("ğŸ¯ ì•ˆì •ì  íƒ€ê²Ÿ ìƒì„± ì¤‘...")

        targets = pd.DataFrame(index=data.index)
        returns = data['returns']

        # ë‹¤ì–‘í•œ ì˜ˆì¸¡ ê¸°ê°„ì˜ ë³€ë™ì„±
        for horizon in [5, 10, 20]:
            vol_values = []
            for i in range(len(returns)):
                if i + horizon < len(returns):
                    future_returns = returns.iloc[i+1:i+1+horizon]
                    vol_values.append(future_returns.std())
                else:
                    vol_values.append(np.nan)
            targets[f'target_vol_{horizon}d'] = vol_values

        return targets

    def optimize_regularization_strength(self, X, y):
        """ì •ê·œí™” ê°•ë„ ìµœì í™” (Walk-Forward ê¸°ì¤€)"""
        print("ğŸ”§ ì •ê·œí™” ê°•ë„ ìµœì í™” ì¤‘...")

        # í›„ë³´ ì •ê·œí™” ê°•ë„ë“¤
        ridge_alphas = [0.1, 1.0, 5.0, 10.0, 25.0, 50.0, 100.0]
        lasso_alphas = [0.001, 0.005, 0.01, 0.05, 0.1]
        elastic_alphas = [0.001, 0.005, 0.01, 0.05]

        best_models = {}

        combined_data = pd.concat([X, y], axis=1).dropna()
        X_clean = combined_data[X.columns]
        y_clean = combined_data[y.name]

        print(f"ìµœì í™” ë°ì´í„°: {len(X_clean)} ìƒ˜í”Œ")

        # ë¹ ë¥¸ Walk-Forward (5ê°œ í´ë“œë§Œ)
        initial_window = 1000  # 4ë…„
        step_size = 200        # 8ê°œì›” ë‹¨ìœ„
        max_folds = 5

        # Ridge ìµœì í™”
        print("  Ridge ì •ê·œí™” ìµœì í™”...")
        ridge_scores = {}

        for alpha in ridge_alphas:
            fold_scores = []
            current_start = 0
            fold = 0

            while fold < max_folds and current_start + initial_window + 100 < len(X_clean):
                train_end = current_start + initial_window
                test_start = train_end
                test_end = min(test_start + 100, len(X_clean))

                X_train = X_clean.iloc[current_start:train_end]
                y_train = y_clean.iloc[current_start:train_end]
                X_test = X_clean.iloc[test_start:test_end]
                y_test = y_clean.iloc[test_start:test_end]

                try:
                    scaler = RobustScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)

                    model = Ridge(alpha=alpha)
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)

                    r2 = r2_score(y_test, y_pred)
                    fold_scores.append(r2)

                except:
                    fold_scores.append(-999)

                current_start += step_size
                fold += 1

            valid_scores = [s for s in fold_scores if s > -900]
            if valid_scores:
                ridge_scores[alpha] = {
                    'mean_r2': np.mean(valid_scores),
                    'std_r2': np.std(valid_scores),
                    'count': len(valid_scores)
                }

            print(f"    Î±={alpha:6.1f}: RÂ²={ridge_scores.get(alpha, {}).get('mean_r2', -999):7.4f}")

        # ìµœê³  Ridge ì„ íƒ
        if ridge_scores:
            best_ridge_alpha = max(ridge_scores.items(), key=lambda x: x[1]['mean_r2'])
            best_models['Ridge'] = {
                'model': Ridge(alpha=best_ridge_alpha[0]),
                'alpha': best_ridge_alpha[0],
                'performance': best_ridge_alpha[1]
            }
            print(f"    âœ… ìµœê³  Ridge: Î±={best_ridge_alpha[0]}, RÂ²={best_ridge_alpha[1]['mean_r2']:.4f}")

        # ElasticNet ìµœì í™” (ê°„ë‹¨íˆ)
        print("  ElasticNet ìµœì í™”...")
        best_elastic_score = -999
        best_elastic_alpha = 0.01

        for alpha in elastic_alphas:
            fold_scores = []
            current_start = 0
            fold = 0

            while fold < 3 and current_start + initial_window + 100 < len(X_clean):  # ë” ë¹ ë¥´ê²Œ
                train_end = current_start + initial_window
                test_start = train_end
                test_end = min(test_start + 100, len(X_clean))

                X_train = X_clean.iloc[current_start:train_end]
                y_train = y_clean.iloc[current_start:train_end]
                X_test = X_clean.iloc[test_start:test_end]
                y_test = y_clean.iloc[test_start:test_end]

                try:
                    scaler = RobustScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)

                    model = ElasticNet(alpha=alpha, l1_ratio=0.7, max_iter=3000)
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)

                    r2 = r2_score(y_test, y_pred)
                    fold_scores.append(r2)

                except:
                    fold_scores.append(-999)

                current_start += step_size
                fold += 1

            valid_scores = [s for s in fold_scores if s > -900]
            if valid_scores:
                mean_score = np.mean(valid_scores)
                if mean_score > best_elastic_score:
                    best_elastic_score = mean_score
                    best_elastic_alpha = alpha

            print(f"    Î±={alpha:6.3f}: RÂ²={mean_score if valid_scores else -999:7.4f}")

        if best_elastic_score > -900:
            best_models['ElasticNet'] = {
                'model': ElasticNet(alpha=best_elastic_alpha, l1_ratio=0.7, max_iter=3000),
                'alpha': best_elastic_alpha,
                'performance': {'mean_r2': best_elastic_score}
            }
            print(f"    âœ… ìµœê³  ElasticNet: Î±={best_elastic_alpha}, RÂ²={best_elastic_score:.4f}")

        return best_models

    def validate_with_extended_walkforward(self, X, y, optimized_models):
        """í™•ì¥ëœ Walk-Forward ê²€ì¦"""
        print("ğŸš€ í™•ì¥ëœ Walk-Forward ê²€ì¦ ì¤‘...")

        combined_data = pd.concat([X, y], axis=1).dropna()
        X_clean = combined_data[X.columns]
        y_clean = combined_data[y.name]

        print(f"ê²€ì¦ ë°ì´í„°: {len(X_clean)} ìƒ˜í”Œ")

        # ë” ë³´ìˆ˜ì ì¸ ì„¤ì •
        initial_window = 1260  # 5ë…„
        step_size = 126        # 6ê°œì›” ë‹¨ìœ„
        test_window = 63       # 3ê°œì›” ì˜ˆì¸¡

        results = {}
        for model_name in optimized_models.keys():
            results[model_name] = []

        current_start = 0
        fold = 0

        while current_start + initial_window + test_window < len(X_clean):
            fold += 1

            train_end = current_start + initial_window
            test_start = train_end
            test_end = min(test_start + test_window, len(X_clean))

            X_train = X_clean.iloc[current_start:train_end]
            y_train = y_clean.iloc[current_start:train_end]
            X_test = X_clean.iloc[test_start:test_end]
            y_test = y_clean.iloc[test_start:test_end]

            print(f"  Fold {fold}: í›ˆë ¨ {len(X_train)} ({X_train.index[0].strftime('%Y-%m')} ~ {X_train.index[-1].strftime('%Y-%m')})")
            print(f"           í…ŒìŠ¤íŠ¸ {len(X_test)} ({X_test.index[0].strftime('%Y-%m')} ~ {X_test.index[-1].strftime('%Y-%m')})")

            for model_name, model_info in optimized_models.items():
                try:
                    model = model_info['model']

                    # ìŠ¤ì¼€ì¼ë§
                    scaler = RobustScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)

                    # í›ˆë ¨ ë° ì˜ˆì¸¡
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)

                    # ì„±ëŠ¥ ê³„ì‚°
                    r2 = r2_score(y_test, y_pred)
                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                    mae = mean_absolute_error(y_test, y_pred)

                    results[model_name].append({
                        'fold': fold,
                        'r2': r2,
                        'rmse': rmse,
                        'mae': mae,
                        'test_period': f"{X_test.index[0].strftime('%Y-%m')} ~ {X_test.index[-1].strftime('%Y-%m')}"
                    })

                    print(f"    {model_name:15}: RÂ²={r2:7.4f}, RMSE={rmse:.5f}")

                except Exception as e:
                    print(f"    {model_name:15}: ì˜¤ë¥˜ - {e}")
                    results[model_name].append({
                        'fold': fold,
                        'r2': -999,
                        'rmse': 999,
                        'mae': 999,
                        'error': str(e)
                    })

            current_start += step_size

        # ê²°ê³¼ ìš”ì•½
        summary = {}
        print(f"\nğŸ“Š í™•ì¥ëœ Walk-Forward ê²°ê³¼:")
        print(f"{'Model':<15} {'Mean RÂ²':<10} {'Std RÂ²':<10} {'Valid Folds':<12} {'Best Fold'}")
        print("-" * 65)

        for model_name, fold_results in results.items():
            valid_r2s = [r['r2'] for r in fold_results if r['r2'] != -999]

            if valid_r2s:
                mean_r2 = np.mean(valid_r2s)
                std_r2 = np.std(valid_r2s)
                max_r2 = np.max(valid_r2s)
                valid_folds = len(valid_r2s)

                summary[model_name] = {
                    'mean_r2': mean_r2,
                    'std_r2': std_r2,
                    'max_r2': max_r2,
                    'valid_folds': valid_folds,
                    'total_folds': len(fold_results)
                }

                print(f"{model_name:<15} {mean_r2:<10.4f} {std_r2:<10.4f} {valid_folds}/{len(fold_results):<12} {max_r2:.4f}")
            else:
                summary[model_name] = {'mean_r2': -999, 'valid_folds': 0}
                print(f"{model_name:<15} {'FAILED':<10} {'N/A':<10} {'0':<12} {'N/A'}")

        return summary, results

def main():
    """ë©”ì¸ í–¥ìƒëœ ì„±ëŠ¥ ê°œì„  í•¨ìˆ˜"""
    print("ğŸš€ Enhanced Performance Model - ì•ˆì „í•œ ì„±ëŠ¥ ê°œì„ ")
    print("=" * 80)
    print("âš ï¸ Walk-Forward ê²€ì¦ì„ ê¸°ë³¸ìœ¼ë¡œ í•˜ì—¬ ê³¼ì í•© ë°©ì§€")
    print("=" * 80)

    predictor = EnhancedPerformancePredictor()

    # 1. í™•ì¥ëœ ë°ì´í„° ë¡œë“œ
    data = predictor.load_extended_data()
    if data is None:
        return

    # 2. í–¥ìƒëœ íŠ¹ì„± ìƒì„±
    features = predictor.create_enhanced_features(data)
    targets = predictor.create_robust_targets(data)

    # 3. ì£¼ìš” íƒ€ê²Ÿì— ì§‘ì¤‘ (5ì¼ ë³€ë™ì„±)
    target_col = 'target_vol_5d'
    if target_col not in targets.columns:
        print(f"âŒ íƒ€ê²Ÿ ì»¬ëŸ¼ {target_col} ì—†ìŒ")
        return

    # 4. íŠ¹ì„± ì„ ë³„ (ìƒê´€ê´€ê³„ ê¸°ì¤€)
    combined = pd.concat([features, targets[[target_col]]], axis=1).dropna()
    print(f"\nğŸ“Š ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(combined)} ìƒ˜í”Œ")

    correlations = combined[features.columns].corrwith(combined[target_col]).abs().sort_values(ascending=False)

    print(f"\nğŸ“ˆ ìƒìœ„ 20ê°œ íŠ¹ì„±:")
    for i, (feature, corr) in enumerate(correlations.head(20).items()):
        print(f"  {i+1:2d}. {feature:30}: {corr:.4f}")

    # ìƒìœ„ íŠ¹ì„± ì„ ë³„ (ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ ì ë‹¹íˆ)
    top_features = correlations.head(20).index
    final_features = features[top_features]

    print(f"\nğŸ¯ ìµœì¢… íŠ¹ì„± ìˆ˜: {len(final_features.columns)}")

    # 5. ì •ê·œí™” ê°•ë„ ìµœì í™”
    optimized_models = predictor.optimize_regularization_strength(final_features, targets[target_col])

    if not optimized_models:
        print("âŒ ìµœì í™”ëœ ëª¨ë¸ ì—†ìŒ")
        return

    # 6. í™•ì¥ëœ Walk-Forward ê²€ì¦
    wf_summary, wf_details = predictor.validate_with_extended_walkforward(
        final_features, targets[target_col], optimized_models
    )

    # 7. ê²°ê³¼ ë¶„ì„
    best_model = None
    best_score = -999

    for model_name, stats in wf_summary.items():
        if stats.get('mean_r2', -999) > best_score:
            best_score = stats['mean_r2']
            best_model = model_name

    # 8. ê²°ê³¼ ì €ì¥
    os.makedirs('results', exist_ok=True)

    enhanced_results = {
        'version': 'Enhanced_Performance_Safe',
        'timestamp': datetime.now().isoformat(),
        'approach': 'Extended data + optimized regularization',
        'data_period': '2000-2024',
        'total_samples': len(combined),
        'features_count': len(final_features.columns),
        'best_model': {
            'name': best_model,
            'mean_r2': best_score,
            'std_r2': wf_summary.get(best_model, {}).get('std_r2', 0) if best_model else 0
        },
        'all_results': wf_summary,
        'top_features': top_features.tolist(),
        'optimization_details': {model: info.get('performance', {}) for model, info in optimized_models.items()},
        'validation_method': 'Extended Walk-Forward',
        'safety_measures': [
            'Walk-Forward validation only',
            'Extended historical data (2000-2024)',
            'Optimized regularization strength',
            'Conservative feature selection',
            'Robust scaling'
        ]
    }

    with open('results/enhanced_performance_model.json', 'w') as f:
        json.dump(enhanced_results, f, indent=2, default=str)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: results/enhanced_performance_model.json")

    # 9. ìµœì¢… í‰ê°€
    if best_model and best_score > 0:
        print(f"\nğŸ‰ ì„±ëŠ¥ ê°œì„  ì„±ê³µ!")
        print(f"   ìµœê³  ëª¨ë¸: {best_model}")
        print(f"   Walk-Forward RÂ²: {best_score:.4f}")

        # ì´ì „ Robust ëª¨ë¸ê³¼ ë¹„êµ
        robust_r2 = 0.0145  # ì´ì „ ê²°ê³¼
        improvement = (best_score - robust_r2) / robust_r2 * 100 if robust_r2 > 0 else 0

        print(f"   ì´ì „ Robust ëª¨ë¸: {robust_r2:.4f}")
        print(f"   ê°œì„ ë„: {improvement:+.1f}%")

        if best_score > robust_r2:
            print(f"   âœ… ì•ˆì „í•œ ì„±ëŠ¥ ê°œì„  ë‹¬ì„±!")
        else:
            print(f"   âš ï¸ ì„±ëŠ¥ ê°œì„  ë¯¸ë¯¸, ì¶”ê°€ ìµœì í™” í•„ìš”")

    else:
        print(f"\nâš ï¸ ì„±ëŠ¥ ê°œì„  ì‹¤íŒ¨")
        print(f"   ìµœê³  ì„±ëŠ¥: {best_score:.4f}")
        print(f"   ì¶”ê°€ ì ‘ê·¼ë²• í•„ìš”")

    print("=" * 80)

if __name__ == "__main__":
    main()