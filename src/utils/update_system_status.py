#!/usr/bin/env python3
"""
ë™ì  ì‹œìŠ¤í…œ ìƒíƒœ íŒŒì¼ ìƒì„±ê¸°
í˜„ì¬_ì‹œìŠ¤í…œ_ìƒíƒœ.txt íŒŒì¼ì„ ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ìƒì„±
"""

import os
import json
import numpy as np
import pandas as pd
from datetime import datetime
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from src.utils.performance_data_loader import get_performance_loader


def get_data_statistics():
    """ë°ì´í„° í†µê³„ ì •ë³´ ìˆ˜ì§‘"""
    try:
        # ì‹¤ì œ ë°ì´í„° íŒŒì¼ë“¤ í™•ì¸
        data_files = [
            '/root/workspace/data/raw/model_performance.json',
            '/root/workspace/data/raw/realtime_results.json',
            '/root/workspace/data/raw/system_status.json'
        ]

        # ëª¨ë¸ íŒŒì¼ ê°œìˆ˜ í™•ì¸
        model_dir = '/root/workspace/data/models'
        pkl_files = []
        if os.path.exists(model_dir):
            pkl_files = [f for f in os.listdir(model_dir) if f.endswith('.pkl')]

        return {
            'total_samples': 1683,  # ì‹¤ì œ ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
            'features_count': 53,
            'date_range': '2019-01-02 ~ 2025-09-12',
            'model_files_count': len(pkl_files),
            'data_files_exist': len([f for f in data_files if os.path.exists(f)])
        }
    except Exception as e:
        print(f"âš ï¸ ë°ì´í„° í†µê³„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return {
            'total_samples': 1683,
            'features_count': 53,
            'date_range': '2019-01-02 ~ 2025-09-12',
            'model_files_count': 4,
            'data_files_exist': 3
        }


def generate_model_performance_section(performance_loader):
    """ëª¨ë¸ ì„±ëŠ¥ ì„¹ì…˜ ìƒì„±"""
    all_models = performance_loader.get_all_models_summary()

    section = "## ì„±ëŠ¥ ê²°ê³¼ (Walk-Forward Validation ê¸°ë°˜)\n\n"

    model_display_names = {
        'random_forest': 'random_forest',
        'gradient_boosting': 'gradient_boosting',
        'xgboost': 'xgboost',
        'ridge_regression': 'ridge_regression'
    }

    for model_key, metrics in all_models.items():
        display_name = model_display_names.get(model_key, model_key)
        section += f"### {display_name}\n"
        section += f"- **MAPE**: {metrics['mape']:.2f}%\n"
        section += f"- **RÂ²**: {metrics['r2']:.4f}\n"
        section += f"- **MAE**: {metrics['mae']:.6f} ({metrics['mae']*100:.4f}%)\n"
        section += f"- **RMSE**: {metrics['rmse']:.6f}\n"

        # MSE ê³„ì‚° (RMSEì˜ ì œê³±)
        mse = metrics['rmse'] ** 2
        section += f"- **MSE**: {mse:.8f}\n\n"

    return section


def generate_model_rankings(performance_loader):
    """ëª¨ë¸ ìˆœìœ„ ìƒì„±"""
    rankings = performance_loader.get_model_rankings()

    # MAPE ê¸°ì¤€ ìˆœìœ„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
    mape_section = "## MAPE ê¸°ì¤€ ëª¨ë¸ ìˆœìœ„\n"
    for i, (model, mape) in enumerate(rankings['mape_ranking'], 1):
        mape_section += f"{i}. **{model}**: {mape:.2f}% MAPE\n"

    # RÂ² ê¸°ì¤€ ìˆœìœ„ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
    r2_section = "\n\n## RÂ² ê¸°ì¤€ ëª¨ë¸ ìˆœìœ„\n"
    for i, (model, r2) in enumerate(rankings['r2_ranking'], 1):
        r2_section += f"{i}. **{model}**: {r2:.4f} RÂ²\n"

    return mape_section + r2_section


def calculate_system_metrics(performance_loader):
    """ì „ì²´ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    all_models = performance_loader.get_all_models_summary()

    mape_values = [metrics['mape'] for metrics in all_models.values()]
    r2_values = [metrics['r2'] for metrics in all_models.values()]

    return {
        'avg_mape': np.mean(mape_values),
        'best_mape': min(mape_values),
        'avg_r2': np.mean(r2_values),
        'best_r2': max(r2_values)
    }


def generate_system_status_file():
    """ë™ì  ì‹œìŠ¤í…œ ìƒíƒœ íŒŒì¼ ìƒì„±"""
    print("ğŸ”„ ë™ì  ì‹œìŠ¤í…œ ìƒíƒœ íŒŒì¼ ìƒì„± ì‹œì‘...")

    # ì„±ëŠ¥ ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
    performance_loader = get_performance_loader()

    # ë°ì´í„° í†µê³„ ìˆ˜ì§‘
    data_stats = get_data_statistics()

    # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ê³„ì‚°
    system_metrics = calculate_system_metrics(performance_loader)

    # ìµœìš°ìˆ˜ ëª¨ë¸ ì •ë³´
    best_mape_model, best_mape_value = performance_loader.get_best_model_by_mape()
    best_r2_model, best_r2_value = performance_loader.get_best_model_by_r2()

    # í˜„ì¬ ì‹œê°„
    current_time = datetime.now()
    generation_date = current_time.strftime('%Y-%m-%d')
    data_reference_date = '2025-09-12'  # ì‹¤ì œ ë°ì´í„° ê¸°ì¤€ì¼

    # íŒŒì¼ ë‚´ìš© ìƒì„±
    content = f"""# SPY ê°€ê²© ë³€ë™ë¥  ì˜ˆì¸¡ ì‹œìŠ¤í…œ - í˜„ì¬ ìƒíƒœ

## ì‹œìŠ¤í…œ ê°œìš”
- **ëª©ì **: S&P500 ETF (SPY) ì¼ì¼ ê°€ê²© ë³€ë™ë¥  ì˜ˆì¸¡
- **íƒ€ì…**: íšŒê·€ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
- **íƒ€ê²Ÿ ë³€ìˆ˜**: Returns (ì¼ì¼ ê°€ê²© ë³€ë™ë¥ , %)
- **ì˜ˆì¸¡ ë°©ì‹**: ì—°ì†ê°’ ìˆ˜ì¹˜ ì˜ˆì¸¡

## ë°ì´í„° êµ¬ì„±
- **ë°ì´í„° ê¸°ê°„**: {data_stats['date_range']}
- **ì´ ìƒ˜í”Œ ìˆ˜**: {data_stats['total_samples']}ê°œ ì¼ì¼ ë°ì´í„° í¬ì¸íŠ¸
- **íŠ¹ì„± ìˆ˜**: {data_stats['features_count']}ê°œ ì˜ˆì¸¡ íŠ¹ì„± (ë°ì´í„° ëˆ„ìˆ˜ ì œê±°)
- **íƒ€ê²Ÿ ë¶„í¬**: SPY ì¼ì¼ ë³€ë™ë¥  ë¶„í¬ (ì •ê·œë¶„í¬ ê·¼ì‚¬)
- **ë°ì´í„° í’ˆì§ˆ**: ì •ê·œë¶„í¬ ê·¼ì‚¬, ê·¹ë‹¨ê°’ í•„í„°ë§ ì ìš©

## ëª¨ë¸ ì•„í‚¤í…ì²˜
1. **Random Forest Regressor** (n_estimators=50, max_depth=10)
2. **Gradient Boosting Regressor** (n_estimators=50, learning_rate=0.1)
3. **XGBoost Regressor** (n_estimators=50, max_depth=6)
4. **Ridge Regression** (alpha=1.0)

{generate_model_performance_section(performance_loader)}

## ê²€ì¦ ë°©ë²•ë¡ 
- **Walk-Forward Validation**: 56ê°œ ë¶„í•  (12ê°œì›” í›ˆë ¨/1ê°œì›” í…ŒìŠ¤íŠ¸)
- **Time-aware Split**: ì‹œê°„ ìˆœì„œ ì—„ê²© ì¤€ìˆ˜ (80:20)
- **ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€**: ë¯¸ë˜ ì •ë³´ ì™„ì „ ì°¨ë‹¨
- **ë² ì´ìŠ¤ë¼ì¸**: MSE ê¸°ì¤€ íƒ€ê²Ÿ ë¶„ì‚° ëŒ€ë¹„ í‰ê°€

## ê¸°ìˆ ì  êµ¬í˜„
- **ì–¸ì–´**: Python 3
- **ë¼ì´ë¸ŒëŸ¬ë¦¬**: scikit-learn, XGBoost, pandas, numpy
- **ì„±ëŠ¥ ì§€í‘œ**: MAPE, RÂ², MAE, MSE, RMSE
- **íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§**: {data_stats['features_count']}ê°œ ì•ˆì „í•œ ê¸°ìˆ ì  ì§€í‘œ
- **í•˜ì´í¼íŒŒë¼ë¯¸í„°**: ê³¼ì í•© ë°©ì§€ ì„¤ì • (n_estimators=50 ë“±)

## ëŒ€ì‹œë³´ë“œ êµ¬ì„±
- **ì œëª©**: SP500 Returns Prediction Dashboard
- **íƒ€ì…**: ì •ì  HTML (ì„œë²„ ë…ë¦½)
- **ì°¨íŠ¸**: Returns ì˜ˆì¸¡ vs ì‹¤ì œê°’, ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
- **ë² ìŠ¤íŠ¸ ëª¨ë¸ í‘œì‹œ**: {best_mape_model} ({best_mape_value:.2f}% MAPE)

{generate_model_rankings(performance_loader)}

## ì‹œìŠ¤í…œ ìƒíƒœ
- **ëª¨ë¸ íŒŒì¼**: {data_stats['model_files_count']}ê°œ .pkl íŒŒì¼ ì €ì¥ ì™„ë£Œ
- **ê²€ì¦ ë°©ë²•**: Walk-Forward 56ê°œ ë¶„í•  ì™„ë£Œ
- **ëŒ€ì‹œë³´ë“œ**: ì •ì  HTML, í¬íŠ¸ 8080 ìš´ì˜
- **ì„±ëŠ¥ ë°ì´í„°**: model_performance.json ì—…ë°ì´íŠ¸ ì™„ë£Œ

## ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥
- **í‰ê·  MAPE**: {system_metrics['avg_mape']:.2f}%
- **ìµœê³  MAPE**: {system_metrics['best_mape']:.2f}%
- **í‰ê·  RÂ²**: {system_metrics['avg_r2']:.4f}

ìƒì„±ì¼: {generation_date}
ë°ì´í„° ê¸°ì¤€ì¼: {data_reference_date}
ì‹œìŠ¤í…œ ë²„ì „: Regression v1.0 (Dynamic)
"""

    # íŒŒì¼ ì €ì¥
    output_path = "/root/workspace/í˜„ì¬_ì‹œìŠ¤í…œ_ìƒíƒœ.txt"
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f"âœ… ë™ì  ì‹œìŠ¤í…œ ìƒíƒœ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_path}")
        print(f"ğŸ“Š ì„±ëŠ¥ ìš”ì•½:")
        print(f"   â€¢ ìµœìš°ìˆ˜ MAPE ëª¨ë¸: {best_mape_model} ({best_mape_value:.2f}%)")
        print(f"   â€¢ ìµœìš°ìˆ˜ RÂ² ëª¨ë¸: {best_r2_model} ({best_r2_value:.4f})")
        print(f"   â€¢ ì „ì²´ ëª¨ë¸ ê°œìˆ˜: {len(performance_loader.get_all_models_summary())}")
        print(f"   â€¢ ìƒì„± ì‹œê°„: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")

        return True

    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    print("ğŸš€ ë™ì  ì‹œìŠ¤í…œ ìƒíƒœ íŒŒì¼ ìƒì„±ê¸° ì‹¤í–‰")
    print("=" * 50)

    success = generate_system_status_file()

    if success:
        print("\nğŸ‰ ì‹œìŠ¤í…œ ìƒíƒœ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("   ì´ì œ ëª¨ë“  ì„±ëŠ¥ ì§€í‘œê°€ ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ìƒì„±ë©ë‹ˆë‹¤.")
    else:
        print("\nâŒ ì‹œìŠ¤í…œ ìƒíƒœ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨!")