#!/usr/bin/env python3
"""
ì¤‘ì•™í™”ëœ ì„±ëŠ¥ ë°ì´í„° ë¡œë”
í•˜ë“œì½”ë”©ëœ ì„±ëŠ¥ ì§€í‘œë¥¼ ì‹¤ì œ ë°ì´í„° íŒŒì¼ì—ì„œ ë¡œë“œí•˜ëŠ” í†µí•© ì¸í„°í˜ì´ìŠ¤
"""

import json
import os
from typing import Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)


class PerformanceDataLoader:
    """ëª¨ë¸ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, data_path: str = "/root/workspace/data/raw/model_performance.json"):
        """
        ì„±ëŠ¥ ë°ì´í„° ë¡œë” ì´ˆê¸°í™”

        Args:
            data_path (str): ì„±ëŠ¥ ë°ì´í„° JSON íŒŒì¼ ê²½ë¡œ
        """
        self.data_path = data_path
        self.advanced_data_path = "/root/workspace/data/raw/advanced_model_performance.json"
        self.clean_data_path = "/root/workspace/data/raw/clean_model_performance.json"
        self.conservative_data_path = "/root/workspace/data/raw/conservative_model_performance.json"
        self.leak_free_data_path = "/root/workspace/data/raw/leak_free_model_performance.json"
        self._performance_data = None


    def load_performance_data(self, force_reload: bool = False) -> Dict[str, Any]:
        """
        ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ (ê¸°ë³¸ + ê³ ê¸‰ + Clean ëª¨ë¸ í¬í•¨)

        Args:
            force_reload (bool): ê°•ì œ ì¬ë¡œë“œ ì—¬ë¶€

        Returns:
            Dict[str, Any]: ì„±ëŠ¥ ë°ì´í„°

        Raises:
            FileNotFoundError: ëª¨ë“  ì„±ëŠ¥ ë°ì´í„° íŒŒì¼ì´ ì—†ì„ ë•Œ
            ValueError: ì„±ëŠ¥ ë°ì´í„° í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆì„ ë•Œ
        """
        if self._performance_data is None or force_reload:
            combined_data = {}
            loaded_files = []

            # 1. ê¸°ë³¸ ëª¨ë¸ ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ
            try:
                if os.path.exists(self.data_path):
                    with open(self.data_path, 'r', encoding='utf-8') as f:
                        basic_data = json.load(f)
                        combined_data.update(basic_data)
                        loaded_files.append("ê¸°ë³¸ ëª¨ë¸")
                    logger.info(f"âœ… ê¸°ë³¸ ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ: {self.data_path}")
            except Exception as e:
                logger.warning(f"âš ï¸ ê¸°ë³¸ ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

            # 2. ê³ ê¸‰ ëª¨ë¸ ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ
            try:
                if os.path.exists(self.advanced_data_path):
                    with open(self.advanced_data_path, 'r', encoding='utf-8') as f:
                        advanced_data = json.load(f)
                        # ê³ ê¸‰ ëª¨ë¸ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        for model_name, model_data in advanced_data.items():
                            if 'test_metrics' in model_data:
                                combined_data[f"{model_name}_advanced"] = {
                                    'mape': model_data['test_metrics']['mape'],
                                    'r2': model_data['test_metrics']['r2'],
                                    'mae': model_data['test_metrics']['mae'],
                                    'rmse': model_data['test_metrics']['rmse'],
                                    'mse': model_data['test_metrics']['mse']
                                }
                        loaded_files.append("ê³ ê¸‰ ëª¨ë¸")
                    logger.info(f"âœ… ê³ ê¸‰ ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ: {self.advanced_data_path}")
            except Exception as e:
                logger.warning(f"âš ï¸ ê³ ê¸‰ ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

            # 3. Leak-Free ëª¨ë¸ ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ (ì§„ì‹¤ - ìµœìš°ì„ )
            try:
                if os.path.exists(self.leak_free_data_path):
                    with open(self.leak_free_data_path, 'r', encoding='utf-8') as f:
                        leak_free_data = json.load(f)
                        # Leak-Free ëª¨ë¸ë§Œ ì‚¬ìš©í•˜ë„ë¡ ê¸°ì¡´ ë°ì´í„°ë¥¼ Clearí•˜ê³  ì§„ì§œ ë°ì´í„°ë§Œ ë¡œë“œ
                        combined_data.clear()
                        for model_name, model_data in leak_free_data.items():
                            if 'final_test' in model_data:
                                combined_data[model_name] = {
                                    'mape': model_data['final_test']['mape'],
                                    'r2': model_data['final_test']['r2'],
                                    'mae': model_data['final_test']['mae'],
                                    'rmse': model_data['final_test']['rmse'],
                                    'mse': model_data['final_test']['mse'],
                                    'direction_accuracy': model_data['final_test']['direction_accuracy'],
                                    'cv_mape': model_data.get('cv_mape_mean', model_data['final_test']['mape']),
                                    'cv_mape_std': model_data.get('cv_mape_std', 0),
                                    'cv_r2': model_data.get('cv_r2', model_data['final_test']['r2']),
                                    'validation_method': model_data.get('validation_method', 'Leak-Free Walk-Forward'),
                                    'data_leakage_check': model_data.get('data_leakage_check', 'VERIFIED CLEAN'),
                                    'reality_check': 'í˜„ì‹¤ì  ê¸ˆìœµ ì‹œì¥ ì„±ëŠ¥'
                                }
                        loaded_files = ["Leak-Free ëª¨ë¸ (ì§„ì‹¤ - ë°ì´í„° ëˆ„ìˆ˜ ì™„ì „ ì œê±°)"]
                    logger.info(f"âœ… Leak-Free ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ (ì§„ì‹¤): {self.leak_free_data_path}")
            except Exception as e:
                logger.warning(f"âš ï¸ Leak-Free ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

                # Leak-Free ë¡œë“œ ì‹¤íŒ¨ ì‹œ Conservative ëª¨ë¸ë¡œ ëŒ€ì²´ (ì—¬ì „íˆ ì˜ì‹¬ìŠ¤ëŸ½ì§€ë§Œ)
                try:
                    if os.path.exists(self.conservative_data_path):
                        with open(self.conservative_data_path, 'r', encoding='utf-8') as f:
                            conservative_data = json.load(f)
                            combined_data.clear()
                            for model_name, model_data in conservative_data.items():
                                if 'final_test' in model_data:
                                    combined_data[model_name] = {
                                        'mape': model_data['final_test']['mape'],
                                        'r2': model_data['final_test']['r2'],
                                        'mae': model_data['final_test']['mae'],
                                        'rmse': model_data['final_test']['rmse'],
                                        'mse': model_data['final_test']['mse'],
                                        'direction_accuracy': model_data['final_test']['direction_accuracy'],
                                        'walk_forward_mape': model_data.get('walk_forward_mape', model_data['final_test']['mape']),
                                        'cv_r2': model_data.get('cv_r2', model_data['final_test']['r2']),
                                        'validation_method': model_data.get('validation_method', 'Conservative Walk-Forward'),
                                        'data_leakage_check': 'ì—¬ì „íˆ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì„±ëŠ¥ - ì¬ê²€ì¦ í•„ìš”'
                                    }
                            loaded_files = ["Conservative ëª¨ë¸ (fallback - ì„±ëŠ¥ ì˜ì‹¬ìŠ¤ëŸ¬ì›€)"]
                        logger.info(f"âš ï¸ Conservative ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ (fallback): {self.conservative_data_path}")
                except Exception as e2:
                    logger.error(f"âŒ Conservative ì„±ëŠ¥ ë°ì´í„° ë¡œë“œë„ ì‹¤íŒ¨: {e2}")

                    # ë§ˆì§€ë§‰ fallbackìœ¼ë¡œ Clean ëª¨ë¸
                    try:
                        if os.path.exists(self.clean_data_path):
                            with open(self.clean_data_path, 'r', encoding='utf-8') as f:
                                clean_data = json.load(f)
                                combined_data.clear()
                                for model_name, model_data in clean_data.items():
                                    if 'final_test' in model_data:
                                        combined_data[model_name] = {
                                            'mape': model_data['final_test']['mape'],
                                            'r2': model_data['final_test']['r2'],
                                            'mae': model_data['final_test']['mae'],
                                            'rmse': model_data['final_test']['rmse'],
                                            'mse': model_data['final_test']['mse'],
                                            'direction_accuracy': model_data['final_test']['direction_accuracy'],
                                            'cv_mape': model_data['cross_validation']['mape'],
                                            'cv_r2': model_data['cross_validation']['r2'],
                                            'validation_method': model_data.get('validation_method', 'Clean Walk-Forward'),
                                            'data_leakage_check': 'Clean but still suspicious'
                                        }
                                loaded_files = ["Clean ëª¨ë¸ (last fallback)"]
                            logger.info(f"âœ… Clean ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ (last fallback): {self.clean_data_path}")
                    except Exception as e3:
                        logger.error(f"âŒ ëª¨ë“  ì„±ëŠ¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e3}")

            # ë°ì´í„° ë¡œë“œ ê²€ì¦
            if not combined_data:
                raise FileNotFoundError(
                    f"ëª¨ë“  ì„±ëŠ¥ ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                    f"í™•ì¸ í•„ìš”: {self.data_path}, {self.advanced_data_path}, {self.clean_data_path}"
                )

            if not loaded_files:
                raise ValueError("ì„±ëŠ¥ ë°ì´í„°ê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")

            logger.info(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„°: {', '.join(loaded_files)} ({len(combined_data)}ê°œ ëª¨ë¸)")
            self._performance_data = combined_data

        return self._performance_data

    def get_model_performance(self, model_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • ëª¨ë¸ì˜ ì„±ëŠ¥ ì§€í‘œ ì¡°íšŒ

        Args:
            model_name (str): ëª¨ë¸ëª…

        Returns:
            Dict[str, Any]: ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ

        Raises:
            KeyError: í•´ë‹¹ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ì„ ë•Œ
        """
        data = self.load_performance_data()
        if model_name not in data:
            raise KeyError(f"ëª¨ë¸ '{model_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {list(data.keys())}")
        return data[model_name]

    def get_mape(self, model_name: str) -> float:
        """íŠ¹ì • ëª¨ë¸ì˜ MAPE ê°’ ì¡°íšŒ"""
        model_data = self.get_model_performance(model_name)
        return model_data.get('mape', 0.0)

    def get_r2(self, model_name: str) -> float:
        """íŠ¹ì • ëª¨ë¸ì˜ RÂ² ê°’ ì¡°íšŒ"""
        model_data = self.get_model_performance(model_name)
        return model_data.get('r2', model_data.get('r2_score', 0.0))

    def get_mae(self, model_name: str) -> float:
        """íŠ¹ì • ëª¨ë¸ì˜ MAE ê°’ ì¡°íšŒ"""
        model_data = self.get_model_performance(model_name)
        return model_data.get('mae', 0.0)

    def get_rmse(self, model_name: str) -> float:
        """íŠ¹ì • ëª¨ë¸ì˜ RMSE ê°’ ì¡°íšŒ"""
        model_data = self.get_model_performance(model_name)
        return model_data.get('rmse', 0.0)

    def get_best_model_by_mape(self) -> tuple[str, float]:
        """MAPE ê¸°ì¤€ ìµœìš°ìˆ˜ ëª¨ë¸ ì¡°íšŒ"""
        data = self.load_performance_data()
        best_model = None
        best_mape = float('inf')

        for model_name, model_data in data.items():
            if isinstance(model_data, dict) and 'mape' in model_data:
                mape = model_data['mape']
                if mape > 0 and mape < best_mape:
                    best_mape = mape
                    best_model = model_name

        if best_model is None:
            raise ValueError("MAPE ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        return best_model, best_mape

    def get_best_model_by_r2(self) -> tuple[str, float]:
        """RÂ² ê¸°ì¤€ ìµœìš°ìˆ˜ ëª¨ë¸ ì¡°íšŒ"""
        data = self.load_performance_data()
        best_model = None
        best_r2 = -float('inf')

        for model_name, model_data in data.items():
            if isinstance(model_data, dict) and 'r2' in model_data:
                r2 = model_data['r2']
                if r2 > best_r2:
                    best_r2 = r2
                    best_model = model_name

        if best_model is None:
            raise ValueError("RÂ² ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        return best_model, best_r2

    def get_all_models_summary(self) -> Dict[str, Dict[str, float]]:
        """ëª¨ë“  ëª¨ë¸ì˜ ìš”ì•½ ì •ë³´ ì¡°íšŒ"""
        data = self.load_performance_data()
        summary = {}

        for model_name, model_data in data.items():
            if isinstance(model_data, dict):
                summary[model_name] = {
                    'mape': model_data.get('mape', 0.0),
                    'r2': model_data.get('r2', 0.0),
                    'mae': model_data.get('mae', 0.0),
                    'rmse': model_data.get('rmse', 0.0)
                }

        return summary

    def get_model_rankings(self) -> Dict[str, list]:
        """ëª¨ë¸ ìˆœìœ„ ì •ë³´ ì¡°íšŒ"""
        data = self.load_performance_data()

        # MAPE ê¸°ì¤€ ìˆœìœ„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        mape_ranking = []
        for model_name, model_data in data.items():
            if isinstance(model_data, dict) and 'mape' in model_data:
                mape_ranking.append((model_name, model_data['mape']))
        mape_ranking.sort(key=lambda x: x[1])

        # RÂ² ê¸°ì¤€ ìˆœìœ„ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        r2_ranking = []
        for model_name, model_data in data.items():
            if isinstance(model_data, dict) and 'r2' in model_data:
                r2_ranking.append((model_name, model_data['r2']))
        r2_ranking.sort(key=lambda x: x[1], reverse=True)

        return {
            'mape_ranking': mape_ranking,
            'r2_ranking': r2_ranking
        }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ - ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ì‚¬ìš©
_performance_loader = None

def get_performance_loader() -> PerformanceDataLoader:
    """ì„±ëŠ¥ ë°ì´í„° ë¡œë” ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _performance_loader
    if _performance_loader is None:
        _performance_loader = PerformanceDataLoader()
    return _performance_loader


# í¸ì˜ í•¨ìˆ˜ë“¤
def get_model_mape(model_name: str) -> float:
    """ëª¨ë¸ì˜ MAPE ê°’ ì¡°íšŒ"""
    return get_performance_loader().get_mape(model_name)

def get_model_r2(model_name: str) -> float:
    """ëª¨ë¸ì˜ RÂ² ê°’ ì¡°íšŒ"""
    return get_performance_loader().get_r2(model_name)

def get_best_model_mape() -> tuple[str, float]:
    """MAPE ê¸°ì¤€ ìµœìš°ìˆ˜ ëª¨ë¸ ì¡°íšŒ"""
    return get_performance_loader().get_best_model_by_mape()

def get_best_model_r2() -> tuple[str, float]:
    """RÂ² ê¸°ì¤€ ìµœìš°ìˆ˜ ëª¨ë¸ ì¡°íšŒ"""
    return get_performance_loader().get_best_model_by_r2()

def get_all_model_performance() -> Dict[str, Dict[str, float]]:
    """ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½"""
    return get_performance_loader().get_all_models_summary()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    loader = get_performance_loader()

    print("ğŸ“Š ì„±ëŠ¥ ë°ì´í„° ë¡œë” í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # ê°œë³„ ëª¨ë¸ ì„±ëŠ¥
    for model in ['random_forest', 'gradient_boosting', 'xgboost', 'ridge_regression']:
        mape = loader.get_mape(model)
        r2 = loader.get_r2(model)
        print(f"{model}: MAPE={mape:.2f}%, RÂ²={r2:.4f}")

    print("\nğŸ† ìµœìš°ìˆ˜ ëª¨ë¸")
    best_mape_model, best_mape = get_best_model_mape()
    best_r2_model, best_r2 = get_best_model_r2()
    print(f"MAPE ê¸°ì¤€: {best_mape_model} ({best_mape:.2f}%)")
    print(f"RÂ² ê¸°ì¤€: {best_r2_model} ({best_r2:.4f})")