import os
import json
import threading
import time
from datetime import datetime
import logging
import pandas as pd  # pandas import ì¶”ê°€


# Missing imports - validation checker and monitoring systems need to be created
# from src.testing.validation_checker import DataValidationChecker
# from src.utils.xai_monitoring import XAIMonitoringSystem
# from src.testing.realtime_testing_system import RealTimeTestingSystem

# LLM imports - these exist
try:
    from src.features.llm_feature_extractor import extract_llm_features
except ImportError:
    extract_llm_features = None

try:
    from src.features.llm_feature_extractor_improved import EnhancedLLMFeatureExtractor
except ImportError:
    EnhancedLLMFeatureExtractor = None

# Available imports
try:
    from src.analysis.xai_analyzer import XAIAnalyzer
except ImportError:
    XAIAnalyzer = None

try:
    from src.utils.directory_manager import DirectoryManager
except ImportError:
    DirectoryManager = None

try:
    from src.core.config_manager import get_config_manager
except ImportError:
    get_config_manager = None

try:
    import tensorflow as tf
except ImportError:
    tf = None


class SystemOrchestrator:
    def __init__(self, data_dir="data/raw"):
        # ë””ë ‰í† ë¦¬ ìë™ ìƒì„± ë¨¼ì € ì‹¤í–‰ (optional)
        if DirectoryManager:
            self.directory_manager = DirectoryManager()
            self.directory_manager.ensure_directories()
        else:
            self.directory_manager = None
            # Create basic directories manually
            os.makedirs("data/raw", exist_ok=True)
            os.makedirs("data/processed", exist_ok=True)
            os.makedirs("logs/system", exist_ok=True)

        # ConfigManager ì´ˆê¸°í™” (optional)
        if get_config_manager:
            self.config_manager = get_config_manager()
        else:
            self.config_manager = None

        self.data_dir = os.path.abspath(data_dir)
        self.components = {}
        self.status = {
            "validation": "not_started",
            "xai_monitoring": "not_started", 
            "realtime_testing": "not_started",
            "overall_health": "unknown",
            "directories": "initialized",
        }

        # ë¡œê¹… ì„¤ì • - ì´ì œ logs ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•¨
        if self.directory_manager and hasattr(self.directory_manager, 'project_root'):
            log_dir = self.directory_manager.project_root / "logs/system"
            log_file = log_dir / "system_orchestrator.log"
        else:
            log_dir = "logs/system"
            log_file = "logs/system/system_orchestrator.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler(str(log_file)),
                logging.StreamHandler(),
            ],
        )
        self.logger = logging.getLogger(__name__)
        
        # ì´ˆê¸°í™” ì™„ë£Œ ë¡œê·¸
        self.logger.info("ğŸš€ ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ì‹œì‘")
        if self.directory_manager and hasattr(self.directory_manager, 'project_root'):
            self.logger.info(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {self.directory_manager.project_root}")
        else:
            self.logger.info(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {os.getcwd()}")
        
        self.check_gpu()

    def check_gpu(self):
        """GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        if tf is None:
            self.logger.info("âš ï¸ TensorFlow ë¯¸ì„¤ì¹˜. GPU í™•ì¸ ê±´ë„ˆëœ€ (Static Mode)")
            return

        gpus = tf.config.list_physical_devices("GPU")
        if gpus:
            self.logger.info(f"âœ… GPU ì¥ì¹˜ ê°ì§€: {gpus}")
        else:
            self.logger.warning("âš ï¸ GPU ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

    def initialize_components(self):
        """ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (ì •ì  ëª¨ë“œ)"""
        self.logger.info("ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹œì‘ (ì •ì  ëª¨ë“œ)")

        try:
            # ë°ì´í„° ê²€ì¦ ì»´í¬ë„ŒíŠ¸ (í˜„ì¬ ì‚¬ìš© ë¶ˆê°€)
            # self.components["validator"] = DataValidationChecker(self.data_dir)
            self.logger.info("âš ï¸ ë°ì´í„° ê²€ì¦ ì»´í¬ë„ŒíŠ¸ ì‚¬ìš© ë¶ˆê°€ (ëª¨ë“ˆ ëˆ„ë½)")

            # XAI ëª¨ë‹ˆí„°ë§ ì»´í¬ë„ŒíŠ¸ (ì •ì  ëª¨ë“œì—ì„œëŠ” ì„ íƒì )
            # XAIMonitoringSystem ëª¨ë“ˆì´ ëˆ„ë½ë˜ì–´ ê±´ë„ˆëœ€
            self.logger.info("âš ï¸ XAI ëª¨ë‹ˆí„°ë§ ì»´í¬ë„ŒíŠ¸ ì‚¬ìš© ë¶ˆê°€ (ëª¨ë“ˆ ëˆ„ë½)")

            # Enhanced XAI ë¶„ì„ ì»´í¬ë„ŒíŠ¸
            try:
                if XAIAnalyzer:
                    self.components["xai_analyzer"] = XAIAnalyzer(data_path=self.data_dir, output_path="data/processed")
                    self.logger.info("âœ… Enhanced XAI ë¶„ì„ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    self.logger.warning("âš ï¸ XAIAnalyzer ëª¨ë“ˆ ì‚¬ìš© ë¶ˆê°€")
            except Exception as e:
                self.logger.warning(f"âš ï¸ Enhanced XAI ë¶„ì„ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

            # Enhanced LLM Feature Extractor
            try:
                if EnhancedLLMFeatureExtractor:
                    self.components["enhanced_llm_extractor"] = EnhancedLLMFeatureExtractor()
                    self.logger.info("âœ… Enhanced LLM Feature Extractor ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    self.logger.warning("âš ï¸ EnhancedLLMFeatureExtractor ëª¨ë“ˆ ì‚¬ìš© ë¶ˆê°€")
            except Exception as e:
                self.logger.warning(f"âš ï¸ Enhanced LLM Feature Extractor ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

            # ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì»´í¬ë„ŒíŠ¸ëŠ” ì •ì  ëª¨ë“œì—ì„œ ì œì™¸
            # self.components["realtime_tester"] = RealTimeTestingSystem(self.data_dir)
            self.logger.info("âœ… ì •ì  ëª¨ë“œ: ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì»´í¬ë„ŒíŠ¸ ê±´ë„ˆëœ€")

            return True

        except Exception as e:
            self.logger.error(f"ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def _run_llm_feature_extraction(self):
        """LLM íŠ¹ì§• ì¶”ì¶œ ì‹¤í–‰"""
        self.logger.info("LLM íŠ¹ì§• ì¶”ì¶œ ì‹œì‘")
        try:
            # news_sentiment_data.csv ë¡œë“œ
            news_data_path = os.path.join(self.data_dir, "news_sentiment_data.csv")
            if not os.path.exists(news_data_path):
                self.logger.error(
                    f"ë‰´ìŠ¤ ê°ì„± ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {news_data_path}"
                )
                return False

            news_df = pd.read_csv(news_data_path)

            # LLM íŠ¹ì§• ì¶”ì¶œ
            llm_enhanced_features = extract_llm_features(news_df)

            # ì¶”ì¶œëœ íŠ¹ì§• ì €ì¥
            output_path = os.path.join(
                self.data_dir.replace("raw", "processed"), "llm_enhanced_features.csv"
            )
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            llm_enhanced_features.to_csv(output_path, index=False)

            self.logger.info(f"âœ… LLM íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ ë° ì €ì¥: {output_path}")
            return True
        except Exception as e:
            self.logger.error(f"LLM íŠ¹ì§• ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def run_system_validation(self):
        """ì‹œìŠ¤í…œ ì „ì²´ ê²€ì¦ (ê°„ì†Œí™”ëœ ë²„ì „)"""
        self.logger.info("ì‹œìŠ¤í…œ ê²€ì¦ ì‹œì‘ (ê°„ì†Œí™”ëœ ë²„ì „)")
        self.status["validation"] = "running"

        try:
            # ê¸°ë³¸ ë””ë ‰í† ë¦¬ ë° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            required_dirs = ["data/raw", "data/processed"]
            missing_dirs = []

            for dir_path in required_dirs:
                if not os.path.exists(dir_path):
                    missing_dirs.append(dir_path)
                    os.makedirs(dir_path, exist_ok=True)
                    self.logger.info(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {dir_path}")

            # ê¸°ë³¸ ë°ì´í„° íŒŒì¼ í™•ì¸
            data_files = ["realtime_results.json", "model_performance.json", "system_status.json"]
            existing_files = []

            for file_name in data_files:
                file_path = os.path.join(self.data_dir, file_name)
                if os.path.exists(file_path):
                    existing_files.append(file_name)

            self.logger.info(f"âœ… ê¸°ì¡´ ë°ì´í„° íŒŒì¼: {len(existing_files)}/{len(data_files)}ê°œ")

            self.status["validation"] = "passed"
            self.logger.info("âœ… ê°„ì†Œí™”ëœ ì‹œìŠ¤í…œ ê²€ì¦ í†µê³¼")
            return True

        except Exception as e:
            self.status["validation"] = "error"
            self.logger.error(f"ì‹œìŠ¤í…œ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def run_xai_monitoring(self):
        """XAI ëª¨ë‹ˆí„°ë§ ì‹¤í–‰ (ì •ì  ëª¨ë“œ)"""
        self.logger.info("XAI ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ì •ì  ëª¨ë“œ)")
        self.status["xai_monitoring"] = "running"

        try:
            # ì •ì  ëª¨ë“œì—ì„œëŠ” ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸
            existing_reports = [
                "model_performance.json",
                "feature_analysis_enhanced.json", 
                "model_ensemble_comparison.json"
            ]
            
            reports_found = 0
            for report in existing_reports:
                report_path = os.path.join(self.data_dir, report)
                if os.path.exists(report_path):
                    reports_found += 1
                    self.logger.info(f"âœ… ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ë°œê²¬: {report}")
            
            if reports_found > 0:
                self.status["xai_monitoring"] = "active_static"
                self.logger.info(f"âœ… XAI ëª¨ë‹ˆí„°ë§ í™œì„±í™” (ì •ì  ëª¨ë“œ) - {reports_found}ê°œ ë³´ê³ ì„œ í™•ì¸")
                return True
            else:
                self.status["xai_monitoring"] = "no_data"
                self.logger.warning("âš ï¸ XAI ë¶„ì„ ë°ì´í„° ì—†ìŒ, ê±´ë„ˆëœ€")
                return True  # ì˜¤ë¥˜ê°€ ì•„ë‹ˆë¯€ë¡œ True ë°˜í™˜

        except Exception as e:
            self.status["xai_monitoring"] = "error"
            self.logger.error(f"XAI ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def start_realtime_testing(self):
        """ì •ì  ë°ì´í„° ê²€ì¦ ì‹¤í–‰"""
        self.logger.info("ì •ì  ë°ì´í„° ê²€ì¦ ì‹œì‘")
        self.status["realtime_testing"] = "starting"

        try:
            # ì •ì  ëª¨ë“œì—ì„œëŠ” ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ í™•ì¸ ë° ê²€ì¦
            static_data_files = [
                "realtime_results.json",
                "model_performance.json",
                "validation_report.json"
            ]
            
            validation_passed = 0
            for data_file in static_data_files:
                file_path = os.path.join(self.data_dir, data_file)
                if os.path.exists(file_path):
                    try:
                        with open(file_path, 'r') as f:
                            data = json.load(f)
                        validation_passed += 1
                        self.logger.info(f"âœ… ì •ì  ë°ì´í„° ê²€ì¦ ì™„ë£Œ: {data_file}")
                    except json.JSONDecodeError:
                        self.logger.warning(f"âš ï¸ ë°ì´í„° íŒŒì¼ ì†ìƒ: {data_file}")
                else:
                    self.logger.warning(f"âš ï¸ ë°ì´í„° íŒŒì¼ ëˆ„ë½: {data_file}")
            
            if validation_passed >= 2:  # ìµœì†Œ 2ê°œ íŒŒì¼ì´ ìˆìœ¼ë©´ ì„±ê³µ
                self.status["realtime_testing"] = "static_validated"
                self.logger.info(f"âœ… ì •ì  ë°ì´í„° ê²€ì¦ ì™„ë£Œ - {validation_passed}ê°œ íŒŒì¼ í™•ì¸ë¨")
                return True
            else:
                self.status["realtime_testing"] = "insufficient_data"
                self.logger.warning("âš ï¸ ì •ì  ë°ì´í„° ë¶€ì¡±, í•˜ì§€ë§Œ ê³„ì† ì§„í–‰")
                return True  # ë°ì´í„°ê°€ ë¶€ì¡±í•´ë„ ì˜¤ë¥˜ëŠ” ì•„ë‹˜

        except Exception as e:
            self.status["realtime_testing"] = "error"
            self.logger.error(f"ì •ì  ë°ì´í„° ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def monitor_system_health(self):
        """ì‹œìŠ¤í…œ í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§"""
        while True:
            try:
                # ì „ì²´ ìƒíƒœ í‰ê°€
                healthy_components = 0
                total_components = 0

                for component, status in self.status.items():
                    if component != "overall_health":
                        total_components += 1
                        if status in ["passed", "active", "running"]:
                            healthy_components += 1

                # ì „ì²´ í—¬ìŠ¤ ìƒíƒœ ê²°ì •
                if healthy_components == total_components:
                    self.status["overall_health"] = "healthy"
                elif healthy_components > 0:
                    self.status["overall_health"] = "degraded"
                else:
                    self.status["overall_health"] = "unhealthy"

                # ìƒíƒœ ì €ì¥
                status_report = {
                    "timestamp": datetime.now().isoformat(),
                    "status": self.status,
                    "components": {
                        name: comp.__class__.__name__
                        for name, comp in self.components.items()
                    },
                }

                with open(f"{self.data_dir}/system_status.json", "w") as f:
                    json.dump(status_report, f, indent=2)

                # ìƒíƒœ ë¡œê·¸
                if self.status["overall_health"] == "healthy":
                    self.logger.info("âœ… ì‹œìŠ¤í…œ ìƒíƒœ: ì •ìƒ")
                elif self.status["overall_health"] == "degraded":
                    self.logger.warning("âš ï¸ ì‹œìŠ¤í…œ ìƒíƒœ: ì¼ë¶€ ë¬¸ì œ")
                else:
                    self.logger.error("âŒ ì‹œìŠ¤í…œ ìƒíƒœ: ë¹„ì •ìƒ")

                time.sleep(300)  # 5ë¶„ë§ˆë‹¤ ì²´í¬

            except Exception as e:
                self.logger.error(f"í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                time.sleep(60)  # ì˜¤ë¥˜ ì‹œ 1ë¶„ ëŒ€ê¸°

    def run_full_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("=== S&P500 ì´ë²¤íŠ¸ íƒì§€ ì‹œìŠ¤í…œ ì‹œì‘ ===")

        # 1. ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        if not self.initialize_components():
            return False

        # 2. LLM íŠ¹ì§• ì¶”ì¶œ (ìƒˆë¡œìš´ ë‹¨ê³„ ì¶”ê°€)
        if not self._run_llm_feature_extraction():
            self.logger.error("LLM íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨ë¡œ ì¸í•´ ì¤‘ë‹¨ë¨")
            return False

        # 3. ì‹œìŠ¤í…œ ê²€ì¦ (ê¸°ì¡´ 2ë‹¨ê³„)
        if not self.run_system_validation():
            self.logger.error("ì‹œìŠ¤í…œ ê²€ì¦ ì‹¤íŒ¨ë¡œ ì¸í•´ ì¤‘ë‹¨ë¨")
            return False

        # 4. XAI ëª¨ë‹ˆí„°ë§ ì‹¤í–‰ (ê¸°ì¡´ 3ë‹¨ê³„)
        if not self.run_xai_monitoring():
            self.logger.warning("XAI ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨, ê³„ì† ì§„í–‰")

        # 5. ì •ì  ë°ì´í„° ê²€ì¦ (ê¸°ì¡´ ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ëŒ€ì²´)
        if not self.start_realtime_testing():
            self.logger.warning("ì •ì  ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨, í•˜ì§€ë§Œ ê³„ì† ì§„í–‰")
            # ì •ì  ëª¨ë“œì—ì„œëŠ” ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨ê°€ ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ

        # 6. í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ë³„ë„ ìŠ¤ë ˆë“œ) (ê¸°ì¡´ 5ë‹¨ê³„)
        health_thread = threading.Thread(target=self.monitor_system_health)
        health_thread.daemon = True
        health_thread.start()

        self.logger.info("=== ì‹œìŠ¤í…œ ì™„ì „ ê°€ë™ ===")
        return True

    def stop_system(self):
        """ì‹œìŠ¤í…œ ì¤‘ì§€"""
        self.logger.info("ì‹œìŠ¤í…œ ì¤‘ì§€ ì‹œì‘")

        try:
            # ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì¤‘ì§€ (ì •ì  ëª¨ë“œì—ì„œëŠ” í•´ë‹¹ ì—†ìŒ)
            if "realtime_tester" in self.components:
                self.components["realtime_tester"].stop_testing()
                self.logger.info("âœ… ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì¤‘ì§€ ì™„ë£Œ")
            else:
                self.logger.info("âœ… ì •ì  ëª¨ë“œ: ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì»´í¬ë„ŒíŠ¸ ì—†ìŒ")

            # ìƒíƒœ ì—…ë°ì´íŠ¸
            self.status["realtime_testing"] = "stopped"
            self.status["overall_health"] = "stopped"

            self.logger.info("âœ… ì‹œìŠ¤í…œ ì¤‘ì§€ ì™„ë£Œ")
            return True

        except Exception as e:
            self.logger.error(f"ì‹œìŠ¤í…œ ì¤‘ì§€ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def run_enhanced_xai_analysis(self, sample_size=10):
        """Enhanced XAI ë¶„ì„ ì‹¤í–‰ (Chain-of-Thought + Attention)"""
        self.logger.info("ğŸ§  Enhanced XAI ë¶„ì„ ì‹œì‘")
        
        try:
            if "xai_analyzer" not in self.components:
                self.logger.warning("âš ï¸ XAI ë¶„ì„ ì»´í¬ë„ŒíŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return False
            
            xai_analyzer = self.components["xai_analyzer"]
            
            # Enhanced XAI ë¶„ì„ ì‹¤í–‰
            result = xai_analyzer.run_complete_analysis(
                sample_size=sample_size,
                news_file="news_sentiment_data.csv"
            )
            
            if "error" in result:
                self.logger.error(f"âŒ Enhanced XAI ë¶„ì„ ì‹¤íŒ¨: {result['error']}")
                return False
            
            # ê²°ê³¼ ë¡œê¹…
            self.logger.info(f"âœ… Enhanced XAI ë¶„ì„ ì™„ë£Œ")
            self.logger.info(f"ğŸ“Š ë¶„ì„ëœ ê¸°ì‚¬ ìˆ˜: {result.get('articles_analyzed', 0)}")
            self.logger.info(f"âœ¨ ì„±ê³µì ì¸ ë¶„ì„: {result.get('successful_analyses', 0)}")
            self.logger.info(f"ğŸ’¾ ì €ì¥ëœ íŒŒì¼: {list(result.get('saved_files', {}).keys())}")
            
            # ì‹œìŠ¤í…œ ìƒíƒœ ì—…ë°ì´íŠ¸
            self.status["enhanced_xai"] = "completed"
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Enhanced XAI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            self.status["enhanced_xai"] = "error"
            return False

    def run_enhanced_llm_extraction(self, sample_size=10):
        """Enhanced LLM íŠ¹ì„± ì¶”ì¶œ ì‹¤í–‰"""
        self.logger.info("ğŸ”¬ Enhanced LLM íŠ¹ì„± ì¶”ì¶œ ì‹œì‘")
        
        try:
            if "enhanced_llm_extractor" not in self.components:
                self.logger.warning("âš ï¸ Enhanced LLM Extractorê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return False
            
            # ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
            news_data_path = os.path.join(self.data_dir, "news_sentiment_data.csv")
            if not os.path.exists(news_data_path):
                self.logger.error(f"âŒ ë‰´ìŠ¤ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {news_data_path}")
                return False
            
            news_df = pd.read_csv(news_data_path)
            
            # ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ì€ ë°ì´í„° ì²˜ë¦¬ ë°©ì§€)
            if len(news_df) > sample_size:
                news_df = news_df.sample(n=sample_size, random_state=42)
                self.logger.info(f"ğŸ“ ë°ì´í„° ìƒ˜í”Œë§: {sample_size}ê°œ ê¸°ì‚¬ ì„ íƒ")
            
            enhanced_extractor = self.components["enhanced_llm_extractor"]
            
            # Enhanced íŠ¹ì„± ì¶”ì¶œ
            enhanced_features = enhanced_extractor.extract_enhanced_features(news_df)
            
            # ê²°ê³¼ ì €ì¥
            output_path = os.path.join(
                self.data_dir.replace("raw", "processed"), 
                "enhanced_llm_features.csv"
            )
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            enhanced_features.to_csv(output_path, index=False)
            
            # í†µê³„ ì¶œë ¥
            successful_extractions = len(enhanced_features[enhanced_features['processing_status'] == 'success'])
            self.logger.info(f"âœ… Enhanced LLM íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ")
            self.logger.info(f"ğŸ“Š ì²˜ë¦¬ëœ ê¸°ì‚¬: {len(enhanced_features)}")
            self.logger.info(f"âœ¨ ì„±ê³µì ì¸ ì¶”ì¶œ: {successful_extractions}")
            self.logger.info(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_path}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Enhanced LLM íŠ¹ì„± ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def run_full_xai_pipeline(self, sample_size=10):
        """ì „ì²´ Enhanced XAI íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("ğŸš€ ì „ì²´ Enhanced XAI íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        try:
            # 1. Enhanced LLM íŠ¹ì„± ì¶”ì¶œ
            if not self.run_enhanced_llm_extraction(sample_size=sample_size):
                self.logger.error("âŒ Enhanced LLM íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨")
                return False
            
            # 2. Enhanced XAI ë¶„ì„
            if not self.run_enhanced_xai_analysis(sample_size=sample_size):
                self.logger.error("âŒ Enhanced XAI ë¶„ì„ ì‹¤íŒ¨")
                return False
            
            self.logger.info("âœ… ì „ì²´ Enhanced XAI íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Enhanced XAI íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def get_system_status(self):
        """í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
        return {
            "status": self.status,
            "components": list(self.components.keys()),
            "timestamp": datetime.now().isoformat(),
        }


if __name__ == "__main__":
    # ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹¤í–‰
    orchestrator = SystemOrchestrator()

    if orchestrator.run_full_pipeline():
        print("ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ì‹œìŠ¤í…œ ìƒíƒœëŠ” raw_data/system_status.jsonì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")

        try:
            while True:
                time.sleep(10)
                status = orchestrator.get_system_status()
                print(f"í˜„ì¬ ìƒíƒœ: {status['status']['overall_health']}")

        except KeyboardInterrupt:
            print("\nì‹œìŠ¤í…œ ì¤‘ì§€ ì¤‘...")
            orchestrator.stop_system()
            print("ì‹œìŠ¤í…œì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("ì‹œìŠ¤í…œ ì‹œì‘ ì‹¤íŒ¨")
